{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"XFSC Specification Phase 2 The second Phase of the XFSC specification builds upon the groundwork laid in GXFS specification Phase 1 and aligns with the principles of the Gaia-X Trust Framework 22.10. The recently defined specifications and supplementary requirements apply to these specific components and are currently subject to a tendering procedure:","title":"Index"},{"location":"#xfsc-specification-phase-2","text":"The second Phase of the XFSC specification builds upon the groundwork laid in GXFS specification Phase 1 and aligns with the principles of the Gaia-X Trust Framework 22.10. The recently defined specifications and supplementary requirements apply to these specific components and are currently subject to a tendering procedure:","title":"XFSC Specification Phase 2"},{"location":"notare/notare/","text":"Software Requirements Specification for Gaia-X Federation Services Notarization API Extension 1CP. NOTARE1 Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA 1 Introduction 1.1 Document Purpose 1.2 Product Scope 1.3 Definitions, Acronyms and Abbreviations 1.4 References 1.5 Document Overview 2 Product Overview 2.1 Product Perspective 2.2 Product Functions 3.3 Product Constraints 2.4 User Classes and Characteristics 2.5 Operating Environment 2.6 User Documentation 2.7 Assumptions and Dependencies 2.8 Prioritization of System Features 3 Requirements 3.1 External Interfaces 3.1.1 User Interfaces 3.1.2 Hardware Interfaces 3.1.3 Software Interfaces 3.1.4 Communications Interfaces 3.2 Functional 3.3 Nonfunctional Requirements 3.3.1 HTTP Requirements 3.3.2 Logging Requirements 3.3.3 Performance Requirements 3.3.4 Safety Requirements 3.3.5 Security Requirements 3.3.6 Software Quality Attributes 3.3.7 Business Rules 3.4 Compliance 3.5 Design and Implementation 3.5.1 Installation 3.5.2 Configuration 3.5.3 Distribution 3.5.4 Service Meshing 3.5.5 Standard Technology 3.5.6 Metrics 3.5.7 Configurability 3.5.8 Maintainability 3.5.9 Reusability 3.5.10 Runtime Stability 3.5.11 High Availability Concepts 3.5.12 Proof of Concept 4 Verification 4.1 Core Verification Requirements 4.2 Support for Kubernetes 4.3 Functionality Acceptance Criteria Appendix A: Glossary Appendix B: Architecture List of Figures Figure 1: References Figure 2: Cooperation View List of Tables Table 1: User Classes Table 2: Priorities Table 3: Technology Stack Introduction To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD]. Document Purpose The purpose of the document is to specify the requirements of the Compliance subcomponent \"Notarization API Extension 1\" with the intention of an European wide public tender for implementing this software extension. Main audience for this document are attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide digital support for existing certification bodies within Gaia-X. Product Scope The product scope is to extend the existing component \"Notarization API\", with the following new features: Protocol agnostic issuances depending on the incoming DID and format definitions New issuance and verification protocols Business validation flow for the notary Documentation for using NOT as the compliance service for memberships Dynamic schema configuration Enrollment of organization to certain trustlists Trust verification before the issuance process with the TRAIN module Automatic Notarization Verification The product extension must include interfaces (API's) to integrate the notarization component smoothly in external software for Non-IT operator usage (e.g., lawyers, notaries, governments, certifiers ...). If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams. Definitions, Acronyms and Abbreviations Please refer to [IDM.AO] for Terminology/Glossary. References Reference Title Link Status [BDD] Getting Started with Behavior Driven Development Specflow 03-18-2023 [CloudEvents] CloudEvents Specification cloudevents.io 03-17-2023 [IDM.AO] Architecture Overview Please refer to \"annex_IDM.AO\" [IDM.TRAIN] GXFS Trust Management Infrastructure Please refer to \"annex_IDM.TRAIN\" [OpenID VCI] OpenID for Verifiable Credential Issuance OpenID VCI Spec 03-18-2023 [OpenID VP] OpenID for Verifiable Presentations OpenID VP Spec 03-18-2023 [PRD] Gaia-X Policy Rules Document Gaia-X PRD 08-01-2023 [RFC2119] Key words for use in RFCs to Indicate Requirement Levels RFC 2119 07-04-2023 [TAD] Gaia-X Architecture Document Gaia-X TAD Figure 1: References Document Overview The document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [CP.NOTAR.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [ RFC 2119 ], are written in capital letters (see also [IDM.AO]- Methodology). Product Overview Product Perspective The purpose of this product extension is to support the trust establishment with new enrollment processes. To reach this goal the software component extension should follow standard formats of credential exchange and enrollment. Therefore, this extension introduces new components. The following problems are being addressed with this extension: Interoperability with other ecosystems & future technology Trust anchor enrollment Trust verification This allows each federation to create and host their own trust anchors and policies. Next to that they can choose between multiple ecosystems. The trust verification module with TRAIN allows the relying parties to verify trust chains more easily before issuing respective certificates. The existing code base [1] MUST be reused and further improved. Other microservices MAY have different languages and architectures. [1] [https://gitlab.eclipse.org/eclipse/xfsc/not] Product Functions The product extension itself follows the microservice component design principles. The functionality is exposed per REST Service and accessible over the Network per HTTPS protocol. The component has to be installed in multi locations and SHOULD NOT be planned as a central hosted system. Therefore, it must be possible to install it within the issuer's organization domain with multiuser access capabilities. The access to the offered functionality of the component extension MUST be protected for the usage in such an environment. This includes role concepts, data storage protection and access control. The overall functionality of the product MUST be auditable (GDPR conform), which means each action MUST be documented with all context-specific information within the system. The main functionality scope of this product extension is to provide a way to enroll new issuers considering the defined policies of the Trust Framework [2] and the federation itself. It also allows Business owners to use different did-methods and be part of other ecosystems. That means each federation can create their own rulebook and allow their own ecosystems. The core functions of the product extension are: Enrollment of new issuers and authorities TRAIN validation & verification [3] [IDM.TRAIN] DID method abstraction Credential issuance & verification Automated external business validations Figure 2: Cooperation View [2] [https://docs.gaia-x.eu/policy-rules-committee/trust-framework/22.10/participant/] [3] [https://gitlab.grnet.gr/essif-lab/infrastructure/fraunhofer] Product Constraints [CP.NOTAR.E1.00000] The document IDM.AO and Core Credential Document The architecture document [IDM.AO] is an essential part of this specification and a prerequisite for understanding the context. The specifications and requirements from the Architecture Document MUST be taken into account during implementation. [CP.NOTAR.E1.00001] The product extension architecture pattern The product extension MUST follow the existing architecture pattern of the first version (see Appendix B). It MUST enhance the existing component with additional and missing features. User Classes and Characteristics User Class Description Frequency Expertise Privilege Level Product Usage Notarization Operator Notarizes given data and confirms the issuing of electronic credentials to a given DID. An operator is an employee of the notarization office. High Low High Managing Frontend Administrator Sets up the system and maintains operator identities. Low High Low Backend Maintenance Organization Business Owner / Authorization Officer Represents a participant. Low Low Low Request Frontends Table 1: User Classes Operating Environment [CP.NOTAR.E1.00002] Kubernetes Environment The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on a SCS cluster (Sovereign Cloud Stack), that will be provided by the Principal. [CP.NOTAR.E1.00003] TLS Protected Endpoints To protect the product endpoint(s), it's necessary to support a network infrastructure e.g., load balancers/proxies which MUST support TLS encryption. The encryption MUST meet the requirements listed in the chapter for security requirements. User Documentation [CP.NOTAR.E1.00004] Participant Administration Documentation The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the products from source code [CP.NOTAR.E1.00006] Participant Documentation The documentation MUST contain: Short Software Description (why and for what, when to use, how to use, where to use) Usage guide GDPR design decisions Security concept Operations concept FAQ Keyword Directory Assumptions and Dependencies [CP.NOTAR.E1.00007] TRAIN Dependencies The product extension has multiple dependencies to the TRAIN module [IDM.TRAIN]. The following parts of the product extension have a close relationship with the TRAIN module: Enrollment of new issuers Verification of verifiable presentations Prioritization of System Features Feature Priority Enrollment of new issuers and authorities 1 TRAIN validation & verification 1 DID method abstraction 2 Credential issuance & verification flow 1 Automated external business validations 2 Table 2: Priorities Please be aware that extending or contributing to the used frameworks means explicitly to actively make changes if necessary. Requirements External Interfaces User Interfaces The User Interface functionality MUST be provided to the Command Line Interface (CLI) implementers. Hardware Interfaces Not applicable. Software Interfaces [CP.NOTAR.E1.00008] OAuth2 The product internal IAM MUST support OAuth2 to grant access to the API. The product MUST be able to support the Identity Provider withinthe integration cluster. The roles used for the profile entitlement MUST be decoupled from the profile name. [CP.NOTAR.E1.00009] Database Connection The connection of the product to its database MUST be TLS encrypted or a similar encryption of the transport level. Communications Interfaces [CP.NOTAR.E1.00010] Eventing If it is required to use events within the software architecture, it is mandatory to use software abstraction according to cloud event specification [CloudEvents] for publishing and subscription. The minimal supported protocol binding MUST be HTTPS Protocol Binding [5]. [5] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/bindings/http-protocol-binding.md] [CP.NOTAR.E1.00011] Eventing Infrastructure The event broker for the eventing MUST abstract the storage and delivery infrastructure. In Kubernetes environments, the event broker MUST be uniform across all Lots by using NATS[6] and/or kNative. [6] [https://nats.io/] [CP.NOTAR.E1.00012] Notarization Request Endpoint The existing request endpoint MUST be enhanced with a new functionality to request a DID enrollment for a trustlist. The functionality of this enhancement is described in chapter 3.2 [CP.NOTAR.E.1.000014] Supported Actions: GET (view), POST (Notarization Request), PATCH (update existing Request), DELETE (Revoke existing Request) and POST for File Upload. Functional [CP.NOTAR.E1.00014] Enrollment of new issuers and authorities Description The enrollment process of new issuers is a process to set a DID and the respective configuration on a trustlist of a federation. This process can be started with the request endpoint and MUST be defined with one attribute. The request of the enrollment MUST follow the same flow as any other request. After the confirmation of the request from the notary the action / output MUST be a new entry on an existing trustlist. To add an entry on the trustlist the TRAIN enrollment module needs to be called. Constraints Own DID for issuing. DID of the organization. Database system. Interfaces TRAIN enrollment module. Database interface. Input A confirmed request record. This needs to include: DID of the organization ID of the trust list ID of the schema Metadata of the entity (to be specified further according to business analyst analysis) Legal Name Certification details Assurance Levels Types of DIDs supported Type of other digital credentials supported (example: x509) Different services offered by the organization Output A new entry in an existing trust list. Acceptance Criteria DID of the request successfully added to the trustlist. The requestor is able to issue the VC mentioned on the trustlist. [CP.NOTAR.E1.00015] TRAIN validation & verification Description The TRAIN validation service needs to be included in the process of verifying a verifiable presentation. If a requestor is showing a verifiable presentation during a task which needs to be fulfilled, the notarization service needs to validate the terms Of Use by calling the TRAIN validation module [IDM.TRAIN.00017]. This will verify if the shown verifiable presentation and the respective owner of it is on a trust list. Constraints DID of the organization. Database system. Interfaces TRAIN validation module. Input A verification with an incoming verifiable presentation. Output Verification output of the TRAIN validation module. Acceptance Criterias The terms Of Use could successfully be verified and validated. The presentation could successfully be proved cryptographically and semantically. [CP.NOTAR.E1.00016] DID method abstraction Description The SSI Issuance controller MUST be able to understand multiple DID methods and MUST also issue the Credential in the respective issuance protocol. The focus MUST lay on the DID methods EBSI, Sovrin (Indy), Web and Key. The notarization service MUST be enhanced with a connection to the EBSI ledger. Depending on the incoming request the SSI Issuance service MUST decide which credential exchange protocol [CP.NOTAR.00022] should be used. The selection of which one must be used depends on which service endpoint is available on the DID document of the requestor. The DID:Web method MUST be configurable for issuing credentials. Constraints DID of the organization. Database system. CP.NOTAR.00022 credential issuance extension Interfaces Database interface. Issuance Endpoint Input Request from the request endpoint. DID of the organization. Output / Acceptance Criterias Successful managed request. [CP.NOTAR.E1.00017] Credential Issuing extension Description The existing SSI issuance service needs to be enhanced with a new protocol to issue verifiable credentials. If a DID supports the respective endpoint the issuance service should use the OpenID for Verifiable credential issuance protocol [OpenID VCI] and the component can perform a Present Proof request before issuing defined in OpenID for Verifiable Presentations [OpenID VP]. The credential issuing is an asynchronous process which checks the database for confirmed request records in the database. All of the found confirmed records will be picked up. Within the record MUST be a linked DID of the participant, which is here used to establish a connection to the Credential Manager (OCM and PCM) of the participant. Constraints Own DID for issuing. DID of the organization. Database system. OpenID for Verifiable credential issuance. OpenID for Verifiable Presentations Interfaces Database interface. Issue Endpoint. Input A confirmed request record. Output An issued credential to the participant DID. Acceptance Criteria Credential successfully issued to participant DID. Credential has the exact type of the request context. Deletion of the request record, after successful issuing. [CP.NOTAR.E1.00018] Proof of Credentials extension Description To prove the trustworthiness of this product extension, it MUST support the OpenID for Verifiable Presentations and it MUST be configurable which proofs are fulfilled automatically (e.g., based on a configured schema). If a DID supports the respective endpoint, the SSI service should use the OpenID for Verifiable presentations protocol. In the case of a JSON-LD Presentation an extended validation MUST be supported via TRAIN [IDM.TRAIN]. After the cryptographic proofing the semantic validation MUST happen via TRAIN. This SHOULD validate the Trust against the Trust Framework and registries. Constraints Control over the Own DID. OpenID for Verifiable presentations protocol. TRAIN. Interfaces Issue Endpoint TRAIN Input Any presentation request described in OpenID for Verifiable Presentations. Output A presentation request according to OpenID for Verifiable Presentations. Acceptance Criteria The Software is able to prove the credentials of the holder. [CP.NOTAR.E1.00019] External business validations Description The notarization administrator MUST have the possibility to add an external business validation. This MUST be an API GET request to an external system to fetch data. Next to that the service needs to validate the fetched data and include them in the issuance process. The verification process should include the Gaia-X compliance service [7] to make additional checks. [7] [https://gitlab.com/gaia-x/lab/compliance/gx-compliance] Constraints DID of the organization. Database system. OpenID for Verifiable credential issuance. Interfaces / Input A confirmed request record. Output Validated data from an external system. Acceptance Criterias External data successfully fetched External data successfully verified [CP.NOTAR.E1.00020] Cloud Configuration The provider MUST support advanced cloud configuration by using Kubernetes config maps provided by HELM templates. Additionally, the provider MUST accept dynamic configuration changes over the configuration UI. [CP.NOTAR.E1.00021] Dynamic schema (profile) configuration The software extension MUST include dynamic schema configuration. For now, the credential schemas (profiles) can only be configured before starting the service. The software extension MUST include a dynamic schema configuration at run time. That means an endpoint needs to be created which can only be used by the admin of the software or the enabled notaries. For the generation of the profile the component IDM.SR should be used. Based on the different Trust anchor and credential format of the profile the schema regeneration should follow a different flow. The following schema generation flows MUST be supported: EBSI schema generation with the Trusted Schemas Registry fromb EBSI[8] IDUnion (Indy) credential schema creation and credential definition JSON-LD schema context generation and storage on IPFS [8] [https://api-pilot.ebsi.eu/docs/apis/trusted-schemas-registry/latest#/] Constraints Attributes of the schema Database system Interfaces Interface to IDM.SR Input Schema attributes Trustanchor VC Format Issuer DID Output Created profile Registered (stored) schema Acceptance Criterias Company data successfully validated [CP.NOTAR.E1.00022] Credential Issuance When a DID Document provides multiple Communication protocols like OIDC4VC, Indy AIP 1.0 and AIP 2.0, the notarization API MUST issue a credential to all of the protocols, to have a consistent set of credentials in all wallets of the user. [CP.NOTAR.E1.00023] Role Management {#cp.notar.e1.00023-role-management .unnumbered} The profiles MUST be decoupled from roles to allow and flexible management. [CP.NOTAR.E1.00024] Swagger Documentation The swagger documentation MUST be in the provided GitLab repository. [CP.NOTAR.E1.00025] Existing Schemas as Template The profile Template collects attributes for issuing a credential, but existing schemas e.g., indy schemas should be accepted as well as template. [CP.NOTAR.E1.00026] OAW Integration The API MUST be accessible for external services like OAW to support the automatic notarization and verification. [CP.NOTAR.E1.00027] Automatic rule-based Notarization The API MUST support an automatic notarization functionality with usage of TSA Policies [9]. [9] [https://gitlab.eclipse.org/eclipse/xfsc/tsa/policies] [CP.NOTAR.E1.00028] Revocation Preparation Additionally, the component MUST prepare an hash-based revocation which is calculated over the proof of the credential in the following way: For RSA signature a SHA256 hash is calculated over the entire signature in raw byte format For EC-DSA Signature the SHA256 hash is calculated over the r value of the proof signature The revocation endpoint MUST provide this calculated hash of W3C credentials[10] to an internal storage grouped by Holder DID which has an internal interface to read the hashes for later integration (later integration is out of scope for this tender). [10] [https://www.w3.org/TR/vc-data-model/] Nonfunctional Requirements HTTP Requirements [CP.NOTAR.E1.00029] HTTPS All HTTP Endpoints MUST be protected by TLS 1.2 (all protocol version numbers SHOULD be superseded by upcoming standards). Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system. [CP.NOTAR.E1.00030] HTTP Protocol Definitions All HTTP Endpoints MUST follow [RFC7231] and [RFC5789], but it MAY be chosen what of the protocols is necessary to realize the functionality. For problem reports the [RFC7807] MUST be used in combination with Standard HTTP Error Codes. Logging Requirements [CP.NOTAR.E1.00031] Data Minimization The data minimization principle is expressed in Article 5(1)(c) of the GDPR and Article 4(1)(c) of Regulation (EU) 2018/1725, which provide that personal data must be \\\"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed\\\". The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of thefollowing elements: a. node\\'s identification b. message identification c. message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review. [CP.NOTAR.E1.00032] Logging Frameworks The product MUST support logging frameworks e.g., graylog, fluentD or logstash to support logging and analysis by enterprise infrastructures. The supported framework MAY be chosen for the first version, but it MUST support potentially the most common open-source logging solutions. The final solution MUST be aligned with the other subcomponents. It MUST be sketched in the operations concept how the support of multiple solutions is given in the future. Performance Requirements [CP.NOTAR.E1.00033] Up/Down Scale All components MUST be able to scale up/down their functionality for undefined amount instances. This requires a parallel execution possibility which will be tested later on by performance tests which are defined by the test team. Safety Requirements [CP.NOTAR.E1.00034] Major Releases All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening. Security Requirements [CP.NOTAR.E1.00035] CVE Patches All software components MUST have applied CVE patches, which are available for major releases. Software Quality Attributes [CP.NOTAR.E1.00036] Software Quality Requirements All software components MUST be compliant to the requirements within the quality assurance repository [11]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology. [11] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues] Business Rules [CP.NOTAR.E1.00037] Software Consistency The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc. [CP.NOTAR.E1.00038] Cherry Picking All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow an enterprise deployment customization. Compliance [CP.NOTAR.E1.00039] GDPR Audit Logging All GDPR relevant access to personal relevant data MUST be logged for a later audit. [CP.NOTAR.E1.00040] GDPR Data Processing Is it necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable. Design and Implementation Installation [CP.NOTAR.E1.00041] Helm/Argo CD Deployment All installations MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a ARGO CD Pipeline defined in the integration repository [12]. [12] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Configuration [CP.NOTAR.E1.00042] Configuration All components MUST support one of the major configuration formats (yaml, Json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged. Distribution [CP.NOTAR.E1.00043] Helm Repositories All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [13]. [13] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml] [CP.NOTAR.E1.00044] Istio Resources Additionally, the Charts MUST provide Istio Resource (eg., Authorization Rules, Virtual Services []{#3.5.4_Service_Meshing .anchor}etc.) following the integration pattern specified in the gxfs-integration repo [14]. [14] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Service Meshing [CP.NOTAR.E1.00045] Istio Support All HELM charts MUST be provided with Istio support aligned together with the project team. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment. Standard Technology [CP.NOTAR.E1.00046] Default Toolstack Each development MUST consider the following standard technologies if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React [15] Ingress Controller Nginx API Testing Postman (manual) Kubernetes 1.26+ API Design OpenAPI Table 3: Technology Stack ###### [15] [https://react-bootstrap.github.io/] The technology stack is mandatory to avoid integration impact. Metrics [CP.NOTAR.E1.00047] Open Telemetry Support All helm charts/services MUST provide metrics endpoints in opentelemetry [16] format. [16] [https://opentelemetry.io/docs/] Configurability [CP.NOTAR.E1.00048] Configuration Profiles Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening [CP.NOTAR.E1.00049] Secret References in Helm Charts The configuration secrets within Helm Charts MUST use secretRefs to support external []{#3.5.8_Maintainability .anchor}Secretmanagement. Clear text secrets within the Helm Charts are not allowed. Maintainability [CP.NOTAR.E1.00050] Micro Service Architecture For a better scale out, maintainability and decentralization, the product architecture MUST have a micro service architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement it. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment). [CP.NOTAR.E1.00051] Domain Driven Design To support the micro service architecture within the maintainability, it MUST be declared a domain model before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers. Reusability [CP.NOTAR.E1.00052] Enterprise Environments All components MUST be reusable in different enterprise environments by customization and white labeling. Means all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.) Runtime Stability [CP.NOTAR.E1.00053] Readiness Checkups All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: A unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state High Availability Concepts [CP.NOTAR.E1.00054] Redundant Deployment Each deployment MUST be configured for a minimum fault tolerance of 2 instances. Proof of Concept [CP.NOTAR.E1.00055] Architecture Changes All Architecture Changes MUST be aligned with the Principal before implementation. Verification Core Verification Requirements All listed verification items/criteria must be fulfilled by a demonstration of the implementation within the provided Kubernetes environment. [CP.NOTAR.E1.00056] Kubernetes Deployment If the verification is related to software components, it must be deployed in a Kubernetes test cluster and the components must be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration. Support for Kubernetes [CP.NOTAR.E1.00057] Eventing All eventings must be demonstrated on basis of cloud events specifications [CloudEvents] together with the kNative [17] broker in a Kubernetes environment. [17] [https://knative.dev/docs/eventing/] [CP.NOTAR.E1.00058] Config Map Support Each service must be demonstrated up and running in Kubernetes, configured by config maps. [CP.NOTAR.E1.00059] Helm Installation The service installation MUST be demonstrated during HELM install. [CP.NOTAR.E1.00060] ArgoCD Integration The helm chart MUST be able to install inside of ArgoCD. This includes the usage of the postgres hooks [18] and the providing of usable values.yaml(s) for all developed services. [18] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration/-/tree/main/helm/charts/postgresql-hook] [CP.NOTAR.E1.00061] SCS Environment All HELM installations MUST run on SCS (Sovereign Cloud Stack). The [final acceptance]{.underline} demonstration cannot be realized on azure, google cloud etc. Functionality Acceptance Criteria Additionally, to the acceptance requirements in the functional description, the following criteria must be considered. [CP.NOTAR.E1.00062] Credential Issuance When a DID Document contains multiple Protocols, all of the used wallets contain the issued credential after an notarization. [CP.NOTAR.E1.00063] Trustlist Integration The enrollments MUST be visible over the DNS resolvers and the trustlists MUST be updated with the new notarized items. Additionally, the notarization MUST provide the trust list endpoints and DNS zones per public profile with the notarization DID Document. [CP.NOTAR.E1.00064] Decision Engine Integration It MUST demonstrate that the notarization API can automatically make decisions for issuing based on OAW and TSA policy outcomes. Note: OAW and TSA MUST be integrated in the demonstration to show the functionality. The environment for these components will be provided by the principal for testing. Appendix A: Glossary For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO]. Appendix B: Architecture","title":"Notarization API Extension"},{"location":"notare/notare/#software-requirements-specification-for-gaia-x-federation-services-notarization-api-extension-1cp-notare1","text":"Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA","title":"Software Requirements Specification  for  Gaia-X Federation Services Notarization API Extension 1CP.  NOTARE1"},{"location":"notare/notare/#1-introduction","text":"","title":"1  Introduction"},{"location":"notare/notare/#11-document-purpose","text":"","title":"1.1  Document Purpose"},{"location":"notare/notare/#12-product-scope","text":"","title":"1.2  Product Scope"},{"location":"notare/notare/#13-definitions-acronyms-and-abbreviations","text":"","title":"1.3  Definitions, Acronyms and Abbreviations"},{"location":"notare/notare/#14-references","text":"","title":"1.4  References"},{"location":"notare/notare/#15-document-overview","text":"","title":"1.5  Document Overview"},{"location":"notare/notare/#2-product-overview","text":"","title":"2  Product Overview"},{"location":"notare/notare/#21-product-perspective","text":"","title":"2.1  Product Perspective"},{"location":"notare/notare/#22-product-functions","text":"","title":"2.2  Product Functions"},{"location":"notare/notare/#33-product-constraints","text":"","title":"3.3  Product Constraints"},{"location":"notare/notare/#24-user-classes-and-characteristics","text":"","title":"2.4  User Classes and Characteristics"},{"location":"notare/notare/#25-operating-environment","text":"","title":"2.5  Operating Environment"},{"location":"notare/notare/#26-user-documentation","text":"","title":"2.6  User Documentation"},{"location":"notare/notare/#27-assumptions-and-dependencies","text":"","title":"2.7  Assumptions and Dependencies"},{"location":"notare/notare/#28-prioritization-of-system-features","text":"","title":"2.8  Prioritization of System Features"},{"location":"notare/notare/#3-requirements","text":"","title":"3  Requirements"},{"location":"notare/notare/#31-external-interfaces","text":"","title":"3.1  External Interfaces"},{"location":"notare/notare/#311-user-interfaces","text":"","title":"3.1.1  User Interfaces"},{"location":"notare/notare/#312-hardware-interfaces","text":"","title":"3.1.2  Hardware Interfaces"},{"location":"notare/notare/#313-software-interfaces","text":"","title":"3.1.3  Software Interfaces"},{"location":"notare/notare/#314-communications-interfaces","text":"","title":"3.1.4  Communications Interfaces"},{"location":"notare/notare/#32-functional","text":"","title":"3.2  Functional"},{"location":"notare/notare/#33-nonfunctional-requirements","text":"","title":"3.3  Nonfunctional Requirements"},{"location":"notare/notare/#331-http-requirements","text":"","title":"3.3.1  HTTP Requirements"},{"location":"notare/notare/#332-logging-requirements","text":"","title":"3.3.2  Logging Requirements"},{"location":"notare/notare/#333-performance-requirements","text":"","title":"3.3.3  Performance Requirements"},{"location":"notare/notare/#334-safety-requirements","text":"","title":"3.3.4  Safety Requirements"},{"location":"notare/notare/#335-security-requirements","text":"","title":"3.3.5  Security Requirements"},{"location":"notare/notare/#336-software-quality-attributes","text":"","title":"3.3.6  Software Quality Attributes"},{"location":"notare/notare/#337-business-rules","text":"","title":"3.3.7  Business Rules"},{"location":"notare/notare/#34-compliance","text":"","title":"3.4  Compliance"},{"location":"notare/notare/#35-design-and-implementation","text":"","title":"3.5  Design and Implementation"},{"location":"notare/notare/#351-installation","text":"","title":"3.5.1  Installation"},{"location":"notare/notare/#352-configuration","text":"","title":"3.5.2  Configuration"},{"location":"notare/notare/#353-distribution","text":"","title":"3.5.3  Distribution"},{"location":"notare/notare/#354-service-meshing","text":"","title":"3.5.4  Service Meshing"},{"location":"notare/notare/#355-standard-technology","text":"","title":"3.5.5  Standard Technology"},{"location":"notare/notare/#356-metrics","text":"","title":"3.5.6  Metrics"},{"location":"notare/notare/#357-configurability","text":"","title":"3.5.7  Configurability"},{"location":"notare/notare/#358-maintainability","text":"","title":"3.5.8  Maintainability"},{"location":"notare/notare/#359-reusability","text":"","title":"3.5.9  Reusability"},{"location":"notare/notare/#3510-runtime-stability","text":"","title":"3.5.10 Runtime Stability"},{"location":"notare/notare/#3511-high-availability-concepts","text":"","title":"3.5.11 High Availability Concepts"},{"location":"notare/notare/#3512-proof-of-concept","text":"","title":"3.5.12 Proof of Concept"},{"location":"notare/notare/#4-verification","text":"","title":"4  Verification"},{"location":"notare/notare/#41-core-verification-requirements","text":"","title":"4.1  Core Verification Requirements"},{"location":"notare/notare/#42-support-for-kubernetes","text":"","title":"4.2  Support for Kubernetes"},{"location":"notare/notare/#43-functionality-acceptance-criteria","text":"Appendix A: Glossary Appendix B: Architecture","title":"4.3  Functionality Acceptance Criteria"},{"location":"notare/notare/#list-of-figures","text":"Figure 1: References Figure 2: Cooperation View","title":"List of Figures"},{"location":"notare/notare/#list-of-tables","text":"Table 1: User Classes Table 2: Priorities Table 3: Technology Stack","title":"List of Tables"},{"location":"notare/notare/#introduction","text":"To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD].","title":"Introduction"},{"location":"notare/notare/#document-purpose","text":"The purpose of the document is to specify the requirements of the Compliance subcomponent \"Notarization API Extension 1\" with the intention of an European wide public tender for implementing this software extension. Main audience for this document are attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide digital support for existing certification bodies within Gaia-X.","title":"Document Purpose"},{"location":"notare/notare/#product-scope","text":"The product scope is to extend the existing component \"Notarization API\", with the following new features: Protocol agnostic issuances depending on the incoming DID and format definitions New issuance and verification protocols Business validation flow for the notary Documentation for using NOT as the compliance service for memberships Dynamic schema configuration Enrollment of organization to certain trustlists Trust verification before the issuance process with the TRAIN module Automatic Notarization Verification The product extension must include interfaces (API's) to integrate the notarization component smoothly in external software for Non-IT operator usage (e.g., lawyers, notaries, governments, certifiers ...). If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams.","title":"Product Scope"},{"location":"notare/notare/#definitions-acronyms-and-abbreviations","text":"Please refer to [IDM.AO] for Terminology/Glossary.","title":"Definitions, Acronyms and Abbreviations"},{"location":"notare/notare/#references","text":"Reference Title Link Status [BDD] Getting Started with Behavior Driven Development Specflow 03-18-2023 [CloudEvents] CloudEvents Specification cloudevents.io 03-17-2023 [IDM.AO] Architecture Overview Please refer to \"annex_IDM.AO\" [IDM.TRAIN] GXFS Trust Management Infrastructure Please refer to \"annex_IDM.TRAIN\" [OpenID VCI] OpenID for Verifiable Credential Issuance OpenID VCI Spec 03-18-2023 [OpenID VP] OpenID for Verifiable Presentations OpenID VP Spec 03-18-2023 [PRD] Gaia-X Policy Rules Document Gaia-X PRD 08-01-2023 [RFC2119] Key words for use in RFCs to Indicate Requirement Levels RFC 2119 07-04-2023 [TAD] Gaia-X Architecture Document Gaia-X TAD","title":"References"},{"location":"notare/notare/#figure-1-references","text":"","title":"Figure 1: References"},{"location":"notare/notare/#document-overview","text":"The document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [CP.NOTAR.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [ RFC 2119 ], are written in capital letters (see also [IDM.AO]- Methodology).","title":"Document Overview"},{"location":"notare/notare/#product-overview","text":"","title":"Product Overview"},{"location":"notare/notare/#product-perspective","text":"The purpose of this product extension is to support the trust establishment with new enrollment processes. To reach this goal the software component extension should follow standard formats of credential exchange and enrollment. Therefore, this extension introduces new components. The following problems are being addressed with this extension: Interoperability with other ecosystems & future technology Trust anchor enrollment Trust verification This allows each federation to create and host their own trust anchors and policies. Next to that they can choose between multiple ecosystems. The trust verification module with TRAIN allows the relying parties to verify trust chains more easily before issuing respective certificates. The existing code base [1] MUST be reused and further improved. Other microservices MAY have different languages and architectures.","title":"Product Perspective"},{"location":"notare/notare/#1-httpsgitlabeclipseorgeclipsexfscnot","text":"","title":"[1] [https://gitlab.eclipse.org/eclipse/xfsc/not]"},{"location":"notare/notare/#product-functions","text":"The product extension itself follows the microservice component design principles. The functionality is exposed per REST Service and accessible over the Network per HTTPS protocol. The component has to be installed in multi locations and SHOULD NOT be planned as a central hosted system. Therefore, it must be possible to install it within the issuer's organization domain with multiuser access capabilities. The access to the offered functionality of the component extension MUST be protected for the usage in such an environment. This includes role concepts, data storage protection and access control. The overall functionality of the product MUST be auditable (GDPR conform), which means each action MUST be documented with all context-specific information within the system. The main functionality scope of this product extension is to provide a way to enroll new issuers considering the defined policies of the Trust Framework [2] and the federation itself. It also allows Business owners to use different did-methods and be part of other ecosystems. That means each federation can create their own rulebook and allow their own ecosystems. The core functions of the product extension are: Enrollment of new issuers and authorities TRAIN validation & verification [3] [IDM.TRAIN] DID method abstraction Credential issuance & verification Automated external business validations","title":"Product Functions"},{"location":"notare/notare/#figure-2-cooperation-view","text":"","title":"Figure 2: Cooperation View"},{"location":"notare/notare/#2-httpsdocsgaia-xeupolicy-rules-committeetrust-framework2210participant","text":"","title":"[2] [https://docs.gaia-x.eu/policy-rules-committee/trust-framework/22.10/participant/]"},{"location":"notare/notare/#3httpsgitlabgrnetgressif-labinfrastructurefraunhofer","text":"","title":"[3][https://gitlab.grnet.gr/essif-lab/infrastructure/fraunhofer]"},{"location":"notare/notare/#product-constraints","text":"","title":"Product Constraints"},{"location":"notare/notare/#cpnotare100000-the-document-idmao-and-core-credential-document","text":"The architecture document [IDM.AO] is an essential part of this specification and a prerequisite for understanding the context. The specifications and requirements from the Architecture Document MUST be taken into account during implementation.","title":"[CP.NOTAR.E1.00000] The document IDM.AO and Core Credential Document"},{"location":"notare/notare/#cpnotare100001-the-product-extension-architecture-pattern","text":"The product extension MUST follow the existing architecture pattern of the first version (see Appendix B). It MUST enhance the existing component with additional and missing features.","title":"[CP.NOTAR.E1.00001] The product extension architecture pattern"},{"location":"notare/notare/#user-classes-and-characteristics","text":"User Class Description Frequency Expertise Privilege Level Product Usage Notarization Operator Notarizes given data and confirms the issuing of electronic credentials to a given DID. An operator is an employee of the notarization office. High Low High Managing Frontend Administrator Sets up the system and maintains operator identities. Low High Low Backend Maintenance Organization Business Owner / Authorization Officer Represents a participant. Low Low Low Request Frontends","title":"User Classes and Characteristics"},{"location":"notare/notare/#table-1-user-classes","text":"","title":"Table 1: User Classes"},{"location":"notare/notare/#operating-environment","text":"","title":"Operating Environment"},{"location":"notare/notare/#cpnotare100002-kubernetes-environment","text":"The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on a SCS cluster (Sovereign Cloud Stack), that will be provided by the Principal.","title":"[CP.NOTAR.E1.00002] Kubernetes Environment"},{"location":"notare/notare/#cpnotare100003-tls-protected-endpoints","text":"To protect the product endpoint(s), it's necessary to support a network infrastructure e.g., load balancers/proxies which MUST support TLS encryption. The encryption MUST meet the requirements listed in the chapter for security requirements.","title":"[CP.NOTAR.E1.00003] TLS Protected Endpoints"},{"location":"notare/notare/#user-documentation","text":"","title":"User Documentation"},{"location":"notare/notare/#cpnotare100004-participant-administration-documentation","text":"The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the products from source code","title":"[CP.NOTAR.E1.00004] Participant Administration Documentation"},{"location":"notare/notare/#cpnotare100006-participant-documentation","text":"The documentation MUST contain: Short Software Description (why and for what, when to use, how to use, where to use) Usage guide GDPR design decisions Security concept Operations concept FAQ Keyword Directory","title":"[CP.NOTAR.E1.00006] Participant Documentation"},{"location":"notare/notare/#assumptions-and-dependencies","text":"","title":"Assumptions and Dependencies"},{"location":"notare/notare/#cpnotare100007-train-dependencies","text":"The product extension has multiple dependencies to the TRAIN module [IDM.TRAIN]. The following parts of the product extension have a close relationship with the TRAIN module: Enrollment of new issuers Verification of verifiable presentations","title":"[CP.NOTAR.E1.00007] TRAIN Dependencies"},{"location":"notare/notare/#prioritization-of-system-features","text":"Feature Priority Enrollment of new issuers and authorities 1 TRAIN validation & verification 1 DID method abstraction 2 Credential issuance & verification flow 1 Automated external business validations 2","title":"Prioritization of System Features"},{"location":"notare/notare/#table-2-priorities","text":"Please be aware that extending or contributing to the used frameworks means explicitly to actively make changes if necessary.","title":"Table 2: Priorities"},{"location":"notare/notare/#requirements","text":"","title":"Requirements"},{"location":"notare/notare/#external-interfaces","text":"","title":"External Interfaces"},{"location":"notare/notare/#user-interfaces","text":"The User Interface functionality MUST be provided to the Command Line Interface (CLI) implementers.","title":"User Interfaces"},{"location":"notare/notare/#hardware-interfaces","text":"Not applicable.","title":"Hardware Interfaces"},{"location":"notare/notare/#software-interfaces","text":"","title":"Software Interfaces"},{"location":"notare/notare/#cpnotare100008-oauth2","text":"The product internal IAM MUST support OAuth2 to grant access to the API. The product MUST be able to support the Identity Provider withinthe integration cluster. The roles used for the profile entitlement MUST be decoupled from the profile name.","title":"[CP.NOTAR.E1.00008] OAuth2"},{"location":"notare/notare/#cpnotare100009-database-connection","text":"The connection of the product to its database MUST be TLS encrypted or a similar encryption of the transport level.","title":"[CP.NOTAR.E1.00009] Database Connection"},{"location":"notare/notare/#communications-interfaces","text":"","title":"Communications Interfaces"},{"location":"notare/notare/#cpnotare100010-eventing","text":"If it is required to use events within the software architecture, it is mandatory to use software abstraction according to cloud event specification [CloudEvents] for publishing and subscription. The minimal supported protocol binding MUST be HTTPS Protocol Binding [5].","title":"[CP.NOTAR.E1.00010] Eventing"},{"location":"notare/notare/#5-httpsgithubcomcloudeventsspecblobv102cloudeventsbindingshttp-protocol-bindingmd","text":"","title":"[5] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/bindings/http-protocol-binding.md]"},{"location":"notare/notare/#cpnotare100011-eventing-infrastructure","text":"The event broker for the eventing MUST abstract the storage and delivery infrastructure. In Kubernetes environments, the event broker MUST be uniform across all Lots by using NATS[6] and/or kNative.","title":"[CP.NOTAR.E1.00011] Eventing Infrastructure"},{"location":"notare/notare/#6-httpsnatsio","text":"","title":"[6] [https://nats.io/]"},{"location":"notare/notare/#cpnotare100012-notarization-request-endpoint","text":"The existing request endpoint MUST be enhanced with a new functionality to request a DID enrollment for a trustlist. The functionality of this enhancement is described in chapter 3.2 [CP.NOTAR.E.1.000014] Supported Actions: GET (view), POST (Notarization Request), PATCH (update existing Request), DELETE (Revoke existing Request) and POST for File Upload.","title":"[CP.NOTAR.E1.00012] Notarization Request Endpoint"},{"location":"notare/notare/#functional","text":"","title":"Functional"},{"location":"notare/notare/#cpnotare100014-enrollment-of-new-issuers-and-authorities","text":"","title":"[CP.NOTAR.E1.00014] Enrollment of new issuers and authorities"},{"location":"notare/notare/#description","text":"The enrollment process of new issuers is a process to set a DID and the respective configuration on a trustlist of a federation. This process can be started with the request endpoint and MUST be defined with one attribute. The request of the enrollment MUST follow the same flow as any other request. After the confirmation of the request from the notary the action / output MUST be a new entry on an existing trustlist. To add an entry on the trustlist the TRAIN enrollment module needs to be called.","title":" Description "},{"location":"notare/notare/#constraints","text":"Own DID for issuing. DID of the organization. Database system.","title":" Constraints "},{"location":"notare/notare/#interfaces","text":"TRAIN enrollment module. Database interface.","title":" Interfaces "},{"location":"notare/notare/#input","text":"A confirmed request record. This needs to include: DID of the organization ID of the trust list ID of the schema Metadata of the entity (to be specified further according to business analyst analysis) Legal Name Certification details Assurance Levels Types of DIDs supported Type of other digital credentials supported (example: x509) Different services offered by the organization","title":" Input "},{"location":"notare/notare/#output","text":"A new entry in an existing trust list.","title":" Output "},{"location":"notare/notare/#acceptance-criteria","text":"DID of the request successfully added to the trustlist. The requestor is able to issue the VC mentioned on the trustlist.","title":" Acceptance Criteria "},{"location":"notare/notare/#cpnotare100015-train-validation-verification","text":"","title":"[CP.NOTAR.E1.00015] TRAIN validation &amp; verification"},{"location":"notare/notare/#description_1","text":"The TRAIN validation service needs to be included in the process of verifying a verifiable presentation. If a requestor is showing a verifiable presentation during a task which needs to be fulfilled, the notarization service needs to validate the terms Of Use by calling the TRAIN validation module [IDM.TRAIN.00017]. This will verify if the shown verifiable presentation and the respective owner of it is on a trust list.","title":" Description "},{"location":"notare/notare/#constraints_1","text":"DID of the organization. Database system.","title":" Constraints "},{"location":"notare/notare/#interfaces_1","text":"TRAIN validation module.","title":" Interfaces "},{"location":"notare/notare/#input_1","text":"A verification with an incoming verifiable presentation.","title":" Input "},{"location":"notare/notare/#output_1","text":"Verification output of the TRAIN validation module.","title":" Output "},{"location":"notare/notare/#acceptance-criterias","text":"The terms Of Use could successfully be verified and validated. The presentation could successfully be proved cryptographically and semantically.","title":" Acceptance Criterias "},{"location":"notare/notare/#cpnotare100016-did-method-abstraction","text":"","title":"[CP.NOTAR.E1.00016] DID method abstraction"},{"location":"notare/notare/#description_2","text":"The SSI Issuance controller MUST be able to understand multiple DID methods and MUST also issue the Credential in the respective issuance protocol. The focus MUST lay on the DID methods EBSI, Sovrin (Indy), Web and Key. The notarization service MUST be enhanced with a connection to the EBSI ledger. Depending on the incoming request the SSI Issuance service MUST decide which credential exchange protocol [CP.NOTAR.00022] should be used. The selection of which one must be used depends on which service endpoint is available on the DID document of the requestor. The DID:Web method MUST be configurable for issuing credentials.","title":" Description "},{"location":"notare/notare/#constraints_2","text":"DID of the organization. Database system. CP.NOTAR.00022 credential issuance extension","title":" Constraints "},{"location":"notare/notare/#interfaces_2","text":"Database interface. Issuance Endpoint","title":" Interfaces "},{"location":"notare/notare/#input_2","text":"Request from the request endpoint. DID of the organization.","title":" Input "},{"location":"notare/notare/#output_2","text":"/","title":" Output "},{"location":"notare/notare/#acceptance-criterias_1","text":"Successful managed request.","title":" Acceptance Criterias "},{"location":"notare/notare/#cpnotare100017-credential-issuing-extension","text":"","title":"[CP.NOTAR.E1.00017] Credential Issuing extension"},{"location":"notare/notare/#description_3","text":"The existing SSI issuance service needs to be enhanced with a new protocol to issue verifiable credentials. If a DID supports the respective endpoint the issuance service should use the OpenID for Verifiable credential issuance protocol [OpenID VCI] and the component can perform a Present Proof request before issuing defined in OpenID for Verifiable Presentations [OpenID VP]. The credential issuing is an asynchronous process which checks the database for confirmed request records in the database. All of the found confirmed records will be picked up. Within the record MUST be a linked DID of the participant, which is here used to establish a connection to the Credential Manager (OCM and PCM) of the participant.","title":" Description "},{"location":"notare/notare/#constraints_3","text":"Own DID for issuing. DID of the organization. Database system. OpenID for Verifiable credential issuance. OpenID for Verifiable Presentations","title":" Constraints "},{"location":"notare/notare/#interfaces_3","text":"Database interface. Issue Endpoint.","title":" Interfaces "},{"location":"notare/notare/#input_3","text":"A confirmed request record.","title":" Input "},{"location":"notare/notare/#output_3","text":"An issued credential to the participant DID.","title":" Output "},{"location":"notare/notare/#acceptance-criteria_1","text":"Credential successfully issued to participant DID. Credential has the exact type of the request context. Deletion of the request record, after successful issuing.","title":" Acceptance Criteria "},{"location":"notare/notare/#cpnotare100018-proof-of-credentials-extension","text":"","title":"[CP.NOTAR.E1.00018] Proof of Credentials extension"},{"location":"notare/notare/#description_4","text":"To prove the trustworthiness of this product extension, it MUST support the OpenID for Verifiable Presentations and it MUST be configurable which proofs are fulfilled automatically (e.g., based on a configured schema). If a DID supports the respective endpoint, the SSI service should use the OpenID for Verifiable presentations protocol. In the case of a JSON-LD Presentation an extended validation MUST be supported via TRAIN [IDM.TRAIN]. After the cryptographic proofing the semantic validation MUST happen via TRAIN. This SHOULD validate the Trust against the Trust Framework and registries.","title":" Description "},{"location":"notare/notare/#constraints_4","text":"Control over the Own DID. OpenID for Verifiable presentations protocol. TRAIN.","title":" Constraints "},{"location":"notare/notare/#interfaces_4","text":"Issue Endpoint TRAIN","title":" Interfaces "},{"location":"notare/notare/#input_4","text":"Any presentation request described in OpenID for Verifiable Presentations.","title":" Input "},{"location":"notare/notare/#output_4","text":"A presentation request according to OpenID for Verifiable Presentations.","title":" Output "},{"location":"notare/notare/#acceptance-criteria_2","text":"The Software is able to prove the credentials of the holder.","title":" Acceptance Criteria "},{"location":"notare/notare/#cpnotare100019-external-business-validations","text":"","title":"[CP.NOTAR.E1.00019] External business validations"},{"location":"notare/notare/#description_5","text":"The notarization administrator MUST have the possibility to add an external business validation. This MUST be an API GET request to an external system to fetch data. Next to that the service needs to validate the fetched data and include them in the issuance process. The verification process should include the Gaia-X compliance service [7] to make additional checks.","title":" Description "},{"location":"notare/notare/#7-httpsgitlabcomgaia-xlabcompliancegx-compliance","text":"","title":"[7] [https://gitlab.com/gaia-x/lab/compliance/gx-compliance]"},{"location":"notare/notare/#constraints_5","text":"DID of the organization. Database system. OpenID for Verifiable credential issuance.","title":" Constraints "},{"location":"notare/notare/#interfaces_5","text":"/","title":" Interfaces "},{"location":"notare/notare/#input_5","text":"A confirmed request record.","title":" Input "},{"location":"notare/notare/#output_5","text":"Validated data from an external system.","title":" Output "},{"location":"notare/notare/#acceptance-criterias_2","text":"External data successfully fetched External data successfully verified","title":" Acceptance Criterias "},{"location":"notare/notare/#cpnotare100020-cloud-configuration","text":"The provider MUST support advanced cloud configuration by using Kubernetes config maps provided by HELM templates. Additionally, the provider MUST accept dynamic configuration changes over the configuration UI.","title":"[CP.NOTAR.E1.00020] Cloud Configuration"},{"location":"notare/notare/#cpnotare100021-dynamic-schema-profile-configuration","text":"The software extension MUST include dynamic schema configuration. For now, the credential schemas (profiles) can only be configured before starting the service. The software extension MUST include a dynamic schema configuration at run time. That means an endpoint needs to be created which can only be used by the admin of the software or the enabled notaries. For the generation of the profile the component IDM.SR should be used. Based on the different Trust anchor and credential format of the profile the schema regeneration should follow a different flow. The following schema generation flows MUST be supported: EBSI schema generation with the Trusted Schemas Registry fromb EBSI[8] IDUnion (Indy) credential schema creation and credential definition JSON-LD schema context generation and storage on IPFS","title":"[CP.NOTAR.E1.00021] Dynamic schema (profile) configuration"},{"location":"notare/notare/#8-httpsapi-pilotebsieudocsapistrusted-schemas-registrylatest","text":"","title":"[8] [https://api-pilot.ebsi.eu/docs/apis/trusted-schemas-registry/latest#/]"},{"location":"notare/notare/#constraints_6","text":"Attributes of the schema Database system","title":" Constraints "},{"location":"notare/notare/#interfaces_6","text":"Interface to IDM.SR","title":" Interfaces "},{"location":"notare/notare/#input_6","text":"Schema attributes Trustanchor VC Format Issuer DID","title":" Input "},{"location":"notare/notare/#output_6","text":"Created profile Registered (stored) schema","title":" Output "},{"location":"notare/notare/#acceptance-criterias_3","text":"Company data successfully validated","title":" Acceptance Criterias "},{"location":"notare/notare/#cpnotare100022-credential-issuance","text":"When a DID Document provides multiple Communication protocols like OIDC4VC, Indy AIP 1.0 and AIP 2.0, the notarization API MUST issue a credential to all of the protocols, to have a consistent set of credentials in all wallets of the user.","title":"[CP.NOTAR.E1.00022] Credential Issuance"},{"location":"notare/notare/#cpnotare100023-role-management-cpnotare100023-role-management-unnumbered","text":"The profiles MUST be decoupled from roles to allow and flexible management.","title":"[CP.NOTAR.E1.00023] Role Management {#cp.notar.e1.00023-role-management .unnumbered}"},{"location":"notare/notare/#cpnotare100024-swagger-documentation","text":"The swagger documentation MUST be in the provided GitLab repository.","title":"[CP.NOTAR.E1.00024] Swagger Documentation"},{"location":"notare/notare/#cpnotare100025-existing-schemas-as-template","text":"The profile Template collects attributes for issuing a credential, but existing schemas e.g., indy schemas should be accepted as well as template.","title":"[CP.NOTAR.E1.00025] Existing Schemas as Template"},{"location":"notare/notare/#cpnotare100026-oaw-integration","text":"The API MUST be accessible for external services like OAW to support the automatic notarization and verification.","title":"[CP.NOTAR.E1.00026] OAW Integration"},{"location":"notare/notare/#cpnotare100027-automatic-rule-based-notarization","text":"The API MUST support an automatic notarization functionality with usage of TSA Policies [9].","title":"[CP.NOTAR.E1.00027] Automatic rule-based Notarization"},{"location":"notare/notare/#9-httpsgitlabeclipseorgeclipsexfsctsapolicies","text":"","title":"[9] [https://gitlab.eclipse.org/eclipse/xfsc/tsa/policies]"},{"location":"notare/notare/#cpnotare100028-revocation-preparation","text":"Additionally, the component MUST prepare an hash-based revocation which is calculated over the proof of the credential in the following way: For RSA signature a SHA256 hash is calculated over the entire signature in raw byte format For EC-DSA Signature the SHA256 hash is calculated over the r value of the proof signature The revocation endpoint MUST provide this calculated hash of W3C credentials[10] to an internal storage grouped by Holder DID which has an internal interface to read the hashes for later integration (later integration is out of scope for this tender).","title":"[CP.NOTAR.E1.00028] Revocation Preparation"},{"location":"notare/notare/#10-httpswwww3orgtrvc-data-model","text":"","title":"[10] [https://www.w3.org/TR/vc-data-model/]"},{"location":"notare/notare/#nonfunctional-requirements","text":"","title":"Nonfunctional Requirements"},{"location":"notare/notare/#http-requirements","text":"","title":"HTTP Requirements"},{"location":"notare/notare/#cpnotare100029-https","text":"All HTTP Endpoints MUST be protected by TLS 1.2 (all protocol version numbers SHOULD be superseded by upcoming standards). Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system.","title":"[CP.NOTAR.E1.00029] HTTPS"},{"location":"notare/notare/#cpnotare100030-http-protocol-definitions","text":"All HTTP Endpoints MUST follow [RFC7231] and [RFC5789], but it MAY be chosen what of the protocols is necessary to realize the functionality. For problem reports the [RFC7807] MUST be used in combination with Standard HTTP Error Codes.","title":"[CP.NOTAR.E1.00030] HTTP Protocol Definitions"},{"location":"notare/notare/#logging-requirements","text":"","title":"Logging Requirements"},{"location":"notare/notare/#cpnotare100031-data-minimization","text":"The data minimization principle is expressed in Article 5(1)(c) of the GDPR and Article 4(1)(c) of Regulation (EU) 2018/1725, which provide that personal data must be \\\"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed\\\". The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of thefollowing elements: a. node\\'s identification b. message identification c. message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review.","title":"[CP.NOTAR.E1.00031] Data Minimization"},{"location":"notare/notare/#cpnotare100032-logging-frameworks","text":"The product MUST support logging frameworks e.g., graylog, fluentD or logstash to support logging and analysis by enterprise infrastructures. The supported framework MAY be chosen for the first version, but it MUST support potentially the most common open-source logging solutions. The final solution MUST be aligned with the other subcomponents. It MUST be sketched in the operations concept how the support of multiple solutions is given in the future.","title":"[CP.NOTAR.E1.00032] Logging Frameworks"},{"location":"notare/notare/#performance-requirements","text":"","title":"Performance Requirements"},{"location":"notare/notare/#cpnotare100033-updown-scale","text":"All components MUST be able to scale up/down their functionality for undefined amount instances. This requires a parallel execution possibility which will be tested later on by performance tests which are defined by the test team.","title":"[CP.NOTAR.E1.00033] Up/Down Scale"},{"location":"notare/notare/#safety-requirements","text":"","title":"Safety Requirements"},{"location":"notare/notare/#cpnotare100034-major-releases","text":"All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening.","title":"[CP.NOTAR.E1.00034] Major Releases"},{"location":"notare/notare/#security-requirements","text":"","title":"Security Requirements"},{"location":"notare/notare/#cpnotare100035-cve-patches","text":"All software components MUST have applied CVE patches, which are available for major releases.","title":"[CP.NOTAR.E1.00035] CVE Patches"},{"location":"notare/notare/#software-quality-attributes","text":"","title":"Software Quality Attributes"},{"location":"notare/notare/#cpnotare100036-software-quality-requirements","text":"All software components MUST be compliant to the requirements within the quality assurance repository [11]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology.","title":"[CP.NOTAR.E1.00036] Software Quality Requirements"},{"location":"notare/notare/#11-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesquality-assurance-issues","text":"","title":"[11] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues]"},{"location":"notare/notare/#business-rules","text":"","title":"Business Rules"},{"location":"notare/notare/#cpnotare100037-software-consistency","text":"The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc.","title":"[CP.NOTAR.E1.00037] Software Consistency"},{"location":"notare/notare/#cpnotare100038-cherry-picking","text":"All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow an enterprise deployment customization.","title":"[CP.NOTAR.E1.00038] Cherry Picking"},{"location":"notare/notare/#compliance","text":"","title":"Compliance"},{"location":"notare/notare/#cpnotare100039-gdpr-audit-logging","text":"All GDPR relevant access to personal relevant data MUST be logged for a later audit.","title":"[CP.NOTAR.E1.00039] GDPR Audit Logging"},{"location":"notare/notare/#cpnotare100040-gdpr-data-processing","text":"Is it necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable.","title":"[CP.NOTAR.E1.00040] GDPR Data Processing"},{"location":"notare/notare/#design-and-implementation","text":"","title":"Design and Implementation"},{"location":"notare/notare/#installation","text":"","title":"Installation"},{"location":"notare/notare/#cpnotare100041-helmargo-cd-deployment","text":"All installations MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a ARGO CD Pipeline defined in the integration repository [12].","title":"[CP.NOTAR.E1.00041] Helm/Argo CD Deployment"},{"location":"notare/notare/#12-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[12] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"notare/notare/#configuration","text":"","title":"Configuration"},{"location":"notare/notare/#cpnotare100042-configuration","text":"All components MUST support one of the major configuration formats (yaml, Json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged.","title":"[CP.NOTAR.E1.00042] Configuration"},{"location":"notare/notare/#distribution","text":"","title":"Distribution"},{"location":"notare/notare/#cpnotare100043-helm-repositories","text":"All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [13].","title":"[CP.NOTAR.E1.00043] Helm Repositories"},{"location":"notare/notare/#13-httpsgitlabcomapiv4projects41175300packageshelmintegrationindexyaml","text":"","title":"[13] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml]"},{"location":"notare/notare/#cpnotare100044-istio-resources","text":"Additionally, the Charts MUST provide Istio Resource (eg., Authorization Rules, Virtual Services []{#3.5.4_Service_Meshing .anchor}etc.) following the integration pattern specified in the gxfs-integration repo [14].","title":"[CP.NOTAR.E1.00044] Istio Resources"},{"location":"notare/notare/#14-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[14] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"notare/notare/#service-meshing","text":"","title":"Service Meshing"},{"location":"notare/notare/#cpnotare100045-istio-support","text":"All HELM charts MUST be provided with Istio support aligned together with the project team. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment.","title":"[CP.NOTAR.E1.00045] Istio Support"},{"location":"notare/notare/#standard-technology","text":"","title":"Standard Technology"},{"location":"notare/notare/#cpnotare100046-default-toolstack","text":"Each development MUST consider the following standard technologies if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React [15] Ingress Controller Nginx API Testing Postman (manual) Kubernetes 1.26+ API Design OpenAPI","title":"[CP.NOTAR.E1.00046] Default Toolstack"},{"location":"notare/notare/#table-3-technology-stack","text":"###### [15] [https://react-bootstrap.github.io/] The technology stack is mandatory to avoid integration impact.","title":"Table 3: Technology Stack"},{"location":"notare/notare/#metrics","text":"","title":"Metrics"},{"location":"notare/notare/#cpnotare100047-open-telemetry-support","text":"All helm charts/services MUST provide metrics endpoints in opentelemetry [16] format.","title":"[CP.NOTAR.E1.00047] Open Telemetry Support"},{"location":"notare/notare/#16-httpsopentelemetryiodocs","text":"","title":"[16] [https://opentelemetry.io/docs/]"},{"location":"notare/notare/#configurability","text":"","title":"Configurability"},{"location":"notare/notare/#cpnotare100048-configuration-profiles","text":"Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening","title":"[CP.NOTAR.E1.00048] Configuration Profiles"},{"location":"notare/notare/#cpnotare100049-secret-references-in-helm-charts","text":"The configuration secrets within Helm Charts MUST use secretRefs to support external []{#3.5.8_Maintainability .anchor}Secretmanagement. Clear text secrets within the Helm Charts are not allowed.","title":"[CP.NOTAR.E1.00049] Secret References in Helm Charts"},{"location":"notare/notare/#maintainability","text":"","title":"Maintainability"},{"location":"notare/notare/#cpnotare100050-micro-service-architecture","text":"For a better scale out, maintainability and decentralization, the product architecture MUST have a micro service architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement it. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment).","title":"[CP.NOTAR.E1.00050] Micro Service Architecture"},{"location":"notare/notare/#cpnotare100051-domain-driven-design","text":"To support the micro service architecture within the maintainability, it MUST be declared a domain model before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers.","title":"[CP.NOTAR.E1.00051] Domain Driven Design"},{"location":"notare/notare/#reusability","text":"","title":"Reusability"},{"location":"notare/notare/#cpnotare100052-enterprise-environments","text":"All components MUST be reusable in different enterprise environments by customization and white labeling. Means all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.)","title":"[CP.NOTAR.E1.00052] Enterprise Environments"},{"location":"notare/notare/#runtime-stability","text":"","title":"Runtime Stability"},{"location":"notare/notare/#cpnotare100053-readiness-checkups","text":"All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: A unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state","title":"[CP.NOTAR.E1.00053] Readiness Checkups"},{"location":"notare/notare/#high-availability-concepts","text":"","title":"High Availability Concepts"},{"location":"notare/notare/#cpnotare100054-redundant-deployment","text":"Each deployment MUST be configured for a minimum fault tolerance of 2 instances.","title":"[CP.NOTAR.E1.00054] Redundant Deployment"},{"location":"notare/notare/#proof-of-concept","text":"","title":"Proof of Concept"},{"location":"notare/notare/#cpnotare100055-architecture-changes","text":"All Architecture Changes MUST be aligned with the Principal before implementation.","title":"[CP.NOTAR.E1.00055] Architecture Changes"},{"location":"notare/notare/#verification","text":"","title":"Verification"},{"location":"notare/notare/#core-verification-requirements","text":"All listed verification items/criteria must be fulfilled by a demonstration of the implementation within the provided Kubernetes environment.","title":"Core Verification Requirements"},{"location":"notare/notare/#cpnotare100056-kubernetes-deployment","text":"If the verification is related to software components, it must be deployed in a Kubernetes test cluster and the components must be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration.","title":"[CP.NOTAR.E1.00056] Kubernetes Deployment"},{"location":"notare/notare/#support-for-kubernetes","text":"","title":"Support for Kubernetes"},{"location":"notare/notare/#cpnotare100057-eventing","text":"All eventings must be demonstrated on basis of cloud events specifications [CloudEvents] together with the kNative [17] broker in a Kubernetes environment.","title":"[CP.NOTAR.E1.00057] Eventing"},{"location":"notare/notare/#17-httpsknativedevdocseventing","text":"","title":"[17] [https://knative.dev/docs/eventing/]"},{"location":"notare/notare/#cpnotare100058-config-map-support","text":"Each service must be demonstrated up and running in Kubernetes, configured by config maps.","title":"[CP.NOTAR.E1.00058] Config Map Support"},{"location":"notare/notare/#cpnotare100059-helm-installation","text":"The service installation MUST be demonstrated during HELM install.","title":"[CP.NOTAR.E1.00059] Helm Installation"},{"location":"notare/notare/#cpnotare100060-argocd-integration","text":"The helm chart MUST be able to install inside of ArgoCD. This includes the usage of the postgres hooks [18] and the providing of usable values.yaml(s) for all developed services.","title":"[CP.NOTAR.E1.00060] ArgoCD Integration"},{"location":"notare/notare/#18-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesgxfs-integration-treemainhelmchartspostgresql-hook","text":"","title":"[18] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration/-/tree/main/helm/charts/postgresql-hook]"},{"location":"notare/notare/#cpnotare100061-scs-environment","text":"All HELM installations MUST run on SCS (Sovereign Cloud Stack). The [final acceptance]{.underline} demonstration cannot be realized on azure, google cloud etc.","title":"[CP.NOTAR.E1.00061] SCS Environment"},{"location":"notare/notare/#functionality-acceptance-criteria","text":"Additionally, to the acceptance requirements in the functional description, the following criteria must be considered.","title":"Functionality Acceptance Criteria"},{"location":"notare/notare/#cpnotare100062-credential-issuance","text":"When a DID Document contains multiple Protocols, all of the used wallets contain the issued credential after an notarization.","title":"[CP.NOTAR.E1.00062] Credential Issuance"},{"location":"notare/notare/#cpnotare100063-trustlist-integration","text":"The enrollments MUST be visible over the DNS resolvers and the trustlists MUST be updated with the new notarized items. Additionally, the notarization MUST provide the trust list endpoints and DNS zones per public profile with the notarization DID Document.","title":"[CP.NOTAR.E1.00063] Trustlist Integration"},{"location":"notare/notare/#cpnotare100064-decision-engine-integration","text":"It MUST demonstrate that the notarization API can automatically make decisions for issuing based on OAW and TSA policy outcomes. Note: OAW and TSA MUST be integrated in the demonstration to show the functionality. The environment for these components will be provided by the principal for testing.","title":"[CP.NOTAR.E1.00064] Decision Engine Integration"},{"location":"notare/notare/#appendix-a-glossary","text":"For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO].","title":"Appendix A: Glossary"},{"location":"notare/notare/#appendix-b-architecture","text":"","title":"Appendix B: Architecture"},{"location":"ocme1/ocme1/","text":"Software Requirements Specification for Gaia-XFederation Services Organization Credential ManagerExtension 1IDM.OCM.E1 Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons Attribution 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA 1 Introduction 1.1 Document Purpose 1.2 Product Scope 1.3 Definitions, Acronyms and Abbreviations 1.4 References 1.5 Document Overview 2 Product Overview 2.1 Product Perspective 2.2 Product Functions 2.3 Product Constraints 2.4 User Classes and Characteristics 2.5 Operating Environment 2.6 User Documentation 2.7 Assumptions and Dependencies 3 Requirements 3.1 External Interfaces 3.1.1 Software Interfaces 3.1.2 Communications Interfaces 3.1.2.1 General 3.1.2.2 SSI Abstraction Service 3.2 Functional 3.2.1 Connection Manager 3.3 Nonfunctional Requirements 3.3.1 Performance Requirements 3.3.2 Safety Requirements 3.3.3 Security Requirements 3.3.4 Software Quality Attributes 3.3.5 Business Rules 3.4 Compliance 3.5 Design and Implementation 3.5.1 Installation 3.5.2 Configuration 3.5.3 Distribution 3.5.4 Service Meshing 3.5.5 Standard Technology 3.5.6 Metrics 3.5.7 Configurability 3.5.8 Maintainability 3.5.9 Reusability 3.5.10 Runtime Stability 3.5.11 High Availability Concepts 3.5.12 Proof of Concept 4 System Features 4.1 Attestation Management Service 4.1.1 Description 4.1.2 Functional Requirements 4.2 Connection Management Service 4.2.1 Description 4.2.2 Functional Requirements 4.3 Schema Management Service 4.3.1 Description 4.3.2 Functional Requirements 4.4 Credential Management Service 4.4.1 Description 4.4.2 Functional Requirements 4.5 SSI Abstraction Services 4.5.1 Description 5 Verification 5.1 Acceptance Criteria 5.1.1 General 5.1.2 Product Constraints 5.1.3 User Documentation 5.1.4 SSI Abstraction 5.1.5 Connection Manager 5.1.6 Attestation Manager 5.1.7 Schema Manager 5.1.8 Credential Manager 5.1.9 Proof Manager 5.2 Support for Kubernetes Appendix A: Glossary Appendix B: Architecture List of Figures Figure 1: Architecture (semi-transparent boxes are out of scope) List of Tables Table 1: References Table 2: Technology Stack Table 3: Functional Requirements Attestation Manager Table 4: Functional Requirements Connection Manager Table 5: Functional Requirements Schema Manager Table 6: Functional Requirements Credential Manager Introduction To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD]. Document Purpose The purpose of this document is to specify the requirements of the Identity Management and Trust Subcomponent \"Organization Credential Manager Extension 1\" with the intention of a European wide public tender for implementing this software extension. Main audience for this document are attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide digital support for existing certification bodies within Gaia-X. Product Scope The purpose of this extension is to provide changes to the OCM components to enhance the OCM in its functionality and adopt the latest Gaia-X requirements. The Organization Credential Manager Extension 1 (OCM.E1) enhances the participant's interaction with the SSI-based ecosystem in a trustful and secure environment. This comprises the utilization of the participants digital identity for different functionalities: Extended management of secure and trustable connections with other parties Refreshing and Revocation of verifiable credentials from attesting parties (e.g., Gaia-X Membership credential from a verified notary) Utilization of AIP v2.0 alongside AIP v1.0 by updating the AFJ Framework Provision of verifiable Public Profile The described functionalities allow other components in the Identity Management context to interact with the SSI-based ecosystem. If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams. Definitions, Acronyms and Abbreviations The IDM and Trust Architecture Overview Document [IDM.AO] MUST be considered and applied as the core technical concept that also includes the Terminology and Glossary. References Reference Title Link Status [AFJ] Aries Framework JavaScript GitHub - Aries Framework JavaScript [BDD] Behavior Driven Development SpecFlow BDD Status: 03-18-2023 [DID] Decentralized Identifiers (DIDs) v1.0 W3C - DID Status: 03-18-2021 [IDM.AO] Gaia-X WP1 Identity & Trust Architecture Overview Please refer to annex \"annex_GX_IDM_AO\" [OCM] Gaia-X Organization Credential Manager Document Please refer to \"annex_Organization Credential Manager\" document [PRD] Gaia-X Policy Rules Document Gaia-X PRD Status: 08-01-2023 [RFC 2119] Key words for use in RFCs to Indicate Requirement Levels RFC 2119 [TAD] Gaia-X Architecture Document Gaia-X TAD [TDR] Gaia-X Federation Services Technical Development Requirements Please refer to annex \"GXFS_Technical_Development_Requirements\" [TSA] Gaia-X Trusted Services API Document Please refer to \"annex_Trusted Services API\" document Table 1: References Document Overview This document describes the product perspective, functions, and constraints. Furthermore, it lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [RFC 2119], are written in capital letters (see also [IDM.AO] - Methodology). Product Overview Product Perspective Please refer to [TDR]. Product Functions The functions of the Organization Credential Manager Extension 1 (OCM.E1) component are provided as a runtime component and MUST expose endpoints as REST services and made accessible over the network using encrypted connections (e.g., HTTPS). The scalability of these services MUST be taken into consideration using well-known and tested concepts like a microservice based architecture and load balancing. Since this component is the very core of trust relationships between participants in the Gaia- X ecosystem, security measures MUST be in place accordingly. This includes the protection of exposed service endpoints, data storage protection and access control. The storage for cryptographic material MUST be particularly secured, e.g., by integrating Hardware Security Modules. The overall functionality of the OCM.E1 component and exposed services MUST be auditable (in compliance with GDPR). Figure 1: Architecture (semi-transparent boxes are out of scope) Please be aware that the semi-transparent boxes are out of scope for further modification but not out of scope for refactoring and problem resolving. The core functions of the OCM.E1 are: Extended managing of trusted connections between entities(Connections in this context are private, secured, and persistentchannels between entities) Blocking of Connections Handling of blocked connections Handling of verifiable credentials exchanges Refreshing of credentials of participants principals, assets etc. Revocation of credentials of participants, principals, assets etc. Handling of revoked credentials Providing publicly visible and verifiable service endpoints within OCM DID Document Configuration of Public Custom Endpoints Configuration of Private Custom Endpoints (with DID-Auth/OIDC) Configuration of Endpoint Mappings to internal/external functionality The updated SSI Abstraction Service provides the required SSI functionality to the other components but is not aware of the Gaia-X context. In this document, the context-specific aspects and interaction with Trust Services are implemented in the specific components: Connection Manager Attestation Manager Product Constraints Please refer to [OCM] section 2.3 and [TSA] section 2.3. The intended environment that is used to support the OCM.E1 product is bound to Aries protocols. User Classes and Characteristics Please refer to [OCM] section 2.4. Operating Environment [IDM.OCM.E1.00000] Kubernetes Environment The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on the provided SCS cluster (Sovereign Cloud Stack), that will be provided by the Client. User Documentation [IDM.OCM.E1.00001] Participant Administration Documentation The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the products from source code [IDM.OCM.E1.00002] Participant Documentation The documentation MUST contain: Short Software Description (why and for what, when to use, how to use, where to use) Usage guide GDPR design decisions Security concept Operations concept FAQ Keyword Directory Assumptions and Dependencies An understanding of the overall Gaia-X architecture and philosophy is necessary as well as understanding of the OCM architecture and implementation details. Please refer to [TAD], [PRD] and [OCM]. Attendees of the public tender MUST assume responsibility of: The existing code and improvements upon the existing code base (semi-transparent boxes listed on Figure 1) Extending or contributing to the used frameworks in order to provision a way in which realization of the requirements can be achieved Updating dependencies to the latest stable version Refactoring the Software Architecture Please be aware that extending or contributing to the used frameworks means explicitly to actively make or drive changes if necessary. Driving or making changes could be: creating git issues, discussing with framework contributors and maintainers, making changes in the Codebase. Requirements External Interfaces Software Interfaces General [IDM.OCM.E1.00003] General Operation Requirements Every component must be able to run as a container. For scalable deployment e.g., a helm chart must be provided. If database connections are used, it must provide options to run the container \"stand-alone\", e.g., in-memory and with an external, configurable database. Communications Interfaces General [IDM.OCM.E1.00004] Event Handling A lot of services within the OCM are publishing and receiving events, events are related to the scope of SSI for the different protocol flows. The way to publish and subscribe these events must be consistent throughout the functionality of the OCM.E1. SSI Abstraction Service [IDM.OCM.E1.00005] AIP v2.0 support The current implementation uses version 1.0 of the Aries JavaScript Framework. In order to support AIP v2.0 the SSI Abstraction Service MUST implement the latest stable version of Aries Framework JavaScript [1] [AFJ] and handle the necessary changes to the other services accordingly. [1] [https://github.com/hyperledger/aries-framework-javascript] Functional Connection Manager [IDM.OCM.E1.00006] Block Connection The Connection Manager must provide a Block Connection endpoint. The endpoint should accept either connection ID or DID. It should delete the connection from the SSI Abstraction service and mark it as 'blocked' in the Connection Manager. [IDM.OCM.E1.00007] Refuse blocked connections The Connection Manager must refuse connections if they match the connection ID or DID of a connection in the database, which has been marked as 'blocked'. The response of an unsuccessful connection in this case should include the reason for refusal in the response message. [IDM.OCM.E1.00008] Auto-accept Connections to Self The Connection Manager must automatically accept connections if they match the DID of the OCM. [IDM.OCM.E1.00009] Trusted Connection to Self The Connection Manager must mark connections as \"trusted\" if they match the DID of the OCM. [IDM.OCM.E1.00010] TSA Acception The Connection Manager MUST use TSA to accept/block connections automatically according to the incoming DID. [IDM.OCM.E1.00011] Connection List Endpoint The Connection Manager MUST provide an Endpoint to List all existing connections. Attestation Manager [IDM.OCM.E1.00012] Responsibilities of components The Attestation Manager is currently responsible for the operations on schemas, credential definitions and credentials. It MUST be separated into two distinct components - Schema manager, which handles schema and credential definition operations, and Credential Manager, which handles credential operations. [IDM.OCM.E1.00013] Endpoints for Credential Requests/Proposals The attestation manager MUST provide an endpoint which delivers open credential offerings and credential requests. Schema Manager [IDM.OCM.E1.00014] Schemas and Credential Definitions The Schema Manager MUST implement all necessary schema and credential definition operations, including but not limited to the current endpoints in the Attestation Manager of the OCM, responsible for schema and credential definition operations. Credential Manager [IDM.OCM.E1.00015] Credentials The Credential Manager MUST implement all necessary credential operations, including but not limited to the current endpoints in the Attestation Manager of the OCM, responsible for issuing and other operations with credentials. [IDM.OCM.E1.00016] Credential Revocation The Credential Manager MUST provide a Revoke Credential endpoint. [IDM.OCM.E1.00017] Auto-Reissued Credential Ability for auto-reissuing of a VC MUST be provided. [IDM.OCM.E1.00018] Credential Auto-Revocation The Credential Manager provides Automated Revocation of Credentials, based on the expiration date (if specified), as well as additional parameters describing whether the specific credential should be automatically revoked. [IDM.OCM.E1.00019] Credential Refreshing Depending on the autoReissued value of the credential, the Credential Manager reissues the credential with a new expiration date. The refresh option is included in the credential, which would allow the holder to refresh the credential before creating a verifiable presentation. [IDM.OCM.E1.00020] Auto-accept Self-issued Credentials The Credential Manager must automatically accept Verifiable Credentials that have been issued by the OCM over a DIDComm connection with itself (self-issuing). Proof Manager [IDM.OCM.E1.00021] JSON-LD Mapping When a presentation is made, the presentation can be mapped to a prepared JSON-LD. Common Enhancements [IDM.OCM.E1.00022] Custom Service Endpoint Configuration The OCM MUST support the configuration of custom endpoints which are visible in the DID Documents Service Endpoint Section ([DID] Section 5.4). It MUST be possible to define either private or public endpoints secured by DID Auth and OIDC, which are configurable in a OCM config. [IDM.OCM.E1.00023] DID Configuration Provision The OCM MUST provide to a configured URL an DID Configuration according to the Identity Foundation specification [2]. [2] [https://identity.foundation/specs/did-configuration/] [IDM.OCM.E1.00024] DID Document Resolving The DID Document of the OCM MUST be resolvable by the Universal Resolver and it MUST contain all key material used by the OCM including all endpoints following this service configuration format by enhancing the W3C spec [3]: { id: {idName} type: {typeName}, accept: \\[\"didcomm/v2\",\"didcomm/v1\",{otherProtocols}\\], serviceEndpoint:\\[\"https://...\"\\] } [3] [https://www.w3.org/TR/did-core/#example-usage-of-the-service-property] [IDM.OCM.E1.00025] Event Restructuring The current structure contains a structure which uses partially NATS Events and partially Rest API calls of the underlying Aries Extensions, but in cause of a micro service approach the entire structure MUST be reorganized for NATS eventing to clean up the communication between the components e.g., \"Aries Event Extension\". [IDM.OCM.E1.00026] Multi Tenancy The component MUST support multi tenancy with possibility to scale down to zero. [IDM.OCM.E1.00027] Selective Disclosure JWT The component MUST support Selective Disclosure JWT described in the specification [4]. [4] [https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/] Nonfunctional Requirements Performance Requirements [IDM.OCM.E1.00028] Up/Down Scale All components MUST be able to scale up/down their functionality for undefined amount instances. This requires a parallel execution possibility which will be tested later on by performance tests which are defined by the test team. [IDM.OCM.E1.00029] Performance by Design The product SHOULD be designed and implemented in a way that the implementation is non- blocking and performance oriented. It SHOULD be a microservice architecture, but it MAY follow other concepts. The decision MUST be documented. Safety Requirements [IDM.OCM.E1.00030] Major Releases All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening. Security Requirements [IDM.OCM.E1.00031] CVE Patches All software components MUST have applied CVE patches, which are available for major releases. Software Quality Attributes [IDM.OCM.E1.00032] Software Quality Requirements All software components MUST be compliant to the requirements within the quality assurance repository [5]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology. [5] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues] [IDM.OCM.E1.00033] Descriptive Logging Descriptive logging of key points in the code MUST be implemented. For the purpose of proper monitoring logs MUST be included in all potential failing points in the functions of the code, as well as all major steps of successful operations. Business Rules [IDM.OCM.E1.00034] Software Consistency The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc. [IDM.OCM.E1.00035] Cherry Picking All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow an enterprise deployment customization. Compliance [IDM.OCM.E1.00036] GDPR Audit Logging All GDPR relevant access to personal relevant data MUST be logged for a later audit. [IDM.OCM.E1.00037] GDPR Data Processing Is it necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable. Design and Implementation Installation [IDM.OCM.E1.00038] Helm/Argo CD Deployment All installations MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a ARGO CD Pipeline defined in the gxfs-integration repository [6]. [6] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Configuration [IDM.OCM.E1.00039] Configuration All components MUST support one of the major configuration formats (yaml, json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged. Distribution [IDM.OCM.E1.00040] Helm Repositories All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [7]. [7] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml] [IDM.OCM.E1.00041] Istio Resources Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc. ) following the integration pattern specified in the gxfs-integration repo [8]. [8] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Service Meshing [IDM.OCM.E1.00042] Istio Support All HELM charts MUST be provided with Istio support aligned together with the project team. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment. Standard Technology [IDM.OCM.E1.00043] Default Toolstack Each development MUST consider the following standard technologies, if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React [9] Ingress Controller Nginx API Testing Postman (manual) API Design OpenAPI Kubernetes v1.26+ Table 2: Technology Stack [9] [https://react-bootstrap.github.io/] The technology stack is mandatory to avoid integration impact. Metrics [IDM.OCM.E1.00044] Opentelemtry Support All helm charts/services MUST provide metrics endpoints in opentelemetry [10] format. [10] [https://opentelemetry.io/docs/] Configurability [IDM.OCM.E1.00045] Configuration Profiles Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening [IDM.OCM.E1.00046] Secret References in Helm Charts The configuration secrets within Helm Charts MUST use secretRefs to support external Secretmanagement. Clear text secrets within the Helm Charts are not allowed. Maintainability [IDM.OCM.E1.00047] Micro Service Architecture For a better scale out, maintainability and decentralization, the product architecture MUST have a micro service architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement it. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment). [IDM.OCM.E1.00048] Domain Driven Design To support the micro service architecture within the maintainability, it MUST be declared a domain model before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers. Reusability [IDM.OCM.E1.00049] Enterprise Environments All components MUST be reusable in different enterprise environments by customization and whitelabeling. This means all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.) Runtime Stability [IDM.OCM.E1.00050] Readiness Checkups All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: An unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state High Availability Concepts [IDM.OCM.E1.00051] Redundant Deployment Each deployment MUST be configured for a minimum fault tolerance of 2 instances. Proof of Concept [IDM.OCM.E1.00052] Architecture Changes All Architecture Changes MUST be aligned with the Client before implementation. System Features Attestation Management Service Attestation Management Service Description The Attestation Management Service should separate the functionalities regarding credentials, schemas and credential definitions in two distinct components that handle credentials, and schemas and credential definitions respectively. Attestation Management Service Functional Requirements Legacy - Responsibilities of components - Endpoints for Credential Requests/Proposals Table 3: Functional Requirements Attestation Manager Connection Management Service Connection Management Service Description The Connection Management Service should maintain the existing Connection Manager functionality and additionally handle all the requirements regarding the blocked connections, which includes the blocking and unblocking of a connection based on a common identifier (an identifier that is not defined per connection, but is shared between different connections to the same Participant), as well as subsequent interactions with the blocked connection. Connection Management Service Functional Requirements Endpoints -Block Connection Functions - Refuse blocked connections - Auto-accept Connections to Self - Trusted Connection to Self Table 4: Functional Requirements Connection Manager Schema Management Service Schema Management Service Description The Schema Management service is responsible for utilizing the existing schema and credential definition functionality of the existing Attestation Manager ([OCM] Section 4.5). Schema Management Service Functional Requirements Legacy -Schemas and Credential Definitions Table 5: Functional Requirements Schema Manager Credential Management Service Credential Management Service Description The Credential Management Service is responsible for utilizing the existing credential functionality of the Attestation Manager ([OCM] Section 4.5). It should also be responsible for the credential revocation and refreshing of credentials, as well as all needed additional functionalities for automatic refreshing and revocation management. Credential Management Service Functional Requirements Endpoints -Credential Revocation Functions -Auto-Reissued Credential -Credential Auto-Revocation -Credential Refreshing -Auto-accept Self-issued Legacy -Credentials Table 6: Functional Requirements Credential Manager SSI Abstraction Services SSI Abstraction Service Description The SSI Abstraction Service ([OCM] Section 4.6) is currently employing the Aries JavaScript Framework at its core and provides its functionality to the other components. The package version is at 0.1.0 and should be updated to the latest stable version, as well the Aries rest extension that provides access to the agent via REST endpoints. It should be able to accommodate the desired functional requirements of both [OCM] and OCM.E1. SSI Abstraction Service Verification All listed verification items/criterias, must be fulfilled by a demonstration of the implementation within the Kubernetes environment. [IDM.OCM.E1.00053] Automated Integration Tests Current Automation Suite MUST be extended and updated accordingly. Verification All listed verification items/criterias, must be fulfilled by a demonstration of the implementation within the Kubernetes environment. [IDM.OCM.E1.00053] Automated Integration Tests Current Automation Suite MUST be extended and updated accordingly. Acceptance Criteria General - Verification [IDM.OCM.E1.00054] General Operation Requirements Every component is demonstrated to be able to run as a container and functioning helm charts are provided. [IDM.OCM.E1.00055] Event Handling Previously used events are not disrupted or malfunctioning, and newly created ones are demonstrated or through the functions they enable it is implied that they are properly functioning. Product Constraints - Verification [IDM.OCM.E1.00056] Microservice Approach The Services interact with each other through standard APIs and protocols and are deployed as microservices. User Documentation - Verification [IDM.OCM.E1.00057] Documentation Update The current documentation is updated and enhanced, and the new services and functions are added to the existing documentation or in a newly created one if it is needed. SSI Abstraction [IDM.OCM.E1.00058] AIP v2.0 support The SSI abstraction service's core ([AFJ] ) MUST be updated to the latest stable version (for the purposes of this iteration) and provides AIP v2.0 protocols. Connection Manager - Verification [IDM.OCM.E1.00059] Block Connection The blocked connection is discoverable through the [OCM] List Connection API endpoint and is displayed as 'blocked'. [IDM.OCM.E1.00060] Refuse blocked connections Any further interactions through a blocked connection (e.g., proof request, issue credential, etc.) are demonstrated as unavailable and the response returned from the respective endpoint is unsuccessful. [IDM.OCM.E1.00061] Auto-accept Connections to Self The OCM automatically accepts connections with itself. [IDM.OCM.E1.00062] Trusted Connection to Self DIDComm Connections that are between the OCM and itself are always by configuration marked as \"trusted\". [IDM.OCM.E1.00063] Policy Based Acception Connections are accepted on the basis of a policy. Attestation Manager - Verification [IDM.OCM.E1.00064] Responsibilities of components The Attestation Manager no longer exists, but its functionality is split into the Schema and Credential Managers. Schema Manager - Verification [IDM.OCM.E1.00065] Schemas and Credential Definitions The Schema Manager is shown to be responsible for all schema operations, previously existent on the Attestation Manager Service. Credential Manager - Verification [IDM.OCM.E1.00066] Credentials The Credential Manager is shown to be responsible for all credential operations, previously existent on the Attestation Manager Service. [IDM.OCM.E1.00067] Get Credentials The OCM endpoint delivers all credentials of the wallet. [IDM.OCM.E1.00068] Credential Revocation The Credential Manager successfully performs revocation of Verifiable Credentials. [IDM.OCM.E1.00069] Auto-Reissued Credential In the stored data of the Verifiable Credential, a field for autoReissuance (not bound to the exact mention of its name) is present. [IDM.OCM.E1.00070] Credential Auto-Revocation The Credential Manager is able to successfully revoke a Verifiable Credential once the expiration date attribute's value has been reached. This should be done for all stored Verifiable Credentials. [IDM.OCM.E1.00071] Credential Refreshing Depending on the autoReissued value of the credential database entry, the Credential Manager successfully reissues a Verifiable Credential if autoReissued's condition is met and does not do so if the condition is not met. [IDM.OCM.E1.00072] Auto-accept Self-issued Credentials Credentials issued by the OCM to itself are automatically accepted. Proof Manager - Verification [IDM.OCM.E1.00073] JSON-LD Mapping When a presentation is made, the presentation can be mapped to a prepared JSON-LD. Support for Kubernetes [IDM.OCM.E1.00074] Eventing All eventings MUST be demonstrated on basis of cloud events specifications [Cloud.Events] together with the kNative [11] broker in a Kubernetes environment. [11] [https://knative.dev/docs/eventing/] [IDM.OCM.E1.00075] Config Map Support Each service must be demonstrated up and running in Kubernetes, configured by config maps. [IDM.OCM.E1.00076] Helm Installation The service installation MUST be demonstrated during HELM install. [IDM.OCM.E1.00077] ArgoCD Integration The helm chart MUST be able to install inside of AgroCD. This includes the usage of the postgres hooks [12] and the providing of usable values.yaml(s) for all developed services. [12] [https://gitlab.eclipse.org/eclipse/xfsc/integration/-/tree/main/helm/charts/postgresql-hook] [IDM.OCM.E1.00078] SCS Environment All HELM installations MUST run on SCS (Sovereign Cloud Stack). The final acceptance demonstration cannot be realized on azure, google cloud etc. Appendix A: Glossary For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO] Appendix B: Architecture (semi-transparent boxes are out of scope)","title":"Organization Credential Manager Extension"},{"location":"ocme1/ocme1/#software-requirements-specification-for-gaia-xfederation-services-organization-credential-managerextension-1idmocme1","text":"Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons Attribution 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA","title":"Software Requirements Specification  for  Gaia-XFederation Services Organization Credential ManagerExtension 1IDM.OCM.E1"},{"location":"ocme1/ocme1/#1-introduction","text":"","title":"1  Introduction"},{"location":"ocme1/ocme1/#11-document-purpose","text":"","title":"1.1  Document Purpose"},{"location":"ocme1/ocme1/#12-product-scope","text":"","title":"1.2  Product Scope"},{"location":"ocme1/ocme1/#13-definitions-acronyms-and-abbreviations","text":"","title":"1.3  Definitions, Acronyms and Abbreviations"},{"location":"ocme1/ocme1/#14-references","text":"","title":"1.4  References"},{"location":"ocme1/ocme1/#15-document-overview","text":"","title":"1.5  Document Overview"},{"location":"ocme1/ocme1/#2-product-overview","text":"","title":"2  Product Overview"},{"location":"ocme1/ocme1/#21-product-perspective","text":"","title":"2.1  Product Perspective"},{"location":"ocme1/ocme1/#22-product-functions","text":"","title":"2.2  Product Functions"},{"location":"ocme1/ocme1/#23-product-constraints","text":"","title":"2.3  Product Constraints"},{"location":"ocme1/ocme1/#24-user-classes-and-characteristics","text":"","title":"2.4  User Classes and Characteristics"},{"location":"ocme1/ocme1/#25-operating-environment","text":"","title":"2.5  Operating Environment"},{"location":"ocme1/ocme1/#26-user-documentation","text":"","title":"2.6  User Documentation"},{"location":"ocme1/ocme1/#27-assumptions-and-dependencies","text":"","title":"2.7  Assumptions and Dependencies"},{"location":"ocme1/ocme1/#3-requirements","text":"","title":"3  Requirements"},{"location":"ocme1/ocme1/#31-external-interfaces","text":"","title":"3.1  External Interfaces"},{"location":"ocme1/ocme1/#311-software-interfaces","text":"","title":"3.1.1  Software Interfaces"},{"location":"ocme1/ocme1/#312-communications-interfaces","text":"","title":"3.1.2  Communications Interfaces"},{"location":"ocme1/ocme1/#3121-general","text":"","title":"3.1.2.1 General"},{"location":"ocme1/ocme1/#3122-ssi-abstraction-service","text":"","title":"3.1.2.2 SSI Abstraction Service"},{"location":"ocme1/ocme1/#32-functional","text":"","title":"3.2  Functional"},{"location":"ocme1/ocme1/#321-connection-manager","text":"","title":"3.2.1  Connection Manager"},{"location":"ocme1/ocme1/#33-nonfunctional-requirements","text":"","title":"3.3  Nonfunctional Requirements"},{"location":"ocme1/ocme1/#331-performance-requirements","text":"","title":"3.3.1  Performance Requirements"},{"location":"ocme1/ocme1/#332-safety-requirements","text":"","title":"3.3.2  Safety Requirements"},{"location":"ocme1/ocme1/#333-security-requirements","text":"","title":"3.3.3  Security Requirements"},{"location":"ocme1/ocme1/#334-software-quality-attributes","text":"","title":"3.3.4  Software Quality Attributes"},{"location":"ocme1/ocme1/#335-business-rules","text":"","title":"3.3.5  Business Rules"},{"location":"ocme1/ocme1/#34-compliance","text":"","title":"3.4  Compliance"},{"location":"ocme1/ocme1/#35-design-and-implementation","text":"","title":"3.5  Design and Implementation"},{"location":"ocme1/ocme1/#351-installation","text":"","title":"3.5.1  Installation"},{"location":"ocme1/ocme1/#352-configuration","text":"","title":"3.5.2  Configuration"},{"location":"ocme1/ocme1/#353-distribution","text":"","title":"3.5.3  Distribution"},{"location":"ocme1/ocme1/#354-service-meshing","text":"","title":"3.5.4  Service Meshing"},{"location":"ocme1/ocme1/#355-standard-technology","text":"","title":"3.5.5  Standard Technology"},{"location":"ocme1/ocme1/#356-metrics","text":"","title":"3.5.6  Metrics"},{"location":"ocme1/ocme1/#357-configurability","text":"","title":"3.5.7  Configurability"},{"location":"ocme1/ocme1/#358-maintainability","text":"","title":"3.5.8  Maintainability"},{"location":"ocme1/ocme1/#359-reusability","text":"","title":"3.5.9  Reusability"},{"location":"ocme1/ocme1/#3510-runtime-stability","text":"","title":"3.5.10 Runtime Stability"},{"location":"ocme1/ocme1/#3511-high-availability-concepts","text":"","title":"3.5.11 High Availability Concepts"},{"location":"ocme1/ocme1/#3512-proof-of-concept","text":"","title":"3.5.12 Proof of Concept"},{"location":"ocme1/ocme1/#4-system-features","text":"","title":"4  System Features"},{"location":"ocme1/ocme1/#41-attestation-management-service","text":"","title":"4.1  Attestation Management Service"},{"location":"ocme1/ocme1/#411-description","text":"","title":"4.1.1  Description"},{"location":"ocme1/ocme1/#412-functional-requirements","text":"","title":"4.1.2  Functional Requirements"},{"location":"ocme1/ocme1/#42-connection-management-service","text":"","title":"4.2 Connection Management Service"},{"location":"ocme1/ocme1/#421-description","text":"","title":"4.2.1  Description"},{"location":"ocme1/ocme1/#422-functional-requirements","text":"","title":"4.2.2  Functional Requirements"},{"location":"ocme1/ocme1/#43-schema-management-service","text":"","title":"4.3  Schema Management Service"},{"location":"ocme1/ocme1/#431-description","text":"","title":"4.3.1  Description"},{"location":"ocme1/ocme1/#432-functional-requirements","text":"","title":"4.3.2  Functional Requirements"},{"location":"ocme1/ocme1/#44-credential-management-service","text":"","title":"4.4  Credential Management Service"},{"location":"ocme1/ocme1/#441-description","text":"","title":"4.4.1  Description"},{"location":"ocme1/ocme1/#442-functional-requirements","text":"","title":"4.4.2  Functional Requirements"},{"location":"ocme1/ocme1/#45-ssi-abstraction-services","text":"","title":"4.5  SSI Abstraction Services"},{"location":"ocme1/ocme1/#451-description","text":"","title":"4.5.1  Description"},{"location":"ocme1/ocme1/#5-verification","text":"","title":"5  Verification"},{"location":"ocme1/ocme1/#51-acceptance-criteria","text":"","title":"5.1  Acceptance Criteria"},{"location":"ocme1/ocme1/#511-general","text":"","title":"5.1.1  General"},{"location":"ocme1/ocme1/#512-product-constraints","text":"","title":"5.1.2  Product Constraints"},{"location":"ocme1/ocme1/#513-user-documentation","text":"","title":"5.1.3  User Documentation"},{"location":"ocme1/ocme1/#514-ssi-abstraction","text":"","title":"5.1.4  SSI Abstraction"},{"location":"ocme1/ocme1/#515-connection-manager","text":"","title":"5.1.5  Connection Manager"},{"location":"ocme1/ocme1/#516-attestation-manager","text":"","title":"5.1.6  Attestation Manager"},{"location":"ocme1/ocme1/#517-schema-manager","text":"","title":"5.1.7  Schema Manager"},{"location":"ocme1/ocme1/#518-credential-manager","text":"","title":"5.1.8  Credential Manager"},{"location":"ocme1/ocme1/#519-proof-manager","text":"","title":"5.1.9  Proof Manager"},{"location":"ocme1/ocme1/#52-support-for-kubernetes","text":"Appendix A: Glossary Appendix B: Architecture","title":"5.2  Support for Kubernetes"},{"location":"ocme1/ocme1/#list-of-figures","text":"Figure 1: Architecture (semi-transparent boxes are out of scope)","title":"List of Figures"},{"location":"ocme1/ocme1/#list-of-tables","text":"Table 1: References Table 2: Technology Stack Table 3: Functional Requirements Attestation Manager Table 4: Functional Requirements Connection Manager Table 5: Functional Requirements Schema Manager Table 6: Functional Requirements Credential Manager","title":"List of Tables"},{"location":"ocme1/ocme1/#introduction","text":"To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD].","title":"Introduction"},{"location":"ocme1/ocme1/#document-purpose","text":"The purpose of this document is to specify the requirements of the Identity Management and Trust Subcomponent \"Organization Credential Manager Extension 1\" with the intention of a European wide public tender for implementing this software extension. Main audience for this document are attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide digital support for existing certification bodies within Gaia-X.","title":"Document Purpose"},{"location":"ocme1/ocme1/#product-scope","text":"The purpose of this extension is to provide changes to the OCM components to enhance the OCM in its functionality and adopt the latest Gaia-X requirements. The Organization Credential Manager Extension 1 (OCM.E1) enhances the participant's interaction with the SSI-based ecosystem in a trustful and secure environment. This comprises the utilization of the participants digital identity for different functionalities: Extended management of secure and trustable connections with other parties Refreshing and Revocation of verifiable credentials from attesting parties (e.g., Gaia-X Membership credential from a verified notary) Utilization of AIP v2.0 alongside AIP v1.0 by updating the AFJ Framework Provision of verifiable Public Profile The described functionalities allow other components in the Identity Management context to interact with the SSI-based ecosystem. If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams.","title":"Product Scope"},{"location":"ocme1/ocme1/#definitions-acronyms-and-abbreviations","text":"The IDM and Trust Architecture Overview Document [IDM.AO] MUST be considered and applied as the core technical concept that also includes the Terminology and Glossary.","title":"Definitions, Acronyms and Abbreviations"},{"location":"ocme1/ocme1/#references","text":"Reference Title Link Status [AFJ] Aries Framework JavaScript GitHub - Aries Framework JavaScript [BDD] Behavior Driven Development SpecFlow BDD Status: 03-18-2023 [DID] Decentralized Identifiers (DIDs) v1.0 W3C - DID Status: 03-18-2021 [IDM.AO] Gaia-X WP1 Identity & Trust Architecture Overview Please refer to annex \"annex_GX_IDM_AO\" [OCM] Gaia-X Organization Credential Manager Document Please refer to \"annex_Organization Credential Manager\" document [PRD] Gaia-X Policy Rules Document Gaia-X PRD Status: 08-01-2023 [RFC 2119] Key words for use in RFCs to Indicate Requirement Levels RFC 2119 [TAD] Gaia-X Architecture Document Gaia-X TAD [TDR] Gaia-X Federation Services Technical Development Requirements Please refer to annex \"GXFS_Technical_Development_Requirements\" [TSA] Gaia-X Trusted Services API Document Please refer to \"annex_Trusted Services API\" document","title":"References"},{"location":"ocme1/ocme1/#table-1-references","text":"","title":"Table 1: References"},{"location":"ocme1/ocme1/#document-overview","text":"This document describes the product perspective, functions, and constraints. Furthermore, it lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [RFC 2119], are written in capital letters (see also [IDM.AO] - Methodology).","title":"Document Overview"},{"location":"ocme1/ocme1/#product-overview","text":"","title":"Product Overview"},{"location":"ocme1/ocme1/#product-perspective","text":"Please refer to [TDR].","title":"Product Perspective"},{"location":"ocme1/ocme1/#product-functions","text":"The functions of the Organization Credential Manager Extension 1 (OCM.E1) component are provided as a runtime component and MUST expose endpoints as REST services and made accessible over the network using encrypted connections (e.g., HTTPS). The scalability of these services MUST be taken into consideration using well-known and tested concepts like a microservice based architecture and load balancing. Since this component is the very core of trust relationships between participants in the Gaia- X ecosystem, security measures MUST be in place accordingly. This includes the protection of exposed service endpoints, data storage protection and access control. The storage for cryptographic material MUST be particularly secured, e.g., by integrating Hardware Security Modules. The overall functionality of the OCM.E1 component and exposed services MUST be auditable (in compliance with GDPR).","title":"Product Functions"},{"location":"ocme1/ocme1/#figure-1-architecture-semi-transparent-boxes-are-out-of-scope","text":"Please be aware that the semi-transparent boxes are out of scope for further modification but not out of scope for refactoring and problem resolving. The core functions of the OCM.E1 are: Extended managing of trusted connections between entities(Connections in this context are private, secured, and persistentchannels between entities) Blocking of Connections Handling of blocked connections Handling of verifiable credentials exchanges Refreshing of credentials of participants principals, assets etc. Revocation of credentials of participants, principals, assets etc. Handling of revoked credentials Providing publicly visible and verifiable service endpoints within OCM DID Document Configuration of Public Custom Endpoints Configuration of Private Custom Endpoints (with DID-Auth/OIDC) Configuration of Endpoint Mappings to internal/external functionality The updated SSI Abstraction Service provides the required SSI functionality to the other components but is not aware of the Gaia-X context. In this document, the context-specific aspects and interaction with Trust Services are implemented in the specific components: Connection Manager Attestation Manager","title":"Figure 1: Architecture (semi-transparent boxes are out of scope)"},{"location":"ocme1/ocme1/#product-constraints","text":"Please refer to [OCM] section 2.3 and [TSA] section 2.3. The intended environment that is used to support the OCM.E1 product is bound to Aries protocols.","title":"Product Constraints"},{"location":"ocme1/ocme1/#user-classes-and-characteristics","text":"Please refer to [OCM] section 2.4.","title":"User Classes and Characteristics"},{"location":"ocme1/ocme1/#operating-environment","text":"","title":"Operating Environment"},{"location":"ocme1/ocme1/#idmocme100000-kubernetes-environment","text":"The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on the provided SCS cluster (Sovereign Cloud Stack), that will be provided by the Client.","title":"[IDM.OCM.E1.00000] Kubernetes Environment"},{"location":"ocme1/ocme1/#user-documentation","text":"","title":"User Documentation"},{"location":"ocme1/ocme1/#idmocme100001-participant-administration-documentation","text":"The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the products from source code","title":"[IDM.OCM.E1.00001] Participant Administration Documentation"},{"location":"ocme1/ocme1/#idmocme100002-participant-documentation","text":"The documentation MUST contain: Short Software Description (why and for what, when to use, how to use, where to use) Usage guide GDPR design decisions Security concept Operations concept FAQ Keyword Directory","title":"[IDM.OCM.E1.00002] Participant Documentation"},{"location":"ocme1/ocme1/#assumptions-and-dependencies","text":"An understanding of the overall Gaia-X architecture and philosophy is necessary as well as understanding of the OCM architecture and implementation details. Please refer to [TAD], [PRD] and [OCM]. Attendees of the public tender MUST assume responsibility of: The existing code and improvements upon the existing code base (semi-transparent boxes listed on Figure 1) Extending or contributing to the used frameworks in order to provision a way in which realization of the requirements can be achieved Updating dependencies to the latest stable version Refactoring the Software Architecture Please be aware that extending or contributing to the used frameworks means explicitly to actively make or drive changes if necessary. Driving or making changes could be: creating git issues, discussing with framework contributors and maintainers, making changes in the Codebase.","title":"Assumptions and Dependencies"},{"location":"ocme1/ocme1/#requirements","text":"","title":"Requirements"},{"location":"ocme1/ocme1/#external-interfaces","text":"","title":"External Interfaces"},{"location":"ocme1/ocme1/#software-interfaces","text":"","title":"Software Interfaces"},{"location":"ocme1/ocme1/#general","text":"","title":"General"},{"location":"ocme1/ocme1/#idmocme100003-general-operation-requirements","text":"Every component must be able to run as a container. For scalable deployment e.g., a helm chart must be provided. If database connections are used, it must provide options to run the container \"stand-alone\", e.g., in-memory and with an external, configurable database.","title":"[IDM.OCM.E1.00003] General Operation Requirements"},{"location":"ocme1/ocme1/#communications-interfaces","text":"","title":"Communications Interfaces"},{"location":"ocme1/ocme1/#general_1","text":"","title":"General"},{"location":"ocme1/ocme1/#idmocme100004-event-handling","text":"A lot of services within the OCM are publishing and receiving events, events are related to the scope of SSI for the different protocol flows. The way to publish and subscribe these events must be consistent throughout the functionality of the OCM.E1.","title":"[IDM.OCM.E1.00004] Event Handling"},{"location":"ocme1/ocme1/#ssi-abstraction-service","text":"","title":"SSI Abstraction Service"},{"location":"ocme1/ocme1/#idmocme100005-aip-v20-support","text":"The current implementation uses version 1.0 of the Aries JavaScript Framework. In order to support AIP v2.0 the SSI Abstraction Service MUST implement the latest stable version of Aries Framework JavaScript [1] [AFJ] and handle the necessary changes to the other services accordingly.","title":"[IDM.OCM.E1.00005] AIP v2.0 support"},{"location":"ocme1/ocme1/#1-httpsgithubcomhyperledgeraries-framework-javascript","text":"","title":"[1] [https://github.com/hyperledger/aries-framework-javascript]"},{"location":"ocme1/ocme1/#functional","text":"","title":"Functional"},{"location":"ocme1/ocme1/#connection-manager","text":"","title":"Connection Manager"},{"location":"ocme1/ocme1/#idmocme100006-block-connection","text":"The Connection Manager must provide a Block Connection endpoint. The endpoint should accept either connection ID or DID. It should delete the connection from the SSI Abstraction service and mark it as 'blocked' in the Connection Manager.","title":"[IDM.OCM.E1.00006] Block Connection"},{"location":"ocme1/ocme1/#idmocme100007-refuse-blocked-connections","text":"The Connection Manager must refuse connections if they match the connection ID or DID of a connection in the database, which has been marked as 'blocked'. The response of an unsuccessful connection in this case should include the reason for refusal in the response message.","title":"[IDM.OCM.E1.00007] Refuse blocked connections"},{"location":"ocme1/ocme1/#idmocme100008-auto-accept-connections-to-self","text":"The Connection Manager must automatically accept connections if they match the DID of the OCM.","title":"[IDM.OCM.E1.00008] Auto-accept Connections to Self"},{"location":"ocme1/ocme1/#idmocme100009-trusted-connection-to-self","text":"The Connection Manager must mark connections as \"trusted\" if they match the DID of the OCM.","title":"[IDM.OCM.E1.00009] Trusted Connection to Self"},{"location":"ocme1/ocme1/#idmocme100010-tsa-acception","text":"The Connection Manager MUST use TSA to accept/block connections automatically according to the incoming DID.","title":"[IDM.OCM.E1.00010] TSA Acception"},{"location":"ocme1/ocme1/#idmocme100011-connection-list-endpoint","text":"The Connection Manager MUST provide an Endpoint to List all existing connections.","title":"[IDM.OCM.E1.00011] Connection List Endpoint"},{"location":"ocme1/ocme1/#attestation-manager","text":"","title":"Attestation Manager"},{"location":"ocme1/ocme1/#idmocme100012-responsibilities-of-components","text":"The Attestation Manager is currently responsible for the operations on schemas, credential definitions and credentials. It MUST be separated into two distinct components - Schema manager, which handles schema and credential definition operations, and Credential Manager, which handles credential operations.","title":"[IDM.OCM.E1.00012] Responsibilities of components"},{"location":"ocme1/ocme1/#idmocme100013-endpoints-for-credential-requestsproposals","text":"The attestation manager MUST provide an endpoint which delivers open credential offerings and credential requests.","title":"[IDM.OCM.E1.00013] Endpoints for Credential Requests/Proposals"},{"location":"ocme1/ocme1/#schema-manager","text":"","title":"Schema Manager"},{"location":"ocme1/ocme1/#idmocme100014-schemas-and-credential-definitions","text":"The Schema Manager MUST implement all necessary schema and credential definition operations, including but not limited to the current endpoints in the Attestation Manager of the OCM, responsible for schema and credential definition operations.","title":"[IDM.OCM.E1.00014] Schemas and Credential Definitions"},{"location":"ocme1/ocme1/#credential-manager","text":"","title":"Credential Manager"},{"location":"ocme1/ocme1/#idmocme100015-credentials","text":"The Credential Manager MUST implement all necessary credential operations, including but not limited to the current endpoints in the Attestation Manager of the OCM, responsible for issuing and other operations with credentials.","title":"[IDM.OCM.E1.00015] Credentials"},{"location":"ocme1/ocme1/#idmocme100016-credential-revocation","text":"The Credential Manager MUST provide a Revoke Credential endpoint.","title":"[IDM.OCM.E1.00016] Credential Revocation"},{"location":"ocme1/ocme1/#idmocme100017-auto-reissued-credential","text":"Ability for auto-reissuing of a VC MUST be provided.","title":"[IDM.OCM.E1.00017] Auto-Reissued Credential"},{"location":"ocme1/ocme1/#idmocme100018-credential-auto-revocation","text":"The Credential Manager provides Automated Revocation of Credentials, based on the expiration date (if specified), as well as additional parameters describing whether the specific credential should be automatically revoked.","title":"[IDM.OCM.E1.00018] Credential Auto-Revocation"},{"location":"ocme1/ocme1/#idmocme100019-credential-refreshing","text":"Depending on the autoReissued value of the credential, the Credential Manager reissues the credential with a new expiration date. The refresh option is included in the credential, which would allow the holder to refresh the credential before creating a verifiable presentation.","title":"[IDM.OCM.E1.00019] Credential Refreshing"},{"location":"ocme1/ocme1/#idmocme100020-auto-accept-self-issued-credentials","text":"The Credential Manager must automatically accept Verifiable Credentials that have been issued by the OCM over a DIDComm connection with itself (self-issuing).","title":"[IDM.OCM.E1.00020] Auto-accept Self-issued Credentials"},{"location":"ocme1/ocme1/#proof-manager","text":"","title":"Proof Manager"},{"location":"ocme1/ocme1/#idmocme100021-json-ld-mapping","text":"When a presentation is made, the presentation can be mapped to a prepared JSON-LD.","title":"[IDM.OCM.E1.00021] JSON-LD Mapping"},{"location":"ocme1/ocme1/#common-enhancements","text":"","title":"Common Enhancements"},{"location":"ocme1/ocme1/#idmocme100022-custom-service-endpoint-configuration","text":"The OCM MUST support the configuration of custom endpoints which are visible in the DID Documents Service Endpoint Section ([DID] Section 5.4). It MUST be possible to define either private or public endpoints secured by DID Auth and OIDC, which are configurable in a OCM config.","title":"[IDM.OCM.E1.00022] Custom Service Endpoint Configuration"},{"location":"ocme1/ocme1/#idmocme100023-did-configuration-provision","text":"The OCM MUST provide to a configured URL an DID Configuration according to the Identity Foundation specification [2].","title":"[IDM.OCM.E1.00023] DID Configuration Provision"},{"location":"ocme1/ocme1/#2-httpsidentityfoundationspecsdid-configuration","text":"","title":"[2] [https://identity.foundation/specs/did-configuration/]"},{"location":"ocme1/ocme1/#idmocme100024-did-document-resolving","text":"The DID Document of the OCM MUST be resolvable by the Universal Resolver and it MUST contain all key material used by the OCM including all endpoints following this service configuration format by enhancing the W3C spec [3]: { id: {idName} type: {typeName}, accept: \\[\"didcomm/v2\",\"didcomm/v1\",{otherProtocols}\\], serviceEndpoint:\\[\"https://...\"\\] }","title":"[IDM.OCM.E1.00024] DID Document Resolving"},{"location":"ocme1/ocme1/#3-httpswwww3orgtrdid-coreexample-usage-of-the-service-property","text":"","title":"[3] [https://www.w3.org/TR/did-core/#example-usage-of-the-service-property]"},{"location":"ocme1/ocme1/#idmocme100025-event-restructuring","text":"The current structure contains a structure which uses partially NATS Events and partially Rest API calls of the underlying Aries Extensions, but in cause of a micro service approach the entire structure MUST be reorganized for NATS eventing to clean up the communication between the components e.g., \"Aries Event Extension\".","title":"[IDM.OCM.E1.00025] Event Restructuring"},{"location":"ocme1/ocme1/#idmocme100026-multi-tenancy","text":"The component MUST support multi tenancy with possibility to scale down to zero.","title":"[IDM.OCM.E1.00026] Multi Tenancy"},{"location":"ocme1/ocme1/#idmocme100027-selective-disclosure-jwt","text":"The component MUST support Selective Disclosure JWT described in the specification [4].","title":"[IDM.OCM.E1.00027] Selective Disclosure JWT"},{"location":"ocme1/ocme1/#4-httpsdatatrackerietforgdocdraft-ietf-oauth-selective-disclosure-jwt","text":"","title":"[4] [https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/]"},{"location":"ocme1/ocme1/#nonfunctional-requirements","text":"","title":"Nonfunctional Requirements"},{"location":"ocme1/ocme1/#performance-requirements","text":"","title":"Performance Requirements"},{"location":"ocme1/ocme1/#idmocme100028-updown-scale","text":"All components MUST be able to scale up/down their functionality for undefined amount instances. This requires a parallel execution possibility which will be tested later on by performance tests which are defined by the test team.","title":"[IDM.OCM.E1.00028] Up/Down Scale"},{"location":"ocme1/ocme1/#idmocme100029-performance-by-design","text":"The product SHOULD be designed and implemented in a way that the implementation is non- blocking and performance oriented. It SHOULD be a microservice architecture, but it MAY follow other concepts. The decision MUST be documented.","title":"[IDM.OCM.E1.00029] Performance by Design"},{"location":"ocme1/ocme1/#safety-requirements","text":"","title":"Safety Requirements"},{"location":"ocme1/ocme1/#idmocme100030-major-releases","text":"All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening.","title":"[IDM.OCM.E1.00030] Major Releases"},{"location":"ocme1/ocme1/#security-requirements","text":"","title":"Security Requirements"},{"location":"ocme1/ocme1/#idmocme100031-cve-patches","text":"All software components MUST have applied CVE patches, which are available for major releases.","title":"[IDM.OCM.E1.00031] CVE Patches"},{"location":"ocme1/ocme1/#software-quality-attributes","text":"","title":"Software Quality Attributes"},{"location":"ocme1/ocme1/#idmocme100032-software-quality-requirements","text":"All software components MUST be compliant to the requirements within the quality assurance repository [5]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology.","title":"[IDM.OCM.E1.00032] Software Quality Requirements"},{"location":"ocme1/ocme1/#5-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesquality-assurance-issues","text":"","title":"[5] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues]"},{"location":"ocme1/ocme1/#idmocme100033-descriptive-logging","text":"Descriptive logging of key points in the code MUST be implemented. For the purpose of proper monitoring logs MUST be included in all potential failing points in the functions of the code, as well as all major steps of successful operations.","title":"[IDM.OCM.E1.00033] Descriptive Logging"},{"location":"ocme1/ocme1/#business-rules","text":"","title":"Business Rules"},{"location":"ocme1/ocme1/#idmocme100034-software-consistency","text":"The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc.","title":"[IDM.OCM.E1.00034] Software Consistency"},{"location":"ocme1/ocme1/#idmocme100035-cherry-picking","text":"All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow an enterprise deployment customization.","title":"[IDM.OCM.E1.00035] Cherry Picking"},{"location":"ocme1/ocme1/#compliance","text":"","title":"Compliance"},{"location":"ocme1/ocme1/#idmocme100036-gdpr-audit-logging","text":"All GDPR relevant access to personal relevant data MUST be logged for a later audit.","title":"[IDM.OCM.E1.00036] GDPR Audit Logging"},{"location":"ocme1/ocme1/#idmocme100037-gdpr-data-processing","text":"Is it necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable.","title":"[IDM.OCM.E1.00037] GDPR Data Processing"},{"location":"ocme1/ocme1/#design-and-implementation","text":"","title":"Design and Implementation"},{"location":"ocme1/ocme1/#installation","text":"","title":"Installation"},{"location":"ocme1/ocme1/#idmocme100038-helmargo-cd-deployment","text":"All installations MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a ARGO CD Pipeline defined in the gxfs-integration repository [6].","title":"[IDM.OCM.E1.00038] Helm/Argo CD Deployment"},{"location":"ocme1/ocme1/#6-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[6] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"ocme1/ocme1/#configuration","text":"","title":"Configuration"},{"location":"ocme1/ocme1/#idmocme100039-configuration","text":"All components MUST support one of the major configuration formats (yaml, json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged.","title":"[IDM.OCM.E1.00039] Configuration"},{"location":"ocme1/ocme1/#distribution","text":"","title":"Distribution"},{"location":"ocme1/ocme1/#idmocme100040-helm-repositories","text":"All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [7].","title":"[IDM.OCM.E1.00040] Helm Repositories"},{"location":"ocme1/ocme1/#7-httpsgitlabcomapiv4projects41175300packageshelmintegrationindexyaml","text":"","title":"[7] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml]"},{"location":"ocme1/ocme1/#idmocme100041-istio-resources","text":"Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc. ) following the integration pattern specified in the gxfs-integration repo [8].","title":"[IDM.OCM.E1.00041] Istio Resources"},{"location":"ocme1/ocme1/#8-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[8] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"ocme1/ocme1/#service-meshing","text":"","title":"Service Meshing"},{"location":"ocme1/ocme1/#idmocme100042-istio-support","text":"All HELM charts MUST be provided with Istio support aligned together with the project team. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment.","title":"[IDM.OCM.E1.00042] Istio Support"},{"location":"ocme1/ocme1/#standard-technology","text":"","title":"Standard Technology"},{"location":"ocme1/ocme1/#idmocme100043-default-toolstack","text":"Each development MUST consider the following standard technologies, if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React [9] Ingress Controller Nginx API Testing Postman (manual) API Design OpenAPI Kubernetes v1.26+","title":"[IDM.OCM.E1.00043] Default Toolstack"},{"location":"ocme1/ocme1/#table-2-technology-stack","text":"","title":"Table 2: Technology Stack"},{"location":"ocme1/ocme1/#9-httpsreact-bootstrapgithubio","text":"The technology stack is mandatory to avoid integration impact.","title":"[9] [https://react-bootstrap.github.io/]"},{"location":"ocme1/ocme1/#metrics","text":"","title":"Metrics"},{"location":"ocme1/ocme1/#idmocme100044-opentelemtry-support","text":"All helm charts/services MUST provide metrics endpoints in opentelemetry [10] format.","title":"[IDM.OCM.E1.00044] Opentelemtry Support"},{"location":"ocme1/ocme1/#10-httpsopentelemetryiodocs","text":"","title":"[10] [https://opentelemetry.io/docs/]"},{"location":"ocme1/ocme1/#configurability","text":"","title":"Configurability"},{"location":"ocme1/ocme1/#idmocme100045-configuration-profiles","text":"Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening","title":"[IDM.OCM.E1.00045] Configuration Profiles"},{"location":"ocme1/ocme1/#idmocme100046-secret-references-in-helm-charts","text":"The configuration secrets within Helm Charts MUST use secretRefs to support external Secretmanagement. Clear text secrets within the Helm Charts are not allowed.","title":"[IDM.OCM.E1.00046] Secret References in Helm Charts"},{"location":"ocme1/ocme1/#maintainability","text":"","title":"Maintainability"},{"location":"ocme1/ocme1/#idmocme100047-micro-service-architecture","text":"For a better scale out, maintainability and decentralization, the product architecture MUST have a micro service architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement it. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment).","title":"[IDM.OCM.E1.00047] Micro Service Architecture"},{"location":"ocme1/ocme1/#idmocme100048-domain-driven-design","text":"To support the micro service architecture within the maintainability, it MUST be declared a domain model before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers.","title":"[IDM.OCM.E1.00048] Domain Driven Design"},{"location":"ocme1/ocme1/#reusability","text":"","title":"Reusability"},{"location":"ocme1/ocme1/#idmocme100049-enterprise-environments","text":"All components MUST be reusable in different enterprise environments by customization and whitelabeling. This means all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.)","title":"[IDM.OCM.E1.00049] Enterprise Environments"},{"location":"ocme1/ocme1/#runtime-stability","text":"","title":"Runtime Stability"},{"location":"ocme1/ocme1/#idmocme100050-readiness-checkups","text":"All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: An unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state","title":"[IDM.OCM.E1.00050] Readiness Checkups"},{"location":"ocme1/ocme1/#high-availability-concepts","text":"","title":"High Availability Concepts"},{"location":"ocme1/ocme1/#idmocme100051-redundant-deployment","text":"Each deployment MUST be configured for a minimum fault tolerance of 2 instances.","title":"[IDM.OCM.E1.00051] Redundant Deployment"},{"location":"ocme1/ocme1/#proof-of-concept","text":"","title":"Proof of Concept"},{"location":"ocme1/ocme1/#idmocme100052-architecture-changes","text":"All Architecture Changes MUST be aligned with the Client before implementation.","title":"[IDM.OCM.E1.00052] Architecture Changes"},{"location":"ocme1/ocme1/#system-features","text":"","title":"System Features"},{"location":"ocme1/ocme1/#attestation-management-service","text":"","title":"Attestation Management Service"},{"location":"ocme1/ocme1/#attestation-management-service-description","text":"The Attestation Management Service should separate the functionalities regarding credentials, schemas and credential definitions in two distinct components that handle credentials, and schemas and credential definitions respectively.","title":"Attestation Management Service Description"},{"location":"ocme1/ocme1/#attestation-management-service-functional-requirements","text":"Legacy - Responsibilities of components - Endpoints for Credential Requests/Proposals","title":"Attestation Management Service Functional Requirements"},{"location":"ocme1/ocme1/#table-3-functional-requirements-attestation-manager","text":"","title":"Table 3: Functional Requirements Attestation Manager"},{"location":"ocme1/ocme1/#connection-management-service","text":"","title":"Connection Management Service"},{"location":"ocme1/ocme1/#connection-management-service-description","text":"The Connection Management Service should maintain the existing Connection Manager functionality and additionally handle all the requirements regarding the blocked connections, which includes the blocking and unblocking of a connection based on a common identifier (an identifier that is not defined per connection, but is shared between different connections to the same Participant), as well as subsequent interactions with the blocked connection.","title":"Connection Management Service Description"},{"location":"ocme1/ocme1/#connection-management-service-functional-requirements","text":"Endpoints -Block Connection Functions - Refuse blocked connections - Auto-accept Connections to Self - Trusted Connection to Self","title":"Connection Management Service Functional Requirements"},{"location":"ocme1/ocme1/#table-4-functional-requirements-connection-manager","text":"","title":"Table 4: Functional Requirements Connection Manager"},{"location":"ocme1/ocme1/#schema-management-service","text":"","title":"Schema Management Service"},{"location":"ocme1/ocme1/#schema-management-service-description","text":"The Schema Management service is responsible for utilizing the existing schema and credential definition functionality of the existing Attestation Manager ([OCM] Section 4.5).","title":"Schema Management Service Description"},{"location":"ocme1/ocme1/#schema-management-service-functional-requirements","text":"Legacy -Schemas and Credential Definitions","title":"Schema Management Service Functional Requirements"},{"location":"ocme1/ocme1/#table-5-functional-requirements-schema-manager","text":"","title":"Table 5: Functional Requirements Schema Manager"},{"location":"ocme1/ocme1/#credential-management-service","text":"","title":"Credential Management Service"},{"location":"ocme1/ocme1/#credential-management-service-description","text":"The Credential Management Service is responsible for utilizing the existing credential functionality of the Attestation Manager ([OCM] Section 4.5). It should also be responsible for the credential revocation and refreshing of credentials, as well as all needed additional functionalities for automatic refreshing and revocation management.","title":"Credential Management Service Description"},{"location":"ocme1/ocme1/#credential-management-service-functional-requirements","text":"Endpoints -Credential Revocation Functions -Auto-Reissued Credential -Credential Auto-Revocation -Credential Refreshing -Auto-accept Self-issued Legacy -Credentials","title":"Credential Management Service Functional Requirements"},{"location":"ocme1/ocme1/#table-6-functional-requirements-credential-manager","text":"","title":"Table 6: Functional Requirements Credential Manager"},{"location":"ocme1/ocme1/#ssi-abstraction-services","text":"","title":"SSI Abstraction Services"},{"location":"ocme1/ocme1/#ssi-abstraction-service-description","text":"The SSI Abstraction Service ([OCM] Section 4.6) is currently employing the Aries JavaScript Framework at its core and provides its functionality to the other components. The package version is at 0.1.0 and should be updated to the latest stable version, as well the Aries rest extension that provides access to the agent via REST endpoints. It should be able to accommodate the desired functional requirements of both [OCM] and OCM.E1.","title":"SSI Abstraction Service Description"},{"location":"ocme1/ocme1/#ssi-abstraction-service-verification","text":"All listed verification items/criterias, must be fulfilled by a demonstration of the implementation within the Kubernetes environment.","title":"SSI Abstraction Service Verification"},{"location":"ocme1/ocme1/#idmocme100053-automated-integration-tests","text":"Current Automation Suite MUST be extended and updated accordingly.","title":"[IDM.OCM.E1.00053] Automated Integration Tests"},{"location":"ocme1/ocme1/#verification","text":"All listed verification items/criterias, must be fulfilled by a demonstration of the implementation within the Kubernetes environment.","title":"Verification"},{"location":"ocme1/ocme1/#idmocme100053-automated-integration-tests_1","text":"Current Automation Suite MUST be extended and updated accordingly.","title":"[IDM.OCM.E1.00053] Automated Integration Tests"},{"location":"ocme1/ocme1/#acceptance-criteria","text":"","title":"Acceptance Criteria"},{"location":"ocme1/ocme1/#general-verification","text":"","title":"General - Verification"},{"location":"ocme1/ocme1/#idmocme100054-general-operation-requirements","text":"Every component is demonstrated to be able to run as a container and functioning helm charts are provided.","title":"[IDM.OCM.E1.00054] General Operation Requirements"},{"location":"ocme1/ocme1/#idmocme100055-event-handling","text":"Previously used events are not disrupted or malfunctioning, and newly created ones are demonstrated or through the functions they enable it is implied that they are properly functioning.","title":"[IDM.OCM.E1.00055] Event Handling"},{"location":"ocme1/ocme1/#product-constraints-verification","text":"","title":"Product Constraints - Verification"},{"location":"ocme1/ocme1/#idmocme100056-microservice-approach","text":"The Services interact with each other through standard APIs and protocols and are deployed as microservices.","title":"[IDM.OCM.E1.00056] Microservice Approach"},{"location":"ocme1/ocme1/#user-documentation-verification","text":"","title":"User Documentation - Verification"},{"location":"ocme1/ocme1/#idmocme100057-documentation-update","text":"The current documentation is updated and enhanced, and the new services and functions are added to the existing documentation or in a newly created one if it is needed.","title":"[IDM.OCM.E1.00057] Documentation Update"},{"location":"ocme1/ocme1/#ssi-abstraction","text":"","title":"SSI Abstraction"},{"location":"ocme1/ocme1/#idmocme100058-aip-v20-support","text":"The SSI abstraction service's core ([AFJ] ) MUST be updated to the latest stable version (for the purposes of this iteration) and provides AIP v2.0 protocols.","title":"[IDM.OCM.E1.00058] AIP v2.0 support"},{"location":"ocme1/ocme1/#connection-manager-verification","text":"","title":"Connection Manager - Verification"},{"location":"ocme1/ocme1/#idmocme100059-block-connection","text":"The blocked connection is discoverable through the [OCM] List Connection API endpoint and is displayed as 'blocked'.","title":"[IDM.OCM.E1.00059] Block Connection"},{"location":"ocme1/ocme1/#idmocme100060-refuse-blocked-connections","text":"Any further interactions through a blocked connection (e.g., proof request, issue credential, etc.) are demonstrated as unavailable and the response returned from the respective endpoint is unsuccessful.","title":"[IDM.OCM.E1.00060] Refuse blocked connections"},{"location":"ocme1/ocme1/#idmocme100061-auto-accept-connections-to-self","text":"The OCM automatically accepts connections with itself.","title":"[IDM.OCM.E1.00061] Auto-accept Connections to Self"},{"location":"ocme1/ocme1/#idmocme100062-trusted-connection-to-self","text":"DIDComm Connections that are between the OCM and itself are always by configuration marked as \"trusted\".","title":"[IDM.OCM.E1.00062] Trusted Connection to Self"},{"location":"ocme1/ocme1/#idmocme100063-policy-based-acception","text":"Connections are accepted on the basis of a policy.","title":"[IDM.OCM.E1.00063] Policy Based Acception"},{"location":"ocme1/ocme1/#attestation-manager-verification","text":"","title":"Attestation Manager - Verification"},{"location":"ocme1/ocme1/#idmocme100064-responsibilities-of-components","text":"The Attestation Manager no longer exists, but its functionality is split into the Schema and Credential Managers.","title":"[IDM.OCM.E1.00064] Responsibilities of components"},{"location":"ocme1/ocme1/#schema-manager-verification","text":"","title":"Schema Manager - Verification"},{"location":"ocme1/ocme1/#idmocme100065-schemas-and-credential-definitions","text":"The Schema Manager is shown to be responsible for all schema operations, previously existent on the Attestation Manager Service.","title":"[IDM.OCM.E1.00065] Schemas and Credential Definitions"},{"location":"ocme1/ocme1/#credential-manager-verification","text":"","title":"Credential Manager - Verification"},{"location":"ocme1/ocme1/#idmocme100066-credentials","text":"The Credential Manager is shown to be responsible for all credential operations, previously existent on the Attestation Manager Service.","title":"[IDM.OCM.E1.00066] Credentials"},{"location":"ocme1/ocme1/#idmocme100067-get-credentials","text":"The OCM endpoint delivers all credentials of the wallet.","title":"[IDM.OCM.E1.00067] Get Credentials"},{"location":"ocme1/ocme1/#idmocme100068-credential-revocation","text":"The Credential Manager successfully performs revocation of Verifiable Credentials.","title":"[IDM.OCM.E1.00068] Credential Revocation"},{"location":"ocme1/ocme1/#idmocme100069-auto-reissued-credential","text":"In the stored data of the Verifiable Credential, a field for autoReissuance (not bound to the exact mention of its name) is present.","title":"[IDM.OCM.E1.00069] Auto-Reissued Credential"},{"location":"ocme1/ocme1/#idmocme100070-credential-auto-revocation","text":"The Credential Manager is able to successfully revoke a Verifiable Credential once the expiration date attribute's value has been reached. This should be done for all stored Verifiable Credentials.","title":"[IDM.OCM.E1.00070] Credential Auto-Revocation"},{"location":"ocme1/ocme1/#idmocme100071-credential-refreshing","text":"Depending on the autoReissued value of the credential database entry, the Credential Manager successfully reissues a Verifiable Credential if autoReissued's condition is met and does not do so if the condition is not met.","title":"[IDM.OCM.E1.00071] Credential Refreshing"},{"location":"ocme1/ocme1/#idmocme100072-auto-accept-self-issued-credentials","text":"Credentials issued by the OCM to itself are automatically accepted.","title":"[IDM.OCM.E1.00072] Auto-accept Self-issued Credentials"},{"location":"ocme1/ocme1/#proof-manager-verification","text":"","title":"Proof Manager - Verification"},{"location":"ocme1/ocme1/#idmocme100073-json-ld-mapping","text":"When a presentation is made, the presentation can be mapped to a prepared JSON-LD.","title":"[IDM.OCM.E1.00073] JSON-LD Mapping"},{"location":"ocme1/ocme1/#support-for-kubernetes","text":"","title":"Support for Kubernetes"},{"location":"ocme1/ocme1/#idmocme100074-eventing","text":"All eventings MUST be demonstrated on basis of cloud events specifications [Cloud.Events] together with the kNative [11] broker in a Kubernetes environment.","title":"[IDM.OCM.E1.00074] Eventing"},{"location":"ocme1/ocme1/#11-httpsknativedevdocseventing","text":"","title":"[11] [https://knative.dev/docs/eventing/]"},{"location":"ocme1/ocme1/#idmocme100075-config-map-support","text":"Each service must be demonstrated up and running in Kubernetes, configured by config maps.","title":"[IDM.OCM.E1.00075] Config Map Support"},{"location":"ocme1/ocme1/#idmocme100076-helm-installation","text":"The service installation MUST be demonstrated during HELM install.","title":"[IDM.OCM.E1.00076] Helm Installation"},{"location":"ocme1/ocme1/#idmocme100077-argocd-integration","text":"The helm chart MUST be able to install inside of AgroCD. This includes the usage of the postgres hooks [12] and the providing of usable values.yaml(s) for all developed services.","title":"[IDM.OCM.E1.00077] ArgoCD Integration"},{"location":"ocme1/ocme1/#12-httpsgitlabeclipseorgeclipsexfscintegration-treemainhelmchartspostgresql-hook","text":"","title":"[12] [https://gitlab.eclipse.org/eclipse/xfsc/integration/-/tree/main/helm/charts/postgresql-hook]"},{"location":"ocme1/ocme1/#idmocme100078-scs-environment","text":"All HELM installations MUST run on SCS (Sovereign Cloud Stack). The final acceptance demonstration cannot be realized on azure, google cloud etc.","title":"[IDM.OCM.E1.00078] SCS Environment"},{"location":"ocme1/ocme1/#appendix-a-glossary","text":"For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO]","title":"Appendix A: Glossary"},{"location":"ocme1/ocme1/#appendix-b-architecture","text":"(semi-transparent boxes are out of scope)","title":"Appendix B: Architecture"},{"location":"ocmwstack/ocmwstack/","text":"Software Requirements Specification for Gaia-X Federation Services Organization Credential Manager W-STACK IDM.OCM.W-STACK Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA 1 Introduction 1.1 Document Purpose 1.2 Product Scope 1.3 Definitions, Acronyms and Abbreviations 1.4 References 1.5 Document Overview 2 Product Overview 2.1 Product Perspective 2.2 Product Functions 2.3 Product Constraints 2.4 User Classes and Characteristics 2.5 Operating Environment 2.6 User Documentation 2.7 Assumptions and Dependencies 3 Requirements 3.1 External Interfaces 3.1.1 Software Interfaces 3.1.2 Communications Interfaces 3.1.3 Hardware Interfaces 3.2 Functional 3.2.1 General 3.3 Nonfunctional Requirements 3.3.1 Performance Requirements 3.3.2 Safety Requirements 3.3.3 Security Requirements 3.3.4 Software Quality Attributes 3.3.5 Business Rules 3.4 Compliance 3.5 Design and Implementation 3.5.1 Installation 3.5.2 Configuration 3.5.3 Distribution 3.5.4 Service Meshing 3.5.5 Standard Technology 3.5.6 Metrics 3.5.7 Configurability 3.5.8 Maintainability 3.5.9 Reusability 3.5.10 Runtime Stability 3.5.11 High Availability Concepts 3.5.12 Proof of Concept 4 System Features 4.1 Connection Management Service 4.1.1 Description 4.1.2 Functional Requirements 4.2 Credential Management Service 4.2.1 Description 4.2.2 Functional Requirements 4.3 Credential and Connection Storage 4.3.1 Description 4.3.2 Functional Requirements 4.4 DID Document Management Service 4.4.1 Description 4.4.2 Functional Requirements 4.5 Credential Signing and Verification Service 4.5.1 Description 4.5.2 Functional Requirements 4.6 Schema Management Service 4.6.1 Description 4.6.2 Functional Requirements 5 Verification 5.1 Acceptance Criteria 5.1.1 General 5.1.2 Connection Manager 5.1.3 Credential Manager 5.1.4 Issue Credential 5.1.5 Dispute Credential 5.1.6 Revoke Credential 5.1.7 Prove Credential 5.1.8 Credential Types 5.1.9 Credential and Connection Storage 5.1.10 DID Document Manager 5.1.11 Credential Signing and Verification 5.1.12 Secrets Management 5.1.13 Schema Management 5.1.14 Nonfunctional Appendix A: Glossary Appendix B: Architecture List of Figures Figure 1: Architecture (also see appendix B) Figure 2: Architecture Block Diagram List of Tables Table 1: References Table 2: User Classes and Characteristics Table 3: Technology Stack Table 4: Functional Requirements Connection Manager Table 5: Functional Requirements Credential Manager Table 6: Functional Requirements Connection Manager Table 7: Functional Requirements DID Document Manager Table 8: Functional Requirements Credential Signing and Verification Service Table 9: Functional Requirements Schema Management Service Introduction To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD]. Document Purpose The purpose of this document is to specify the requirements of the Identity Management and Trust Subcomponent \"Organization Credential Manager W-STACK\" with the intention of a European wide public tender for implementing this software extension. Main audience for this document are attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide digital support for existing certification bodies within Gaia-X. Product Scope The purpose of these products is to provide all necessary components for the extension of the administration of the digital identity of a participant in the Gaia-X context. The Organization Credential Manager W-STACK (IDM.OCM.W-STACK) enhances the participant's interaction with the SSI-based ecosystem in a trustful and secure way. This comprises the utilization of the participants digital identity for different functionalities: Implementation of Full W3C DID/VC/VP Support for Credential Exchange and Trust Implementation of OpenID Standards OpenId4VC/VP SIOP VC Issuance Protocol Extension Establishment of secure and trustable connections with other parties Request and reception of verifiable credentials from attesting parties (e.g., Gaia-X Membership credential from a verified notary) in JSON-LD Format Attestation of attributes to principals in the form of verifiable credentials (e.g., employees, technical assets) Validation of received verifiable presentations from other parties (e.g., validation of Gaia-X membership of other participants) Maintenance of the verifiable Public Profile Scalable VC/VP Storage Graph Indexing for Linking VC/VP The described functionalities allow other components in the Identity Management context to interact with the SSI-based ecosystem. >Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams. Definitions, Acronyms and Abbreviations The IDM and Trust Architecture Overview Document [IDM.AO] MUST be considered and applied as the core technical concept that also includes the Terminology and Glossary. References Reference Title Status [BDD] Getting Started with Behavior Driven Development (Specflow, n.D.) 03-17-2023 [Cloud Events] CloudEvents Specification (CloudEvents Authors, The Linux Foundation, 2021) 03-17-2023 [EBSI] EBSI (CEF Digital, 2021) 08-15-2023 [EIDAS] SSI eIDAS Legal Report (Dr. Ignacio Alamillo Domingo, 2020) 07-13-2023 [GDPR] General Data Protection Regulation GDPR (Intersoft Consulting, 2019) 03-17-2023 [IDM.AA] Authentication/Authorization Document (Gaia-X, European Association for Data and Cloud, AISBL, 2021) - [IDM.AO] Architecture Overview (GAIA-X WP1, 2021) - [IDM.TSA] Trusted Services API (Gaia-X, European Association for Data and Cloud, AISBL, 2021) - [OIDC] OpenID working groups specifications - [OID4VC] OpenID for Verifiable Credential Issuance 03-17-2023 [OID4VP] OpenID for Verifiable Presentations 03-17-2023 [PRD] Gaia-X Policy Rules Document (Gaia-X, European Association for Data and Cloud, AISBL, 2022) 08-14-2023 [RFC2119] Key words for use in RFCs to Indicate Requirement Levels 07-04-2023 [TAD] Gaia-X Architecture Document (Gaia-X, European Association for Data and Cloud, AISBL, 2022) - [TDR] GXFS_Technical_Development_Requirements (Gaia-X Federation Services Technical Development Requirements) - [W3C] Verifiable Credentials Data Model (W3C) 03-17-2023 Table 1: References Document Overview This document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID (e.g. IDM.ID.Number ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [RFC 2119], are written in capital letters (see also [IDM.AO] - Methodology). Product Overview Product Perspective The product is necessary to establish trust and credential exchange between the different participants within the Gaia-X ecosystem and to create a level of trust using a decentralized approach. The product fulfills parts of the functionality that an identity provider provides for centralized or federated identity approaches but in a decentralized fashion using concepts of decentralized identity, verifiable credentials, and verifiable presentations. To achieve this goal, components are required that on the one hand allow the management of a participant identity for the creation of signatures for various properties, attributes, and documents, and on the other hand enable the verification of external documents. This includes the creation of verifiable credentials with a corresponding digital signature based on an identity, the issuing of verifiable presentations based on existing and already received verifiable credentials, the requesting of verifiable credentials from third parties for the attestation of own attributes, for example, as well as the validation of incoming connection requests and proof requests. The format used for communication is based on the RFCs described in the W3C [1,2] and OpenID specifications [OIDC] to guarantee a uniform process flow and exchange formats. [1] [https://www.w3.org/TR/did-core/] [2] [https://www.w3.org/TR/vc-data-model/] Product Functions The functions of the Organization Credential Manager W-Stack (OCM.W-STACK) component are provided as a runtime component and MUST expose endpoints as REST services and made accessible over the network using encrypted connections (e.g., HTTPS). The scalability of these services MUST be taken into consideration using well-known and tested concepts like a microservice based architecture and load balancing. Security measures MUST be in place accordingly. This includes the protection of exposed service endpoints, data storage protection and access control. The overall functionality of the OCM.W-STACK component and exposed services MUST be auditable (in compliance with [GDPR]). Figure 1: Architecture (also see appendix B) Please be aware that red boxes have the possibility to be either modified from existing functionality in the Trust Service API (TSA) [IDM.TSA], or can interface directly with the TSA to achieve the required result. Orange boxes encompass external services or components outside the GXFS (GAIA-X Federation Services). Please be aware, that changes on the TSA Signer Service[3] are in scope as well, when the implementation requires it. [3] [https://gitlab.eclipse.org/eclipse/xfsc/tsa/signer] The core functions of the OCM.W-STACK are: Establishing and managing trusted connections between entities (Connections in this context are private, secured, and persistent channels between entities) Creation of connection invitations Handling of incoming connection invitations Managing of existing connections Association of a connection and proven attributes, allowing for a connection that is trusted according to the scope of Gaia-X Handling of verifiable credentials exchanges by using OIDC4VP/VC[4,5] Issuing credentials to participants, principals, assets etc. Handling of incoming Credential proposals Handling of verifiable proof exchanges by using OIDC4VP/VC Requesting and verifying proofs from other entities (e.g., participants) in the ecosystem Handling of incoming proof requests Secure storage of credentials Checking the validity of proof presentations Schema Handling Using JSON LD Schemas from Public Sources and Creating Credential Definitions for it Providing publicly visible and verifiable service endpoints Public Profile: Company information that is made publicly available (e.g., imprint). One aspect that has to be served is the self-description according to Gaia-X, other aspects can be served according to the trust policies of the Participant TrustedList: A list of participants that are trusted by this instance of OCM An architecture for the OCM W-Stack SHOULD look like the following block diagram: [4] [https://openid.net/specs/openid-4-verifiable-credential-issuance-1_0.html] [5] [https://openid.net/specs/openid-4-verifiable-presentations-1_0.html] Figure 2: Architecture Block Diagram Product Constraints [IDM.OCM.W-STACK.00000] The document IDM.AO is the common basis for this functional specification The architecture document \\\"IDM.AO\\\" [IDM.AO] is an essential part of this specification and a prerequisite for understanding the context. The specifications and requirements from the Architecture Document MUST be considered during implementation. [IDM.OCM.W-STACK.00001] Micro Service Architecture For a better scale out and decentralization, the product architecture MUST be a micro service architecture. The modules MUST NOT be tightly integrated into the IAM solution, as Plugin or Extensions, rather should interact with the said system through standard APIs and Protocols. [IDM.OCM.W-STACK.00002] TSA Signer Service The signer service of TSA [6] is reused in this solution, therefore it could be required to do code changes on this solution for implementing the W-Stack functionality. A separate signing implementation is not allowed. [6] [https://gitlab.eclipse.org/eclipse/xfsc/tsa/signer] User Classes and Characteristics User Class Attributes Administrator - Setup, organize, and monitor the system. Integration into the company systems and networks wherever necessary. Low frequency, high expertise, high privilege. Maintenance. Principal - Principals receive credentials to prove affiliation to the organization. Low frequency, low expertise, low privilege. Trusted Connections and Information Exchange. Trust Services - Controls the usage of most OCM functions via policies. High frequency, high expertise, high privilege. Administration of trusted connections and information exchange. Organization Internal Systems - Internal systems provide and consume data to/from the OCM. High frequency, high expertise, low privilege. Information / Trust Sources. External Participants/Principals - Provides data or requests Proofs. High frequency, high expertise, low privilege. Trusted Connections and Information Exchange. Table 2: User Classes and Characteristics Operating Environment Please refer to [TDR] for further binding requirements regarding the operating environment. [IDM.OCM.W-STACK.00003] Kubernetes Environment The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on the provided SCS cluster (Sovereign Cloud Stack), which will be provided by the Client. User Documentation [IDM.OCM.W-STACK.00004] Participant Administration Documentation The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment Description of the Automatic Tests / Verification How to build the products from source code [IDM.OCM.W-STACK.00005] Participant Documentation The documentation MUST contain: Short Software Description/Usage Usage Guide GDPR Design Decisions Security Concept Operations Concept FAQ Keyword Directory Assumptions and Dependencies An understanding of the overall Gaia-X architecture and philosophy is necessary as well as understanding of the OCM architecture and implementation details. Please refer to [TAD] and [PRD]. Attendees of the public tender MUST assume responsibility of: The existing code used and improvements upon the existing code Extending or contributing to the used frameworks in order to provision a way in which realization of the requirements can be achieved Updating dependencies to the latest stable version Requirements External Interfaces Software Interfaces General [IDM.OCM.W-STACK.00006] General Operation Requirements Every component must be able to run as a container. For scalable deployment e.g., a helm chart SHOULD be provided. If database connections are used, it must provide options to run the container \"stand-alone\", e.g., in-memory and with an external, configurable database. [IDM.OCM.W-STACK.00007] Protocol and Definition Requirements All component functions MUST be compliant with W3C standards. Credential exchange MUST follow the [OIDC] SIOP and [OID4VC] specifications. Proof exchange MUST follow [OIDC] SIOP and [OID4VP] specifications. Exchange protocols MUST be developed with extensibility considerations for the purpose of supporting multiple protocols in future iterations. Communications Interfaces General [IDM.OCM.W-STACK.00008] Event Handling A lot of services within the OCM.W-STACK are publishing and receiving events, mostly events in the scope of SSI for the different protocol flows. The way to publish and subscribe these events MUST be consistent throughout the functionality of the OCM.W-STACK and the other lots by using NATS. [IDM.OCM.W-STACK.00009] External Schemas All schemas MUST be defined in the predefined identity network. [IDM.OCM.W-STACK.00010] Rest API All components MUST provide an internal and external Rest API which provides the functionality. External APIs MUST be protected by a JWT mechanism. Hardware Interfaces [IDM.OCM.W-STACK.00011] Hardware Encryption An option to securely create, store and access cryptographic material MUST be provided (e.g., HSM, Vault, Keymanager). Functional The Implementer MUST fill the functional gaps between different components, even if they are not specified, to ensure a fluent workflow for administration, security, operation, compliance of the OCM.W-STACK. General [IDM.OCM.W-STACK.00012] Authenticate Endpoints The use of endpoints provided by the OCM.W-STACK should be available by providing valid authentication that is in consideration with the [IDM.AA] services especially for using the OIDC flows. [IDM.OCM.W-STACK.00013] DID Configuration Provision The OCM MUST provide to a configured URL an DID Configuration according to the Identity Foundation specification [7]. [7] [https://identity.foundation/specs/did-configuration/] [IDM.OCM.W-STACK.00014] DID Document Resolving The DID Document of the OCM MUST be resolvable by the Universal Resolver and it MUST contain all key material used by the OCM including all endpoints following this service configuration format by enhancing the W3C spec [8]: [8] [https://www.w3.org/TR/did-core/#example-usage-of-the-service-property] > { > > id: {idName} > > type: {typeName}, > > accept: \\[\"didcomm/v2\",\"didcomm/v1\",{otherProtocols}\\], > > serviceEndpoint:\\[\"https://...\"\\] > > } > [IDM.OCM.W-STACK.00015] NATS Eventing All actions of the OCM MUST be published via NATS to support external consumers in their actions. The event names and payloads MUST follow one standardized structure for eventing (e.g., cloud events pattern) [IDM.OCM.W-STACK.00016] General Microservice Structure All functional blocks MUST be encapsulated in microservices to ensure that the system asymmetrically scales. It MUST be ensured, that for example querying credentials can be outscaled without scaling the resources for issuing. The outage protection MUST be designed in the same way. It MUST be possible to switch off for example the issuing, without affecting the reading. The architecture for this structure MUST be clarified with the principal. [IDM.OCM.W-STACK.00017] Multi Tenancy The component MUST support multi tenancy with possibility to scale down to zero. [IDM.OCM.W-STACK.00018] Selective Disclosure JWT The component MUST support Selective Disclosure JWT described in the specification [9]. [9] [https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/] Connection Manager [IDM.OCM.W-STACK.00019] Create Connection Endpoints The Connection Manager MUST provide a Create Invitation endpoint as well as a connection acceptance endpoint. The response body is composed of JSON content. A connection SHOULD be accepted and made consumable only if the Trusted Content Resolver responds accordingly. [IDM.OCM.W-STACK.00020] Connection Information Endpoint/s The Connection Manager MUST provide a connection information endpoint where other components can request if a connection for a specific DID/ID already exists. The endpoint supports as input a ConnectionID or a DID as well as a flag for \"all-information\" which also covers all received presentations and issued credentials and responds with existing information (connection status, ConnectionID, if requested additional information) or nothing if it does not exist. An endpoint or the same endpoint without parameters must be provided to return all connections. [IDM.OCM.W-STACK.00021] Connection Status The Connection Manager MUST provide a function that allows a component to subscribe/unsubscribe for connection events to receive updates when the status changes. A list of subscribers MUST be in place and maintained based on the respective implementation. (subscribe, unsubscribe MUST be possible). This functionality of publishing events SHOULD be provided via a REST service, but a message bus system can also be considered. [IDM.OCM.W-STACK.00022] Connection Update The Connection Manager MUST provide an endpoint that allows a component to update a connection entry by connectionID or DID. [IDM.OCM.W-STACK.00023] Connection Deletion The Connection Manager MUST provide an endpoint that allows a component to delete a connection entry by connectionID or DID. If a connection is deleted, it MUST not affect Verifiable Credential or Verifiable Presentation exchanges that have already taken place over it. [IDM.OCM.W-STACK.00024] Block Connection The Connection Manager MUST provide a Block Connection endpoint. The endpoint should accept either connection ID or DID. It should mark the connection as 'blocked' in the Connection storage. [IDM.OCM.W-STACK.00025] Refuse blocked connections The Connection Manager MUST refuse connections if they match the connection ID or DID of a connection in the storage, which has been marked as 'blocked'. The response of an unsuccessful connection in this case should include the reason for refusal in the response message. [IDM.OCM.W-STACK.00026] TSA Interface The Connection Manager MUST support the interface with the TSA in order to get a decision whether a connection should be accepted or not. Credential Manager [IDM.OCM.W-STACK.00027] Get Credentials The Credential Manager MUST provide an endpoint to request existing credentials inside the storage of the OCM. This request MUST support a simple query language or offer query/path parameters to query for credentials based on schemas, issuer DIDs, attribute names, attribute values, or an internal CredentialID. [IDM.OCM.W-STACK.00028] Open Credential Requests/Offerings The Credential Manager MUST provide an endpoint to list the open requests and offerings by connection. Issue Credential [IDM.OCM.W-STACK.00029] Credential Issue Endpoint The Credential Manager MUST provide an endpoint to allow the request for issuing a credential for a specific subject DID from another component. The endpoint expects the following attributes as payload Subject DID Schema Claims for Credential Additional Information like expiration date, dispute endpoints etc. What is specified in [W3C] Whether the credential should be automatically refreshed Constraints: A connection for the provided subject DID MUST be established before. Issuance of credentials to external subject DIDs require a \"trusted\" state of the connection existing (by utilizing the Trustlist Manager). It MUST follow the [OIDC] credential exchange specification. [IDM.OCM.W-STACK.00030] Credential Status The Credential Manager MUST provide a way to receive updates for an ongoing issue credential process. Constraints: A credential issue process already has been started Dispute Credential [IDM.OCM.W-STACK.00031] Credential Dispute The Credential Manager MUST provide an Endpoint or a function to allow the request for disputing a credential for a specific subject DID from another component. Reissuance of credentials to external subject DIDs still require a \"trusted\" state of the connection existing (by utilizing the Trusted Content Resolver Interface). Revoke Credential [IDM.OCM.W-STACK.00032] Credential Revocation The Credential Manager MUST provide a function to allow the revocation of a credential for a specific issuer DID from another component once the expiration condition has been met. The endpoint SHOULD follow the [[W3C]]. Reissuance of credentials to external subject DIDs still require a \"trusted\" state of the connection existing (by utilizing the Trustlist Manager). Additionally, the component MUST prepare an hash-based revocation which is calculated over the proof of the credential in the following way: For RSA signature a SHA256 hash is calculated over the entire signature in raw byte format For EC-DSA Signature the SHA256 hash is calculated over the r value of the proof signature The revocation endpoint MUST provide this calculated hash of W3C credentials [10] to an internal storage grouped by Issuer DID which has an internal interface to read the hashes for later integration (later integration is out of scope for this tender). [10] [www.w3.org/TR/vc-data-model/] [IDM.OCM.W-STACK.00033] Credential Refresh Endpoint The Credential Manager MUST provide an Endpoint to allow the reissuance of a revoked credential for a specific subject DID from another component once the expiration condition has been met. The credential MUST follow the exact structure of the previously issued credential. The refresh endpoint can be included in the VC. Reissuance of credentials to external subject DIDs still require a \"trusted\" state of the connection existing (by utilizing the Trustlist Manager). [IDM.OCM.W-STACK.00034] Credential Refresh Function The Credential Manager MUST provide a function to allow the reissuance of a revoked credential for a specific subject DID from another component once the expiration condition has been met and the credential has been marked as valid for automatic reissuance. The credential MUST follow the exact structure of the previously issued credential. Reissuance of credentials to external subject DIDs still require a \"trusted\" state of the connection existing (by utilizing the Trustlist Manager). Prove Credential [IDM.OCM.W-STACK.00035] Presentation Request The Credential Manager MUST provide an endpoint to request a presentation over an existing connection. If the holder DID for the request is a Participant and no connection exists, a trusted connection MUST be established beforehand. The relevant payload or attributes for the request as well as the connection or a DID for the request MUST be provided. The Credential Manager can also receive presentation requests and MUST respond with the respective Verifiable Presentation/s. All presentations must be checked for revocation state. [IDM.OCM.W-STACK.00036] Presentation Status The Credential Manager MUST provide a way for a component to subscribe/unsubscribe for Presentation event updates when new Presentations are received or the status changes. A list of subscribers for a specific connectionID MUST be in place and maintained based on the respective implementation. This functionality of publishing events SHOULD be provided via a REST service, but a message bus system can also be considered. Credential Types [IDM.OCM.W-STACK.00037] Public Credential The Credential Manager MUST provide an endpoint for a component to modify a credential to contain a value which configures whether credentials can be public or not (e.g., the participant credential). It MUST be allowed to be public through a policy in the Trust Services. [IDM.OCM.W-STACK.00038] Credential Type The Credential Manager MUST provide an endpoint to configure credential types used for issuing. The type refers to a specific schema that is used for the issuing of the credential. Its intended purpose is ease of use in the process of operating the organization. Credential and Connection Storage [IDM.OCM.W-STACK.00039] Credential / Connection Storing Once a connection has been created it MUST be stored in a database. Once a credential has been issued, the resulting JSON structure with its corresponding values MUST also be stored in the database. [IDM.OCM.W-STACK.00040] Credential / Connection Querying The Credential and Connection Storage MUST provide a way for components to query the storage with the Create, Read, Update, Delete operations. [IDM.OCM.W-STACK.00041] Credential Storage Scaling The Credential Storage MUST be highly scalable for read operations to allow high intensive parallel reads (e.g., for reporting or analysis similar to Digital Product Pass or Supply Chain Tracking/Tracing). [IDM.OCM.W-STACK.00042] Credential Storage Graph Indexing The Credential Storage MUST support the chaining of VCs by using Graph Technologies and Queries to support the chaining of credentials e.g., for provenance proofs. [IDM.OCM.W-STACK.00043] Storage Microservice Structure The Credential Storage functionality MUST be separated in a micro service for the graph functionality as well for high scalable storage for VCs/VP. Especially the chaining of VCs, SHOULD be a separated service to avoid the mixing of Graph Technology, Proof Formats and Common Database Technology. If this is not possible, an alternative solution MUST be provided which fulfills the goal of splitting the functionality in specialized services. The general goal MUST be to provide microservices which are able to extract a graph of Json objects belonging to a key (e.g. ID), provide high scalable storage to read Json objects (e.g. a document based storage), provide an component which is able to sign a graph, provide a component which is able to visualize and filter the existing content, provide credential encryption and an appropriate key management solution (e.g. Hashicorp Vault). [IDM.OCM.W-STACK.00044] Storage Content All credentials or presentations MUST be stored as JSON-LD. It's not allowed to serialize the JSON objects by using (ORM) Mappers e.g., NHibernate. Technical optimizations of storing the documents is allowed (e.g., by using BSON), but it MUST be ensured that the graph building and data analysis is not lacking in performance (e.g., by using postgres JSON Objects, which support just basic queries, but no JSON object aggregation/manipulation). DID Document Manager [IDM.OCM.W-STACK.00045] Create DID Creates a DID that will be used for identifying and resolving to a DID Document. [IDM.OCM.W-STACK.00046] Create Public Profile Endpoint Creates and publishes the Public Profile Endpoint. It serves the Self-Description of the organization. It is composed of all the Verifiable Credentials that the administrators or the Trust Services mark as \"public\". [IDM.OCM.W-STACK.00047] Update Public Profile Endpoint Updates the Public Profile Endpoint. [IDM.OCM.W-STACK.00048] Delete Public Profile Endpoint Deletes the Public Profile Endpoint. [IDM.OCM.W-STACK.00049] Append Terms of Use Each Participant should have terms of use listed in the public DID Document. It can be achieved through exposing an endpoint that appends a link to the terms of use. [IDM.OCM.W-STACK.00050] Append Service Endpoints Each Participant should have service endpoints listed in the public DID Document. Another Service Endpoints MUST dynamically addable by an interface e.g., a refresh service endpoint that allows refreshing of credentials issued by the OCM. [IDM.OCM.W-STACK.00051] Write, Update, Delete DID Document Endpoints The DID Document Manager MUST have three endpoints that allow writing, updating, and deleting of the public DID Document. [IDM.OCM.W-STACK.00052] TSA Interface The DID Document Manager should interface with the TSA for choosing what information is listed in the public DID Document. [IDM.OCM.W-STACK.00053] DID Document Storage The DID Document Storage MUST provide interfaces for [EBSI] and IPFS to anchor DID Documents within these systems when the features are enabled. In the case of not using these features DID Web as a Service [11] (generating DID Documents on the fly) built on TSA basis MUST be the default for generating and managing DID documents. [11] [https://gitlab.com/gaia-x/gaia-x-community/gx-hackathon/gx-hackathon-6/-/tree/main/DIDAsAService] Credential Signing and Verification This component must implement and extend the needed functionality of the Trust Services API. [IDM.OCM.W-STACK.00054] Credential Signer The Credential Signer MUST be an endpoint that allows signing of Verifiable Credentials and other messages with different types of proof: QES proof Linked proof Provenance proof Selective Disclosure proofs (e.g., BBS+ [12]) Other proofs [12] [https://identity.foundation/bbs-signature/draft-irtf-cfrg-bbs-signatures.html] [IDM.OCM.W-STACK.00055] Credential Verifier The Credential Verifier MUST be an endpoint that allows verifying of Verifiable Credentials and other messages with different types of proof: QES proof Linked proof Provenance proof Selective Disclosure proof (e.g., BBS+) Other proofs Secrets Management This component MUST be modified from the already existing \"signing\" service in the Trust Services API. All cryptographic material MUST be [eIDAS] compliant. [IDM.OCM.W-STACK.00056] QES Signatures A concept to support QES MUST be implemented and documented. [IDM.OCM.W-STACK.00057] Create Secrets The Secrets Management Service MUST be able to create and store secret cryptographic material without releasing the private key or using seeds which can be leaked. In general, the secret handling MUST be adoptable by HSMs or other existing IT security infrastructure. [IDM.OCM.W-STACK.00058] HSM modularity The Secrets Management Service MUST be able to use interchangeably or allow the modular replacement of different Hardware Security Modules and/or secret storages by implementing the signing/verification of signatures in separate modules. Schema Manager [IDM.OCM.W-STACK.00059] Trusted Schema Content API The Schema Manager Service MUST expose endpoint/s that allow the management of schemas (e.g., Create, Update, Get, Resolve schema) to dock different APIs for schema creation like EBSI. [IDM.OCM.W-STACK.00060] Trusted Schema Management The Schema Manager MUST be able to Create, Update, Get and Resolve schema content through the Verifiable Ledger Abstraction. [IDM.OCM.W-STACK.00061] Verifiable Ledger Abstraction The Verifiable Ledger Abstraction interfaces with and links Schema Manager and the Credential Schema Verifier. It must implement a level of abstraction that allows interchangeability and, if possible, interoperability between different verifiable ledgers. [EBSI] MUST be one of the options for a verifiable ledger. Nonfunctional Requirements Performance Requirements [IDM.OCM.W-STACK.00062] Up/Down Scale All components MUST be able to scale up/down their functionality for a undefined number of instances. This requires a parallel execution possibility. Safety Requirements [IDM.OCM.W-STACK.00063] Major Releases All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening. Security Requirements [IDM.OCM.W-STACK.00064] CVE Patches All software components MUST have applied CVE patches, which are available for major releases. Software Quality Attributes [IDM.OCM.W-STACK.00065] Software Quality Requirements All software components MUST be compliant to the requirements within the quality assurance repository [13]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology. [13] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues] Business Rules [IDM.OCM.W-STACK.00066] Software Consistency The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc. [IDM.OCM.W-STACK.00067] Cherry Picking All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow an enterprise deployment customization. Compliance [IDM.OCM.W-STACK.00068] GDPR Audit Logging All GDPR relevant access to personal relevant data MUST be logged for a later audit. [IDM.OCM.W-STACK.00069] GDPR Data Processing It is necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable. Design and Implementation Installation [IDM.OCM.W-STACK.00070] Helm/Argo CD Deployment All installations MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a Argo CD Pipeline defined in the gxfs-integration repository [14]. [14] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Configuration [IDM.OCM.W-STACK.00071] Configuration All components MUST support one of the major configuration formats (yaml, Json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged. Distribution [IDM.OCM.W-STACK.00072] Helm Repositories All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [15]. [15] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml] [IDM.OCM.W-STACK.00073] Istio Resources Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc. ) following the integration pattern specified in the gxfs-integration repo [16]. [16] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Service Meshing [IDM.OCM.W-STACK.00074] Istio Support All HELM charts MUST be provided with Istio support aligned together with the project team. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment. Standard Technology [IDM.OCM.W-STACK.00075] Default Toolstack Each development MUST consider the following standard technologies if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React 17 Ingress Controller Nginx/Istio API Testing Postman (manual) Kubernetes v1.26+ API Design OpenAPI [17] [https://react-bootstrap.github.io/] Table 3: Technology Stack The technology stack is mandatory to avoid integration impact. Metrics [IDM.OCM.W-STACK.00076] Opentelemtry Support All helm charts/services MUST provide metrics endpoints in opentelemetry [18] format. [18] [https://opentelemetry.io/docs/] Configurability [IDM.OCM.W-STACK.00077] Configuration Profiles Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening [IDM.OCM.W-STACK.00078] Secret References in Helm Charts The configuration secrets within Helm Charts MUST use secretRefs to support external Secretmanagement. Clear text secrets within the Helm Charts are not allowed. Maintainability [IDM.OCM.W-STACK.00079] Micro Service Architecture For a better scale out, maintainability and decentralization, the product architecture MUST have a micro service architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement it. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment). [IDM.OCM.W-STACK.00080] Domain Driven Design To support the micro service architecture within the maintainability, it MUST be declared a domain model before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers. Reusability [IDM.OCM.W-STACK.00081] Enterprise Environments All components MUST be reusable in different enterprise environments by customization and whitelabeling. Means all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.) Runtime Stability [IDM.OCM.W-STACK.00082] Readiness Check Ups All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: An unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state High Availability Concepts [IDM.OCM.W-STACK.00083] Redundant Deployment Each deployment MUST be configured for a minimum fault tolerance of 2 instances. Proof of Concept [IDM.OCM.W-STACK.00084] Architecture Changes All Architecture Changes MUST be aligned with the Principal before implementation. System Features Connection Management Service Description - Connection Management Service The Connection Management Service should contain all the needed functions for establishing, maintaining, querying, and using connections to other organizational and personal agents. The individual requests are forwarded to the trust service component for validation and assessment of whether corresponding connections may be established and processed. The other components of the OCM.W-STACK can retrieve information regarding existing connection requests and inform themselves about the current status of the connections. Functional Requirements - Connection Management Service Endpoints Create Connection Endpoint Connection Information Endpoint Connection Update Connection Deletion Block Connection Functions Connection Status Refuse blocked connections Trusted Content Resolver Interface Table 4: Functional Requirements Connection Manager Credential Management Service Description - Credential Management Service The Credential Management Service is the component responsible for issuing, managing, revoking, and maintaining all credentials, as well as managing their proofs. Functional Requirements - Credential Management Service Credential Dispute Endpoints Get Credentials Credential Issue Endpoint Credential Refresh Endpoint Presentation Request Public Credential Credential Type Functions Credential Status Credential Revocation Credential Refresh Function Presentation Status Table 5: Functional Requirements Credential Manager Credential and Connection Storage Description - Credential and Connection Storage The Credential and Connection Storage is a secure storage for the credential and connection JSON structures. Functional Requirements - Credential and Connection Storage Credential / Connection Storing Credential / Connection Querying Table 6: Functional Requirements Connection Manager DID Document Management Service Description - DID Document Management Service The DID Document of the Participant is the description that is publicly available and consists of data such as (but not limited to): Participant Public profile, Terms of use, Service endpoint, other necessary information for the purposes of integration with the other lots. The Public Profile is an endpoint listed in the DID Document of the Participant. It returns a JSON-LD Verifiable Presentation that contains various Verifiable Credentials - those VC, the Participant marked as publicly available. The Self-Description served by the Public Profile can be extended through additional JSON-LD contexts. Functional Requirements - DID Document Management Service Endpoints / Functions Endpoints Create Public Profile Endpoint Update Public Profile Endpoint Delete Public Profile Endpoint Append Terms of Use Append Service Endpoint Write, Update, Delete DID Document Endpoints Functions Create DID TSA Interface Table 7: Functional Requirements DID Document Manager Credential Signing and Verification Service Description - Credential Signing and Verification Service The Credential Signing and Verification Service should be able to generate different types of proofs on Verifiable Credentials and other messages as well as verify them. Functional Requirements - Credential Signing and Verification Service Endpoints Credential Signer Credential Verifier Table 8: Functional Requirements Credential Signing and Verification Service Schema Management Service Description - Schema Management Service The Schema Management Service is responsible for interfacing with the external Verifiable Ledgers. Functional Requirements - Schema Management Service Endpoints Trusted Schema Content API Functions Trusted Schema Management Verifiable Ledger Abstraction Table 9: Functional Requirements Schema Management Service Verification [IDM.OCM.W-STACK.00085] Behavior Driven Design Verification of fulfillment of the requirements and characteristics MUST be done using automated tests which are part of the deliverables. They SHOULD be done by patterns of the Behavior Driven Development [BDD] using the \"Gherkin Syntax\". [IDM.OCM.W-STACK.00086] Test Environment All functionalities MUST be demonstrated in a test environment within a sandbox, with the following infrastructure components: Load Balancer, e.g., HAProxy API Gateway, e.g., Kong Service Mesh, e.g., Linkerd/Istio DNS Multiple Servers Firewalls All tests MUST be passed in this test environment. [IDM.OCM.W-STACK.00087] Load Tests Scalability and Performance around the high workload scenarios MUST be demonstrated, by using any kind of Load Test Framework for HTTP APIs. [IDM.OCM.W-STACK.00088] Automated Integration Tests Automation Integration tests must be created, and they must be runnable by a CI job. [IDM.OCM.W-STACK.00089] Kubernetes Deployment If the verification is related to software components, it must be deployed in a Kubernetes test cluster and the components must be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration. [IDM.OCM.W-STACK.00090] Eventing All eventings must be demonstrated on basis of cloud events [Cloud Events] specifications together with the kNative [19] broker together with NATS in a KKubernetes environment. [19] [https://knative.dev/docs/eventing/] [IDM.OCM.W-STACK.00091] Config Map Support Each service must be demonstrated up and running in kubernetes, configured by config maps. [IDM.OCM.W-STACK.00092] Helm Installation The service installation MUST be demonstrated during HELM install. [IDM.OCM.W-STACK.00093] ArgoCD Integration The helm chart MUST be able to install inside of Argo CD. This includes the usage of the postgres hooks [20]and the providing of usable values.yaml(s) for all developed services. [20] [https://gitlab.eclipse.org/eclipse/xfsc/integration/-/tree/main/helm/charts/postgresql-hook] [IDM.OCM.W-STACK.00094] SCS Environment All HELM installations MUST run on SCS (Sovereign Cloud Stack). The final acceptance demonstration cannot be realized on azure, google cloud etc. Acceptance Criteria General - Acceptance Criteria [IDM.OCM.W-STACK.00095] General Operation Requirements Components run as containers and a helm chart is provided. [IDM.OCM.W-STACK.00096] Protocol and Definition Requirements All relevant components and functions are compliant with [W3C], and [OIDC] specifications. [IDM.OCM.W-STACK.00097] Event Handling Events are published and consumed to enable the needed functionality. [IDM.OCM.W-STACK.00098] External Schemas Schemas are defined in the external network and are resolvable. [IDM.OCM.W-STACK.00099] Hardware Encryption An interface with an HSM is provided. [IDM.OCM.W-STACK.00100] Authenticate Endpoints A middleware for authentication in order to use the exposed endpoints is provided as well as the possibility to be integrated with the [IDM.AA] Services. Connection Manager - Acceptance Criteria [IDM.OCM.W-STACK.00101] Create Connection Endpoint A connection is created and validated. [IDM.OCM.W-STACK.00102] Connection Information Endpoint/s By providing identifiable data for a specific connection all relevant information and metainformation is returned, or alternatively - by not providing identifiable data, all connections are returned with the minimum identifiable data to allow the specific search of information. [IDM.OCM.W-STACK.00103] Connection Status The connection status attribute exists and when changed is handled through events. [IDM.OCM.W-STACK.00104] Connection Update The required connection field is updated and reflected properly. [IDM.OCM.W-STACK.00105] Connection Deletion A specific connection or a group of connections based on a condition are deleted from the connection storage. [IDM.OCM.W-STACK.00106] Block Connection The specified connection is marked as 'blocked'. [IDM.OCM.W-STACK.00107] Refuse blocked connections Interactions over the connections marked as 'blocked' are not fulfilled. [IDM.OCM.W-STACK.00108] Trusted Content Resolver Interface The Connection Manager interfaces with the Trusted Content Resolver at the appropriate place/s. But at least for resolving DIDs and trust lists. Credential Manager - Acceptance Criteria [IDM.OCM.W-STACK.00109] Get Credentials Credentials in the Credential Storage are returned, and filtering based on a condition is possible. Issue Credential - Acceptance Criteria [IDM.OCM.W-STACK.00110] Credential Issue Endpoint Credentials are issued and are compliant with the [OID4VC] specifications. [IDM.OCM.W-STACK.00111] Credential Status Credentials' statuses exist, are updated, and handled through events. Dispute Credential - Acceptance Criteria [IDM.OCM.W-STACK.00112] Credential Dispute Credential dispute is available and done according to [W3C] specifications. Revoke Credential - Acceptance Criteria [IDM.OCM.W-STACK.00113] Credential Revocation Credential revocation is available and done according to [W3C] specifications. [IDM.OCM.W-STACK.00114] Credential Refresh Endpoint Existing credentials can be reissued with the same attributes to the same DID / wallet. [IDM.OCM.W-STACK.00115] Credential Refresh Function Existing credentials can be automatically reissued based on a property of the previously issued credential. Prove Credential - Acceptance Criteria [IDM.OCM.W-STACK.00116] Presentation Requests A presentation request is sent, and if no connection to the presenter exists, it is created. A presentation can also be sent as a response to a request. [IDM.OCM.W-STACK.00117] Presentation Status Presentation status attribute exists and is handled accordingly through events. Credential Types - Acceptance Criteria [IDM.OCM.W-STACK.00118] Public Credential Credentials can be marked as public and be able to access from outside the cluster. [IDM.OCM.W-STACK.00119] Credential Type Credential types are existing and are bound to specific schemas. The issuing is able to use it. Credential and Connection Storage - Acceptance Criteria [IDM.OCM.W-STACK.00120] Credential / Connection Storing Credentials and Connections are stored. [IDM.OCM.W-STACK.00121] Credential / Connection Querying Credentials and Connections can be queried. DID Document Manager - Acceptance Criteria [IDM.OCM.W-STACK.00122] Create DID A DID is created and the document is resolvable over the universal resolver. The document contains valid key material of the OCM. [IDM.OCM.W-STACK.00123] Create Public Profile Endpoint A Public Profile Endpoint exists and serves the Self-Declaration of the organization in the format of signed VP. [IDM.OCM.W-STACK.00124] Update Public Profile Endpoint The Public Profile Endpoint can be updated successfully, and the endpoints are available in the DID Documents during resolving. [IDM.OCM.W-STACK.00125] Delete Public Profile Endpoint The Public Profile Endpoint can be deleted successfully and the did document does not contain the endpoint anymore after resolving. [IDM.OCM.W-STACK.00126] Append Terms of Use The Terms of Use can be linked successfully to a trust zone and a credential contains the correct values during issuing. [IDM.OCM.W-STACK.00127] Append Evidence The Evidence Section can be linked successfully, and a credential contains the correct values during issuing. [IDM.OCM.W-STACK.00128] Append Dispute The Dispute Section can be linked successfully, and a credential contains the correct values during issuing. [IDM.OCM.W-STACK.00129] Append Service Endpoints Service Endpoints can be linked successfully, and the document contains the configured type and the configured endpoints. [IDM.OCM.W-STACK.00130] Write, Update, Delete DID Document Endpoints Endpoints for the manipulation of the DID Document exist and the did document contains the configured service endpoints after the endpoint was used. [IDM.OCM.W-STACK.00131] TSA Interface The DID Document Manager interfaces with the TSA at the appropriate times / places, if applicable. TSA is used to verify incoming connection for blacklist entries, incoming DID, IP address etc. and TSA is used for issuing/receiving credentials for trusted parties and connections. Credential Signing and Verification - Acceptance Criteria [IDM.OCM.W-STACK.00132] Credential Signer The Credential Signer successfully signs a Credential with an eIDAS compliant signature which is verifiable with the DSS framework[21]. [21] [https://ec.europa.eu/digital-building-blocks/DSS/webapp-demo/doc/dss-documentation.html] [IDM.OCM.W-STACK.00133] Credential Verifier The Credential Verifier successfully proves the signature on a Credential by using the DSS Framework. Secrets Management - Acceptance Criteria [IDM.OCM.W-STACK.00134] Create Secrets The Secrets Management Service successfully creates and stores secret cryptographic material. [IDM.OCM.W-STACK.00135] QES Signatures The concept is prepared, and connectable to a QES TSP. [IDM.OCM.W-STACK.00136] Secret Engine Selection The implementation MUST be able to support multiple secret engines to support multi tenancy. This SHOULD be realized by inserting the used hashicorp vault secret engine name into the rest API calls. [IDM.OCM.W-STACK.00137] TSA Service All signing and verification operations MUST be done over the TSA Signing/Verification Service. These services using the hashicorp vault transit engine, which MUST be in any case the solution for signing and verification purposes. Schema Management - Acceptance Criteria [IDM.OCM.W-STACK.00138] Trusted Schema Content API The exposed endpoints are demonstrated to effectively and securely create, update, get and resolve schemas. [IDM.OCM.W-STACK.00139] Trusted Schema Management The create, update, get and resolve functionality is securely accessible through the endpoints. [IDM.OCM.W-STACK.00140] Verifiable Ledger Abstraction Schemas are created, resolvable and read on the verifiable ledger, one of which is [EBSI]. Schemas are also creatable and resolvable from IPFS Gateways and from Webservers. Nonfunctional - Acceptance Criteria [IDM.OCM.W-STACK.00141] Performance Scalability The services are demonstrated to be scalable. [IDM.OCM.W-STACK.00142] GDPR Audit Logging Access to [GDPR] specific personal data is specified. [IDM.OCM.W-STACK.00143] GDPR Data Processing [GDPR] relevant personal data used in business processes is described and deleted (if applicable). Appendix A: Glossary For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO] Appendix B: Architecture","title":"Organization Credential Manager W-STACK"},{"location":"ocmwstack/ocmwstack/#software-requirements-specification-for-gaia-x-federation-services-organization-credential-manager-w-stack-idmocmw-stack","text":"Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA","title":"Software Requirements Specification for Gaia-X Federation Services Organization Credential Manager       W-STACK IDM.OCM.W-STACK"},{"location":"ocmwstack/ocmwstack/#1-introduction","text":"","title":"1  Introduction"},{"location":"ocmwstack/ocmwstack/#11-document-purpose","text":"","title":"1.1  Document Purpose"},{"location":"ocmwstack/ocmwstack/#12-product-scope","text":"","title":"1.2  Product Scope"},{"location":"ocmwstack/ocmwstack/#13-definitions-acronyms-and-abbreviations","text":"","title":"1.3  Definitions, Acronyms and Abbreviations"},{"location":"ocmwstack/ocmwstack/#14-references","text":"","title":"1.4  References"},{"location":"ocmwstack/ocmwstack/#15-document-overview","text":"","title":"1.5  Document Overview"},{"location":"ocmwstack/ocmwstack/#2-product-overview","text":"","title":"2  Product Overview"},{"location":"ocmwstack/ocmwstack/#21-product-perspective","text":"","title":"2.1  Product Perspective"},{"location":"ocmwstack/ocmwstack/#22-product-functions","text":"","title":"2.2  Product Functions"},{"location":"ocmwstack/ocmwstack/#23-product-constraints","text":"","title":"2.3  Product Constraints"},{"location":"ocmwstack/ocmwstack/#24-user-classes-and-characteristics","text":"","title":"2.4  User Classes and Characteristics"},{"location":"ocmwstack/ocmwstack/#25-operating-environment","text":"","title":"2.5  Operating Environment"},{"location":"ocmwstack/ocmwstack/#26-user-documentation","text":"","title":"2.6  User Documentation"},{"location":"ocmwstack/ocmwstack/#27-assumptions-and-dependencies","text":"","title":"2.7  Assumptions and Dependencies"},{"location":"ocmwstack/ocmwstack/#3-requirements","text":"","title":"3  Requirements"},{"location":"ocmwstack/ocmwstack/#31-external-interfaces","text":"","title":"3.1  External Interfaces"},{"location":"ocmwstack/ocmwstack/#311-software-interfaces","text":"","title":"3.1.1  Software Interfaces"},{"location":"ocmwstack/ocmwstack/#312-communications-interfaces","text":"","title":"3.1.2  Communications Interfaces"},{"location":"ocmwstack/ocmwstack/#313-hardware-interfaces","text":"","title":"3.1.3  Hardware Interfaces"},{"location":"ocmwstack/ocmwstack/#32-functional","text":"","title":"3.2  Functional"},{"location":"ocmwstack/ocmwstack/#321-general","text":"","title":"3.2.1  General"},{"location":"ocmwstack/ocmwstack/#33-nonfunctional-requirements","text":"","title":"3.3  Nonfunctional Requirements"},{"location":"ocmwstack/ocmwstack/#331-performance-requirements","text":"","title":"3.3.1  Performance Requirements"},{"location":"ocmwstack/ocmwstack/#332-safety-requirements","text":"","title":"3.3.2  Safety Requirements"},{"location":"ocmwstack/ocmwstack/#333-security-requirements","text":"","title":"3.3.3  Security Requirements"},{"location":"ocmwstack/ocmwstack/#334-software-quality-attributes","text":"","title":"3.3.4  Software Quality Attributes"},{"location":"ocmwstack/ocmwstack/#335-business-rules","text":"","title":"3.3.5  Business Rules"},{"location":"ocmwstack/ocmwstack/#34-compliance","text":"","title":"3.4  Compliance"},{"location":"ocmwstack/ocmwstack/#35-design-and-implementation","text":"","title":"3.5  Design and Implementation"},{"location":"ocmwstack/ocmwstack/#351-installation","text":"","title":"3.5.1  Installation"},{"location":"ocmwstack/ocmwstack/#352-configuration","text":"","title":"3.5.2  Configuration"},{"location":"ocmwstack/ocmwstack/#353-distribution","text":"","title":"3.5.3  Distribution"},{"location":"ocmwstack/ocmwstack/#354-service-meshing","text":"","title":"3.5.4  Service Meshing"},{"location":"ocmwstack/ocmwstack/#355-standard-technology","text":"","title":"3.5.5  Standard Technology"},{"location":"ocmwstack/ocmwstack/#356-metrics","text":"","title":"3.5.6  Metrics"},{"location":"ocmwstack/ocmwstack/#357-configurability","text":"","title":"3.5.7  Configurability"},{"location":"ocmwstack/ocmwstack/#358-maintainability","text":"","title":"3.5.8  Maintainability"},{"location":"ocmwstack/ocmwstack/#359-reusability","text":"","title":"3.5.9  Reusability"},{"location":"ocmwstack/ocmwstack/#3510-runtime-stability","text":"","title":"3.5.10 Runtime Stability"},{"location":"ocmwstack/ocmwstack/#3511-high-availability-concepts","text":"","title":"3.5.11 High Availability Concepts"},{"location":"ocmwstack/ocmwstack/#3512-proof-of-concept","text":"","title":"3.5.12 Proof of Concept"},{"location":"ocmwstack/ocmwstack/#4-system-features","text":"","title":"4  System Features"},{"location":"ocmwstack/ocmwstack/#41-connection-management-service","text":"","title":"4.1  Connection Management Service"},{"location":"ocmwstack/ocmwstack/#411-description","text":"","title":"4.1.1  Description"},{"location":"ocmwstack/ocmwstack/#412-functional-requirements","text":"","title":"4.1.2  Functional Requirements"},{"location":"ocmwstack/ocmwstack/#42-credential-management-service","text":"","title":"4.2  Credential Management Service"},{"location":"ocmwstack/ocmwstack/#421-description","text":"","title":"4.2.1  Description"},{"location":"ocmwstack/ocmwstack/#422-functional-requirements","text":"","title":"4.2.2  Functional Requirements"},{"location":"ocmwstack/ocmwstack/#43-credential-and-connection-storage","text":"","title":"4.3  Credential and Connection Storage"},{"location":"ocmwstack/ocmwstack/#431-description","text":"","title":"4.3.1  Description"},{"location":"ocmwstack/ocmwstack/#432-functional-requirements","text":"","title":"4.3.2  Functional Requirements"},{"location":"ocmwstack/ocmwstack/#44-did-document-management-service","text":"","title":"4.4  DID Document Management Service"},{"location":"ocmwstack/ocmwstack/#441-description","text":"","title":"4.4.1  Description"},{"location":"ocmwstack/ocmwstack/#442-functional-requirements","text":"","title":"4.4.2  Functional Requirements"},{"location":"ocmwstack/ocmwstack/#45-credential-signing-and-verification-service","text":"","title":"4.5  Credential Signing and Verification Service"},{"location":"ocmwstack/ocmwstack/#451-description","text":"","title":"4.5.1  Description"},{"location":"ocmwstack/ocmwstack/#452-functional-requirements","text":"","title":"4.5.2  Functional Requirements"},{"location":"ocmwstack/ocmwstack/#46-schema-management-service","text":"","title":"4.6  Schema Management Service"},{"location":"ocmwstack/ocmwstack/#461-description","text":"","title":"4.6.1  Description"},{"location":"ocmwstack/ocmwstack/#462-functional-requirements","text":"","title":"4.6.2  Functional Requirements"},{"location":"ocmwstack/ocmwstack/#5-verification","text":"","title":"5  Verification"},{"location":"ocmwstack/ocmwstack/#51-acceptance-criteria","text":"","title":"5.1  Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#511-general","text":"","title":"5.1.1  General"},{"location":"ocmwstack/ocmwstack/#512-connection-manager","text":"","title":"5.1.2  Connection Manager"},{"location":"ocmwstack/ocmwstack/#513-credential-manager","text":"","title":"5.1.3  Credential Manager"},{"location":"ocmwstack/ocmwstack/#514-issue-credential","text":"","title":"5.1.4  Issue Credential"},{"location":"ocmwstack/ocmwstack/#515-dispute-credential","text":"","title":"5.1.5  Dispute Credential"},{"location":"ocmwstack/ocmwstack/#516-revoke-credential","text":"","title":"5.1.6  Revoke Credential"},{"location":"ocmwstack/ocmwstack/#517-prove-credential","text":"","title":"5.1.7  Prove Credential"},{"location":"ocmwstack/ocmwstack/#518-credential-types","text":"","title":"5.1.8  Credential Types"},{"location":"ocmwstack/ocmwstack/#519-credential-and-connection-storage","text":"","title":"5.1.9  Credential and Connection Storage"},{"location":"ocmwstack/ocmwstack/#5110-did-document-manager","text":"","title":"5.1.10 DID Document Manager"},{"location":"ocmwstack/ocmwstack/#5111-credential-signing-and-verification","text":"","title":"5.1.11 Credential Signing and Verification"},{"location":"ocmwstack/ocmwstack/#5112-secrets-management","text":"","title":"5.1.12 Secrets Management"},{"location":"ocmwstack/ocmwstack/#5113-schema-management","text":"","title":"5.1.13 Schema Management"},{"location":"ocmwstack/ocmwstack/#5114-nonfunctional","text":"Appendix A: Glossary Appendix B: Architecture","title":"5.1.14 Nonfunctional"},{"location":"ocmwstack/ocmwstack/#list-of-figures","text":"Figure 1: Architecture (also see appendix B) Figure 2: Architecture Block Diagram","title":"List of Figures"},{"location":"ocmwstack/ocmwstack/#list-of-tables","text":"Table 1: References Table 2: User Classes and Characteristics Table 3: Technology Stack Table 4: Functional Requirements Connection Manager Table 5: Functional Requirements Credential Manager Table 6: Functional Requirements Connection Manager Table 7: Functional Requirements DID Document Manager Table 8: Functional Requirements Credential Signing and Verification Service Table 9: Functional Requirements Schema Management Service","title":"List of Tables"},{"location":"ocmwstack/ocmwstack/#introduction","text":"To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD].","title":"Introduction"},{"location":"ocmwstack/ocmwstack/#document-purpose","text":"The purpose of this document is to specify the requirements of the Identity Management and Trust Subcomponent \"Organization Credential Manager W-STACK\" with the intention of a European wide public tender for implementing this software extension. Main audience for this document are attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide digital support for existing certification bodies within Gaia-X.","title":"Document Purpose"},{"location":"ocmwstack/ocmwstack/#product-scope","text":"The purpose of these products is to provide all necessary components for the extension of the administration of the digital identity of a participant in the Gaia-X context. The Organization Credential Manager W-STACK (IDM.OCM.W-STACK) enhances the participant's interaction with the SSI-based ecosystem in a trustful and secure way. This comprises the utilization of the participants digital identity for different functionalities: Implementation of Full W3C DID/VC/VP Support for Credential Exchange and Trust Implementation of OpenID Standards OpenId4VC/VP SIOP VC Issuance Protocol Extension Establishment of secure and trustable connections with other parties Request and reception of verifiable credentials from attesting parties (e.g., Gaia-X Membership credential from a verified notary) in JSON-LD Format Attestation of attributes to principals in the form of verifiable credentials (e.g., employees, technical assets) Validation of received verifiable presentations from other parties (e.g., validation of Gaia-X membership of other participants) Maintenance of the verifiable Public Profile Scalable VC/VP Storage Graph Indexing for Linking VC/VP The described functionalities allow other components in the Identity Management context to interact with the SSI-based ecosystem.","title":"Product Scope"},{"location":"ocmwstack/ocmwstack/#please-note-that-it-is-explicitly-required-to-deliver-the-software-up-and-running-responsibility-for-existing-code-cannot-be-shifted-to-previous-development-teams","text":"","title":"&gt;Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams."},{"location":"ocmwstack/ocmwstack/#definitions-acronyms-and-abbreviations","text":"The IDM and Trust Architecture Overview Document [IDM.AO] MUST be considered and applied as the core technical concept that also includes the Terminology and Glossary.","title":"Definitions, Acronyms and Abbreviations"},{"location":"ocmwstack/ocmwstack/#references","text":"Reference Title Status [BDD] Getting Started with Behavior Driven Development (Specflow, n.D.) 03-17-2023 [Cloud Events] CloudEvents Specification (CloudEvents Authors, The Linux Foundation, 2021) 03-17-2023 [EBSI] EBSI (CEF Digital, 2021) 08-15-2023 [EIDAS] SSI eIDAS Legal Report (Dr. Ignacio Alamillo Domingo, 2020) 07-13-2023 [GDPR] General Data Protection Regulation GDPR (Intersoft Consulting, 2019) 03-17-2023 [IDM.AA] Authentication/Authorization Document (Gaia-X, European Association for Data and Cloud, AISBL, 2021) - [IDM.AO] Architecture Overview (GAIA-X WP1, 2021) - [IDM.TSA] Trusted Services API (Gaia-X, European Association for Data and Cloud, AISBL, 2021) - [OIDC] OpenID working groups specifications - [OID4VC] OpenID for Verifiable Credential Issuance 03-17-2023 [OID4VP] OpenID for Verifiable Presentations 03-17-2023 [PRD] Gaia-X Policy Rules Document (Gaia-X, European Association for Data and Cloud, AISBL, 2022) 08-14-2023 [RFC2119] Key words for use in RFCs to Indicate Requirement Levels 07-04-2023 [TAD] Gaia-X Architecture Document (Gaia-X, European Association for Data and Cloud, AISBL, 2022) - [TDR] GXFS_Technical_Development_Requirements (Gaia-X Federation Services Technical Development Requirements) - [W3C] Verifiable Credentials Data Model (W3C) 03-17-2023 Table 1: References","title":"References"},{"location":"ocmwstack/ocmwstack/#document-overview","text":"This document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID (e.g. IDM.ID.Number ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [RFC 2119], are written in capital letters (see also [IDM.AO] - Methodology).","title":"Document Overview"},{"location":"ocmwstack/ocmwstack/#product-overview","text":"","title":"Product Overview"},{"location":"ocmwstack/ocmwstack/#product-perspective","text":"The product is necessary to establish trust and credential exchange between the different participants within the Gaia-X ecosystem and to create a level of trust using a decentralized approach. The product fulfills parts of the functionality that an identity provider provides for centralized or federated identity approaches but in a decentralized fashion using concepts of decentralized identity, verifiable credentials, and verifiable presentations. To achieve this goal, components are required that on the one hand allow the management of a participant identity for the creation of signatures for various properties, attributes, and documents, and on the other hand enable the verification of external documents. This includes the creation of verifiable credentials with a corresponding digital signature based on an identity, the issuing of verifiable presentations based on existing and already received verifiable credentials, the requesting of verifiable credentials from third parties for the attestation of own attributes, for example, as well as the validation of incoming connection requests and proof requests. The format used for communication is based on the RFCs described in the W3C [1,2] and OpenID specifications [OIDC] to guarantee a uniform process flow and exchange formats.","title":"Product Perspective"},{"location":"ocmwstack/ocmwstack/#1-httpswwww3orgtrdid-core","text":"","title":"[1] [https://www.w3.org/TR/did-core/]"},{"location":"ocmwstack/ocmwstack/#2-httpswwww3orgtrvc-data-model","text":"","title":"[2] [https://www.w3.org/TR/vc-data-model/]"},{"location":"ocmwstack/ocmwstack/#product-functions","text":"The functions of the Organization Credential Manager W-Stack (OCM.W-STACK) component are provided as a runtime component and MUST expose endpoints as REST services and made accessible over the network using encrypted connections (e.g., HTTPS). The scalability of these services MUST be taken into consideration using well-known and tested concepts like a microservice based architecture and load balancing. Security measures MUST be in place accordingly. This includes the protection of exposed service endpoints, data storage protection and access control. The overall functionality of the OCM.W-STACK component and exposed services MUST be auditable (in compliance with [GDPR]). Figure 1: Architecture (also see appendix B) Please be aware that red boxes have the possibility to be either modified from existing functionality in the Trust Service API (TSA) [IDM.TSA], or can interface directly with the TSA to achieve the required result. Orange boxes encompass external services or components outside the GXFS (GAIA-X Federation Services). Please be aware, that changes on the TSA Signer Service[3] are in scope as well, when the implementation requires it.","title":"Product Functions"},{"location":"ocmwstack/ocmwstack/#3-httpsgitlabeclipseorgeclipsexfsctsasigner","text":"The core functions of the OCM.W-STACK are: Establishing and managing trusted connections between entities (Connections in this context are private, secured, and persistent channels between entities) Creation of connection invitations Handling of incoming connection invitations Managing of existing connections Association of a connection and proven attributes, allowing for a connection that is trusted according to the scope of Gaia-X Handling of verifiable credentials exchanges by using OIDC4VP/VC[4,5] Issuing credentials to participants, principals, assets etc. Handling of incoming Credential proposals Handling of verifiable proof exchanges by using OIDC4VP/VC Requesting and verifying proofs from other entities (e.g., participants) in the ecosystem Handling of incoming proof requests Secure storage of credentials Checking the validity of proof presentations Schema Handling Using JSON LD Schemas from Public Sources and Creating Credential Definitions for it Providing publicly visible and verifiable service endpoints Public Profile: Company information that is made publicly available (e.g., imprint). One aspect that has to be served is the self-description according to Gaia-X, other aspects can be served according to the trust policies of the Participant TrustedList: A list of participants that are trusted by this instance of OCM An architecture for the OCM W-Stack SHOULD look like the following block diagram:","title":"[3] [https://gitlab.eclipse.org/eclipse/xfsc/tsa/signer]"},{"location":"ocmwstack/ocmwstack/#4-httpsopenidnetspecsopenid-4-verifiable-credential-issuance-1_0html","text":"","title":"[4] [https://openid.net/specs/openid-4-verifiable-credential-issuance-1_0.html]"},{"location":"ocmwstack/ocmwstack/#5-httpsopenidnetspecsopenid-4-verifiable-presentations-1_0html","text":"Figure 2: Architecture Block Diagram","title":"[5] [https://openid.net/specs/openid-4-verifiable-presentations-1_0.html]"},{"location":"ocmwstack/ocmwstack/#product-constraints","text":"","title":"Product Constraints"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00000-the-document-idmao-is-the-common-basis-for-this-functional-specification","text":"The architecture document \\\"IDM.AO\\\" [IDM.AO] is an essential part of this specification and a prerequisite for understanding the context. The specifications and requirements from the Architecture Document MUST be considered during implementation.","title":"[IDM.OCM.W-STACK.00000] The document IDM.AO is the common basis for this functional specification"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00001-micro-service-architecture","text":"For a better scale out and decentralization, the product architecture MUST be a micro service architecture. The modules MUST NOT be tightly integrated into the IAM solution, as Plugin or Extensions, rather should interact with the said system through standard APIs and Protocols.","title":"[IDM.OCM.W-STACK.00001] Micro Service Architecture"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00002-tsa-signer-service","text":"The signer service of TSA [6] is reused in this solution, therefore it could be required to do code changes on this solution for implementing the W-Stack functionality. A separate signing implementation is not allowed.","title":"[IDM.OCM.W-STACK.00002] TSA Signer Service"},{"location":"ocmwstack/ocmwstack/#6-httpsgitlabeclipseorgeclipsexfsctsasigner","text":"","title":"[6] [https://gitlab.eclipse.org/eclipse/xfsc/tsa/signer]"},{"location":"ocmwstack/ocmwstack/#user-classes-and-characteristics","text":"User Class Attributes Administrator - Setup, organize, and monitor the system. Integration into the company systems and networks wherever necessary. Low frequency, high expertise, high privilege. Maintenance. Principal - Principals receive credentials to prove affiliation to the organization. Low frequency, low expertise, low privilege. Trusted Connections and Information Exchange. Trust Services - Controls the usage of most OCM functions via policies. High frequency, high expertise, high privilege. Administration of trusted connections and information exchange. Organization Internal Systems - Internal systems provide and consume data to/from the OCM. High frequency, high expertise, low privilege. Information / Trust Sources. External Participants/Principals - Provides data or requests Proofs. High frequency, high expertise, low privilege. Trusted Connections and Information Exchange. Table 2: User Classes and Characteristics","title":"User Classes and Characteristics"},{"location":"ocmwstack/ocmwstack/#operating-environment","text":"Please refer to [TDR] for further binding requirements regarding the operating environment.","title":"Operating Environment"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00003-kubernetes-environment","text":"The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on the provided SCS cluster (Sovereign Cloud Stack), which will be provided by the Client.","title":"[IDM.OCM.W-STACK.00003] Kubernetes Environment"},{"location":"ocmwstack/ocmwstack/#user-documentation","text":"","title":"User Documentation"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00004-participant-administration-documentation","text":"The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment Description of the Automatic Tests / Verification How to build the products from source code","title":"[IDM.OCM.W-STACK.00004] Participant Administration Documentation"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00005-participant-documentation","text":"The documentation MUST contain: Short Software Description/Usage Usage Guide GDPR Design Decisions Security Concept Operations Concept FAQ Keyword Directory","title":"[IDM.OCM.W-STACK.00005] Participant Documentation"},{"location":"ocmwstack/ocmwstack/#assumptions-and-dependencies","text":"An understanding of the overall Gaia-X architecture and philosophy is necessary as well as understanding of the OCM architecture and implementation details. Please refer to [TAD] and [PRD]. Attendees of the public tender MUST assume responsibility of: The existing code used and improvements upon the existing code Extending or contributing to the used frameworks in order to provision a way in which realization of the requirements can be achieved Updating dependencies to the latest stable version","title":"Assumptions and Dependencies"},{"location":"ocmwstack/ocmwstack/#requirements","text":"","title":"Requirements"},{"location":"ocmwstack/ocmwstack/#external-interfaces","text":"","title":"External Interfaces"},{"location":"ocmwstack/ocmwstack/#software-interfaces","text":"","title":"Software Interfaces"},{"location":"ocmwstack/ocmwstack/#general","text":"","title":"General"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00006-general-operation-requirements","text":"Every component must be able to run as a container. For scalable deployment e.g., a helm chart SHOULD be provided. If database connections are used, it must provide options to run the container \"stand-alone\", e.g., in-memory and with an external, configurable database.","title":"[IDM.OCM.W-STACK.00006] General Operation Requirements"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00007-protocol-and-definition-requirements","text":"All component functions MUST be compliant with W3C standards. Credential exchange MUST follow the [OIDC] SIOP and [OID4VC] specifications. Proof exchange MUST follow [OIDC] SIOP and [OID4VP] specifications. Exchange protocols MUST be developed with extensibility considerations for the purpose of supporting multiple protocols in future iterations.","title":"[IDM.OCM.W-STACK.00007] Protocol and Definition Requirements"},{"location":"ocmwstack/ocmwstack/#communications-interfaces","text":"","title":"Communications Interfaces"},{"location":"ocmwstack/ocmwstack/#general_1","text":"","title":"General"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00008-event-handling","text":"A lot of services within the OCM.W-STACK are publishing and receiving events, mostly events in the scope of SSI for the different protocol flows. The way to publish and subscribe these events MUST be consistent throughout the functionality of the OCM.W-STACK and the other lots by using NATS.","title":"[IDM.OCM.W-STACK.00008] Event Handling"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00009-external-schemas","text":"All schemas MUST be defined in the predefined identity network.","title":"[IDM.OCM.W-STACK.00009] External Schemas"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00010-rest-api","text":"All components MUST provide an internal and external Rest API which provides the functionality. External APIs MUST be protected by a JWT mechanism.","title":"[IDM.OCM.W-STACK.00010] Rest API"},{"location":"ocmwstack/ocmwstack/#hardware-interfaces","text":"","title":"Hardware Interfaces"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00011-hardware-encryption","text":"An option to securely create, store and access cryptographic material MUST be provided (e.g., HSM, Vault, Keymanager).","title":"[IDM.OCM.W-STACK.00011] Hardware Encryption"},{"location":"ocmwstack/ocmwstack/#functional","text":"The Implementer MUST fill the functional gaps between different components, even if they are not specified, to ensure a fluent workflow for administration, security, operation, compliance of the OCM.W-STACK.","title":"Functional"},{"location":"ocmwstack/ocmwstack/#general_2","text":"","title":"General"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00012-authenticate-endpoints","text":"The use of endpoints provided by the OCM.W-STACK should be available by providing valid authentication that is in consideration with the [IDM.AA] services especially for using the OIDC flows.","title":"[IDM.OCM.W-STACK.00012] Authenticate Endpoints"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00013-did-configuration-provision","text":"The OCM MUST provide to a configured URL an DID Configuration according to the Identity Foundation specification [7].","title":"[IDM.OCM.W-STACK.00013] DID Configuration Provision"},{"location":"ocmwstack/ocmwstack/#7-httpsidentityfoundationspecsdid-configuration","text":"","title":"[7] [https://identity.foundation/specs/did-configuration/]"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00014-did-document-resolving","text":"The DID Document of the OCM MUST be resolvable by the Universal Resolver and it MUST contain all key material used by the OCM including all endpoints following this service configuration format by enhancing the W3C spec [8]:","title":"[IDM.OCM.W-STACK.00014] DID Document Resolving"},{"location":"ocmwstack/ocmwstack/#8-httpswwww3orgtrdid-coreexample-usage-of-the-service-property","text":"> { > > id: {idName} > > type: {typeName}, > > accept: \\[\"didcomm/v2\",\"didcomm/v1\",{otherProtocols}\\], > > serviceEndpoint:\\[\"https://...\"\\] > > } >","title":"[8] [https://www.w3.org/TR/did-core/#example-usage-of-the-service-property]"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00015-nats-eventing","text":"All actions of the OCM MUST be published via NATS to support external consumers in their actions. The event names and payloads MUST follow one standardized structure for eventing (e.g., cloud events pattern)","title":"[IDM.OCM.W-STACK.00015] NATS Eventing"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00016-general-microservice-structure","text":"All functional blocks MUST be encapsulated in microservices to ensure that the system asymmetrically scales. It MUST be ensured, that for example querying credentials can be outscaled without scaling the resources for issuing. The outage protection MUST be designed in the same way. It MUST be possible to switch off for example the issuing, without affecting the reading. The architecture for this structure MUST be clarified with the principal.","title":"[IDM.OCM.W-STACK.00016] General Microservice Structure"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00017-multi-tenancy","text":"The component MUST support multi tenancy with possibility to scale down to zero.","title":"[IDM.OCM.W-STACK.00017] Multi Tenancy"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00018-selective-disclosure-jwt","text":"The component MUST support Selective Disclosure JWT described in the specification [9].","title":"[IDM.OCM.W-STACK.00018] Selective Disclosure JWT"},{"location":"ocmwstack/ocmwstack/#9-httpsdatatrackerietforgdocdraft-ietf-oauth-selective-disclosure-jwt","text":"","title":"[9] [https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/]"},{"location":"ocmwstack/ocmwstack/#connection-manager","text":"","title":"Connection Manager"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00019-create-connection-endpoints","text":"The Connection Manager MUST provide a Create Invitation endpoint as well as a connection acceptance endpoint. The response body is composed of JSON content. A connection SHOULD be accepted and made consumable only if the Trusted Content Resolver responds accordingly.","title":"[IDM.OCM.W-STACK.00019] Create Connection Endpoints"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00020-connection-information-endpoints","text":"The Connection Manager MUST provide a connection information endpoint where other components can request if a connection for a specific DID/ID already exists. The endpoint supports as input a ConnectionID or a DID as well as a flag for \"all-information\" which also covers all received presentations and issued credentials and responds with existing information (connection status, ConnectionID, if requested additional information) or nothing if it does not exist. An endpoint or the same endpoint without parameters must be provided to return all connections.","title":"[IDM.OCM.W-STACK.00020] Connection Information Endpoint/s"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00021-connection-status","text":"The Connection Manager MUST provide a function that allows a component to subscribe/unsubscribe for connection events to receive updates when the status changes. A list of subscribers MUST be in place and maintained based on the respective implementation. (subscribe, unsubscribe MUST be possible). This functionality of publishing events SHOULD be provided via a REST service, but a message bus system can also be considered.","title":"[IDM.OCM.W-STACK.00021] Connection Status"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00022-connection-update","text":"The Connection Manager MUST provide an endpoint that allows a component to update a connection entry by connectionID or DID.","title":"[IDM.OCM.W-STACK.00022] Connection Update"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00023-connection-deletion","text":"The Connection Manager MUST provide an endpoint that allows a component to delete a connection entry by connectionID or DID. If a connection is deleted, it MUST not affect Verifiable Credential or Verifiable Presentation exchanges that have already taken place over it.","title":"[IDM.OCM.W-STACK.00023] Connection Deletion"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00024-block-connection","text":"The Connection Manager MUST provide a Block Connection endpoint. The endpoint should accept either connection ID or DID. It should mark the connection as 'blocked' in the Connection storage.","title":"[IDM.OCM.W-STACK.00024] Block Connection"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00025-refuse-blocked-connections","text":"The Connection Manager MUST refuse connections if they match the connection ID or DID of a connection in the storage, which has been marked as 'blocked'. The response of an unsuccessful connection in this case should include the reason for refusal in the response message.","title":"[IDM.OCM.W-STACK.00025] Refuse blocked connections"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00026-tsa-interface","text":"The Connection Manager MUST support the interface with the TSA in order to get a decision whether a connection should be accepted or not.","title":"[IDM.OCM.W-STACK.00026] TSA Interface"},{"location":"ocmwstack/ocmwstack/#credential-manager","text":"","title":"Credential Manager"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00027-get-credentials","text":"The Credential Manager MUST provide an endpoint to request existing credentials inside the storage of the OCM. This request MUST support a simple query language or offer query/path parameters to query for credentials based on schemas, issuer DIDs, attribute names, attribute values, or an internal CredentialID.","title":"[IDM.OCM.W-STACK.00027] Get Credentials"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00028-open-credential-requestsofferings","text":"The Credential Manager MUST provide an endpoint to list the open requests and offerings by connection.","title":"[IDM.OCM.W-STACK.00028] Open Credential Requests/Offerings"},{"location":"ocmwstack/ocmwstack/#issue-credential","text":"","title":"Issue Credential"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00029-credential-issue-endpoint","text":"The Credential Manager MUST provide an endpoint to allow the request for issuing a credential for a specific subject DID from another component. The endpoint expects the following attributes as payload Subject DID Schema Claims for Credential Additional Information like expiration date, dispute endpoints etc. What is specified in [W3C] Whether the credential should be automatically refreshed Constraints: A connection for the provided subject DID MUST be established before. Issuance of credentials to external subject DIDs require a \"trusted\" state of the connection existing (by utilizing the Trustlist Manager). It MUST follow the [OIDC] credential exchange specification.","title":"[IDM.OCM.W-STACK.00029] Credential Issue Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00030-credential-status","text":"The Credential Manager MUST provide a way to receive updates for an ongoing issue credential process. Constraints: A credential issue process already has been started","title":"[IDM.OCM.W-STACK.00030] Credential Status"},{"location":"ocmwstack/ocmwstack/#dispute-credential","text":"","title":"Dispute Credential"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00031-credential-dispute","text":"The Credential Manager MUST provide an Endpoint or a function to allow the request for disputing a credential for a specific subject DID from another component. Reissuance of credentials to external subject DIDs still require a \"trusted\" state of the connection existing (by utilizing the Trusted Content Resolver Interface).","title":"[IDM.OCM.W-STACK.00031] Credential Dispute"},{"location":"ocmwstack/ocmwstack/#revoke-credential","text":"","title":"Revoke Credential"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00032-credential-revocation","text":"The Credential Manager MUST provide a function to allow the revocation of a credential for a specific issuer DID from another component once the expiration condition has been met. The endpoint SHOULD follow the [[W3C]]. Reissuance of credentials to external subject DIDs still require a \"trusted\" state of the connection existing (by utilizing the Trustlist Manager). Additionally, the component MUST prepare an hash-based revocation which is calculated over the proof of the credential in the following way: For RSA signature a SHA256 hash is calculated over the entire signature in raw byte format For EC-DSA Signature the SHA256 hash is calculated over the r value of the proof signature The revocation endpoint MUST provide this calculated hash of W3C credentials [10] to an internal storage grouped by Issuer DID which has an internal interface to read the hashes for later integration (later integration is out of scope for this tender).","title":"[IDM.OCM.W-STACK.00032] Credential Revocation"},{"location":"ocmwstack/ocmwstack/#10-wwww3orgtrvc-data-model","text":"","title":"[10] [www.w3.org/TR/vc-data-model/]"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00033-credential-refresh-endpoint","text":"The Credential Manager MUST provide an Endpoint to allow the reissuance of a revoked credential for a specific subject DID from another component once the expiration condition has been met. The credential MUST follow the exact structure of the previously issued credential. The refresh endpoint can be included in the VC. Reissuance of credentials to external subject DIDs still require a \"trusted\" state of the connection existing (by utilizing the Trustlist Manager).","title":"[IDM.OCM.W-STACK.00033] Credential Refresh Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00034-credential-refresh-function","text":"The Credential Manager MUST provide a function to allow the reissuance of a revoked credential for a specific subject DID from another component once the expiration condition has been met and the credential has been marked as valid for automatic reissuance. The credential MUST follow the exact structure of the previously issued credential. Reissuance of credentials to external subject DIDs still require a \"trusted\" state of the connection existing (by utilizing the Trustlist Manager).","title":"[IDM.OCM.W-STACK.00034] Credential Refresh Function"},{"location":"ocmwstack/ocmwstack/#prove-credential","text":"","title":"Prove Credential"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00035-presentation-request","text":"The Credential Manager MUST provide an endpoint to request a presentation over an existing connection. If the holder DID for the request is a Participant and no connection exists, a trusted connection MUST be established beforehand. The relevant payload or attributes for the request as well as the connection or a DID for the request MUST be provided. The Credential Manager can also receive presentation requests and MUST respond with the respective Verifiable Presentation/s. All presentations must be checked for revocation state.","title":"[IDM.OCM.W-STACK.00035] Presentation Request"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00036-presentation-status","text":"The Credential Manager MUST provide a way for a component to subscribe/unsubscribe for Presentation event updates when new Presentations are received or the status changes. A list of subscribers for a specific connectionID MUST be in place and maintained based on the respective implementation. This functionality of publishing events SHOULD be provided via a REST service, but a message bus system can also be considered.","title":"[IDM.OCM.W-STACK.00036] Presentation Status"},{"location":"ocmwstack/ocmwstack/#credential-types","text":"","title":"Credential Types"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00037-public-credential","text":"The Credential Manager MUST provide an endpoint for a component to modify a credential to contain a value which configures whether credentials can be public or not (e.g., the participant credential). It MUST be allowed to be public through a policy in the Trust Services.","title":"[IDM.OCM.W-STACK.00037] Public Credential"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00038-credential-type","text":"The Credential Manager MUST provide an endpoint to configure credential types used for issuing. The type refers to a specific schema that is used for the issuing of the credential. Its intended purpose is ease of use in the process of operating the organization.","title":"[IDM.OCM.W-STACK.00038] Credential Type"},{"location":"ocmwstack/ocmwstack/#credential-and-connection-storage","text":"","title":"Credential and Connection Storage"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00039-credential-connection-storing","text":"Once a connection has been created it MUST be stored in a database. Once a credential has been issued, the resulting JSON structure with its corresponding values MUST also be stored in the database.","title":"[IDM.OCM.W-STACK.00039] Credential / Connection Storing"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00040-credential-connection-querying","text":"The Credential and Connection Storage MUST provide a way for components to query the storage with the Create, Read, Update, Delete operations.","title":"[IDM.OCM.W-STACK.00040] Credential / Connection Querying"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00041-credential-storage-scaling","text":"The Credential Storage MUST be highly scalable for read operations to allow high intensive parallel reads (e.g., for reporting or analysis similar to Digital Product Pass or Supply Chain Tracking/Tracing).","title":"[IDM.OCM.W-STACK.00041] Credential Storage Scaling"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00042-credential-storage-graph-indexing","text":"The Credential Storage MUST support the chaining of VCs by using Graph Technologies and Queries to support the chaining of credentials e.g., for provenance proofs.","title":"[IDM.OCM.W-STACK.00042] Credential Storage Graph Indexing"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00043-storage-microservice-structure","text":"The Credential Storage functionality MUST be separated in a micro service for the graph functionality as well for high scalable storage for VCs/VP. Especially the chaining of VCs, SHOULD be a separated service to avoid the mixing of Graph Technology, Proof Formats and Common Database Technology. If this is not possible, an alternative solution MUST be provided which fulfills the goal of splitting the functionality in specialized services. The general goal MUST be to provide microservices which are able to extract a graph of Json objects belonging to a key (e.g. ID), provide high scalable storage to read Json objects (e.g. a document based storage), provide an component which is able to sign a graph, provide a component which is able to visualize and filter the existing content, provide credential encryption and an appropriate key management solution (e.g. Hashicorp Vault).","title":"[IDM.OCM.W-STACK.00043] Storage Microservice Structure"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00044-storage-content","text":"All credentials or presentations MUST be stored as JSON-LD. It's not allowed to serialize the JSON objects by using (ORM) Mappers e.g., NHibernate. Technical optimizations of storing the documents is allowed (e.g., by using BSON), but it MUST be ensured that the graph building and data analysis is not lacking in performance (e.g., by using postgres JSON Objects, which support just basic queries, but no JSON object aggregation/manipulation).","title":"[IDM.OCM.W-STACK.00044] Storage Content"},{"location":"ocmwstack/ocmwstack/#did-document-manager","text":"","title":"DID Document Manager"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00045-create-did","text":"Creates a DID that will be used for identifying and resolving to a DID Document.","title":"[IDM.OCM.W-STACK.00045] Create DID"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00046-create-public-profile-endpoint","text":"Creates and publishes the Public Profile Endpoint. It serves the Self-Description of the organization. It is composed of all the Verifiable Credentials that the administrators or the Trust Services mark as \"public\".","title":"[IDM.OCM.W-STACK.00046] Create Public Profile Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00047-update-public-profile-endpoint","text":"Updates the Public Profile Endpoint.","title":"[IDM.OCM.W-STACK.00047] Update Public Profile Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00048-delete-public-profile-endpoint","text":"Deletes the Public Profile Endpoint.","title":"[IDM.OCM.W-STACK.00048] Delete Public Profile Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00049-append-terms-of-use","text":"Each Participant should have terms of use listed in the public DID Document. It can be achieved through exposing an endpoint that appends a link to the terms of use.","title":"[IDM.OCM.W-STACK.00049] Append Terms of Use"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00050-append-service-endpoints","text":"Each Participant should have service endpoints listed in the public DID Document. Another Service Endpoints MUST dynamically addable by an interface e.g., a refresh service endpoint that allows refreshing of credentials issued by the OCM.","title":"[IDM.OCM.W-STACK.00050] Append Service Endpoints"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00051-write-update-delete-did-document-endpoints","text":"The DID Document Manager MUST have three endpoints that allow writing, updating, and deleting of the public DID Document.","title":"[IDM.OCM.W-STACK.00051] Write, Update, Delete DID Document Endpoints"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00052-tsa-interface","text":"The DID Document Manager should interface with the TSA for choosing what information is listed in the public DID Document.","title":"[IDM.OCM.W-STACK.00052] TSA Interface"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00053-did-document-storage","text":"The DID Document Storage MUST provide interfaces for [EBSI] and IPFS to anchor DID Documents within these systems when the features are enabled. In the case of not using these features DID Web as a Service [11] (generating DID Documents on the fly) built on TSA basis MUST be the default for generating and managing DID documents.","title":"[IDM.OCM.W-STACK.00053] DID Document Storage"},{"location":"ocmwstack/ocmwstack/#11-httpsgitlabcomgaia-xgaia-x-communitygx-hackathongx-hackathon-6-treemaindidasaservice","text":"","title":"[11] [https://gitlab.com/gaia-x/gaia-x-community/gx-hackathon/gx-hackathon-6/-/tree/main/DIDAsAService]"},{"location":"ocmwstack/ocmwstack/#credential-signing-and-verification","text":"This component must implement and extend the needed functionality of the Trust Services API.","title":"Credential Signing and Verification"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00054-credential-signer","text":"The Credential Signer MUST be an endpoint that allows signing of Verifiable Credentials and other messages with different types of proof: QES proof Linked proof Provenance proof Selective Disclosure proofs (e.g., BBS+ [12]) Other proofs","title":"[IDM.OCM.W-STACK.00054] Credential Signer"},{"location":"ocmwstack/ocmwstack/#12-httpsidentityfoundationbbs-signaturedraft-irtf-cfrg-bbs-signatureshtml","text":"","title":"[12] [https://identity.foundation/bbs-signature/draft-irtf-cfrg-bbs-signatures.html]"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00055-credential-verifier","text":"The Credential Verifier MUST be an endpoint that allows verifying of Verifiable Credentials and other messages with different types of proof: QES proof Linked proof Provenance proof Selective Disclosure proof (e.g., BBS+) Other proofs","title":"[IDM.OCM.W-STACK.00055] Credential Verifier"},{"location":"ocmwstack/ocmwstack/#secrets-management","text":"This component MUST be modified from the already existing \"signing\" service in the Trust Services API. All cryptographic material MUST be [eIDAS] compliant.","title":"Secrets Management"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00056-qes-signatures","text":"A concept to support QES MUST be implemented and documented.","title":"[IDM.OCM.W-STACK.00056] QES Signatures"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00057-create-secrets","text":"The Secrets Management Service MUST be able to create and store secret cryptographic material without releasing the private key or using seeds which can be leaked. In general, the secret handling MUST be adoptable by HSMs or other existing IT security infrastructure.","title":"[IDM.OCM.W-STACK.00057] Create Secrets"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00058-hsm-modularity","text":"The Secrets Management Service MUST be able to use interchangeably or allow the modular replacement of different Hardware Security Modules and/or secret storages by implementing the signing/verification of signatures in separate modules.","title":"[IDM.OCM.W-STACK.00058] HSM modularity"},{"location":"ocmwstack/ocmwstack/#schema-manager","text":"","title":"Schema Manager"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00059-trusted-schema-content-api","text":"The Schema Manager Service MUST expose endpoint/s that allow the management of schemas (e.g., Create, Update, Get, Resolve schema) to dock different APIs for schema creation like EBSI.","title":"[IDM.OCM.W-STACK.00059] Trusted Schema Content API"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00060-trusted-schema-management","text":"The Schema Manager MUST be able to Create, Update, Get and Resolve schema content through the Verifiable Ledger Abstraction.","title":"[IDM.OCM.W-STACK.00060] Trusted Schema Management"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00061-verifiable-ledger-abstraction","text":"The Verifiable Ledger Abstraction interfaces with and links Schema Manager and the Credential Schema Verifier. It must implement a level of abstraction that allows interchangeability and, if possible, interoperability between different verifiable ledgers. [EBSI] MUST be one of the options for a verifiable ledger.","title":"[IDM.OCM.W-STACK.00061] Verifiable Ledger Abstraction"},{"location":"ocmwstack/ocmwstack/#nonfunctional-requirements","text":"","title":"Nonfunctional Requirements"},{"location":"ocmwstack/ocmwstack/#performance-requirements","text":"","title":"Performance Requirements"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00062-updown-scale","text":"All components MUST be able to scale up/down their functionality for a undefined number of instances. This requires a parallel execution possibility.","title":"[IDM.OCM.W-STACK.00062] Up/Down Scale"},{"location":"ocmwstack/ocmwstack/#safety-requirements","text":"","title":"Safety Requirements"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00063-major-releases","text":"All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening.","title":"[IDM.OCM.W-STACK.00063] Major Releases"},{"location":"ocmwstack/ocmwstack/#security-requirements","text":"","title":"Security Requirements"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00064-cve-patches","text":"All software components MUST have applied CVE patches, which are available for major releases.","title":"[IDM.OCM.W-STACK.00064] CVE Patches"},{"location":"ocmwstack/ocmwstack/#software-quality-attributes","text":"","title":"Software Quality Attributes"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00065-software-quality-requirements","text":"All software components MUST be compliant to the requirements within the quality assurance repository [13]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology.","title":"[IDM.OCM.W-STACK.00065] Software Quality Requirements"},{"location":"ocmwstack/ocmwstack/#13-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesquality-assurance-issues","text":"","title":"[13] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues]"},{"location":"ocmwstack/ocmwstack/#business-rules","text":"","title":"Business Rules"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00066-software-consistency","text":"The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc.","title":"[IDM.OCM.W-STACK.00066] Software Consistency"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00067-cherry-picking","text":"All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow an enterprise deployment customization.","title":"[IDM.OCM.W-STACK.00067] Cherry Picking"},{"location":"ocmwstack/ocmwstack/#compliance","text":"","title":"Compliance"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00068-gdpr-audit-logging","text":"All GDPR relevant access to personal relevant data MUST be logged for a later audit.","title":"[IDM.OCM.W-STACK.00068] GDPR Audit Logging"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00069-gdpr-data-processing","text":"It is necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable.","title":"[IDM.OCM.W-STACK.00069] GDPR Data Processing"},{"location":"ocmwstack/ocmwstack/#design-and-implementation","text":"","title":"Design and Implementation"},{"location":"ocmwstack/ocmwstack/#installation","text":"","title":"Installation"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00070-helmargo-cd-deployment","text":"All installations MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a Argo CD Pipeline defined in the gxfs-integration repository [14].","title":"[IDM.OCM.W-STACK.00070] Helm/Argo CD Deployment"},{"location":"ocmwstack/ocmwstack/#14-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[14] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"ocmwstack/ocmwstack/#configuration","text":"","title":"Configuration"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00071-configuration","text":"All components MUST support one of the major configuration formats (yaml, Json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged.","title":"[IDM.OCM.W-STACK.00071] Configuration"},{"location":"ocmwstack/ocmwstack/#distribution","text":"","title":"Distribution"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00072-helm-repositories","text":"All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [15].","title":"[IDM.OCM.W-STACK.00072] Helm Repositories"},{"location":"ocmwstack/ocmwstack/#15-httpsgitlabcomapiv4projects41175300packageshelmintegrationindexyaml","text":"","title":"[15] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml]"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00073-istio-resources","text":"Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc. ) following the integration pattern specified in the gxfs-integration repo [16].","title":"[IDM.OCM.W-STACK.00073] Istio Resources"},{"location":"ocmwstack/ocmwstack/#16-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[16] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"ocmwstack/ocmwstack/#service-meshing","text":"","title":"Service Meshing"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00074-istio-support","text":"All HELM charts MUST be provided with Istio support aligned together with the project team. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment.","title":"[IDM.OCM.W-STACK.00074] Istio Support"},{"location":"ocmwstack/ocmwstack/#standard-technology","text":"","title":"Standard Technology"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00075-default-toolstack","text":"Each development MUST consider the following standard technologies if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React 17 Ingress Controller Nginx/Istio API Testing Postman (manual) Kubernetes v1.26+ API Design OpenAPI","title":"[IDM.OCM.W-STACK.00075] Default Toolstack"},{"location":"ocmwstack/ocmwstack/#17-httpsreact-bootstrapgithubio","text":"Table 3: Technology Stack The technology stack is mandatory to avoid integration impact.","title":"[17] [https://react-bootstrap.github.io/]"},{"location":"ocmwstack/ocmwstack/#metrics","text":"","title":"Metrics"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00076-opentelemtry-support","text":"All helm charts/services MUST provide metrics endpoints in opentelemetry [18] format.","title":"[IDM.OCM.W-STACK.00076] Opentelemtry Support"},{"location":"ocmwstack/ocmwstack/#18-httpsopentelemetryiodocs","text":"","title":"[18] [https://opentelemetry.io/docs/]"},{"location":"ocmwstack/ocmwstack/#configurability","text":"","title":"Configurability"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00077-configuration-profiles","text":"Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening","title":"[IDM.OCM.W-STACK.00077] Configuration Profiles"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00078-secret-references-in-helm-charts","text":"The configuration secrets within Helm Charts MUST use secretRefs to support external Secretmanagement. Clear text secrets within the Helm Charts are not allowed.","title":"[IDM.OCM.W-STACK.00078] Secret References in Helm Charts"},{"location":"ocmwstack/ocmwstack/#maintainability","text":"","title":"Maintainability"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00079-micro-service-architecture","text":"For a better scale out, maintainability and decentralization, the product architecture MUST have a micro service architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement it. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment).","title":"[IDM.OCM.W-STACK.00079] Micro Service Architecture"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00080-domain-driven-design","text":"To support the micro service architecture within the maintainability, it MUST be declared a domain model before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers.","title":"[IDM.OCM.W-STACK.00080] Domain Driven Design"},{"location":"ocmwstack/ocmwstack/#reusability","text":"","title":"Reusability"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00081-enterprise-environments","text":"All components MUST be reusable in different enterprise environments by customization and whitelabeling. Means all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.)","title":"[IDM.OCM.W-STACK.00081] Enterprise Environments"},{"location":"ocmwstack/ocmwstack/#runtime-stability","text":"","title":"Runtime Stability"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00082-readiness-check-ups","text":"All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: An unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state","title":"[IDM.OCM.W-STACK.00082] Readiness Check Ups"},{"location":"ocmwstack/ocmwstack/#high-availability-concepts","text":"","title":"High Availability Concepts"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00083-redundant-deployment","text":"Each deployment MUST be configured for a minimum fault tolerance of 2 instances.","title":"[IDM.OCM.W-STACK.00083] Redundant Deployment"},{"location":"ocmwstack/ocmwstack/#proof-of-concept","text":"","title":"Proof of Concept"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00084-architecture-changes","text":"All Architecture Changes MUST be aligned with the Principal before implementation.","title":"[IDM.OCM.W-STACK.00084] Architecture Changes"},{"location":"ocmwstack/ocmwstack/#system-features","text":"","title":"System Features"},{"location":"ocmwstack/ocmwstack/#connection-management-service","text":"","title":"Connection Management Service"},{"location":"ocmwstack/ocmwstack/#description-connection-management-service","text":"The Connection Management Service should contain all the needed functions for establishing, maintaining, querying, and using connections to other organizational and personal agents. The individual requests are forwarded to the trust service component for validation and assessment of whether corresponding connections may be established and processed. The other components of the OCM.W-STACK can retrieve information regarding existing connection requests and inform themselves about the current status of the connections.","title":"Description - Connection Management Service"},{"location":"ocmwstack/ocmwstack/#functional-requirements-connection-management-service","text":"Endpoints Create Connection Endpoint Connection Information Endpoint Connection Update Connection Deletion Block Connection Functions Connection Status Refuse blocked connections Trusted Content Resolver Interface Table 4: Functional Requirements Connection Manager","title":"Functional Requirements - Connection Management Service"},{"location":"ocmwstack/ocmwstack/#credential-management-service","text":"","title":"Credential Management Service"},{"location":"ocmwstack/ocmwstack/#description-credential-management-service","text":"The Credential Management Service is the component responsible for issuing, managing, revoking, and maintaining all credentials, as well as managing their proofs.","title":"Description - Credential Management Service"},{"location":"ocmwstack/ocmwstack/#functional-requirements-credential-management-service","text":"Credential Dispute Endpoints Get Credentials Credential Issue Endpoint Credential Refresh Endpoint Presentation Request Public Credential Credential Type Functions Credential Status Credential Revocation Credential Refresh Function Presentation Status Table 5: Functional Requirements Credential Manager","title":"Functional Requirements - Credential Management Service"},{"location":"ocmwstack/ocmwstack/#credential-and-connection-storage_1","text":"","title":"Credential and Connection Storage"},{"location":"ocmwstack/ocmwstack/#description-credential-and-connection-storage","text":"The Credential and Connection Storage is a secure storage for the credential and connection JSON structures.","title":"Description - Credential and Connection Storage"},{"location":"ocmwstack/ocmwstack/#functional-requirements-credential-and-connection-storage","text":"Credential / Connection Storing Credential / Connection Querying Table 6: Functional Requirements Connection Manager","title":"Functional Requirements - Credential and Connection Storage"},{"location":"ocmwstack/ocmwstack/#did-document-management-service","text":"","title":"DID Document Management Service"},{"location":"ocmwstack/ocmwstack/#description-did-document-management-service","text":"The DID Document of the Participant is the description that is publicly available and consists of data such as (but not limited to): Participant Public profile, Terms of use, Service endpoint, other necessary information for the purposes of integration with the other lots. The Public Profile is an endpoint listed in the DID Document of the Participant. It returns a JSON-LD Verifiable Presentation that contains various Verifiable Credentials - those VC, the Participant marked as publicly available. The Self-Description served by the Public Profile can be extended through additional JSON-LD contexts.","title":"Description - DID Document Management Service"},{"location":"ocmwstack/ocmwstack/#functional-requirements-did-document-management-service","text":"Endpoints / Functions Endpoints Create Public Profile Endpoint Update Public Profile Endpoint Delete Public Profile Endpoint Append Terms of Use Append Service Endpoint Write, Update, Delete DID Document Endpoints Functions Create DID TSA Interface Table 7: Functional Requirements DID Document Manager","title":"Functional Requirements - DID Document Management Service"},{"location":"ocmwstack/ocmwstack/#credential-signing-and-verification-service","text":"","title":"Credential Signing and Verification Service"},{"location":"ocmwstack/ocmwstack/#description-credential-signing-and-verification-service","text":"The Credential Signing and Verification Service should be able to generate different types of proofs on Verifiable Credentials and other messages as well as verify them.","title":"Description - Credential Signing and Verification Service"},{"location":"ocmwstack/ocmwstack/#functional-requirements-credential-signing-and-verification-service","text":"Endpoints Credential Signer Credential Verifier Table 8: Functional Requirements Credential Signing and Verification Service","title":"Functional Requirements - Credential Signing and Verification Service"},{"location":"ocmwstack/ocmwstack/#schema-management-service","text":"","title":"Schema Management Service"},{"location":"ocmwstack/ocmwstack/#description-schema-management-service","text":"The Schema Management Service is responsible for interfacing with the external Verifiable Ledgers.","title":"Description - Schema Management Service"},{"location":"ocmwstack/ocmwstack/#functional-requirements-schema-management-service","text":"Endpoints Trusted Schema Content API Functions Trusted Schema Management Verifiable Ledger Abstraction Table 9: Functional Requirements Schema Management Service","title":"Functional Requirements - Schema Management Service"},{"location":"ocmwstack/ocmwstack/#verification","text":"","title":"Verification"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00085-behavior-driven-design","text":"Verification of fulfillment of the requirements and characteristics MUST be done using automated tests which are part of the deliverables. They SHOULD be done by patterns of the Behavior Driven Development [BDD] using the \"Gherkin Syntax\".","title":"[IDM.OCM.W-STACK.00085] Behavior Driven Design"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00086-test-environment","text":"All functionalities MUST be demonstrated in a test environment within a sandbox, with the following infrastructure components: Load Balancer, e.g., HAProxy API Gateway, e.g., Kong Service Mesh, e.g., Linkerd/Istio DNS Multiple Servers Firewalls All tests MUST be passed in this test environment.","title":"[IDM.OCM.W-STACK.00086] Test Environment"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00087-load-tests","text":"Scalability and Performance around the high workload scenarios MUST be demonstrated, by using any kind of Load Test Framework for HTTP APIs.","title":"[IDM.OCM.W-STACK.00087] Load Tests"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00088-automated-integration-tests","text":"Automation Integration tests must be created, and they must be runnable by a CI job.","title":"[IDM.OCM.W-STACK.00088] Automated Integration Tests"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00089-kubernetes-deployment","text":"If the verification is related to software components, it must be deployed in a Kubernetes test cluster and the components must be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration.","title":"[IDM.OCM.W-STACK.00089] Kubernetes Deployment"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00090-eventing","text":"All eventings must be demonstrated on basis of cloud events [Cloud Events] specifications together with the kNative [19] broker together with NATS in a KKubernetes environment.","title":"[IDM.OCM.W-STACK.00090] Eventing"},{"location":"ocmwstack/ocmwstack/#19-httpsknativedevdocseventing","text":"","title":"[19] [https://knative.dev/docs/eventing/]"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00091-config-map-support","text":"Each service must be demonstrated up and running in kubernetes, configured by config maps.","title":"[IDM.OCM.W-STACK.00091] Config Map Support"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00092-helm-installation","text":"The service installation MUST be demonstrated during HELM install.","title":"[IDM.OCM.W-STACK.00092] Helm Installation"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00093-argocd-integration","text":"The helm chart MUST be able to install inside of Argo CD. This includes the usage of the postgres hooks [20]and the providing of usable values.yaml(s) for all developed services.","title":"[IDM.OCM.W-STACK.00093] ArgoCD Integration"},{"location":"ocmwstack/ocmwstack/#20-httpsgitlabeclipseorgeclipsexfscintegration-treemainhelmchartspostgresql-hook","text":"","title":"[20] [https://gitlab.eclipse.org/eclipse/xfsc/integration/-/tree/main/helm/charts/postgresql-hook]"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00094-scs-environment","text":"All HELM installations MUST run on SCS (Sovereign Cloud Stack). The final acceptance demonstration cannot be realized on azure, google cloud etc.","title":"[IDM.OCM.W-STACK.00094] SCS Environment"},{"location":"ocmwstack/ocmwstack/#acceptance-criteria","text":"","title":"Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#general-acceptance-criteria","text":"","title":"General - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00095-general-operation-requirements","text":"Components run as containers and a helm chart is provided.","title":"[IDM.OCM.W-STACK.00095] General Operation Requirements"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00096-protocol-and-definition-requirements","text":"All relevant components and functions are compliant with [W3C], and [OIDC] specifications.","title":"[IDM.OCM.W-STACK.00096] Protocol and Definition Requirements"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00097-event-handling","text":"Events are published and consumed to enable the needed functionality.","title":"[IDM.OCM.W-STACK.00097] Event Handling"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00098-external-schemas","text":"Schemas are defined in the external network and are resolvable.","title":"[IDM.OCM.W-STACK.00098] External Schemas"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00099-hardware-encryption","text":"An interface with an HSM is provided.","title":"[IDM.OCM.W-STACK.00099] Hardware Encryption"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00100-authenticate-endpoints","text":"A middleware for authentication in order to use the exposed endpoints is provided as well as the possibility to be integrated with the [IDM.AA] Services.","title":"[IDM.OCM.W-STACK.00100] Authenticate Endpoints"},{"location":"ocmwstack/ocmwstack/#connection-manager-acceptance-criteria","text":"","title":"Connection Manager - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00101-create-connection-endpoint","text":"A connection is created and validated.","title":"[IDM.OCM.W-STACK.00101] Create Connection Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00102-connection-information-endpoints","text":"By providing identifiable data for a specific connection all relevant information and metainformation is returned, or alternatively - by not providing identifiable data, all connections are returned with the minimum identifiable data to allow the specific search of information.","title":"[IDM.OCM.W-STACK.00102] Connection Information Endpoint/s"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00103-connection-status","text":"The connection status attribute exists and when changed is handled through events.","title":"[IDM.OCM.W-STACK.00103] Connection Status"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00104-connection-update","text":"The required connection field is updated and reflected properly.","title":"[IDM.OCM.W-STACK.00104] Connection Update"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00105-connection-deletion","text":"A specific connection or a group of connections based on a condition are deleted from the connection storage.","title":"[IDM.OCM.W-STACK.00105] Connection Deletion"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00106-block-connection","text":"The specified connection is marked as 'blocked'.","title":"[IDM.OCM.W-STACK.00106] Block Connection"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00107-refuse-blocked-connections","text":"Interactions over the connections marked as 'blocked' are not fulfilled.","title":"[IDM.OCM.W-STACK.00107] Refuse blocked connections"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00108-trusted-content-resolver-interface","text":"The Connection Manager interfaces with the Trusted Content Resolver at the appropriate place/s. But at least for resolving DIDs and trust lists.","title":"[IDM.OCM.W-STACK.00108] Trusted Content Resolver Interface"},{"location":"ocmwstack/ocmwstack/#credential-manager-acceptance-criteria","text":"","title":"Credential Manager - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00109-get-credentials","text":"Credentials in the Credential Storage are returned, and filtering based on a condition is possible.","title":"[IDM.OCM.W-STACK.00109] Get Credentials"},{"location":"ocmwstack/ocmwstack/#issue-credential-acceptance-criteria","text":"","title":"Issue Credential - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00110-credential-issue-endpoint","text":"Credentials are issued and are compliant with the [OID4VC] specifications.","title":"[IDM.OCM.W-STACK.00110] Credential Issue Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00111-credential-status","text":"Credentials' statuses exist, are updated, and handled through events.","title":"[IDM.OCM.W-STACK.00111] Credential Status"},{"location":"ocmwstack/ocmwstack/#dispute-credential-acceptance-criteria","text":"","title":"Dispute Credential - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00112-credential-dispute","text":"Credential dispute is available and done according to [W3C] specifications.","title":"[IDM.OCM.W-STACK.00112] Credential Dispute"},{"location":"ocmwstack/ocmwstack/#revoke-credential-acceptance-criteria","text":"","title":"Revoke Credential - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00113-credential-revocation","text":"Credential revocation is available and done according to [W3C] specifications.","title":"[IDM.OCM.W-STACK.00113] Credential Revocation"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00114-credential-refresh-endpoint","text":"Existing credentials can be reissued with the same attributes to the same DID / wallet.","title":"[IDM.OCM.W-STACK.00114] Credential Refresh Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00115-credential-refresh-function","text":"Existing credentials can be automatically reissued based on a property of the previously issued credential.","title":"[IDM.OCM.W-STACK.00115] Credential Refresh Function"},{"location":"ocmwstack/ocmwstack/#prove-credential-acceptance-criteria","text":"","title":"Prove Credential - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00116-presentation-requests","text":"A presentation request is sent, and if no connection to the presenter exists, it is created. A presentation can also be sent as a response to a request.","title":"[IDM.OCM.W-STACK.00116] Presentation Requests"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00117-presentation-status","text":"Presentation status attribute exists and is handled accordingly through events.","title":"[IDM.OCM.W-STACK.00117] Presentation Status"},{"location":"ocmwstack/ocmwstack/#credential-types-acceptance-criteria","text":"","title":"Credential Types - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00118-public-credential","text":"Credentials can be marked as public and be able to access from outside the cluster.","title":"[IDM.OCM.W-STACK.00118] Public Credential"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00119-credential-type","text":"Credential types are existing and are bound to specific schemas. The issuing is able to use it.","title":"[IDM.OCM.W-STACK.00119] Credential Type"},{"location":"ocmwstack/ocmwstack/#credential-and-connection-storage-acceptance-criteria","text":"","title":"Credential and Connection Storage - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00120-credential-connection-storing","text":"Credentials and Connections are stored.","title":"[IDM.OCM.W-STACK.00120] Credential / Connection Storing"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00121-credential-connection-querying","text":"Credentials and Connections can be queried.","title":"[IDM.OCM.W-STACK.00121] Credential / Connection Querying"},{"location":"ocmwstack/ocmwstack/#did-document-manager-acceptance-criteria","text":"","title":"DID Document Manager - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00122-create-did","text":"A DID is created and the document is resolvable over the universal resolver. The document contains valid key material of the OCM.","title":"[IDM.OCM.W-STACK.00122] Create DID"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00123-create-public-profile-endpoint","text":"A Public Profile Endpoint exists and serves the Self-Declaration of the organization in the format of signed VP.","title":"[IDM.OCM.W-STACK.00123] Create Public Profile Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00124-update-public-profile-endpoint","text":"The Public Profile Endpoint can be updated successfully, and the endpoints are available in the DID Documents during resolving.","title":"[IDM.OCM.W-STACK.00124] Update Public Profile Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00125-delete-public-profile-endpoint","text":"The Public Profile Endpoint can be deleted successfully and the did document does not contain the endpoint anymore after resolving.","title":"[IDM.OCM.W-STACK.00125] Delete Public Profile Endpoint"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00126-append-terms-of-use","text":"The Terms of Use can be linked successfully to a trust zone and a credential contains the correct values during issuing.","title":"[IDM.OCM.W-STACK.00126] Append Terms of Use"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00127-append-evidence","text":"The Evidence Section can be linked successfully, and a credential contains the correct values during issuing.","title":"[IDM.OCM.W-STACK.00127] Append Evidence"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00128-append-dispute","text":"The Dispute Section can be linked successfully, and a credential contains the correct values during issuing.","title":"[IDM.OCM.W-STACK.00128] Append Dispute"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00129-append-service-endpoints","text":"Service Endpoints can be linked successfully, and the document contains the configured type and the configured endpoints.","title":"[IDM.OCM.W-STACK.00129] Append Service Endpoints"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00130-write-update-delete-did-document-endpoints","text":"Endpoints for the manipulation of the DID Document exist and the did document contains the configured service endpoints after the endpoint was used.","title":"[IDM.OCM.W-STACK.00130] Write, Update, Delete DID Document Endpoints"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00131-tsa-interface","text":"The DID Document Manager interfaces with the TSA at the appropriate times / places, if applicable. TSA is used to verify incoming connection for blacklist entries, incoming DID, IP address etc. and TSA is used for issuing/receiving credentials for trusted parties and connections.","title":"[IDM.OCM.W-STACK.00131] TSA Interface"},{"location":"ocmwstack/ocmwstack/#credential-signing-and-verification-acceptance-criteria","text":"","title":"Credential Signing and Verification - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00132-credential-signer","text":"The Credential Signer successfully signs a Credential with an eIDAS compliant signature which is verifiable with the DSS framework[21].","title":"[IDM.OCM.W-STACK.00132] Credential Signer"},{"location":"ocmwstack/ocmwstack/#21-httpseceuropaeudigital-building-blocksdsswebapp-demodocdss-documentationhtml","text":"","title":"[21] [https://ec.europa.eu/digital-building-blocks/DSS/webapp-demo/doc/dss-documentation.html]"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00133-credential-verifier","text":"The Credential Verifier successfully proves the signature on a Credential by using the DSS Framework.","title":"[IDM.OCM.W-STACK.00133] Credential Verifier"},{"location":"ocmwstack/ocmwstack/#secrets-management-acceptance-criteria","text":"","title":"Secrets Management - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00134-create-secrets","text":"The Secrets Management Service successfully creates and stores secret cryptographic material.","title":"[IDM.OCM.W-STACK.00134] Create Secrets"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00135-qes-signatures","text":"The concept is prepared, and connectable to a QES TSP.","title":"[IDM.OCM.W-STACK.00135] QES Signatures"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00136-secret-engine-selection","text":"The implementation MUST be able to support multiple secret engines to support multi tenancy. This SHOULD be realized by inserting the used hashicorp vault secret engine name into the rest API calls.","title":"[IDM.OCM.W-STACK.00136] Secret Engine Selection"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00137-tsa-service","text":"All signing and verification operations MUST be done over the TSA Signing/Verification Service. These services using the hashicorp vault transit engine, which MUST be in any case the solution for signing and verification purposes.","title":"[IDM.OCM.W-STACK.00137] TSA Service"},{"location":"ocmwstack/ocmwstack/#schema-management-acceptance-criteria","text":"","title":"Schema Management - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00138-trusted-schema-content-api","text":"The exposed endpoints are demonstrated to effectively and securely create, update, get and resolve schemas.","title":"[IDM.OCM.W-STACK.00138] Trusted Schema Content API"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00139-trusted-schema-management","text":"The create, update, get and resolve functionality is securely accessible through the endpoints.","title":"[IDM.OCM.W-STACK.00139] Trusted Schema Management"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00140-verifiable-ledger-abstraction","text":"Schemas are created, resolvable and read on the verifiable ledger, one of which is [EBSI]. Schemas are also creatable and resolvable from IPFS Gateways and from Webservers.","title":"[IDM.OCM.W-STACK.00140] Verifiable Ledger Abstraction"},{"location":"ocmwstack/ocmwstack/#nonfunctional-acceptance-criteria","text":"","title":"Nonfunctional - Acceptance Criteria"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00141-performance-scalability","text":"The services are demonstrated to be scalable.","title":"[IDM.OCM.W-STACK.00141] Performance Scalability"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00142-gdpr-audit-logging","text":"Access to [GDPR] specific personal data is specified.","title":"[IDM.OCM.W-STACK.00142] GDPR Audit Logging"},{"location":"ocmwstack/ocmwstack/#idmocmw-stack00143-gdpr-data-processing","text":"[GDPR] relevant personal data used in business processes is described and deleted (if applicable).","title":"[IDM.OCM.W-STACK.00143] GDPR Data Processing"},{"location":"ocmwstack/ocmwstack/#appendix-a-glossary","text":"For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO]","title":"Appendix A: Glossary"},{"location":"ocmwstack/ocmwstack/#appendix-b-architecture","text":"","title":"Appendix B: Architecture"},{"location":"pcmcloud/pcmcloud/","text":"Software Requirements Specification for Gaia-X Federation Services Cloud Personal Credential Manager IDM.PCM.CLOUD Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA 1 Introduction 1.1 Document Purpose 1.2 Product Scope 1.3 Definitions, Acronyms and Abbreviations 1.4 References 1.5 Document Overview 2 Product Overview 2.1 Product Perspective 2.2 Product Functions 2.2.1 Overview 2.2.2 Frontend 2.2.3 cPCM Core 2.2.4 cPCM Form Factors 2.3 Product Constraints 2.4 User Classes and Characteristics 2.5 Operating Environment 2.6 User Documentation 2.7 Assumptions and Dependencies 3 Requirements 3.1 External Interfaces 3.1.1 User Interfaces 3.1.2 Software Interfaces 3.1.3 Communications Interfaces 3.2 Functional 3.2.1 General 3.2.2 Managing Connections 3.2.3 Managing Credentials 3.2.4 Wallet Backup 3.2.5 Credential Wallet synchronization 3.2.6 End User Authentication 3.2.7 DIDComm Login Support 3.2.8 SIOP Login Support 3.2.9 App Settings Configuration (personalization) 3.2.10 Consent Management 3.2.11 Visualization/UI 3.2.12 Remote Control Protocol 3.2.13 Plugin System 3.2.14 Mediator 3.3 Other Nonfunctional Requirements 3.3.1 HTTP Requirements 3.3.2 User Feedback / Logging Requirements 3.3.3 Security Requirements 3.3.3.1 General Security Requirements 3.3.3.2 Service Speci\ufb01c Security Requirements 3.3.4 Software Quality Attributes 3.4 Compliance 3.5 Design and Implementation 3.5.1 Installation 3.5.2 Usability 3.5.3 Maintainability 3.5.4 Interoperability 3.5.5 Distribution 3.5.6 Service Meshing 3.5.7 Standard Technology 3.5.8 Metrics 3.5.9 Configurability 3.5.10 Runtime Stability 3.5.11 Deployment 4 System Features 4.1 Managing Connections 4.2 Managing Credentials 4.3 Wallet Backup 4.4 Credential Wallet synchronization 4.5 End User Authentication 4.6 DID Input 4.7 SIOP Login 4.8 App Settings Configuration (personalization) 4.9 Browser-based application/addon for stationary PCs and notebooks 4.10 Cloud based User Agent/Wallet 5 Verification 5.1 Acceptance criteria 5.1.1 Connections 5.1.2 Managing credentials 5.1.3 Wallet Backup 5.1.4 Credential Wallet synchronization 5.1.5 End User Authentication 5.1.6 Consent Management 5.1.7 Plugin System 5.1.8 Remote Control 5.2 Support for Kubernetes Appendix A: Glossary Appendix B: Example Consent Management List of Figures Figure 1: Block Overview Figure 2: Communication Overview Figure 3: Personal Credentials Manager: Application Cooperation View List of Tables Table 1: References Table 2: User Classes and Characteristics Table 3: Toolstack Table 4: Functional Requirements Connection Management Table 5: Functional Requirements Credential Management Table 6: Functional Requirements Wallet Backup Table 7: Functional Requirements Credential Wallet Importing/Exporting Table 8: Functional Requirements End User Authentication Table 9: Functional Requirements QR Code Scanning (DID Input) Table 10: Functional Requirements SIOP Login Table 11: Functional Requirements App Settings Configuration (personalization) Introduction To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD]. Document Purpose The purpose of the document is to specify the requirements of the Identity Management and Trust Subcomponent \"Cloud Personal Credential Manager\" with the intention of a European wide public tender for implementing this software. Main audience for this document is attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide a credential manager application to be used by natural people to participate in the Gaia-X trust structure. Product Scope The purpose of these products is to provide all necessary components for the self-sovereign administration of the digital identity of a principal in the Gaia-X context. The Cloud Personal Credential Manager enables a natural person to act as a principal of an organization within the SSI-based Gaia-X ecosystem in a privacy-preserving, trustful and secure way from a computer browser. This comprises the following main functionalities: Remote Management of a Cloud Wallet or multiple Wallets which are connected to the cPCM Reception and management of verifiable credentials from other parties (e.g., a principal credential from a Gaia-X participant) by using the web frontend Presenting Verifiable Presentations to other parties in an automated or manual manner by using plugins Secure storage and management of respective secrets Consent Management Policy Based Decisions about Issuing/Presentations Plugin System which extends the Holder Capabilities The Cloud Personal Credential Manager(cPCM) must be implemented as a cloud component which provides the end user a web front- end for managing the connected OCM [IDM.OCM], OCM W-Stack [IDM.OCM.W-STACK] and TSA [TSA] by providing an integration layer for various use cases of Holders. In general, the cPCM acts as an integration layer between OCM, OCM W-Stack and TSA to orchestrate for the user various use cases by using plugins e.g., \"ID Card Proof Plugin\" which provides the function \"Automatically prove that you own a valid id card\". It's strictly required to use OCM, OCM W-Stack and TSA for this purpose. Building a new agent and reimplementing protocols like aries is not foreseen here! cPCM acts strictly as an integration layer, with a connection to the PCM and must provide just a REST API. All SSI related protocols must be realized over OCM and OCM W-Stack. Furthermore, the necessary tools to operate and maintain the created software components in an enterprise environment with focus on high-availability, security, monitoring, and logging based on common standards. Documentation for developer, operator and user MUST be written in markdown format and have to be published in the provided public repository. If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams. Definitions, Acronyms and Abbreviations The IDM and Trust Architecture Overview Document [IDM.AO] MUST be considered and applied as the core technical concept that also includes the Terminology and Glossary. All requirements from other documents are referenced by[IDM.\\<document-id>.XXXXX] as defined in the chapter \"Methodology\" in the document [IDM.AO]. References Reference Title Status [BDD] Getting Started with Behavior Driven Development - Specflow Status 07-19-2023 [DIDAAS] DID as a Service - DID Management Service Status 08-22-2023 [DID SIOP] OpenID, Self-Issued OpenID Connect Provider DID Profile - OpenID Connect Self-Issued Profile Status 07-19-2023 [IDM.AO] Gaia-X WP1 (2021), Architecture Overview (Base of functional specification) [IDM.PCM] Personal Credential Manager Document (Refer to \"annex_IDM_PCM\") [IDM.TSA] Trust Services API Document (Refer to \"annex_IDM_TSA\") [IDM.OCM] Organization Credential Manager Document (Refer to \"annex_IDM_OCM\") [IDM.OCM.W-STACK] Organization Credential Manager W-Stack Document (Refer to \"annex_IDM.OCM.W-STACK\") [NF.SPBD] Gaia-X Federation Service Non-functional Requirements: Security & Privacy by Design (Refer to annex \"GXFS_Nonfunctional_Requirements_SPBD\") [OIDC] OpenID working groups specifications - OpenID Specifications [OID4VC] OpenID for Verifiable Credential Issuance - OpenID Verifiable Credential Issuance Status 07-19-2023 [OID4VP] OpenID for Verifiable Presentations - OpenID Verifiable Presentations Status 07-19-2023 [PRD] Gaia-X Policy Rules Document - Gaia-X Policy Rules Status 07-19-2023 [TAD] Gaia-X Architecture Document - Gaia-X Architecture Document Status 07-19-2023 [TDR] Gaia-X Federation Services Technical Development Requirements (Refer to annex \"GXFS_Technical_Development_Requirements\") [W3C] Verifiable Credentials Data Model - Verifiable Credentials Data Model Status 07-19-2023 Table 1: References Document Overview The document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.Number] ). Product Overview Product Perspective The Cloud Personal Credential Manager is an integration layer to existing OCM/OCM-W Stack/TSA for natural persons. Within the Gaia-X terminology, such a natural person is named principal . The principal utilizes the cPCM in the respective form factor to manage stored VCs issued to her/him as well as to prove the statements necessary to obtain a service. The cPCM must support the following overall use cases: Managing Credentials over an Web front-end New Business Functionality (e.g., Plugin for Fitness Studio, Plugin for ID Card, Plugin for eID etc.) for the users key material by using Plugins Strong key management, which is connected to OCM, OCM W-Stack and TSA (Hashicorp Vault) which can be used for authentication, consent and creating new DIDs by utilizing the OCM, TSA and OCM W-Stack Providing a Web Socked Based Remote Control Protocol which allows the user to give consent, trigger backups and observe the connected cloud wallets Define Rules and Policies for Credential Acceptance, Credential Issuing and Credential Rejection by using the TSA over the Web front-end Consent Management and Consent Notifications (in general: proof notifications) Event Notifications All of the features described in this document, MUST be set on top of the OCM, OCM W- Stack and the TSA. New Agents are not allowed, but additional microservices to provide the required Features are allowed. The entire software stack is then an aggregation of cPCM Backend, OCM(W-Stack), TSA and PCM as in this block picture: Figure 1: Block Overview As presented in the cPCM big picture layering overview, cPCM consists of different components which effectively comprise the following layers: The front-end layer cPCM Backend Mediator Component In this case the backend has the task to orchestrate the functionality between the components and to provide extension functionality like consent management, credential visualization and control about connections, presentations and issuings. The block diagram above, is the setup for ONE single user. Multi Tenancy is not considered. For the deployment of the Cloud PCM, each tenant needs the entire setup, which makes it strictly required to reduce the footprints of the components and identify improvements for reducing the number of components to deploy. Also, strategies to shutdown components during inactivities etc. must be developed. From communication perspective, the architecture MUST consider the following concept: Figure 2: Communication Overview Product Functions Overview The Cloud PCM acts as an integration layer for the OCM, OCM W-Stack and TSA to support an end user for handling his/her credentials in the cloud. This means from a functional perspective that all features must be securely remotely controllable by the WEB UI or by the PCM app. This requires the establishment of a secure web socket channel between the PCM App/Web UI and the Cloud PCM by developing pairing mechanisms on SSI basis. In general, the cPCM receives commands over the web socket channel and orchestrates the work in the background by utilizing the OCM/OCM W-Stack and the TSA to provide a value add for the end user. The end user doesn\\'t care about credential formats or connections, so the cPCM must be able to provide an UX which hides all agent information from the user by providing core functions and plugin-based extensions. Figure 3: Personal Credentials Manager: Application Cooperation View Frontend In detail the front-end layer is comprised of the following features and components: End User Authentication: component provides for the implementation of secure user authentication policies which can include but are not limited to PIN, password, etc. Graphical User Interface (GUI): enables end users to interact with the cPCM and use the cPCM functions. Local Input Interfaces: comprise link processing. And that provides communication initiation, indirect, or peer-to-peer (contact). cPCM Core The cPCM Core (Wallet) layer consists of the following features and components: Managing Connections (where applicable) App Settings Configuration (Personalization) Managing Credentials Wallet Backup Credential Wallet Importing/Exporting Secret Storage Plugin System Consent Management The Managing Connections service within the backend establishes the connection with the communication entities outside cPCM (such as a Service Provider or a Credentials Issuer) by using the OCM provided REST APIs. For instance, after receiving the bootstrapping request from the Local Input Interfaces in the Frontend . App Settings Configuration abstracts the implementation of possible personalization properties that tailor the respective cPCM instance to the needs and requirements of a specific end user. The Managing Credentials feature provides the functionality for managing credentials in the UI, receiving credentials issued by other participants, enabling the user to view and inspect his/her credentials, and the basic functionality for providing credential attributes to other participants according to the SSI paradigm. The credential manager ensures that the user is always in control, which credentials with which content is presented and issued, and which credentials from which party were received. This includes the UI visualization, notifications and as well the orchestration between different components as OCM(s), TSA and PCM mobile. The Wallet Backup feature provides a secure backup for the received credentials on the smartphone. A web socket function realizes the secure transfer of backup files of the PCM App to the cPCM backend. The Credential Wallet Importing/Exporting feature allows to securely export the credentials from cPCM or PCM, and to import the credentials into other PCM or cPCM. Through this, the so-called cross-wallet compatibility can be ensured in future (that is, the compatibility between different implementations of PCM that share the same standard for credentials definition and management). It should be also possible to store created PCM backups versioned into the cPCM for later usage and restore functionality. This feature is just applicable for W3C credentials [W3C]. Aries credentials are out of scope. Secret storage provides for secure persistent storage of the backuped credentials and files. A separate key management handles the user generate secrets such as private keys or seeds to use it later for the generation of JWT tokens, requesting or issuing credentials by utilizing the connected OCMs. The plugin system provides the capability to develop and enable new plugins for the cPCM, which can interact with the orchestration flow of the linked TSA and the OCMs. This MUST be realized over an eventing pattern which allows developers to integrate their processes into the raised events. Consent Management provides an additional plugin event pattern which observes presentations and issues requests to the underlying OCM(s) which are handled then type by type over a consent plugin. For each type, the plugin executes a flow which forces the user to fill in more required data and to give consents acceptions. Either by accepting conditions, filling in data, adding pins etc. The precise flows of each plugin are out of scope. But the plug-in system must establish a frame, which allows the communication to the PCM mobile and provides basic tools like \"Request Additional Data\" or \"Accept Conditions\" or similar. The Mediator (Relay) layer is represented by the Mediator/Relay component which effectively provides notification management and therefore dispatches the externally received notifications for connection establishment to the respective cPCM where it is applicable. cPCM Form Factors The cPCM frontend MUST be a React Native web page based on bootstrap to support different Form Factors and Responsive Design. Product Constraints [IDM.PCM.CLOUD.00000] The document IDM.AO is the common basis for this functional specification The architecture document [IDM.AO] is an essential part of this specification and a prerequisite for understanding the context. The specifications and requirements from the Architecture Document MUST be considered during implementation. [IDM.PCM.CLOUD.00001] User restriction The cPCM MUST be designed in a way so that one cPCM instance is to be used by a single personal user. One cPCM instance MUST NOT be shared by multiple users. [IDM.PCM.CLOUD.00002] Aries Independency The cPCM backend MUST be a stand-alone backend which is providing rest interfaces as integration layer for OCM, TSA and W-Stack, which means that this backend provides a kind of business layer to the OCM/OCM W-Stack and the TSA stack. Aries RFCs MUST not be implemented, because the cPCM backend MUST NOT act as agent as such. [IDM.PCM.CLOUD.00003] No Agent Implementation The Cloud PCM MUST NOT Implement an Agent framework to avoid complexity. OCM and OCM W-Stack are already SSI Agents where all SSI Agent related things MUST be addressed. [IDM.PCM.CLOUD.00004] Mediator Foundation The aries mediator service [1] MUST be used as the foundation for the mediator service for W3C functionality. [1] [https://github.com/hyperledger/aries-mediator-service] [IDM.PCM.CLOUD.00005] Deployment The entire product is an assembling of OCM Indy/OCM W-Stack, TSA and new microservices for backends. Because of this, the deployment is essential to have the right setup for each user. Therefore, the entire product relies very hard on Helm Charts and Deployment Setups. [IDM.PCM.CLOUD.00006] k8s Operator To simplify the deployment a Kubernetes Operator MUST be developed to support an easier deployment for multi tenancy purposes. The operator MUST ensure that instances are reused, shut down etc. [IDM.PCM.CLOUD.00007] Resource Consumption To have multiple instances of the Cloud PCM can result in very big resource consumption. For this purpose, the architecture MUST be planned in a way that instances per user are less required or just hosted when a user is actively using it. E.g., serverless functions or by bootstrapping postgres database storage just in time when a credential for a user is received or must be presented or bootstrapping a OCM microservice just, when an attestation is required. Main goal of this requirement is to keep the operational costs as low as possible. User Classes and Characteristics User Class Description Expertise Privilege Level Product Usage Personal User The person in possession of the personal credential manager using all functionality of the product Low High Frontend Cloud Operator The cloud operator naturally has some sort of access to the cloud wallet and its infrastructure. The cloud wallet must be implemented in a way so that the cloud operator cannot access or use secrets/credentials stored in the OCM instances or in the cPCM storage. High Operator Backend/Cloud Table 2: User Classes and Characteristics Operating Environment Please refer to [TDR] for further binding requirements regarding the operating environment. [IDM.PCM.CLOUD.00008] Browser Support The product part for the browser extension/app MUST be available for the common browsers: Firefox, Chromium based and Safari. [IDM.PCM.CLOUD.00009] Operating Environments For the Web Frontend the common browsers Chrome, Firefox, Safari and Microsoft Edge must be supported. The cPCM backend MUST be runnable on the open Linux standard in the current LTS version. [IDM.PCM.CLOUD.00010] Kubernetes Environment The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on a provided SCS cluster (Sovereign Cloud Stack). User Documentation Please refer to [TDR] for further requirements regarding documentation. [IDM.PCM.CLOUD.00011] Participant Administration Documentation The documentation MUST contain: Installation Manuals(if applicable) Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests/Verification How to build the product/services from source code [IDM.PCM.CLOUD.00012] Participant Documentation The documentation MUST contain: Short Software Description/Usage Usage Guide GDPR Design Decisions(extended version of the existing one) Security Concept Operations Concept Keyword Directory [IDM.PCM.CLOUD.00013] Cloud Operator Documentation The documentation MUST contain: Operational Handbook Installation Footprint Reduction Assumptions and Dependencies An understanding of the overall Gaia-X architecture and philosophy is necessary. Please refer to [TAD] and [PRD]. The attendees of the public tender must get an understanding of the current implemented features of the PCM [IDM.PCM], OCM [IDM.OCM], OCM W-Stack [IDM.OCM.W-Stack] and TSA [IDM.TSA]. Additionally, knowledge in OIDC4VC/VP [OID4VC] [OID4VP] and SSI is given. Requirements External Interfaces User Interfaces [IDM.PCM.CLOUD.00014] Web Interface for Browser-based Applications The cPCM MUST provide a web interface based react native for browser-based applications. All functions available to the PCM user MUST be available via this web interface (except those which are not applicable such as camera scanning and NFC). Software Interfaces [IDM.PCM.CLOUD.00015] Secure Storage The cPCM implementation MUST be able to use secure storage (internal storage, encrypted storage, dedicated key storage) provided by the target platform for storing cPCM data e.g., backup files. [IDM.PCM.CLOUD.00016] Key Management The cPCM implementation MUST have a secure key management with hashicorp vault to control the used key engine for TSA Signings, OCM W-Stack Signings etc. Communications Interfaces [IDM.PCM.CLOUD.00017] DIDComm Interface The cPCM backend utilizes for all Credential associated DIDComm communications the OCM and the OCM W-Stack and don\\'t implement by itself a DIDComm Communication. [IDM.PCM.CLOUD.00018] OIDC4VC/VP Interface The cPCM backend utilizes for all OIDC4VC/VP communications [OID4VC] [OID4VP] the OCM and the OCM W-Stack and don\\'t implement by itself a OIDC4VC/VP Communication. [IDM.PCM.CLOUD.00019] DIDComm v2 Messaging All interfaces from the PCM to the cPCM backend MUST be implemented as didcomm v2 messages. For instance: List Credentials, Delete Credential, Request Credential etc. The protocol MUST NOT reflect OCM protocols 1:1. e.g., List Connection or List Proofs. The cPCM Backend MUST encapsulate this for a UX by creating an integration layer which speaks an simplified didcomm v2 protocol for notification, consent and remote control. The developed didcomm protocol has to be defined as an architecture diagram and documented in the git repos similar to the Aries RFC documentation pattern. [IDM.PCM.CLOUD.00020] Backup/restore interface for Personal Wallet The cPCM MUST provide an interface for backup and restore of the cPCM data (which is stored in the wallet) based on the didcomm protocol and cPCM Rest API. [IDM.PCM.CLOUD.00021] Import/Export interface for Personal Wallet To provide flexibility and interoperability between Applications and PCM Form Factors, the cPCM MUST provide interfaces for securely Exporting the personal wallet W3C content, as well as interfaces for securely Importing the personal wallet W3C content and restoring them in another application or PCM Form Factor. This includes the key material for using them. A scenario can be that a participant credential is transferred from the OCM W-Stack (which is linked to the cPCM), is transferred to a tablet to use the tablet within an secured area of a manufacturing side without internet access (but WIFI). [IDM.PCM.CLOUD.00022] Personal Wallet Synchronization The cPCM must provide functionality for automatic secure synchronization with a PCM. The synchronization must be bi-directional and is just belonging to W3C credentials (No Aries). The synchronization MUST be configurable in the cPCM backend over an Configuration Endpoint which the user can use to select the connected devices and the content which needs to be synced. [IDM.PCM.CLOUD.00023] PCM management The cPCM backend MUST provide functionality to be managed via PCM or the Web UI. An initial linking between PCM and the cPCM backend works just over the Web UI. All paired devices MUST be visible in the cPCM UI to manage the devices (add, remove, block etc.). [IDM.PCM.CLOUD.00024] Eventing If it is required to use events within the software architecture, it is mandatory to use software abstraction according to cloud event specification [2] for publishing and subscription. The minimal supported protocol binding MUST be HTTP Protocol Binding [3]. [2] [https://cloudevents.io/] [3] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/bindings/http-protocol-binding.md] [IDM.PCM.CLOUD.00025] Eventing Infrastructure The event broker for the eventing MUST abstract the storage and delivery infrastructure. In Kubernetes environments, the event broker MUST be uniform across all lots by using NATS [4] and/or kNative. [4] [https://nats.io/] [IDM.PCM.CLOUD.00026] Login Support The cPCM MUST support OIDC flows for login, such as DID SIOP and Authorization Code Grants by Standard IAM Systems. For a pairing of devices, a separate flow MUST be developed to initiate it. [IDM.PCM.CLOUD.00027] Web Sockets For syncing the Wallets, Web Sockets MUST be used. Each didcomm message structure within the channel MUST be aligned with the technical lead. Functional General [IDM.PCM.CLOUD.00028] DID Document Provisioning To highlight the existing endpoints the cPCM MUST be able to provide DID (Web) Documents for himself which contain the used endpoints and his key material. These DID Documents MUST be configurable in the cPCM database to generate multiple DIDs by TSA DID Web as a Service. Over these DID documents, the cPCM can act as proxy DID for each user and can variate the endpoints which are used by the user. The endpoints themselves are pointing to the OCM instances and TSA endpoints/mediator belonging to the cPCM. Note: Others will resolve this DID to find the communication endpoints, so it MUST be publicly available over an GET endpoint. All service endpoints MUST be configurable as Json to inject it in the TSA policy. [IDM.PCM.CLOUD.00029] DID Document Resolving The DID Document of the cPCM MUST be resolvable by the Universal Resolver and it MUST contain all key material used by the cPCM including all endpoints following this service configuration format by enhancing the W3C spec [5]: > { > id: {idName} > type: {typeName}, > accept: \\[\"didcomm/v2\",\"didcomm/v1\",{otherProtocols}\\], > serviceEndpoint:\\[\"https://...\"\\] > } [5] [https://www.w3.org/TR/did-core/#example-usage-of-the-service-property] [IDM.PCM.CLOUD.00030] Multi Tenancy The Cloud PCM MUST support Scale Down to 0 to avoid high operational costs. [IDM.PCM.CLOUD.00031] Browser Wallet Protocol The Cloud PCM MUST provide a protocol which integrates with external web sites to offer credential presentations triggered by the user/website. Managing Connections [IDM.PCM.CLOUD.00032] Connection invitation Connection requests can be provided to the cPCM user via Text input (URL), and by regular messages. The function can be activated by the cPCM user via the GUI by uploading an QR or pasting an invitation link. An invitation message is received via the PCM app, and the user can decide either take it directly in the PCM app or push it to the cloud app (just in case of aries) [IDM.PCM.CLOUD.00033] List connections The cPCM user can view a list of connections stored in the underlying OCM(s). [IDM.PCM.CLOUD.00034] Search connections The user can search connections stored in the underlying OCM(s). A full text search in all information available for the connection must be provided. The search result MUST be shown at the GUI. [IDM.PCM.CLOUD.00035] Display connection details The cPCM user can view detailed information about a connection. The information shown MUST include the DID document describing the connection contact. [IDM.PCM.CLOUD.00036] Display connection communication history The cPCM user can view detailed information about the communication history of a given connection (Activities where are applicable). [IDM.PCM.CLOUD.00037] Delete connection The cPCM user delete a connection from OCM(s). [IDM.PCM.CLOUD.00038] Block connection The cPCM users delete a connection from OCM(s). [IDM.PCM.CLOUD.00039] Connection Details The user MUST be able to define details to a connection e.g., Name, Company etc. together with details about credentials. Managing Credentials [IDM.PCM.CLOUD.00040] Receive a Verifiable Credential (VC) Within an established connection, a VC can be issued to the user. The cPCM is in the role of the \"Holder\" within this protocol. The request is validated, and the information is notified to the user via the GUI or App. The user MUST get the possibility to accept or to reject the request by using his PCM App or the Web UI. The cPCM orchestrates these requests and notifications and tracks the history in his internal storage. Over the UI the user can see which credentials were received and from whom (displayed as cards). A differentiation between aries, ipfs or w3c MUST not be made. The user MUST see just one card per credential with some hints that his credential type exists multiple times (grouped by schema name). [IDM.PCM.CLOUD.00041] Display/inspect a VC The cPCM user SHOULD view detailed information about a VC per card. The information shown MUST include all VC data items and MUST be integrated in a details view. [IDM.PCM.CLOUD.00042] List VCs The cPCM user can view a list of VCs stored in the connected OCM(s). [IDM.PCM.CLOUD.00043] Search VCs The user can search VCs stored in the OCM(s). A full text search in all information available for the VCs must be provided. [IDM.PCM.CLOUD.00044] Answer Request Verifiable Presentation (VP) The cPCM MUST be able to notify and process Presentation requests received via any OCM. This includes the selection of the credentials which match the criteria, the selective disclosure of attributes (indy based), and the verification of the requestor (train). All of these points need to be controlled by the user either by PCM App or Web UI. If the user has selected his preferred attributes and credentials, he is able to confirm the presentation and the request is processed by the cPCM backend which completes the process in the requesting OCM. If a plugin is listening on the events, the plugin MUST interrupt the process before it is further processed. [IDM.PCM.CLOUD.00045] Display history of presenting Verifiable Presentations (VPs) The user can view detailed information about the history of showing/proofing identity information to other participants. For each presentation, the information MUST be logged including all information contained in the VP shown to a verifier, to which verifier it has been shown, and transaction date/time etc.. [IDM.PCM.CLOUD.00046] Accepting Rules The user MUST be able to define for connections/DIDs, presentations, and issuings, rules to accept/reject automatically. e.g., by Type, Claims etc. For these rules the TSA in the background MUST be used. Wallet Backup [IDM.PCM.CLOUD.00047] Create Backup The cPCM MUST provide a function to backup all information sent by the PCM. The backup file MUST be confidentiality and integrity protected. Protection MUST follow current standards regarding protocols and cryptographic artifacts (refer to section \"Security Requirements\"). The cPCM MUST provide a method for protecting access to the data within the backup with at least two authentication factors. [IDM.PCM.CLOUD.00048] Restore Backup The cPCM MUST provide a function to restore a backup file(s) containing all information stored from the PCM App. The Backup/Restore format MUST be compatible to guarantee PCM interoperability between form factors and between different providers, browsers or Smartphone Application as GXFS PCM. Credential Wallet synchronization [IDM.PCM.CLOUD.00049] Sync Wallets The cPCM provides a functionality to synchronize different personal wallets, e.g., synchronize a cloud wallet with a smartphone wallet GXFS PCM [IDM.PCM] to support offline usage. Secure methods for Importing the GXFS PCM Secrets MUST be provided. [IDM.PCM.CLOUD.00050] Block Wallets If a Device was stolen, the cPCM MUST be able to block devices to stop syncing. End User Authentication [IDM.PCM.CLOUD.00051] Initial user onboarding The cPCM MUST provide a function for the initial user onboarding, when the cPCM is initialized. Additionally, this function also initializes the wallet. For this onboarding the PCM Wallet MUST be used. A user MUST be able to onboard in his PCM App potentially multiple cPCM (e.g., hosted by different providers). [IDM.PCM.CLOUD.00052] User Authentication The cPCM MUST provide a function which performs user authentication to open the cPCM for the user. [IDM.PCM.CLOUD.00053] Configure login credentials The cPCM MUST provide a function, where the user can modify his/her login verifiable credential. [IDM.PCM.CLOUD.00054] Secure Restore of authentication credentials The cPCM MUST provide a function for securely restoring the users' authentication credentials (e.g., forgotten password/pin). [IDM.PCM.CLOUD.00055] Second Factor The cPCM MUST provide a function for second factor login support by using the PCM functionality. DIDComm Login Support [IDM.PCM.CLOUD.00056] DIDComm Login Support Description To login the user with existing Indy Credentials, the cPCM MUST utilize the OCM to request proofs for identification. This is an alternative login variant next to OIDC methods [OIDC]. The detailed process for this is as follows: cPCM provides the indy based login method If user selects it, cPCM requests from OCM an Invitation Link and presents it to the user The user scans it with his cPCM and accepting the connection invitation presented by an QR code The PCM app establishes a DIDComm connection to the cPCM OCM, which will reply with an proof request and the user presents the proof After presenting the proof, and event will be raised and the cPCM can check the presented attributes of the underlying OCM SIOP Login Support [IDM.PCM.CLOUD.00057] SIOP Login Support The cPCM MUST implement a function to process SIOP requests [DID SIOP] in the role of the Self- Issued OpenID Provider (SIOP). Applications (RPs (Relying Parties) in SIOP terminology) can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response. This is also the preferred method to pair PCM App and cPCM if applicable. App Settings Configuration (personalization) [IDM.PCM.CLOUD.00058] Configure Application Preferences The PCM MUST enable the user to configure his/her application preferences. Application preferences MUST include language settings, device names, device groups, OCM connections, rules and policies for TSA and history limits. The default language is English, but the correct localization of the cPCM MUST be demonstrated. Consent Management [IDM.PCM.CLOUD.00059] Consent Management Plugins The product MUST provide the possibility to add Consent Plugins based on the plugin framework, which observe a special type of requested presentations/credentials to establish the consent flow in the direction of the linked PCM wallets. The result of the consent flow MUST be recorded in the consent records of the wallet. The plugins itself MUST be able to interact with the notification channel to the connected wallets, to pick up added data from the consent on the smartphone, to add it later on in disputes for credentials or in audit logs before presentation etc. All activities MUST be aligned with the PCM development Team. An example could be found in Appendix B. [IDM.PCM.CLOUD.00060] Consent Auditability All given consents MUST be logged for audits. Visualization/UI [IDM.PCM.CLOUD.00061] General The entire UI MUST be an user-friendly dashboard, where the user gets a quick overview. It's not allowed to provide command line behavior or just lists or tables. It MUST be graphically designed for end-users e.g., a doctor, a manager or any other non-IT users and well optimized for touch screens (for example for an iPad). [IDM.PCM.CLOUD.00062] Credential Management The web UI MUST provide a dashboard UI for the user which shows the credentials of the connected wallets, and details like containing attributes, DID, Technology etc. The presentation MUST be as cards like \"Credit Cards\" or similar to give the user maximum UX. [IDM.PCM.CLOUD.00063] DID Creation/DID as Service[6] The web UI MUST provide for the user an UI which allows it to generate new DIDs. This includes DID:Key, DID:WEB, DID:Indy and DID:IPFS. The generated DIDs MUST be linked to the underlying technology, means DID:INDY to the OCM and the others to OCM W-Stack. In the case of DID:WEB the DID as a Service approach [DIDAAS] over TSA MUST be used. [6] [https://gitlab.eclipse.org/eclipse/xfsc/por/did-management-service] [IDM.PCM.CLOUD.00064] Connection Management The web UI MUST provide for the user an UI which shows the connections, the rules for accepting, blocking, and deleting connections with details about the DID, trust zones, which credentials are attached to it etc.. [IDM.PCM.CLOUD.00065] Presentation An incoming presentation request MUST be visualized, and possible credentials highlighted which are fitting to the request. If there is any fitting credential, the user MUST be enabled to present or ignore it. [IDM.PCM.CLOUD.00066] Issuance The web UI MUST provide a functionality where an user can pick a schema from a list (e.g., the schema registrar) and start issuing credentials for it by providing Invitation Links with auto issuance options. These links MUST be sendable by email. [IDM.PCM.CLOUD.00067] Onboarding Flow The UI MUST provide a flow to initialize the Cloud PCM for a new User by utilizing the PCM as authentication tool. The linking of multiple wallets MUST be supported and demonstrated for two smartphones/tablets. Remote Control Protocol [IDM.PCM.CLOUD.00068] PCM Remote Control The Cloud PCM Backend MUST provide a protocol over websockets and didcomm, to control over the PCM things like accepting connections, start issuances, confirm presentations, creating dids, rotating keys etc. The remote control MUST work over didcomm messages which needs to be defined together with the cPCM API. Plugin System [IDM.PCM.CLOUD.00069] Plugin Framework The cPCM backend and the Web UI MUST support the adding of plugins by providing an infrastructure and a template. This includes an interface definition for defining plugins, an integrated event pattern for observing events and encapsulations for using the PCM App Communication channel to send notifications, receive triggers and use the internal PCM storage. If a plugin is created, it MUST be hostable without any reboot of the cPCM backend. The preferred solution SHOULD be a separate microservice per plugin to shutdown/enable/monitor plugins easily. If this is not possible, it MUST be another solution provided. [IDM.PCM.CLOUD.00070] Visualization All Plugins MUST be visualized in a plugin overview, where plugins can be configured, disabled or enabled. The available plugins MUST be provided by a service discovery, where the user can select which plugins are relevant. [IDM.PCM.CLOUD.00071] Plugin Secrets Plugins MUST have a dedicated secret engine per plugin which allows the plugin to create keys for signing, encryption and verification. The implementation MUST be abstract, but for the initial version the hashicorp vault transitengine [7] MUST be used (default stack). Other engines MAY be supported in the first version. [7] [https://developer.hashicorp.com/vault/docs/secrets/transit] [IDM.PCM.CLOUD.00072] Plugin Based Well Known Url Each Plugin is able to define its own key material per tenant next to an well-known jwks url/did which resolves to the key material. [IDM.PCM.CLOUD.00073] Plugin Based Rules Each Plugin is able to use TSA rules. [IDM.PCM.CLOUD.00074] Plugin Based Configuration The user can enable/disable and configure Plugins which are available within the cPCM. [IDM.PCM.CLOUD.00075] Plugin Eventing Plugins can be created which listen on cPCM events. Plugins can intercept them to stop/resume internal processes like issuing/presentation/connections. [IDM.PCM.CLOUD.00076] Plugin to App Communication Plugins can use the internal communication channel from cPCM Backend to paired App to notify changes and receive remote commands. Mediator [IDM.PCM.CLOUD.00077] Relay implementation The product MUST provide the hyperledger mediator as a core component of the cPCM. The endpoints for this mediator MUST be configured in the documents of the cPCM. If necessary, potential didcomm mediation MUST be routed over this component as well. Other Nonfunctional Requirements HTTP Requirements [IDM.PCM.CLOUD.00078] HTTPS All HTTP Endpoints MUST be protected by TLS 1.2 (all protocol version numbers SHOULD be superseded by upcoming standards) Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system. [IDM.PCM.CLOUD.00079] HTTP Protocol Definitions All HTTP Endpoints MUST follow [RFC7231] and [RFC5789], but it MAY be chosen what of the protocols is necessary to realize the functionality. For problem reports the [RFC7807] MUST be used in combination with Standard HTTP Error Codes. User Feedback / Logging Requirements [IDM.PCM.CLOUD.00080] Data Minimization From GDPR perspective the product MUST NOT log data which is related to personal information. (e.g., usernames, birth dates etc.) The product MUST only log data, which is relevant to technical operations, except for the purpose that, in the event of an incident, enable reconstruction of the sequence of the message exchange for establishing the place and the nature of the incident. The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of the following elements: (a) node\\'s identification (b) message identification (c) message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review. [IDM.PCM.CLOUD.00081] Logging Frameworks The product MUST support logging frameworks e.g., graylog, fluentD or logstash to support logging and analysis by enterprise infrastructures. The supported framework MAY be chosen for the first version, but it MUST support potentially the most common open-source logging solutions. The final solution MUST be aligned with the other subcomponents. It MUST be sketched in the operations concept how the support of multiple solutions is given in the future. [IDM.PCM.CLOUD.00082] User Feedback information The cPCM user should receive relevant messages regarding events, successes, and failures during the operation of the cPCM. The user should be notified in a timely, descriptive and privacy preserving manner. Security Requirements General Security Requirements Each Gaia-X Federation Service SHALL meet the requirements stated in the document \"Specification of non-functional Requirements Security and Privacy by Design\" [NF.SPBD]. Federation Services specific requirements will be documented in the next chapter. Service Specific Security Requirements This chapter will describe the service specific requirements, which will extend the requirements defined in the chapter above. [IDM.PCM.CLOUD.00083] Secure user authentication To ensure that only allowed entities can access the cPCM authentication methods MUST be implemented to grant access to the cPCM. ** [IDM.PCM.CLOUD.00084] Protection of Secrets (Wallet) and Security for the Restore process** The cPCM secrets must be stored and processed securely. There MUST be additional security procedures in place to guarantee that the secret key can be recovered when the holder requires it, even in case the holder himself has lost access to his unlock key. ** [IDM.PCM.CLOUD.00085] Secure communication between frontend and cloud agent/wallet** The communication interface in case of the cloud agent/Wallet must be protected according to the latest security standards. [IDM.PCM.CLOUD.00086] TLS Certificate Validity Periods In general, the recommended validity period for a certificate used in the system should be one year or less. Under some circumstances (for example RootCA) the certificate validity can be extended. Certificate owners MUST ensure that valid certificates are renewed and replaced before their expiration to prevent service outages. [IDM.PCM.CLOUD.00087] Security by Design T Security MUST be a design principle from the beginning. Means separation of concerns, different administrative roles, especially for private key material and separate access to the data MUST be covered. It MUST be described in the security concept, what are the different security risks of the product and how they are mitigated (e.g., by Threat Modeling Protocols) [IDM.PCM.CLOUD.00088] Pentesting All parts of the product have to be penetration tested, at least for the following criteria: Unauthorized Access to the System MUST be tested Unauthorized Actions MUST be triggered without a user action All interfaces MUST be tested [IDM.PCM.CLOUD.00089] Storage of Secrets The storage of secret information such as private keys MUST take place in state-of-the-art secure environments to protect secret data confidentiality and integrity. Examples of this are Secure Enclaves, TPMs, HSM or Secure Vaults. In case (Personal) Agents are not equipped with a secure storage it may also be possible to store the secrets in a third party (e.g., Cloud) provider (e.g., Secure Wallet) that MUST provide overall the same level of security as the aforementioned methods. [IDM.PCM.CLOUD.00090] Support for Potential Requirements for Secret Storages Devices that hold cryptographic information and perform cryptographic functions MUST be compliant with standard PKCS #11 [8] or other comparable cryptography standards. [8] [https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=pkcs11] [IDM.PCM.CLOUD.00091] Special Availability and Scalability Requirements for Secret Storage Components Secret Storage components play a central role in storage, encryption, and digital signing in the Gaia-X ecosystem, thus they can become a single point of failure for a Gaia-X participant, for example an organization. Therefore, methods and procedures to ensure the availability and scalability of the Secret Storage functionality MUST be implemented. [IDM.PCM.CLOUD.00092] CVE Patches All software components MUST have applied CVE patches, which are available for major releases. [IDM.PCM.CLOUD.00093] Major Releases All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening. Software Quality Attributes [IDM.PCM.CLOUD.00094] Quality Aspects The software MUST meet the following requirements: The quality standards MUST meet ISO 25010 [9] Robustness / Reliability Performance Interoperability with the other work packages from GAIA-X project Security Adaptability / expandability Maintainability and Code Quality [9] [https://iso25000.com/index.php/en/iso-25000-standards/iso-25010] [IDM.PCM.CLOUD.00095] Software Quality Requirements All software components MUST be compliant to the requirements within the quality assurance repository [10]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology. [10] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues] Compliance [IDM.PCM.CLOUD.00096] GDPR Audit Logging All GDPR relevant access to personal relevant data MUST be logged for a later audit. [IDM.PCM.CLOUD.00097] GDPR Data Processing If it is necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant person data MUST be deleted after the processing, if applicable. Design and Implementation Please also refer to [TDR] for further requirements. [IDM.PCM.CLOUD.00098] Architecture Changes All Architecture Changes MUST be aligned with the technical lead and approved by the principal before implementation. Installation [IDM.PCM.CLOUD.00099] Wallet Installation cPCM products must be made available for the common browsers. Wallet should be accessible on internal or publicly available url. [IDM.PCM.CLOUD.00100] Helm/Argo CD Deployment All installations, where applicable, MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a ARGO CD Pipeline defined in the gxfs- integration repository [11]. [11] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Usability [IDM.PCM.CLOUD.00101] Configuration All components MUST support one of the major configuration formats (yaml, Json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged. [IDM.PCM.CLOUD.00102] GUI usability GUI design MUST comply with common GUI recommendations for the target platforms. [IDM.PCM.CLOUD.00103] cPCM accessibility The product must comply with the accessibility requirements depending on the target platforms. [IDM.PCM.CLOUD.00104] Internationalization Support The cPCM MUST support internationalization. At least the following languages MUST be supported: English. Maintainability [IDM.PCM.CLOUD.00105] Continuous Integration All tests MUST be coded in a continuous tool to ensure the software quality in a further development. All the necessary scripts and setups MUST be provided on the public code repository to make it possible for everyone to compile and execute the product. Interoperability [IDM.PCM.CLOUD.00106] Interoperability of IT security features and algorithms The following interoperability requirements of the respective IT security features and algorithms MUST be ensured across the system components: Interoperability of crypto algorithms and protocols (including the novel peer-reviewed ones through the established bodies and communities) Interoperability of secure secret transfer protocols (such as the holistic usage of PKCS#11 [12]for HSM communication, etc.) Format interoperability of crypto material (such as the holistic usage of PKCS#12 for relevant cases) [12] [https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=pkcs11] Distribution [IDM.PCM.CLOUD.00107] Helm Repositories All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [13]. [13] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml] [IDM.PCM.CLOUD.00108] Istio Resources Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc. ) following the integration pattern specified in the gxfs-integration repo [14]. [14] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Service Meshing [IDM.PCM.CLOUD.00109] Istio Support All HELM charts MUST be provided with Istio support aligned together with the technical lead. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment. Standard Technology [IDM.PCM.CLOUD.00110] Default Toolstack Each development MUST consider the following standard technologies, if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React [15] Ingress Controller Nginx API Testing Postman (manual) Kubernetes v1.26+ API Design OpenAPI Table 3: Toolstack [15] [https://react-bootstrap.github.io/] The technology stack is mandatory to avoid integration impact. Metrics [IDM.PCM.CLOUD.00111] Opentelemetry Support All helm charts/services MUST provide metrics endpoints in opentelemetry [16]format. [16] [https://opentelemetry.io/docs/] Configurability [IDM.PCM.CLOUD.00112] Configuration Profiles Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening [IDM.PCM.CLOUD.00113] Secret References in Helm Charts The configuration secrets within Helm Charts MUST use secretRefs to support external Secretmanagement. Clear text secrets within the Helm Charts are not allowed. Runtime Stability [IDM.PCM.CLOUD.00114] Readiness Check Ups All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: A unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state Deployment [IDM.PCM.CLOUD.00115] Deployment Footprint The entire deployment footprint MUST be reduced in that way, that Pods of inactive components are reused or destroyed. For this purpose, strategies MUST be implemented to organize this in the Kubernetes Cluster. E.g., by providing in some component deep multi-tenancy, or shutting down all services up to an activity on a connection etc. The strategies MUST be implemented and demonstrated. [IDM.PCM.CLOUD.00116] Deployment Security The credential storage and the secret storage MUST be protected. All helm charts MUST have the maximum-security settings to support this. [IDM.PCM.CLOUD.00117] Deployment Delivery The product MAY contain additional components like KONG, Nginx etc. which MUST be part of the delivery of the deployment HELM charts. The entire software stack MUST be delivered within an running k8s cluster. [IDM.PCM.CLOUD.00118] Kubernetes Operator The product MUST provide a Kubernetes operator to host multiple instances of the Cloud PCM stack for multi-tenancy. This operator MUST provide an REST API which allows it to configure the instance deployments from inside the cluster. The Operator MUST provide an internal UI to configure the basic settings. System Features Managing Connections - System Features Using this product, the user shall be enabled to manage his Gaia-X connections. Technically, connections are represented by DID-based connections to other Gaia-X participants. Connection data includes the contact DID, DID Document, DIDComm connection status data, and communication history (e.g., VPs exchanged). Via the PCM, the user must be able to establish DIDComm connections based on invitations, which can be input to the PCM by scanning QR-Codes, Text input (URL), NFC, and by regular DIDComm Messages. The following functions are required for connection management: Functional Requirement Functions Connection invitation List connections Search connections Display connection details Functions Display connection communication history Delete connection Table 4: Functional Requirements Connection Management Managing Credentials - System Features The product shall enable the user to manage his verifiable credentials (VCs). Other Gaia-X participants can issue VCs to the user in possession of the personal credential manager. The user must be enabled to inspect his VCs and to show/proof VC information via verifiable presentations (VPs) to other Gaia-X participants. Within the Gaia-X environment, persons in the role of Gaia-X principals need to be able to receive a VC onboarding them as a principal to an organization. Within the PCM, the function \"receive a VC\" can be used for this purpose. The following functions are required for management of VCs: Functional Requirement Functions Receive a Verifiable Credential (VC) Display/inspect a VC List VCs Search VCs Answer Request for Identity Information (VP) Display history of presenting identity information (VPs) to other participants Table 5: Functional Requirements Credential Management Wallet Backup - System Features The product must provide the functionality to create backups of the information stored within the PCM. Backups must be stored in a secure way, so that only the PCM user, who created the backup, can restore the backup. Backups must contain the full status of the PCM. The following functions are required for backup: Functional Requirement Functions Create Backup Restore Backup Table 6: Functional Requirements Wallet Backup Credential Wallet synchronization - System Features The application and form factors implement a procedure to synchronize Verifiable credentials between cPCM and GXFS PCM. The following functions are required for this feature: Functional Requirement Functions Sync Wallets Table 7: Functional Requirements Credential Wallet Importing/Exporting End User Authentication - System Features The product must ensure that only the intended user can use his PCM. the product must require secure user authentication. The user must be enabled to configure authentication methods and artifacts. The following functions are required for user management and authentication: Functional Requirement Functions Initial user onboarding User Authentication Configure login credentials Secure Restore of authentication credentials Table 8: Functional Requirements End User Authentication DID Input The product must be able to read DIDComm messages via url, to support DIDComm login. Functional Requirement Functions DIDComm Login Support Table 9: Functional Requirements QR Code Scanning (DID Input) SIOP Login The product must provide support for applications to login into services via the SIOP protocol. The following functions are required for this: Functional Requirement Functions SIOP Login Support Table 10: Functional Requirements SIOP Login App Settings Configuration (personalization) - System Features The product must provide means to the PCM user to configure and save PCM application preferences. The following functions are required for this: Functional Requirement Functions Configure Application Preferences Table 11: Functional Requirements App Settings Configuration (personalization) Browser-based application/addon for stationary PCs and notebooks [IDM.PCM.CLOUD.00119] Browser-based application/addon for stationary PCs and notebooks The product MUST implement the form factor \"Browser-based application/addon for stationary PCs and notebooks\", so that the cPCM can be used as a full-featured browser-based application that implements the GUI functionalities, the connectivity functionalities and credential and personal wallet management locally on the user's PC/notebook. The backup/restore mechanisms and the configuration management are handled as well locally on the user's PC/notebook. Because PCs/Notebooks do not usually have a fixed communication endpoint an SSI-Mediator needs to remain in the Cloud for PCM Notifications. The Browser-based application/addon for stationary PCs and notebooks MUST include the following system features: Managing Connections Managing Credentials Wallet Backup End User Authentication Notification Support App Settings Configuration Credential Wallet Importing/Exporting Cloud based User Agent/Wallet The product must provide an implementation of a cloud wallet. [IDM.PCM.CLOUD.00120] Cloud based User Agent/Wallet The product MUST implement the form factor \"cloud-based user agent/wallet\". In this form factor, the cPCM Core (Wallet) is implemented as a cloud application. This application implements connection, credential and personal wallet management, backup/restore mechanisms, user authentication and personal configuration mechanisms. As the cloud application of the PCM Core/Wallet has a fixed communication endpoint the SSI- Mediator functionality for PCM Notifications may be included in that application. The PCM in this form factor MUST include the following system features: Managing Connections Managing Credentials Wallet Backup End User Authentication Notification Support App Settings Configuration Ledger Selection Credential Wallet Importing/Exporting Consent Management AIP 2.0 Verification [IDM.PCM.CLOUD.00121] Behavior Driven Design Verification of fulfillment of the requirements and characteristics MUST be done using automated tests which are part of the deliverables. They should be done by patterns of the Behavior Driven Development [BDD] using the \"Gherkin Syntax\". [IDM.PCM.CLOUD.00122] Kubernetes Deployment If the verification is related to software components, it MUST be deployed in a provided Kubernetes test cluster and the components MUST be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration. Acceptance criteria Connections [IDM.PCM.CLOUD.00123] Connection invitation When users are authenticated, then they can receive notification for \"Connection\" . The information is shown to the users via the GUI and requests can be validated. The users can accept or to reject the request. When the request is accepted, then the cPCM performs over the OCM the DIDComm protocol required to establish the connection. The connection must be established and stored in the OCM(s) storage, so that it can be used later. Interfaces GUI, Local DIDComm Input interface, DIDComm interface, DIDComm external endpoint interface [IDM.PCM.CLOUD.00124] List connections When user is logged and select listing connection option, then all the stored connections are listed on the browser GUI. [IDM.PCM.CLOUD.00125] Search connections When users are authenticated, then they should be able to enter characters in the \"Search\" field. Upon entering minimum 3 characters the system should return the result. The system should perform the search based on DID, ConnectionID, and Alies(if exist). [IDM.PCM.CLOUD.00126] Display connection details When users are authenticated, then they should be able to view detailed information about a connection. The information shown must include the DID document describing the connection contact. [IDM.PCM.CLOUD.00127] Display connection communication history When users are authenticated, then they can view detailed information about the communication history of a given connection(Activities). [IDM.PCM.CLOUD.00128] Delete connection When users are authenticated, then via GUI they can delete a stored connection from cPCM storage. Managing credentials - Verification [IDM.PCM.CLOUD.00129] Receive a Verifiable Credential (VC) When a user is authenticated and within an established connection, the user must get notification for VC issuing. The user must get the possibility to accept or to reject the request. The request is validated, and the information is shown to the user via the GUI. The user MUST get the possibility to accept or to reject the request. The issued credential MUST be stored in the OCM(s) storage. Interfaces GUI, Local DIDComm Input interface, DIDComm interface, DIDComm external endpoint interface [IDM.PCM.CLOUD.00130] Display/inspect a VC When users are authenticated , then via GUI they can view detailed information about a VC. The users must get the possibility to review all VC data items. [IDM.PCM.CLOUD.00131] List VCs When users are authenticated and they select the opening the VCs dashboard, then all the stored VCs are listed via the browser GUI in card format. [IDM.PCM.CLOUD.00132] Search VCs When users are authenticated, then they should be able to enter characters via dashboard in the \"Search\" field. A full text search in all information available for the VCs must be provided by filtering the cards. [IDM.PCM.CLOUD.00133] Answer Request for Verifiable Presentation (VP) When users are authenticated and Connection established, then: If the user has given his consent, a VP has been proved to the verifier. If the presentation has not been completed successfully, problems have been reported to the users via GUI. Interfaces: Local DIDComm Input interface, DIDComm interface, DIDComm external endpoint interface [IDM.PCM.CLOUD.00134] Display history of verifiable presentations (VPs) to other participants When users are authenticated, then they can view detailed information about the history of showing/proofing identity information to other participants. History information must list information about the transaction date and time, and to whom has been presented. [IDM.PCM.CLOUD.00135] Usage with external Web Sites When a website requests an credential presentation, the website must be able to redirect to the cloud wallet solution (e.g., by help of the PCM mobile). The protocol decision must be aligned with the technical lead. Wallet Backup - Verification [IDM.PCM.CLOUD.00136] Create Backup When users are authenticated, then they can select a backup option. Upon selecting the backup option, the system must archive all stored information in a secure manner. The backup file MUST be confidentiality and integrity protected. [IDM.PCM.CLOUD.00137] Restore Backup When users are authenticated, they must have a function to restore a backup containing all information stored in the cPCM. When users select the backup file, the restore must be performed only after confirming the security authentication. When successful restoration is completed, users should be informed about the status and they must see all their data (such as VC, Connections, etc.). Credential Wallet synchronization - Verification [IDM.PCM.CLOUD.00138] Sync Wallets When users are authenticated, then they must be able to configure synchronization with GXFS PCM. After successfully establishing a secure connection, then bi-directional synchronization should be triggered. End User Authentication - Verification [IDM.PCM.CLOUD.00139] Initial user creation When a user selects an option for account creation, then he is guided via GUI to set up a cPCM wallet. User must receive an option to restore access to his wallet in case he wants to move to another laptop/PC. During the registration process, the user must set up a secure method(authentication credentials) for authenticating upon next login. [IDM.PCM.CLOUD.00140] User Authentication When users want to access all data in their cPCM, then they must enter authentication credentials. The protected cPCM functions can be used by the user only if authentication was successful. [IDM.PCM.CLOUD.00141] Configure login credentials When users are authenticated, then they can modify their authentication credentials. Users must receive information for successfully changed authentication credentials. [IDM.PCM.CLOUD.00142] SIOP Login Support The cPCM implement a function to process SIOP requests [DID SIOP] in the role of the Self- Issued OpenID Provider (SIOP). Applications (RPs (Relying Parties) in SIOP terminology) can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response. [IDM.PCM.CLOUD.00143] Configure Application Preferences When users are authenticated, they can configure their application preferences such as language. Consent Management - Verification [IDM.PCM.CLOUD.00144] Presentation Request When an external party is requesting a credential proof, the consent plugin must intercept this request by sending to the mobile app a consent request. If this consent is successfully answered, the presentation with the existing credentials in the OCM/OCM W-Stack is fulfilled with the credential selected/attribute selection of the user to the requestor. This consent action can be reviewed then in the consent history. [IDM.PCM.CLOUD.00145] Consent Based Issuing When an external party requests and issues credentials for accessing a service belonging to the user, the consent plugin system must be able to forward this request to the user. After giving his consent, the consent plugin will create a credential for the configured service (e.g., by creating a token) and issue this credential to the requestor. The requestor uses this credential to access the service. [IDM.PCM.CLOUD.00146] Consent Based Authorization Each consent plugin must provide an OIDC compliant well known JKWS url next to an consent plugin DID that an external service can rely on this key material for verifying the consent credentials. The external service will insert this JWKS url or this DID to its API so that the user can provide consents for accessing the data. This can be demonstrated by configuring an Rest API by did auth or jwt auth. After the consent issues a credential (either JWT or W3C VC), the API must be able to allow or deny the access based on the DID/JWKS information of the consent plugin. Plugin System - Verification [IDM.PCM.CLOUD.00147] Plugin Token The user is able to generate a plugin and a token, and the token can be used for an external service. The external service is able to verify over the DID or the jwks well known url the token. Remote Control [IDM.PCM.CLOUD.00148] Remote Commands The cPCM backend integrates OCM and OCM W-Stack to a simplified layer to answer remote commands for: listing, deleting and blocking of connections and credentials. Additionally, the remote control can activate TSA rules for (consent) plugins, viewing the history, triggering the backups, viewing the backups, viewing keys, creating keys, deleting keys, enabling plugins, disable plugins, viewing devices, and removing devices. Support for Kubernetes [IDM.PCM.CLOUD.00149] Eventing All eventings must be demonstrated on basis of cloud events specifications [17] together with the kNative [18] broker together with NATS in a Kubernetes environment. [17] [https://cloudevents.io/] [18] [https://knative.dev/docs/eventing/] [IDM.PCM.CLOUD.00150] Config Map Support Each service must be demonstrated up and running in the provided Kubernetes environment, configured by config maps. [IDM.PCM.CLOUD.00151] Helm Installation The service installation MUST be demonstrated during HELM install. [IDM.PCM.CLOUD.00152] ArgoCD Integration The helm chart MUST be able to install inside of ArgoCD. This includes the usage of the postgres hooks [19] and the providing of usable values.yaml(s) for all developed services. [19] [https://gitlab.eclipse.org/eclipse/xfsc/integration/-/tree/main/helm/charts/postgresql-hook/] [IDM.PCM.CLOUD.00153] SCS Environment All HELM installations MUST run on SCS (Sovereign Cloud Stack). The final acceptance demonstration cannot be realized on azure, google cloud etc. [IDM.PCM.CLOUD.00154] Kubernetes Operator The Kubernetes Operator MUST be controllable over an API to deploy/destroy multiple instances of the cPCM on demand. Appendix A: Glossary For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO] Appendix B: Example Consent Management The flows are just for example. Flow optimizations can be proposed. Flow 1: External Actor requests Access to Protected API Flow 2: External Actor gives Access to protected Resources","title":"Cloud Personal Credential Manager"},{"location":"pcmcloud/pcmcloud/#software-requirements-specification-for-gaia-x-federation-services-cloud-personal-credential-manager-idmpcmcloud","text":"Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA","title":"Software Requirements Specification for Gaia-X Federation Services Cloud Personal Credential Manager IDM.PCM.CLOUD"},{"location":"pcmcloud/pcmcloud/#1-introduction","text":"","title":"1  Introduction"},{"location":"pcmcloud/pcmcloud/#11-document-purpose","text":"","title":"1.1  Document Purpose"},{"location":"pcmcloud/pcmcloud/#12-product-scope","text":"","title":"1.2  Product Scope"},{"location":"pcmcloud/pcmcloud/#13-definitions-acronyms-and-abbreviations","text":"","title":"1.3  Definitions, Acronyms and Abbreviations"},{"location":"pcmcloud/pcmcloud/#14-references","text":"","title":"1.4  References"},{"location":"pcmcloud/pcmcloud/#15-document-overview","text":"","title":"1.5  Document Overview"},{"location":"pcmcloud/pcmcloud/#2-product-overview","text":"","title":"2  Product Overview"},{"location":"pcmcloud/pcmcloud/#21-product-perspective","text":"","title":"2.1  Product Perspective"},{"location":"pcmcloud/pcmcloud/#22-product-functions","text":"","title":"2.2  Product Functions"},{"location":"pcmcloud/pcmcloud/#221-overview","text":"","title":"2.2.1  Overview"},{"location":"pcmcloud/pcmcloud/#222-frontend","text":"","title":"2.2.2  Frontend"},{"location":"pcmcloud/pcmcloud/#223-cpcm-core","text":"","title":"2.2.3  cPCM Core"},{"location":"pcmcloud/pcmcloud/#224-cpcm-form-factors","text":"","title":"2.2.4  cPCM Form Factors"},{"location":"pcmcloud/pcmcloud/#23-product-constraints","text":"","title":"2.3  Product Constraints"},{"location":"pcmcloud/pcmcloud/#24-user-classes-and-characteristics","text":"","title":"2.4  User Classes and Characteristics"},{"location":"pcmcloud/pcmcloud/#25-operating-environment","text":"","title":"2.5  Operating Environment"},{"location":"pcmcloud/pcmcloud/#26-user-documentation","text":"","title":"2.6  User Documentation"},{"location":"pcmcloud/pcmcloud/#27-assumptions-and-dependencies","text":"","title":"2.7  Assumptions and Dependencies"},{"location":"pcmcloud/pcmcloud/#3-requirements","text":"","title":"3  Requirements"},{"location":"pcmcloud/pcmcloud/#31-external-interfaces","text":"","title":"3.1  External Interfaces"},{"location":"pcmcloud/pcmcloud/#311-user-interfaces","text":"","title":"3.1.1  User Interfaces"},{"location":"pcmcloud/pcmcloud/#312-software-interfaces","text":"","title":"3.1.2  Software Interfaces"},{"location":"pcmcloud/pcmcloud/#313-communications-interfaces","text":"","title":"3.1.3  Communications Interfaces"},{"location":"pcmcloud/pcmcloud/#32-functional","text":"","title":"3.2  Functional"},{"location":"pcmcloud/pcmcloud/#321-general","text":"","title":"3.2.1  General"},{"location":"pcmcloud/pcmcloud/#322-managing-connections","text":"","title":"3.2.2  Managing Connections"},{"location":"pcmcloud/pcmcloud/#323-managing-credentials","text":"","title":"3.2.3  Managing Credentials"},{"location":"pcmcloud/pcmcloud/#324-wallet-backup","text":"","title":"3.2.4  Wallet Backup"},{"location":"pcmcloud/pcmcloud/#325-credential-wallet-synchronization","text":"","title":"3.2.5  Credential Wallet synchronization"},{"location":"pcmcloud/pcmcloud/#326-end-user-authentication","text":"","title":"3.2.6  End User Authentication"},{"location":"pcmcloud/pcmcloud/#327-didcomm-login-support","text":"","title":"3.2.7  DIDComm Login Support"},{"location":"pcmcloud/pcmcloud/#328-siop-login-support","text":"","title":"3.2.8  SIOP Login Support"},{"location":"pcmcloud/pcmcloud/#329-app-settings-configuration-personalization","text":"","title":"3.2.9  App Settings Configuration (personalization)"},{"location":"pcmcloud/pcmcloud/#3210-consent-management","text":"","title":"3.2.10 Consent Management"},{"location":"pcmcloud/pcmcloud/#3211-visualizationui","text":"","title":"3.2.11 Visualization/UI"},{"location":"pcmcloud/pcmcloud/#3212-remote-control-protocol","text":"","title":"3.2.12 Remote Control Protocol"},{"location":"pcmcloud/pcmcloud/#3213-plugin-system","text":"","title":"3.2.13 Plugin System"},{"location":"pcmcloud/pcmcloud/#3214-mediator","text":"","title":"3.2.14 Mediator"},{"location":"pcmcloud/pcmcloud/#33-other-nonfunctional-requirements","text":"","title":"3.3  Other Nonfunctional Requirements"},{"location":"pcmcloud/pcmcloud/#331-http-requirements","text":"","title":"3.3.1  HTTP Requirements"},{"location":"pcmcloud/pcmcloud/#332-user-feedback-logging-requirements","text":"","title":"3.3.2  User Feedback / Logging Requirements"},{"location":"pcmcloud/pcmcloud/#333-security-requirements","text":"","title":"3.3.3  Security Requirements"},{"location":"pcmcloud/pcmcloud/#3331-general-security-requirements","text":"","title":"3.3.3.1  General Security Requirements"},{"location":"pcmcloud/pcmcloud/#3332-service-specific-security-requirements","text":"","title":"3.3.3.2  Service Speci\ufb01c Security Requirements"},{"location":"pcmcloud/pcmcloud/#334-software-quality-attributes","text":"","title":"3.3.4  Software Quality Attributes"},{"location":"pcmcloud/pcmcloud/#34-compliance","text":"","title":"3.4  Compliance"},{"location":"pcmcloud/pcmcloud/#35-design-and-implementation","text":"","title":"3.5  Design and Implementation"},{"location":"pcmcloud/pcmcloud/#351-installation","text":"","title":"3.5.1  Installation"},{"location":"pcmcloud/pcmcloud/#352-usability","text":"","title":"3.5.2  Usability"},{"location":"pcmcloud/pcmcloud/#353-maintainability","text":"","title":"3.5.3  Maintainability"},{"location":"pcmcloud/pcmcloud/#354-interoperability","text":"","title":"3.5.4  Interoperability"},{"location":"pcmcloud/pcmcloud/#355-distribution","text":"","title":"3.5.5  Distribution"},{"location":"pcmcloud/pcmcloud/#356-service-meshing","text":"","title":"3.5.6  Service Meshing"},{"location":"pcmcloud/pcmcloud/#357-standard-technology","text":"","title":"3.5.7  Standard Technology"},{"location":"pcmcloud/pcmcloud/#358-metrics","text":"","title":"3.5.8  Metrics"},{"location":"pcmcloud/pcmcloud/#359-configurability","text":"","title":"3.5.9  Configurability"},{"location":"pcmcloud/pcmcloud/#3510-runtime-stability","text":"","title":"3.5.10 Runtime Stability"},{"location":"pcmcloud/pcmcloud/#3511-deployment","text":"","title":"3.5.11 Deployment"},{"location":"pcmcloud/pcmcloud/#4-system-features","text":"","title":"4  System Features"},{"location":"pcmcloud/pcmcloud/#41-managing-connections","text":"","title":"4.1  Managing Connections"},{"location":"pcmcloud/pcmcloud/#42-managing-credentials","text":"","title":"4.2  Managing Credentials"},{"location":"pcmcloud/pcmcloud/#43-wallet-backup","text":"","title":"4.3  Wallet Backup"},{"location":"pcmcloud/pcmcloud/#44-credential-wallet-synchronization","text":"","title":"4.4  Credential Wallet synchronization"},{"location":"pcmcloud/pcmcloud/#45-end-user-authentication","text":"","title":"4.5  End User Authentication"},{"location":"pcmcloud/pcmcloud/#46-did-input","text":"","title":"4.6  DID Input"},{"location":"pcmcloud/pcmcloud/#47-siop-login","text":"","title":"4.7  SIOP Login"},{"location":"pcmcloud/pcmcloud/#48-app-settings-configuration-personalization","text":"","title":"4.8  App Settings Configuration (personalization)"},{"location":"pcmcloud/pcmcloud/#49-browser-based-applicationaddon-for-stationary-pcs-and-notebooks","text":"","title":"4.9  Browser-based application/addon for stationary PCs and notebooks"},{"location":"pcmcloud/pcmcloud/#410-cloud-based-user-agentwallet","text":"","title":"4.10 Cloud based User Agent/Wallet"},{"location":"pcmcloud/pcmcloud/#5-verification","text":"","title":"5  Verification"},{"location":"pcmcloud/pcmcloud/#51-acceptance-criteria","text":"","title":"5.1  Acceptance criteria"},{"location":"pcmcloud/pcmcloud/#511-connections","text":"","title":"5.1.1  Connections"},{"location":"pcmcloud/pcmcloud/#512-managing-credentials","text":"","title":"5.1.2  Managing credentials"},{"location":"pcmcloud/pcmcloud/#513-wallet-backup","text":"","title":"5.1.3  Wallet Backup"},{"location":"pcmcloud/pcmcloud/#514-credential-wallet-synchronization","text":"","title":"5.1.4  Credential Wallet synchronization"},{"location":"pcmcloud/pcmcloud/#515-end-user-authentication","text":"","title":"5.1.5  End User Authentication"},{"location":"pcmcloud/pcmcloud/#516-consent-management","text":"","title":"5.1.6  Consent Management"},{"location":"pcmcloud/pcmcloud/#517-plugin-system","text":"","title":"5.1.7  Plugin System"},{"location":"pcmcloud/pcmcloud/#518-remote-control","text":"","title":"5.1.8  Remote Control"},{"location":"pcmcloud/pcmcloud/#52-support-for-kubernetes","text":"Appendix A: Glossary Appendix B: Example Consent Management","title":"5.2  Support for Kubernetes"},{"location":"pcmcloud/pcmcloud/#list-of-figures","text":"Figure 1: Block Overview Figure 2: Communication Overview Figure 3: Personal Credentials Manager: Application Cooperation View","title":"List of Figures"},{"location":"pcmcloud/pcmcloud/#list-of-tables","text":"Table 1: References Table 2: User Classes and Characteristics Table 3: Toolstack Table 4: Functional Requirements Connection Management Table 5: Functional Requirements Credential Management Table 6: Functional Requirements Wallet Backup Table 7: Functional Requirements Credential Wallet Importing/Exporting Table 8: Functional Requirements End User Authentication Table 9: Functional Requirements QR Code Scanning (DID Input) Table 10: Functional Requirements SIOP Login Table 11: Functional Requirements App Settings Configuration (personalization)","title":"List of Tables"},{"location":"pcmcloud/pcmcloud/#introduction","text":"To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD].","title":"Introduction"},{"location":"pcmcloud/pcmcloud/#document-purpose","text":"The purpose of the document is to specify the requirements of the Identity Management and Trust Subcomponent \"Cloud Personal Credential Manager\" with the intention of a European wide public tender for implementing this software. Main audience for this document is attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide a credential manager application to be used by natural people to participate in the Gaia-X trust structure.","title":"Document Purpose"},{"location":"pcmcloud/pcmcloud/#product-scope","text":"The purpose of these products is to provide all necessary components for the self-sovereign administration of the digital identity of a principal in the Gaia-X context. The Cloud Personal Credential Manager enables a natural person to act as a principal of an organization within the SSI-based Gaia-X ecosystem in a privacy-preserving, trustful and secure way from a computer browser. This comprises the following main functionalities: Remote Management of a Cloud Wallet or multiple Wallets which are connected to the cPCM Reception and management of verifiable credentials from other parties (e.g., a principal credential from a Gaia-X participant) by using the web frontend Presenting Verifiable Presentations to other parties in an automated or manual manner by using plugins Secure storage and management of respective secrets Consent Management Policy Based Decisions about Issuing/Presentations Plugin System which extends the Holder Capabilities The Cloud Personal Credential Manager(cPCM) must be implemented as a cloud component which provides the end user a web front- end for managing the connected OCM [IDM.OCM], OCM W-Stack [IDM.OCM.W-STACK] and TSA [TSA] by providing an integration layer for various use cases of Holders. In general, the cPCM acts as an integration layer between OCM, OCM W-Stack and TSA to orchestrate for the user various use cases by using plugins e.g., \"ID Card Proof Plugin\" which provides the function \"Automatically prove that you own a valid id card\". It's strictly required to use OCM, OCM W-Stack and TSA for this purpose. Building a new agent and reimplementing protocols like aries is not foreseen here! cPCM acts strictly as an integration layer, with a connection to the PCM and must provide just a REST API. All SSI related protocols must be realized over OCM and OCM W-Stack. Furthermore, the necessary tools to operate and maintain the created software components in an enterprise environment with focus on high-availability, security, monitoring, and logging based on common standards. Documentation for developer, operator and user MUST be written in markdown format and have to be published in the provided public repository. If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams.","title":"Product Scope"},{"location":"pcmcloud/pcmcloud/#definitions-acronyms-and-abbreviations","text":"The IDM and Trust Architecture Overview Document [IDM.AO] MUST be considered and applied as the core technical concept that also includes the Terminology and Glossary. All requirements from other documents are referenced by[IDM.\\<document-id>.XXXXX] as defined in the chapter \"Methodology\" in the document [IDM.AO].","title":"Definitions, Acronyms and Abbreviations"},{"location":"pcmcloud/pcmcloud/#references","text":"Reference Title Status [BDD] Getting Started with Behavior Driven Development - Specflow Status 07-19-2023 [DIDAAS] DID as a Service - DID Management Service Status 08-22-2023 [DID SIOP] OpenID, Self-Issued OpenID Connect Provider DID Profile - OpenID Connect Self-Issued Profile Status 07-19-2023 [IDM.AO] Gaia-X WP1 (2021), Architecture Overview (Base of functional specification) [IDM.PCM] Personal Credential Manager Document (Refer to \"annex_IDM_PCM\") [IDM.TSA] Trust Services API Document (Refer to \"annex_IDM_TSA\") [IDM.OCM] Organization Credential Manager Document (Refer to \"annex_IDM_OCM\") [IDM.OCM.W-STACK] Organization Credential Manager W-Stack Document (Refer to \"annex_IDM.OCM.W-STACK\") [NF.SPBD] Gaia-X Federation Service Non-functional Requirements: Security & Privacy by Design (Refer to annex \"GXFS_Nonfunctional_Requirements_SPBD\") [OIDC] OpenID working groups specifications - OpenID Specifications [OID4VC] OpenID for Verifiable Credential Issuance - OpenID Verifiable Credential Issuance Status 07-19-2023 [OID4VP] OpenID for Verifiable Presentations - OpenID Verifiable Presentations Status 07-19-2023 [PRD] Gaia-X Policy Rules Document - Gaia-X Policy Rules Status 07-19-2023 [TAD] Gaia-X Architecture Document - Gaia-X Architecture Document Status 07-19-2023 [TDR] Gaia-X Federation Services Technical Development Requirements (Refer to annex \"GXFS_Technical_Development_Requirements\") [W3C] Verifiable Credentials Data Model - Verifiable Credentials Data Model Status 07-19-2023 Table 1: References","title":"References"},{"location":"pcmcloud/pcmcloud/#document-overview","text":"The document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.Number] ).","title":"Document Overview"},{"location":"pcmcloud/pcmcloud/#product-overview","text":"","title":"Product Overview"},{"location":"pcmcloud/pcmcloud/#product-perspective","text":"The Cloud Personal Credential Manager is an integration layer to existing OCM/OCM-W Stack/TSA for natural persons. Within the Gaia-X terminology, such a natural person is named principal . The principal utilizes the cPCM in the respective form factor to manage stored VCs issued to her/him as well as to prove the statements necessary to obtain a service. The cPCM must support the following overall use cases: Managing Credentials over an Web front-end New Business Functionality (e.g., Plugin for Fitness Studio, Plugin for ID Card, Plugin for eID etc.) for the users key material by using Plugins Strong key management, which is connected to OCM, OCM W-Stack and TSA (Hashicorp Vault) which can be used for authentication, consent and creating new DIDs by utilizing the OCM, TSA and OCM W-Stack Providing a Web Socked Based Remote Control Protocol which allows the user to give consent, trigger backups and observe the connected cloud wallets Define Rules and Policies for Credential Acceptance, Credential Issuing and Credential Rejection by using the TSA over the Web front-end Consent Management and Consent Notifications (in general: proof notifications) Event Notifications All of the features described in this document, MUST be set on top of the OCM, OCM W- Stack and the TSA. New Agents are not allowed, but additional microservices to provide the required Features are allowed. The entire software stack is then an aggregation of cPCM Backend, OCM(W-Stack), TSA and PCM as in this block picture: Figure 1: Block Overview As presented in the cPCM big picture layering overview, cPCM consists of different components which effectively comprise the following layers: The front-end layer cPCM Backend Mediator Component In this case the backend has the task to orchestrate the functionality between the components and to provide extension functionality like consent management, credential visualization and control about connections, presentations and issuings. The block diagram above, is the setup for ONE single user. Multi Tenancy is not considered. For the deployment of the Cloud PCM, each tenant needs the entire setup, which makes it strictly required to reduce the footprints of the components and identify improvements for reducing the number of components to deploy. Also, strategies to shutdown components during inactivities etc. must be developed. From communication perspective, the architecture MUST consider the following concept: Figure 2: Communication Overview","title":"Product Perspective"},{"location":"pcmcloud/pcmcloud/#product-functions","text":"","title":"Product Functions"},{"location":"pcmcloud/pcmcloud/#overview","text":"The Cloud PCM acts as an integration layer for the OCM, OCM W-Stack and TSA to support an end user for handling his/her credentials in the cloud. This means from a functional perspective that all features must be securely remotely controllable by the WEB UI or by the PCM app. This requires the establishment of a secure web socket channel between the PCM App/Web UI and the Cloud PCM by developing pairing mechanisms on SSI basis. In general, the cPCM receives commands over the web socket channel and orchestrates the work in the background by utilizing the OCM/OCM W-Stack and the TSA to provide a value add for the end user. The end user doesn\\'t care about credential formats or connections, so the cPCM must be able to provide an UX which hides all agent information from the user by providing core functions and plugin-based extensions. Figure 3: Personal Credentials Manager: Application Cooperation View","title":"Overview"},{"location":"pcmcloud/pcmcloud/#frontend","text":"In detail the front-end layer is comprised of the following features and components: End User Authentication: component provides for the implementation of secure user authentication policies which can include but are not limited to PIN, password, etc. Graphical User Interface (GUI): enables end users to interact with the cPCM and use the cPCM functions. Local Input Interfaces: comprise link processing. And that provides communication initiation, indirect, or peer-to-peer (contact).","title":"Frontend"},{"location":"pcmcloud/pcmcloud/#cpcm-core","text":"The cPCM Core (Wallet) layer consists of the following features and components: Managing Connections (where applicable) App Settings Configuration (Personalization) Managing Credentials Wallet Backup Credential Wallet Importing/Exporting Secret Storage Plugin System Consent Management The Managing Connections service within the backend establishes the connection with the communication entities outside cPCM (such as a Service Provider or a Credentials Issuer) by using the OCM provided REST APIs. For instance, after receiving the bootstrapping request from the Local Input Interfaces in the Frontend . App Settings Configuration abstracts the implementation of possible personalization properties that tailor the respective cPCM instance to the needs and requirements of a specific end user. The Managing Credentials feature provides the functionality for managing credentials in the UI, receiving credentials issued by other participants, enabling the user to view and inspect his/her credentials, and the basic functionality for providing credential attributes to other participants according to the SSI paradigm. The credential manager ensures that the user is always in control, which credentials with which content is presented and issued, and which credentials from which party were received. This includes the UI visualization, notifications and as well the orchestration between different components as OCM(s), TSA and PCM mobile. The Wallet Backup feature provides a secure backup for the received credentials on the smartphone. A web socket function realizes the secure transfer of backup files of the PCM App to the cPCM backend. The Credential Wallet Importing/Exporting feature allows to securely export the credentials from cPCM or PCM, and to import the credentials into other PCM or cPCM. Through this, the so-called cross-wallet compatibility can be ensured in future (that is, the compatibility between different implementations of PCM that share the same standard for credentials definition and management). It should be also possible to store created PCM backups versioned into the cPCM for later usage and restore functionality. This feature is just applicable for W3C credentials [W3C]. Aries credentials are out of scope. Secret storage provides for secure persistent storage of the backuped credentials and files. A separate key management handles the user generate secrets such as private keys or seeds to use it later for the generation of JWT tokens, requesting or issuing credentials by utilizing the connected OCMs. The plugin system provides the capability to develop and enable new plugins for the cPCM, which can interact with the orchestration flow of the linked TSA and the OCMs. This MUST be realized over an eventing pattern which allows developers to integrate their processes into the raised events. Consent Management provides an additional plugin event pattern which observes presentations and issues requests to the underlying OCM(s) which are handled then type by type over a consent plugin. For each type, the plugin executes a flow which forces the user to fill in more required data and to give consents acceptions. Either by accepting conditions, filling in data, adding pins etc. The precise flows of each plugin are out of scope. But the plug-in system must establish a frame, which allows the communication to the PCM mobile and provides basic tools like \"Request Additional Data\" or \"Accept Conditions\" or similar. The Mediator (Relay) layer is represented by the Mediator/Relay component which effectively provides notification management and therefore dispatches the externally received notifications for connection establishment to the respective cPCM where it is applicable.","title":"cPCM Core"},{"location":"pcmcloud/pcmcloud/#cpcm-form-factors","text":"The cPCM frontend MUST be a React Native web page based on bootstrap to support different Form Factors and Responsive Design.","title":"cPCM Form Factors"},{"location":"pcmcloud/pcmcloud/#product-constraints","text":"","title":"Product Constraints"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00000-the-document-idmao-is-the-common-basis-for-this-functional-specification","text":"The architecture document [IDM.AO] is an essential part of this specification and a prerequisite for understanding the context. The specifications and requirements from the Architecture Document MUST be considered during implementation.","title":"[IDM.PCM.CLOUD.00000] The document IDM.AO is the common basis for this functional specification"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00001-user-restriction","text":"The cPCM MUST be designed in a way so that one cPCM instance is to be used by a single personal user. One cPCM instance MUST NOT be shared by multiple users.","title":"[IDM.PCM.CLOUD.00001] User restriction"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00002-aries-independency","text":"The cPCM backend MUST be a stand-alone backend which is providing rest interfaces as integration layer for OCM, TSA and W-Stack, which means that this backend provides a kind of business layer to the OCM/OCM W-Stack and the TSA stack. Aries RFCs MUST not be implemented, because the cPCM backend MUST NOT act as agent as such.","title":"[IDM.PCM.CLOUD.00002] Aries Independency"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00003-no-agent-implementation","text":"The Cloud PCM MUST NOT Implement an Agent framework to avoid complexity. OCM and OCM W-Stack are already SSI Agents where all SSI Agent related things MUST be addressed.","title":"[IDM.PCM.CLOUD.00003] No Agent Implementation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00004-mediator-foundation","text":"The aries mediator service [1] MUST be used as the foundation for the mediator service for W3C functionality.","title":"[IDM.PCM.CLOUD.00004] Mediator Foundation"},{"location":"pcmcloud/pcmcloud/#1-httpsgithubcomhyperledgeraries-mediator-service","text":"","title":"[1] [https://github.com/hyperledger/aries-mediator-service]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00005-deployment","text":"The entire product is an assembling of OCM Indy/OCM W-Stack, TSA and new microservices for backends. Because of this, the deployment is essential to have the right setup for each user. Therefore, the entire product relies very hard on Helm Charts and Deployment Setups.","title":"[IDM.PCM.CLOUD.00005] Deployment"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00006-k8s-operator","text":"To simplify the deployment a Kubernetes Operator MUST be developed to support an easier deployment for multi tenancy purposes. The operator MUST ensure that instances are reused, shut down etc.","title":"[IDM.PCM.CLOUD.00006] k8s Operator"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00007-resource-consumption","text":"To have multiple instances of the Cloud PCM can result in very big resource consumption. For this purpose, the architecture MUST be planned in a way that instances per user are less required or just hosted when a user is actively using it. E.g., serverless functions or by bootstrapping postgres database storage just in time when a credential for a user is received or must be presented or bootstrapping a OCM microservice just, when an attestation is required. Main goal of this requirement is to keep the operational costs as low as possible.","title":"[IDM.PCM.CLOUD.00007] Resource Consumption"},{"location":"pcmcloud/pcmcloud/#user-classes-and-characteristics","text":"User Class Description Expertise Privilege Level Product Usage Personal User The person in possession of the personal credential manager using all functionality of the product Low High Frontend Cloud Operator The cloud operator naturally has some sort of access to the cloud wallet and its infrastructure. The cloud wallet must be implemented in a way so that the cloud operator cannot access or use secrets/credentials stored in the OCM instances or in the cPCM storage. High Operator Backend/Cloud Table 2: User Classes and Characteristics","title":"User Classes and Characteristics"},{"location":"pcmcloud/pcmcloud/#operating-environment","text":"Please refer to [TDR] for further binding requirements regarding the operating environment.","title":"Operating Environment"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00008-browser-support","text":"The product part for the browser extension/app MUST be available for the common browsers: Firefox, Chromium based and Safari.","title":"[IDM.PCM.CLOUD.00008] Browser Support"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00009-operating-environments","text":"For the Web Frontend the common browsers Chrome, Firefox, Safari and Microsoft Edge must be supported. The cPCM backend MUST be runnable on the open Linux standard in the current LTS version.","title":"[IDM.PCM.CLOUD.00009] Operating Environments"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00010-kubernetes-environment","text":"The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on a provided SCS cluster (Sovereign Cloud Stack).","title":"[IDM.PCM.CLOUD.00010] Kubernetes Environment"},{"location":"pcmcloud/pcmcloud/#user-documentation","text":"Please refer to [TDR] for further requirements regarding documentation.","title":"User Documentation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00011-participant-administration-documentation","text":"The documentation MUST contain: Installation Manuals(if applicable) Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests/Verification How to build the product/services from source code","title":"[IDM.PCM.CLOUD.00011] Participant Administration Documentation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00012-participant-documentation","text":"The documentation MUST contain: Short Software Description/Usage Usage Guide GDPR Design Decisions(extended version of the existing one) Security Concept Operations Concept Keyword Directory","title":"[IDM.PCM.CLOUD.00012] Participant Documentation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00013-cloud-operator-documentation","text":"The documentation MUST contain: Operational Handbook Installation Footprint Reduction","title":"[IDM.PCM.CLOUD.00013] Cloud Operator Documentation"},{"location":"pcmcloud/pcmcloud/#assumptions-and-dependencies","text":"An understanding of the overall Gaia-X architecture and philosophy is necessary. Please refer to [TAD] and [PRD]. The attendees of the public tender must get an understanding of the current implemented features of the PCM [IDM.PCM], OCM [IDM.OCM], OCM W-Stack [IDM.OCM.W-Stack] and TSA [IDM.TSA]. Additionally, knowledge in OIDC4VC/VP [OID4VC] [OID4VP] and SSI is given.","title":"Assumptions and Dependencies"},{"location":"pcmcloud/pcmcloud/#requirements","text":"","title":"Requirements"},{"location":"pcmcloud/pcmcloud/#external-interfaces","text":"","title":"External Interfaces"},{"location":"pcmcloud/pcmcloud/#user-interfaces","text":"","title":"User Interfaces"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00014-web-interface-for-browser-based-applications","text":"The cPCM MUST provide a web interface based react native for browser-based applications. All functions available to the PCM user MUST be available via this web interface (except those which are not applicable such as camera scanning and NFC).","title":"[IDM.PCM.CLOUD.00014] Web Interface for Browser-based Applications"},{"location":"pcmcloud/pcmcloud/#software-interfaces","text":"","title":"Software Interfaces"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00015-secure-storage","text":"The cPCM implementation MUST be able to use secure storage (internal storage, encrypted storage, dedicated key storage) provided by the target platform for storing cPCM data e.g., backup files.","title":"[IDM.PCM.CLOUD.00015] Secure Storage"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00016-key-management","text":"The cPCM implementation MUST have a secure key management with hashicorp vault to control the used key engine for TSA Signings, OCM W-Stack Signings etc.","title":"[IDM.PCM.CLOUD.00016] Key Management"},{"location":"pcmcloud/pcmcloud/#communications-interfaces","text":"","title":"Communications Interfaces"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00017-didcomm-interface","text":"The cPCM backend utilizes for all Credential associated DIDComm communications the OCM and the OCM W-Stack and don\\'t implement by itself a DIDComm Communication.","title":"[IDM.PCM.CLOUD.00017] DIDComm Interface"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00018-oidc4vcvp-interface","text":"The cPCM backend utilizes for all OIDC4VC/VP communications [OID4VC] [OID4VP] the OCM and the OCM W-Stack and don\\'t implement by itself a OIDC4VC/VP Communication.","title":"[IDM.PCM.CLOUD.00018] OIDC4VC/VP Interface"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00019-didcomm-v2-messaging","text":"All interfaces from the PCM to the cPCM backend MUST be implemented as didcomm v2 messages. For instance: List Credentials, Delete Credential, Request Credential etc. The protocol MUST NOT reflect OCM protocols 1:1. e.g., List Connection or List Proofs. The cPCM Backend MUST encapsulate this for a UX by creating an integration layer which speaks an simplified didcomm v2 protocol for notification, consent and remote control. The developed didcomm protocol has to be defined as an architecture diagram and documented in the git repos similar to the Aries RFC documentation pattern.","title":"[IDM.PCM.CLOUD.00019] DIDComm v2 Messaging"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00020-backuprestore-interface-for-personal-wallet","text":"The cPCM MUST provide an interface for backup and restore of the cPCM data (which is stored in the wallet) based on the didcomm protocol and cPCM Rest API.","title":"[IDM.PCM.CLOUD.00020] Backup/restore interface for Personal Wallet"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00021-importexport-interface-for-personal-wallet","text":"To provide flexibility and interoperability between Applications and PCM Form Factors, the cPCM MUST provide interfaces for securely Exporting the personal wallet W3C content, as well as interfaces for securely Importing the personal wallet W3C content and restoring them in another application or PCM Form Factor. This includes the key material for using them. A scenario can be that a participant credential is transferred from the OCM W-Stack (which is linked to the cPCM), is transferred to a tablet to use the tablet within an secured area of a manufacturing side without internet access (but WIFI).","title":"[IDM.PCM.CLOUD.00021] Import/Export interface for Personal Wallet"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00022-personal-wallet-synchronization","text":"The cPCM must provide functionality for automatic secure synchronization with a PCM. The synchronization must be bi-directional and is just belonging to W3C credentials (No Aries). The synchronization MUST be configurable in the cPCM backend over an Configuration Endpoint which the user can use to select the connected devices and the content which needs to be synced.","title":"[IDM.PCM.CLOUD.00022] Personal Wallet Synchronization"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00023-pcm-management","text":"The cPCM backend MUST provide functionality to be managed via PCM or the Web UI. An initial linking between PCM and the cPCM backend works just over the Web UI. All paired devices MUST be visible in the cPCM UI to manage the devices (add, remove, block etc.).","title":"[IDM.PCM.CLOUD.00023] PCM management"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00024-eventing","text":"If it is required to use events within the software architecture, it is mandatory to use software abstraction according to cloud event specification [2] for publishing and subscription. The minimal supported protocol binding MUST be HTTP Protocol Binding [3].","title":"[IDM.PCM.CLOUD.00024] Eventing"},{"location":"pcmcloud/pcmcloud/#2-httpscloudeventsio","text":"","title":"[2] [https://cloudevents.io/]"},{"location":"pcmcloud/pcmcloud/#3-httpsgithubcomcloudeventsspecblobv102cloudeventsbindingshttp-protocol-bindingmd","text":"","title":"[3] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/bindings/http-protocol-binding.md]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00025-eventing-infrastructure","text":"The event broker for the eventing MUST abstract the storage and delivery infrastructure. In Kubernetes environments, the event broker MUST be uniform across all lots by using NATS [4] and/or kNative.","title":"[IDM.PCM.CLOUD.00025] Eventing Infrastructure"},{"location":"pcmcloud/pcmcloud/#4-httpsnatsio","text":"","title":"[4] [https://nats.io/]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00026-login-support","text":"The cPCM MUST support OIDC flows for login, such as DID SIOP and Authorization Code Grants by Standard IAM Systems. For a pairing of devices, a separate flow MUST be developed to initiate it.","title":"[IDM.PCM.CLOUD.00026] Login Support"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00027-web-sockets","text":"For syncing the Wallets, Web Sockets MUST be used. Each didcomm message structure within the channel MUST be aligned with the technical lead.","title":"[IDM.PCM.CLOUD.00027] Web Sockets"},{"location":"pcmcloud/pcmcloud/#functional","text":"","title":"Functional"},{"location":"pcmcloud/pcmcloud/#general","text":"","title":"General"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00028-did-document-provisioning","text":"To highlight the existing endpoints the cPCM MUST be able to provide DID (Web) Documents for himself which contain the used endpoints and his key material. These DID Documents MUST be configurable in the cPCM database to generate multiple DIDs by TSA DID Web as a Service. Over these DID documents, the cPCM can act as proxy DID for each user and can variate the endpoints which are used by the user. The endpoints themselves are pointing to the OCM instances and TSA endpoints/mediator belonging to the cPCM. Note: Others will resolve this DID to find the communication endpoints, so it MUST be publicly available over an GET endpoint. All service endpoints MUST be configurable as Json to inject it in the TSA policy.","title":"[IDM.PCM.CLOUD.00028] DID Document Provisioning"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00029-did-document-resolving","text":"The DID Document of the cPCM MUST be resolvable by the Universal Resolver and it MUST contain all key material used by the cPCM including all endpoints following this service configuration format by enhancing the W3C spec [5]: > { > id: {idName} > type: {typeName}, > accept: \\[\"didcomm/v2\",\"didcomm/v1\",{otherProtocols}\\], > serviceEndpoint:\\[\"https://...\"\\] > }","title":"[IDM.PCM.CLOUD.00029] DID Document Resolving"},{"location":"pcmcloud/pcmcloud/#5-httpswwww3orgtrdid-coreexample-usage-of-the-service-property","text":"","title":"[5] [https://www.w3.org/TR/did-core/#example-usage-of-the-service-property]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00030-multi-tenancy","text":"The Cloud PCM MUST support Scale Down to 0 to avoid high operational costs.","title":"[IDM.PCM.CLOUD.00030] Multi Tenancy"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00031-browser-wallet-protocol","text":"The Cloud PCM MUST provide a protocol which integrates with external web sites to offer credential presentations triggered by the user/website.","title":"[IDM.PCM.CLOUD.00031] Browser Wallet Protocol"},{"location":"pcmcloud/pcmcloud/#managing-connections","text":"","title":"Managing Connections"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00032-connection-invitation","text":"Connection requests can be provided to the cPCM user via Text input (URL), and by regular messages. The function can be activated by the cPCM user via the GUI by uploading an QR or pasting an invitation link. An invitation message is received via the PCM app, and the user can decide either take it directly in the PCM app or push it to the cloud app (just in case of aries)","title":"[IDM.PCM.CLOUD.00032] Connection invitation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00033-list-connections","text":"The cPCM user can view a list of connections stored in the underlying OCM(s).","title":"[IDM.PCM.CLOUD.00033] List connections"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00034-search-connections","text":"The user can search connections stored in the underlying OCM(s). A full text search in all information available for the connection must be provided. The search result MUST be shown at the GUI.","title":"[IDM.PCM.CLOUD.00034] Search connections"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00035-display-connection-details","text":"The cPCM user can view detailed information about a connection. The information shown MUST include the DID document describing the connection contact.","title":"[IDM.PCM.CLOUD.00035] Display connection details"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00036-display-connection-communication-history","text":"The cPCM user can view detailed information about the communication history of a given connection (Activities where are applicable).","title":"[IDM.PCM.CLOUD.00036] Display connection communication history"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00037-delete-connection","text":"The cPCM user delete a connection from OCM(s).","title":"[IDM.PCM.CLOUD.00037] Delete connection"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00038-block-connection","text":"The cPCM users delete a connection from OCM(s).","title":"[IDM.PCM.CLOUD.00038] Block connection"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00039-connection-details","text":"The user MUST be able to define details to a connection e.g., Name, Company etc. together with details about credentials.","title":"[IDM.PCM.CLOUD.00039] Connection Details"},{"location":"pcmcloud/pcmcloud/#managing-credentials","text":"","title":"Managing Credentials"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00040-receive-a-verifiable-credential-vc","text":"Within an established connection, a VC can be issued to the user. The cPCM is in the role of the \"Holder\" within this protocol. The request is validated, and the information is notified to the user via the GUI or App. The user MUST get the possibility to accept or to reject the request by using his PCM App or the Web UI. The cPCM orchestrates these requests and notifications and tracks the history in his internal storage. Over the UI the user can see which credentials were received and from whom (displayed as cards). A differentiation between aries, ipfs or w3c MUST not be made. The user MUST see just one card per credential with some hints that his credential type exists multiple times (grouped by schema name).","title":"[IDM.PCM.CLOUD.00040] Receive a Verifiable Credential (VC)"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00041-displayinspect-a-vc","text":"The cPCM user SHOULD view detailed information about a VC per card. The information shown MUST include all VC data items and MUST be integrated in a details view.","title":"[IDM.PCM.CLOUD.00041] Display/inspect a VC"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00042-list-vcs","text":"The cPCM user can view a list of VCs stored in the connected OCM(s).","title":"[IDM.PCM.CLOUD.00042] List VCs"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00043-search-vcs","text":"The user can search VCs stored in the OCM(s). A full text search in all information available for the VCs must be provided.","title":"[IDM.PCM.CLOUD.00043] Search VCs"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00044-answer-request-verifiable-presentation-vp","text":"The cPCM MUST be able to notify and process Presentation requests received via any OCM. This includes the selection of the credentials which match the criteria, the selective disclosure of attributes (indy based), and the verification of the requestor (train). All of these points need to be controlled by the user either by PCM App or Web UI. If the user has selected his preferred attributes and credentials, he is able to confirm the presentation and the request is processed by the cPCM backend which completes the process in the requesting OCM. If a plugin is listening on the events, the plugin MUST interrupt the process before it is further processed.","title":"[IDM.PCM.CLOUD.00044] Answer Request Verifiable Presentation (VP)"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00045-display-history-of-presenting-verifiable-presentations-vps","text":"The user can view detailed information about the history of showing/proofing identity information to other participants. For each presentation, the information MUST be logged including all information contained in the VP shown to a verifier, to which verifier it has been shown, and transaction date/time etc..","title":"[IDM.PCM.CLOUD.00045] Display history of presenting Verifiable Presentations (VPs)"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00046-accepting-rules","text":"The user MUST be able to define for connections/DIDs, presentations, and issuings, rules to accept/reject automatically. e.g., by Type, Claims etc. For these rules the TSA in the background MUST be used.","title":"[IDM.PCM.CLOUD.00046] Accepting Rules"},{"location":"pcmcloud/pcmcloud/#wallet-backup","text":"","title":"Wallet Backup"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00047-create-backup","text":"The cPCM MUST provide a function to backup all information sent by the PCM. The backup file MUST be confidentiality and integrity protected. Protection MUST follow current standards regarding protocols and cryptographic artifacts (refer to section \"Security Requirements\"). The cPCM MUST provide a method for protecting access to the data within the backup with at least two authentication factors.","title":"[IDM.PCM.CLOUD.00047] Create Backup"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00048-restore-backup","text":"The cPCM MUST provide a function to restore a backup file(s) containing all information stored from the PCM App. The Backup/Restore format MUST be compatible to guarantee PCM interoperability between form factors and between different providers, browsers or Smartphone Application as GXFS PCM.","title":"[IDM.PCM.CLOUD.00048] Restore Backup"},{"location":"pcmcloud/pcmcloud/#credential-wallet-synchronization","text":"","title":"Credential Wallet synchronization"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00049-sync-wallets","text":"The cPCM provides a functionality to synchronize different personal wallets, e.g., synchronize a cloud wallet with a smartphone wallet GXFS PCM [IDM.PCM] to support offline usage. Secure methods for Importing the GXFS PCM Secrets MUST be provided.","title":"[IDM.PCM.CLOUD.00049] Sync Wallets"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00050-block-wallets","text":"If a Device was stolen, the cPCM MUST be able to block devices to stop syncing.","title":"[IDM.PCM.CLOUD.00050] Block Wallets"},{"location":"pcmcloud/pcmcloud/#end-user-authentication","text":"","title":"End User Authentication"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00051-initial-user-onboarding","text":"The cPCM MUST provide a function for the initial user onboarding, when the cPCM is initialized. Additionally, this function also initializes the wallet. For this onboarding the PCM Wallet MUST be used. A user MUST be able to onboard in his PCM App potentially multiple cPCM (e.g., hosted by different providers).","title":"[IDM.PCM.CLOUD.00051] Initial user onboarding"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00052-user-authentication","text":"The cPCM MUST provide a function which performs user authentication to open the cPCM for the user.","title":"[IDM.PCM.CLOUD.00052] User Authentication"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00053-configure-login-credentials","text":"The cPCM MUST provide a function, where the user can modify his/her login verifiable credential.","title":"[IDM.PCM.CLOUD.00053] Configure login credentials"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00054-secure-restore-of-authentication-credentials","text":"The cPCM MUST provide a function for securely restoring the users' authentication credentials (e.g., forgotten password/pin).","title":"[IDM.PCM.CLOUD.00054] Secure Restore of authentication credentials"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00055-second-factor","text":"The cPCM MUST provide a function for second factor login support by using the PCM functionality.","title":"[IDM.PCM.CLOUD.00055] Second Factor"},{"location":"pcmcloud/pcmcloud/#didcomm-login-support","text":"","title":"DIDComm Login Support"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00056-didcomm-login-support","text":"Description To login the user with existing Indy Credentials, the cPCM MUST utilize the OCM to request proofs for identification. This is an alternative login variant next to OIDC methods [OIDC]. The detailed process for this is as follows: cPCM provides the indy based login method If user selects it, cPCM requests from OCM an Invitation Link and presents it to the user The user scans it with his cPCM and accepting the connection invitation presented by an QR code The PCM app establishes a DIDComm connection to the cPCM OCM, which will reply with an proof request and the user presents the proof After presenting the proof, and event will be raised and the cPCM can check the presented attributes of the underlying OCM","title":"[IDM.PCM.CLOUD.00056] DIDComm Login Support"},{"location":"pcmcloud/pcmcloud/#siop-login-support","text":"","title":"SIOP Login Support"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00057-siop-login-support","text":"The cPCM MUST implement a function to process SIOP requests [DID SIOP] in the role of the Self- Issued OpenID Provider (SIOP). Applications (RPs (Relying Parties) in SIOP terminology) can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response. This is also the preferred method to pair PCM App and cPCM if applicable.","title":"[IDM.PCM.CLOUD.00057] SIOP Login Support"},{"location":"pcmcloud/pcmcloud/#app-settings-configuration-personalization","text":"","title":"App Settings Configuration (personalization)"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00058-configure-application-preferences","text":"The PCM MUST enable the user to configure his/her application preferences. Application preferences MUST include language settings, device names, device groups, OCM connections, rules and policies for TSA and history limits. The default language is English, but the correct localization of the cPCM MUST be demonstrated.","title":"[IDM.PCM.CLOUD.00058] Configure Application Preferences"},{"location":"pcmcloud/pcmcloud/#consent-management","text":"","title":"Consent Management"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00059-consent-management-plugins","text":"The product MUST provide the possibility to add Consent Plugins based on the plugin framework, which observe a special type of requested presentations/credentials to establish the consent flow in the direction of the linked PCM wallets. The result of the consent flow MUST be recorded in the consent records of the wallet. The plugins itself MUST be able to interact with the notification channel to the connected wallets, to pick up added data from the consent on the smartphone, to add it later on in disputes for credentials or in audit logs before presentation etc. All activities MUST be aligned with the PCM development Team. An example could be found in Appendix B.","title":"[IDM.PCM.CLOUD.00059] Consent Management Plugins"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00060-consent-auditability","text":"All given consents MUST be logged for audits.","title":"[IDM.PCM.CLOUD.00060] Consent Auditability"},{"location":"pcmcloud/pcmcloud/#visualizationui","text":"","title":"Visualization/UI"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00061-general","text":"The entire UI MUST be an user-friendly dashboard, where the user gets a quick overview. It's not allowed to provide command line behavior or just lists or tables. It MUST be graphically designed for end-users e.g., a doctor, a manager or any other non-IT users and well optimized for touch screens (for example for an iPad).","title":"[IDM.PCM.CLOUD.00061] General"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00062-credential-management","text":"The web UI MUST provide a dashboard UI for the user which shows the credentials of the connected wallets, and details like containing attributes, DID, Technology etc. The presentation MUST be as cards like \"Credit Cards\" or similar to give the user maximum UX.","title":"[IDM.PCM.CLOUD.00062] Credential Management"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00063-did-creationdid-as-service6","text":"The web UI MUST provide for the user an UI which allows it to generate new DIDs. This includes DID:Key, DID:WEB, DID:Indy and DID:IPFS. The generated DIDs MUST be linked to the underlying technology, means DID:INDY to the OCM and the others to OCM W-Stack. In the case of DID:WEB the DID as a Service approach [DIDAAS] over TSA MUST be used.","title":"[IDM.PCM.CLOUD.00063] DID Creation/DID as Service[6]"},{"location":"pcmcloud/pcmcloud/#6-httpsgitlabeclipseorgeclipsexfscpordid-management-service","text":"","title":"[6] [https://gitlab.eclipse.org/eclipse/xfsc/por/did-management-service]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00064-connection-management","text":"The web UI MUST provide for the user an UI which shows the connections, the rules for accepting, blocking, and deleting connections with details about the DID, trust zones, which credentials are attached to it etc..","title":"[IDM.PCM.CLOUD.00064] Connection Management"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00065-presentation","text":"An incoming presentation request MUST be visualized, and possible credentials highlighted which are fitting to the request. If there is any fitting credential, the user MUST be enabled to present or ignore it.","title":"[IDM.PCM.CLOUD.00065] Presentation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00066-issuance","text":"The web UI MUST provide a functionality where an user can pick a schema from a list (e.g., the schema registrar) and start issuing credentials for it by providing Invitation Links with auto issuance options. These links MUST be sendable by email.","title":"[IDM.PCM.CLOUD.00066] Issuance"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00067-onboarding-flow","text":"The UI MUST provide a flow to initialize the Cloud PCM for a new User by utilizing the PCM as authentication tool. The linking of multiple wallets MUST be supported and demonstrated for two smartphones/tablets.","title":"[IDM.PCM.CLOUD.00067] Onboarding Flow"},{"location":"pcmcloud/pcmcloud/#remote-control-protocol","text":"","title":"Remote Control Protocol"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00068-pcm-remote-control","text":"The Cloud PCM Backend MUST provide a protocol over websockets and didcomm, to control over the PCM things like accepting connections, start issuances, confirm presentations, creating dids, rotating keys etc. The remote control MUST work over didcomm messages which needs to be defined together with the cPCM API.","title":"[IDM.PCM.CLOUD.00068] PCM Remote Control"},{"location":"pcmcloud/pcmcloud/#plugin-system","text":"","title":"Plugin System"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00069-plugin-framework","text":"The cPCM backend and the Web UI MUST support the adding of plugins by providing an infrastructure and a template. This includes an interface definition for defining plugins, an integrated event pattern for observing events and encapsulations for using the PCM App Communication channel to send notifications, receive triggers and use the internal PCM storage. If a plugin is created, it MUST be hostable without any reboot of the cPCM backend. The preferred solution SHOULD be a separate microservice per plugin to shutdown/enable/monitor plugins easily. If this is not possible, it MUST be another solution provided.","title":"[IDM.PCM.CLOUD.00069] Plugin Framework"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00070-visualization","text":"All Plugins MUST be visualized in a plugin overview, where plugins can be configured, disabled or enabled. The available plugins MUST be provided by a service discovery, where the user can select which plugins are relevant.","title":"[IDM.PCM.CLOUD.00070] Visualization"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00071-plugin-secrets","text":"Plugins MUST have a dedicated secret engine per plugin which allows the plugin to create keys for signing, encryption and verification. The implementation MUST be abstract, but for the initial version the hashicorp vault transitengine [7] MUST be used (default stack). Other engines MAY be supported in the first version.","title":"[IDM.PCM.CLOUD.00071] Plugin Secrets"},{"location":"pcmcloud/pcmcloud/#7-httpsdeveloperhashicorpcomvaultdocssecretstransit","text":"","title":"[7] [https://developer.hashicorp.com/vault/docs/secrets/transit]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00072-plugin-based-well-known-url","text":"Each Plugin is able to define its own key material per tenant next to an well-known jwks url/did which resolves to the key material.","title":"[IDM.PCM.CLOUD.00072] Plugin Based Well Known Url"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00073-plugin-based-rules","text":"Each Plugin is able to use TSA rules.","title":"[IDM.PCM.CLOUD.00073] Plugin Based Rules"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00074-plugin-based-configuration","text":"The user can enable/disable and configure Plugins which are available within the cPCM.","title":"[IDM.PCM.CLOUD.00074] Plugin Based Configuration"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00075-plugin-eventing","text":"Plugins can be created which listen on cPCM events. Plugins can intercept them to stop/resume internal processes like issuing/presentation/connections.","title":"[IDM.PCM.CLOUD.00075] Plugin Eventing"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00076-plugin-to-app-communication","text":"Plugins can use the internal communication channel from cPCM Backend to paired App to notify changes and receive remote commands.","title":"[IDM.PCM.CLOUD.00076] Plugin to App Communication"},{"location":"pcmcloud/pcmcloud/#mediator","text":"","title":"Mediator"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00077-relay-implementation","text":"The product MUST provide the hyperledger mediator as a core component of the cPCM. The endpoints for this mediator MUST be configured in the documents of the cPCM. If necessary, potential didcomm mediation MUST be routed over this component as well.","title":"[IDM.PCM.CLOUD.00077] Relay implementation"},{"location":"pcmcloud/pcmcloud/#other-nonfunctional-requirements","text":"","title":"Other Nonfunctional Requirements"},{"location":"pcmcloud/pcmcloud/#http-requirements","text":"","title":"HTTP Requirements"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00078-https","text":"All HTTP Endpoints MUST be protected by TLS 1.2 (all protocol version numbers SHOULD be superseded by upcoming standards) Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system.","title":"[IDM.PCM.CLOUD.00078] HTTPS"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00079-http-protocol-definitions","text":"All HTTP Endpoints MUST follow [RFC7231] and [RFC5789], but it MAY be chosen what of the protocols is necessary to realize the functionality. For problem reports the [RFC7807] MUST be used in combination with Standard HTTP Error Codes.","title":"[IDM.PCM.CLOUD.00079] HTTP Protocol Definitions"},{"location":"pcmcloud/pcmcloud/#user-feedback-logging-requirements","text":"","title":"User Feedback / Logging Requirements"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00080-data-minimization","text":"From GDPR perspective the product MUST NOT log data which is related to personal information. (e.g., usernames, birth dates etc.) The product MUST only log data, which is relevant to technical operations, except for the purpose that, in the event of an incident, enable reconstruction of the sequence of the message exchange for establishing the place and the nature of the incident. The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of the following elements: (a) node\\'s identification (b) message identification (c) message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review.","title":"[IDM.PCM.CLOUD.00080] Data Minimization"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00081-logging-frameworks","text":"The product MUST support logging frameworks e.g., graylog, fluentD or logstash to support logging and analysis by enterprise infrastructures. The supported framework MAY be chosen for the first version, but it MUST support potentially the most common open-source logging solutions. The final solution MUST be aligned with the other subcomponents. It MUST be sketched in the operations concept how the support of multiple solutions is given in the future.","title":"[IDM.PCM.CLOUD.00081] Logging Frameworks"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00082-user-feedback-information","text":"The cPCM user should receive relevant messages regarding events, successes, and failures during the operation of the cPCM. The user should be notified in a timely, descriptive and privacy preserving manner.","title":"[IDM.PCM.CLOUD.00082] User Feedback information"},{"location":"pcmcloud/pcmcloud/#security-requirements","text":"","title":"Security Requirements"},{"location":"pcmcloud/pcmcloud/#general-security-requirements","text":"Each Gaia-X Federation Service SHALL meet the requirements stated in the document \"Specification of non-functional Requirements Security and Privacy by Design\" [NF.SPBD]. Federation Services specific requirements will be documented in the next chapter.","title":"General Security Requirements"},{"location":"pcmcloud/pcmcloud/#service-specific-security-requirements","text":"This chapter will describe the service specific requirements, which will extend the requirements defined in the chapter above.","title":"Service Specific Security Requirements"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00083-secure-user-authentication","text":"To ensure that only allowed entities can access the cPCM authentication methods MUST be implemented to grant access to the cPCM. ** [IDM.PCM.CLOUD.00084] Protection of Secrets (Wallet) and Security for the Restore process** The cPCM secrets must be stored and processed securely. There MUST be additional security procedures in place to guarantee that the secret key can be recovered when the holder requires it, even in case the holder himself has lost access to his unlock key. ** [IDM.PCM.CLOUD.00085] Secure communication between frontend and cloud agent/wallet** The communication interface in case of the cloud agent/Wallet must be protected according to the latest security standards.","title":"[IDM.PCM.CLOUD.00083] Secure user authentication"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00086-tls-certificate-validity-periods","text":"In general, the recommended validity period for a certificate used in the system should be one year or less. Under some circumstances (for example RootCA) the certificate validity can be extended. Certificate owners MUST ensure that valid certificates are renewed and replaced before their expiration to prevent service outages.","title":"[IDM.PCM.CLOUD.00086] TLS Certificate Validity Periods"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00087-security-by-design","text":"T Security MUST be a design principle from the beginning. Means separation of concerns, different administrative roles, especially for private key material and separate access to the data MUST be covered. It MUST be described in the security concept, what are the different security risks of the product and how they are mitigated (e.g., by Threat Modeling Protocols)","title":"[IDM.PCM.CLOUD.00087] Security by Design"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00088-pentesting","text":"All parts of the product have to be penetration tested, at least for the following criteria: Unauthorized Access to the System MUST be tested Unauthorized Actions MUST be triggered without a user action All interfaces MUST be tested","title":"[IDM.PCM.CLOUD.00088] Pentesting"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00089-storage-of-secrets","text":"The storage of secret information such as private keys MUST take place in state-of-the-art secure environments to protect secret data confidentiality and integrity. Examples of this are Secure Enclaves, TPMs, HSM or Secure Vaults. In case (Personal) Agents are not equipped with a secure storage it may also be possible to store the secrets in a third party (e.g., Cloud) provider (e.g., Secure Wallet) that MUST provide overall the same level of security as the aforementioned methods.","title":"[IDM.PCM.CLOUD.00089] Storage of Secrets"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00090-support-for-potential-requirements-for-secret-storages","text":"Devices that hold cryptographic information and perform cryptographic functions MUST be compliant with standard PKCS #11 [8] or other comparable cryptography standards.","title":"[IDM.PCM.CLOUD.00090] Support for Potential Requirements for Secret Storages"},{"location":"pcmcloud/pcmcloud/#8-httpswwwoasis-openorgcommitteestc_homephpwg_abbrevpkcs11","text":"","title":"[8] [https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=pkcs11]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00091-special-availability-and-scalability-requirements-for-secret-storage-components","text":"Secret Storage components play a central role in storage, encryption, and digital signing in the Gaia-X ecosystem, thus they can become a single point of failure for a Gaia-X participant, for example an organization. Therefore, methods and procedures to ensure the availability and scalability of the Secret Storage functionality MUST be implemented.","title":"[IDM.PCM.CLOUD.00091] Special Availability and Scalability Requirements for Secret Storage Components"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00092-cve-patches","text":"All software components MUST have applied CVE patches, which are available for major releases.","title":"[IDM.PCM.CLOUD.00092] CVE Patches"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00093-major-releases","text":"All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening.","title":"[IDM.PCM.CLOUD.00093] Major Releases"},{"location":"pcmcloud/pcmcloud/#software-quality-attributes","text":"","title":"Software Quality Attributes"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00094-quality-aspects","text":"The software MUST meet the following requirements: The quality standards MUST meet ISO 25010 [9] Robustness / Reliability Performance Interoperability with the other work packages from GAIA-X project Security Adaptability / expandability Maintainability and Code Quality","title":"[IDM.PCM.CLOUD.00094] Quality Aspects"},{"location":"pcmcloud/pcmcloud/#9-httpsiso25000comindexphpeniso-25000-standardsiso-25010","text":"","title":"[9] [https://iso25000.com/index.php/en/iso-25000-standards/iso-25010]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00095-software-quality-requirements","text":"All software components MUST be compliant to the requirements within the quality assurance repository [10]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology.","title":"[IDM.PCM.CLOUD.00095] Software Quality Requirements"},{"location":"pcmcloud/pcmcloud/#10-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesquality-assurance-issues","text":"","title":"[10] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues]"},{"location":"pcmcloud/pcmcloud/#compliance","text":"","title":"Compliance"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00096-gdpr-audit-logging","text":"All GDPR relevant access to personal relevant data MUST be logged for a later audit.","title":"[IDM.PCM.CLOUD.00096] GDPR Audit Logging"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00097-gdpr-data-processing","text":"If it is necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant person data MUST be deleted after the processing, if applicable.","title":"[IDM.PCM.CLOUD.00097] GDPR Data Processing"},{"location":"pcmcloud/pcmcloud/#design-and-implementation","text":"Please also refer to [TDR] for further requirements.","title":"Design and Implementation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00098-architecture-changes","text":"All Architecture Changes MUST be aligned with the technical lead and approved by the principal before implementation.","title":"[IDM.PCM.CLOUD.00098] Architecture Changes"},{"location":"pcmcloud/pcmcloud/#installation","text":"","title":"Installation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00099-wallet-installation","text":"cPCM products must be made available for the common browsers. Wallet should be accessible on internal or publicly available url.","title":"[IDM.PCM.CLOUD.00099] Wallet Installation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00100-helmargo-cd-deployment","text":"All installations, where applicable, MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a ARGO CD Pipeline defined in the gxfs- integration repository [11].","title":"[IDM.PCM.CLOUD.00100] Helm/Argo CD Deployment"},{"location":"pcmcloud/pcmcloud/#11-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[11] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"pcmcloud/pcmcloud/#usability","text":"","title":"Usability"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00101-configuration","text":"All components MUST support one of the major configuration formats (yaml, Json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged.","title":"[IDM.PCM.CLOUD.00101] Configuration"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00102-gui-usability","text":"GUI design MUST comply with common GUI recommendations for the target platforms.","title":"[IDM.PCM.CLOUD.00102] GUI usability"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00103-cpcm-accessibility","text":"The product must comply with the accessibility requirements depending on the target platforms.","title":"[IDM.PCM.CLOUD.00103] cPCM accessibility"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00104-internationalization-support","text":"The cPCM MUST support internationalization. At least the following languages MUST be supported: English.","title":"[IDM.PCM.CLOUD.00104] Internationalization Support"},{"location":"pcmcloud/pcmcloud/#maintainability","text":"","title":"Maintainability"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00105-continuous-integration","text":"All tests MUST be coded in a continuous tool to ensure the software quality in a further development. All the necessary scripts and setups MUST be provided on the public code repository to make it possible for everyone to compile and execute the product.","title":"[IDM.PCM.CLOUD.00105] Continuous Integration"},{"location":"pcmcloud/pcmcloud/#interoperability","text":"","title":"Interoperability"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00106-interoperability-of-it-security-features-and-algorithms","text":"The following interoperability requirements of the respective IT security features and algorithms MUST be ensured across the system components: Interoperability of crypto algorithms and protocols (including the novel peer-reviewed ones through the established bodies and communities) Interoperability of secure secret transfer protocols (such as the holistic usage of PKCS#11 [12]for HSM communication, etc.) Format interoperability of crypto material (such as the holistic usage of PKCS#12 for relevant cases)","title":"[IDM.PCM.CLOUD.00106] Interoperability of IT security features and algorithms"},{"location":"pcmcloud/pcmcloud/#12-httpswwwoasis-openorgcommitteestc_homephpwg_abbrevpkcs11","text":"","title":"[12] [https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=pkcs11]"},{"location":"pcmcloud/pcmcloud/#distribution","text":"","title":"Distribution"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00107-helm-repositories","text":"All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [13].","title":"[IDM.PCM.CLOUD.00107] Helm Repositories"},{"location":"pcmcloud/pcmcloud/#13-httpsgitlabcomapiv4projects41175300packageshelmintegrationindexyaml","text":"","title":"[13] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00108-istio-resources","text":"Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc. ) following the integration pattern specified in the gxfs-integration repo [14].","title":"[IDM.PCM.CLOUD.00108] Istio Resources"},{"location":"pcmcloud/pcmcloud/#14-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[14] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"pcmcloud/pcmcloud/#service-meshing","text":"","title":"Service Meshing"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00109-istio-support","text":"All HELM charts MUST be provided with Istio support aligned together with the technical lead. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment.","title":"[IDM.PCM.CLOUD.00109] Istio Support"},{"location":"pcmcloud/pcmcloud/#standard-technology","text":"","title":"Standard Technology"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00110-default-toolstack","text":"Each development MUST consider the following standard technologies, if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React [15] Ingress Controller Nginx API Testing Postman (manual) Kubernetes v1.26+ API Design OpenAPI Table 3: Toolstack","title":"[IDM.PCM.CLOUD.00110] Default Toolstack"},{"location":"pcmcloud/pcmcloud/#15-httpsreact-bootstrapgithubio","text":"The technology stack is mandatory to avoid integration impact.","title":"[15] [https://react-bootstrap.github.io/]"},{"location":"pcmcloud/pcmcloud/#metrics","text":"","title":"Metrics"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00111-opentelemetry-support","text":"All helm charts/services MUST provide metrics endpoints in opentelemetry [16]format.","title":"[IDM.PCM.CLOUD.00111] Opentelemetry Support"},{"location":"pcmcloud/pcmcloud/#16-httpsopentelemetryiodocs","text":"","title":"[16] [https://opentelemetry.io/docs/]"},{"location":"pcmcloud/pcmcloud/#configurability","text":"","title":"Configurability"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00112-configuration-profiles","text":"Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening","title":"[IDM.PCM.CLOUD.00112] Configuration Profiles"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00113-secret-references-in-helm-charts","text":"The configuration secrets within Helm Charts MUST use secretRefs to support external Secretmanagement. Clear text secrets within the Helm Charts are not allowed.","title":"[IDM.PCM.CLOUD.00113] Secret References in Helm Charts"},{"location":"pcmcloud/pcmcloud/#runtime-stability","text":"","title":"Runtime Stability"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00114-readiness-check-ups","text":"All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: A unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state","title":"[IDM.PCM.CLOUD.00114] Readiness Check Ups"},{"location":"pcmcloud/pcmcloud/#deployment","text":"","title":"Deployment"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00115-deployment-footprint","text":"The entire deployment footprint MUST be reduced in that way, that Pods of inactive components are reused or destroyed. For this purpose, strategies MUST be implemented to organize this in the Kubernetes Cluster. E.g., by providing in some component deep multi-tenancy, or shutting down all services up to an activity on a connection etc. The strategies MUST be implemented and demonstrated.","title":"[IDM.PCM.CLOUD.00115] Deployment Footprint"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00116-deployment-security","text":"The credential storage and the secret storage MUST be protected. All helm charts MUST have the maximum-security settings to support this.","title":"[IDM.PCM.CLOUD.00116] Deployment Security"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00117-deployment-delivery","text":"The product MAY contain additional components like KONG, Nginx etc. which MUST be part of the delivery of the deployment HELM charts. The entire software stack MUST be delivered within an running k8s cluster.","title":"[IDM.PCM.CLOUD.00117] Deployment Delivery"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00118-kubernetes-operator","text":"The product MUST provide a Kubernetes operator to host multiple instances of the Cloud PCM stack for multi-tenancy. This operator MUST provide an REST API which allows it to configure the instance deployments from inside the cluster. The Operator MUST provide an internal UI to configure the basic settings.","title":"[IDM.PCM.CLOUD.00118] Kubernetes Operator"},{"location":"pcmcloud/pcmcloud/#system-features","text":"","title":"System Features"},{"location":"pcmcloud/pcmcloud/#managing-connections-system-features","text":"Using this product, the user shall be enabled to manage his Gaia-X connections. Technically, connections are represented by DID-based connections to other Gaia-X participants. Connection data includes the contact DID, DID Document, DIDComm connection status data, and communication history (e.g., VPs exchanged). Via the PCM, the user must be able to establish DIDComm connections based on invitations, which can be input to the PCM by scanning QR-Codes, Text input (URL), NFC, and by regular DIDComm Messages. The following functions are required for connection management: Functional Requirement Functions Connection invitation List connections Search connections Display connection details Functions Display connection communication history Delete connection Table 4: Functional Requirements Connection Management","title":"Managing Connections - System Features"},{"location":"pcmcloud/pcmcloud/#managing-credentials-system-features","text":"The product shall enable the user to manage his verifiable credentials (VCs). Other Gaia-X participants can issue VCs to the user in possession of the personal credential manager. The user must be enabled to inspect his VCs and to show/proof VC information via verifiable presentations (VPs) to other Gaia-X participants. Within the Gaia-X environment, persons in the role of Gaia-X principals need to be able to receive a VC onboarding them as a principal to an organization. Within the PCM, the function \"receive a VC\" can be used for this purpose. The following functions are required for management of VCs: Functional Requirement Functions Receive a Verifiable Credential (VC) Display/inspect a VC List VCs Search VCs Answer Request for Identity Information (VP) Display history of presenting identity information (VPs) to other participants Table 5: Functional Requirements Credential Management","title":"Managing Credentials - System Features"},{"location":"pcmcloud/pcmcloud/#wallet-backup-system-features","text":"The product must provide the functionality to create backups of the information stored within the PCM. Backups must be stored in a secure way, so that only the PCM user, who created the backup, can restore the backup. Backups must contain the full status of the PCM. The following functions are required for backup: Functional Requirement Functions Create Backup Restore Backup Table 6: Functional Requirements Wallet Backup","title":"Wallet Backup - System Features"},{"location":"pcmcloud/pcmcloud/#credential-wallet-synchronization-system-features","text":"The application and form factors implement a procedure to synchronize Verifiable credentials between cPCM and GXFS PCM. The following functions are required for this feature: Functional Requirement Functions Sync Wallets Table 7: Functional Requirements Credential Wallet Importing/Exporting","title":"Credential Wallet synchronization - System Features"},{"location":"pcmcloud/pcmcloud/#end-user-authentication-system-features","text":"The product must ensure that only the intended user can use his PCM. the product must require secure user authentication. The user must be enabled to configure authentication methods and artifacts. The following functions are required for user management and authentication: Functional Requirement Functions Initial user onboarding User Authentication Configure login credentials Secure Restore of authentication credentials Table 8: Functional Requirements End User Authentication","title":"End User Authentication - System Features"},{"location":"pcmcloud/pcmcloud/#did-input","text":"The product must be able to read DIDComm messages via url, to support DIDComm login. Functional Requirement Functions DIDComm Login Support Table 9: Functional Requirements QR Code Scanning (DID Input)","title":"DID Input"},{"location":"pcmcloud/pcmcloud/#siop-login","text":"The product must provide support for applications to login into services via the SIOP protocol. The following functions are required for this: Functional Requirement Functions SIOP Login Support Table 10: Functional Requirements SIOP Login","title":"SIOP Login"},{"location":"pcmcloud/pcmcloud/#app-settings-configuration-personalization-system-features","text":"The product must provide means to the PCM user to configure and save PCM application preferences. The following functions are required for this: Functional Requirement Functions Configure Application Preferences Table 11: Functional Requirements App Settings Configuration (personalization)","title":"App Settings Configuration (personalization) - System Features"},{"location":"pcmcloud/pcmcloud/#browser-based-applicationaddon-for-stationary-pcs-and-notebooks","text":"","title":"Browser-based application/addon for stationary PCs and notebooks"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00119-browser-based-applicationaddon-for-stationary-pcs-and-notebooks","text":"The product MUST implement the form factor \"Browser-based application/addon for stationary PCs and notebooks\", so that the cPCM can be used as a full-featured browser-based application that implements the GUI functionalities, the connectivity functionalities and credential and personal wallet management locally on the user's PC/notebook. The backup/restore mechanisms and the configuration management are handled as well locally on the user's PC/notebook. Because PCs/Notebooks do not usually have a fixed communication endpoint an SSI-Mediator needs to remain in the Cloud for PCM Notifications. The Browser-based application/addon for stationary PCs and notebooks MUST include the following system features: Managing Connections Managing Credentials Wallet Backup End User Authentication Notification Support App Settings Configuration Credential Wallet Importing/Exporting","title":"[IDM.PCM.CLOUD.00119] Browser-based application/addon for stationary PCs and notebooks"},{"location":"pcmcloud/pcmcloud/#cloud-based-user-agentwallet","text":"The product must provide an implementation of a cloud wallet.","title":"Cloud based User Agent/Wallet"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00120-cloud-based-user-agentwallet","text":"The product MUST implement the form factor \"cloud-based user agent/wallet\". In this form factor, the cPCM Core (Wallet) is implemented as a cloud application. This application implements connection, credential and personal wallet management, backup/restore mechanisms, user authentication and personal configuration mechanisms. As the cloud application of the PCM Core/Wallet has a fixed communication endpoint the SSI- Mediator functionality for PCM Notifications may be included in that application. The PCM in this form factor MUST include the following system features: Managing Connections Managing Credentials Wallet Backup End User Authentication Notification Support App Settings Configuration Ledger Selection Credential Wallet Importing/Exporting Consent Management AIP 2.0","title":"[IDM.PCM.CLOUD.00120] Cloud based User Agent/Wallet"},{"location":"pcmcloud/pcmcloud/#verification","text":"","title":"Verification"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00121-behavior-driven-design","text":"Verification of fulfillment of the requirements and characteristics MUST be done using automated tests which are part of the deliverables. They should be done by patterns of the Behavior Driven Development [BDD] using the \"Gherkin Syntax\".","title":"[IDM.PCM.CLOUD.00121] Behavior Driven Design"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00122-kubernetes-deployment","text":"If the verification is related to software components, it MUST be deployed in a provided Kubernetes test cluster and the components MUST be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration.","title":"[IDM.PCM.CLOUD.00122] Kubernetes Deployment"},{"location":"pcmcloud/pcmcloud/#acceptance-criteria","text":"","title":"Acceptance criteria"},{"location":"pcmcloud/pcmcloud/#connections","text":"","title":"Connections"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00123-connection-invitation","text":"When users are authenticated, then they can receive notification for \"Connection\" . The information is shown to the users via the GUI and requests can be validated. The users can accept or to reject the request. When the request is accepted, then the cPCM performs over the OCM the DIDComm protocol required to establish the connection. The connection must be established and stored in the OCM(s) storage, so that it can be used later. Interfaces GUI, Local DIDComm Input interface, DIDComm interface, DIDComm external endpoint interface","title":"[IDM.PCM.CLOUD.00123] Connection invitation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00124-list-connections","text":"When user is logged and select listing connection option, then all the stored connections are listed on the browser GUI.","title":"[IDM.PCM.CLOUD.00124] List connections"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00125-search-connections","text":"When users are authenticated, then they should be able to enter characters in the \"Search\" field. Upon entering minimum 3 characters the system should return the result. The system should perform the search based on DID, ConnectionID, and Alies(if exist).","title":"[IDM.PCM.CLOUD.00125] Search connections"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00126-display-connection-details","text":"When users are authenticated, then they should be able to view detailed information about a connection. The information shown must include the DID document describing the connection contact.","title":"[IDM.PCM.CLOUD.00126] Display connection details"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00127-display-connection-communication-history","text":"When users are authenticated, then they can view detailed information about the communication history of a given connection(Activities).","title":"[IDM.PCM.CLOUD.00127] Display connection communication history"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00128-delete-connection","text":"When users are authenticated, then via GUI they can delete a stored connection from cPCM storage.","title":"[IDM.PCM.CLOUD.00128] Delete connection"},{"location":"pcmcloud/pcmcloud/#managing-credentials-verification","text":"","title":"Managing credentials - Verification"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00129-receive-a-verifiable-credential-vc","text":"When a user is authenticated and within an established connection, the user must get notification for VC issuing. The user must get the possibility to accept or to reject the request. The request is validated, and the information is shown to the user via the GUI. The user MUST get the possibility to accept or to reject the request. The issued credential MUST be stored in the OCM(s) storage. Interfaces GUI, Local DIDComm Input interface, DIDComm interface, DIDComm external endpoint interface","title":"[IDM.PCM.CLOUD.00129] Receive a Verifiable Credential (VC)"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00130-displayinspect-a-vc","text":"When users are authenticated , then via GUI they can view detailed information about a VC. The users must get the possibility to review all VC data items.","title":"[IDM.PCM.CLOUD.00130] Display/inspect a VC"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00131-list-vcs","text":"When users are authenticated and they select the opening the VCs dashboard, then all the stored VCs are listed via the browser GUI in card format.","title":"[IDM.PCM.CLOUD.00131] List VCs"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00132-search-vcs","text":"When users are authenticated, then they should be able to enter characters via dashboard in the \"Search\" field. A full text search in all information available for the VCs must be provided by filtering the cards.","title":"[IDM.PCM.CLOUD.00132] Search VCs"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00133-answer-request-for-verifiable-presentation-vp","text":"When users are authenticated and Connection established, then: If the user has given his consent, a VP has been proved to the verifier. If the presentation has not been completed successfully, problems have been reported to the users via GUI. Interfaces: Local DIDComm Input interface, DIDComm interface, DIDComm external endpoint interface","title":"[IDM.PCM.CLOUD.00133] Answer Request for Verifiable Presentation (VP)"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00134-display-history-of-verifiable-presentations-vps-to-other-participants","text":"When users are authenticated, then they can view detailed information about the history of showing/proofing identity information to other participants. History information must list information about the transaction date and time, and to whom has been presented.","title":"[IDM.PCM.CLOUD.00134] Display history of verifiable presentations (VPs) to other participants"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00135-usage-with-external-web-sites","text":"When a website requests an credential presentation, the website must be able to redirect to the cloud wallet solution (e.g., by help of the PCM mobile). The protocol decision must be aligned with the technical lead.","title":"[IDM.PCM.CLOUD.00135] Usage with external Web Sites"},{"location":"pcmcloud/pcmcloud/#wallet-backup-verification","text":"","title":"Wallet Backup - Verification"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00136-create-backup","text":"When users are authenticated, then they can select a backup option. Upon selecting the backup option, the system must archive all stored information in a secure manner. The backup file MUST be confidentiality and integrity protected.","title":"[IDM.PCM.CLOUD.00136] Create Backup"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00137-restore-backup","text":"When users are authenticated, they must have a function to restore a backup containing all information stored in the cPCM. When users select the backup file, the restore must be performed only after confirming the security authentication. When successful restoration is completed, users should be informed about the status and they must see all their data (such as VC, Connections, etc.).","title":"[IDM.PCM.CLOUD.00137] Restore Backup"},{"location":"pcmcloud/pcmcloud/#credential-wallet-synchronization-verification","text":"","title":"Credential Wallet synchronization - Verification"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00138-sync-wallets","text":"When users are authenticated, then they must be able to configure synchronization with GXFS PCM. After successfully establishing a secure connection, then bi-directional synchronization should be triggered.","title":"[IDM.PCM.CLOUD.00138] Sync Wallets"},{"location":"pcmcloud/pcmcloud/#end-user-authentication-verification","text":"","title":"End User Authentication - Verification"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00139-initial-user-creation","text":"When a user selects an option for account creation, then he is guided via GUI to set up a cPCM wallet. User must receive an option to restore access to his wallet in case he wants to move to another laptop/PC. During the registration process, the user must set up a secure method(authentication credentials) for authenticating upon next login.","title":"[IDM.PCM.CLOUD.00139] Initial user creation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00140-user-authentication","text":"When users want to access all data in their cPCM, then they must enter authentication credentials. The protected cPCM functions can be used by the user only if authentication was successful.","title":"[IDM.PCM.CLOUD.00140] User Authentication"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00141-configure-login-credentials","text":"When users are authenticated, then they can modify their authentication credentials. Users must receive information for successfully changed authentication credentials.","title":"[IDM.PCM.CLOUD.00141] Configure login credentials"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00142-siop-login-support","text":"The cPCM implement a function to process SIOP requests [DID SIOP] in the role of the Self- Issued OpenID Provider (SIOP). Applications (RPs (Relying Parties) in SIOP terminology) can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response.","title":"[IDM.PCM.CLOUD.00142] SIOP Login Support"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00143-configure-application-preferences","text":"When users are authenticated, they can configure their application preferences such as language.","title":"[IDM.PCM.CLOUD.00143] Configure Application Preferences"},{"location":"pcmcloud/pcmcloud/#consent-management-verification","text":"","title":"Consent Management - Verification"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00144-presentation-request","text":"When an external party is requesting a credential proof, the consent plugin must intercept this request by sending to the mobile app a consent request. If this consent is successfully answered, the presentation with the existing credentials in the OCM/OCM W-Stack is fulfilled with the credential selected/attribute selection of the user to the requestor. This consent action can be reviewed then in the consent history.","title":"[IDM.PCM.CLOUD.00144] Presentation Request"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00145-consent-based-issuing","text":"When an external party requests and issues credentials for accessing a service belonging to the user, the consent plugin system must be able to forward this request to the user. After giving his consent, the consent plugin will create a credential for the configured service (e.g., by creating a token) and issue this credential to the requestor. The requestor uses this credential to access the service.","title":"[IDM.PCM.CLOUD.00145] Consent Based Issuing"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00146-consent-based-authorization","text":"Each consent plugin must provide an OIDC compliant well known JKWS url next to an consent plugin DID that an external service can rely on this key material for verifying the consent credentials. The external service will insert this JWKS url or this DID to its API so that the user can provide consents for accessing the data. This can be demonstrated by configuring an Rest API by did auth or jwt auth. After the consent issues a credential (either JWT or W3C VC), the API must be able to allow or deny the access based on the DID/JWKS information of the consent plugin.","title":"[IDM.PCM.CLOUD.00146] Consent Based Authorization"},{"location":"pcmcloud/pcmcloud/#plugin-system-verification","text":"","title":"Plugin System - Verification"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00147-plugin-token","text":"The user is able to generate a plugin and a token, and the token can be used for an external service. The external service is able to verify over the DID or the jwks well known url the token.","title":"[IDM.PCM.CLOUD.00147] Plugin Token"},{"location":"pcmcloud/pcmcloud/#remote-control","text":"","title":"Remote Control"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00148-remote-commands","text":"The cPCM backend integrates OCM and OCM W-Stack to a simplified layer to answer remote commands for: listing, deleting and blocking of connections and credentials. Additionally, the remote control can activate TSA rules for (consent) plugins, viewing the history, triggering the backups, viewing the backups, viewing keys, creating keys, deleting keys, enabling plugins, disable plugins, viewing devices, and removing devices.","title":"[IDM.PCM.CLOUD.00148] Remote Commands"},{"location":"pcmcloud/pcmcloud/#support-for-kubernetes","text":"","title":"Support for Kubernetes"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00149-eventing","text":"All eventings must be demonstrated on basis of cloud events specifications [17] together with the kNative [18] broker together with NATS in a Kubernetes environment.","title":"[IDM.PCM.CLOUD.00149] Eventing"},{"location":"pcmcloud/pcmcloud/#17-httpscloudeventsio","text":"","title":"[17] [https://cloudevents.io/]"},{"location":"pcmcloud/pcmcloud/#18-httpsknativedevdocseventing","text":"","title":"[18] [https://knative.dev/docs/eventing/]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00150-config-map-support","text":"Each service must be demonstrated up and running in the provided Kubernetes environment, configured by config maps.","title":"[IDM.PCM.CLOUD.00150] Config Map Support"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00151-helm-installation","text":"The service installation MUST be demonstrated during HELM install.","title":"[IDM.PCM.CLOUD.00151] Helm Installation"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00152-argocd-integration","text":"The helm chart MUST be able to install inside of ArgoCD. This includes the usage of the postgres hooks [19] and the providing of usable values.yaml(s) for all developed services.","title":"[IDM.PCM.CLOUD.00152] ArgoCD Integration"},{"location":"pcmcloud/pcmcloud/#19-httpsgitlabeclipseorgeclipsexfscintegration-treemainhelmchartspostgresql-hook","text":"","title":"[19] [https://gitlab.eclipse.org/eclipse/xfsc/integration/-/tree/main/helm/charts/postgresql-hook/]"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00153-scs-environment","text":"All HELM installations MUST run on SCS (Sovereign Cloud Stack). The final acceptance demonstration cannot be realized on azure, google cloud etc.","title":"[IDM.PCM.CLOUD.00153] SCS Environment"},{"location":"pcmcloud/pcmcloud/#idmpcmcloud00154-kubernetes-operator","text":"The Kubernetes Operator MUST be controllable over an API to deploy/destroy multiple instances of the cPCM on demand.","title":"[IDM.PCM.CLOUD.00154] Kubernetes Operator"},{"location":"pcmcloud/pcmcloud/#appendix-a-glossary","text":"For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO]","title":"Appendix A: Glossary"},{"location":"pcmcloud/pcmcloud/#appendix-b-example-consent-management","text":"The flows are just for example. Flow optimizations can be proposed. Flow 1: External Actor requests Access to Protected API Flow 2: External Actor gives Access to protected Resources","title":"Appendix B: Example Consent Management"},{"location":"pcme1/pcme1/","text":"Software Requirements Specification for Gaia-X Federation Services Personal Credential Manager Extension 1 IDM.PCM.E1 Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA 1 Introduction 1.1 Document Purpose 1.2 Product Scope 1.3 Definitions, Acronyms and Abbreviations 1.4 References 1.5 Document Overview 2 Product Overview 2.1 Product Perspective 2.2 Product Functions 2.3 Product Constraints 2.4 User Classes and Characteristics 2.5 Operating Environment 2.6 User Documentation 2.7 Assumptions and Dependencies 2.8 Apportioning of Requirements 3 Requirements 3.1 External Interfaces 3.1.1 User Interfaces 3.1.2 Hardware Interfaces 3.1.3 Software Interfaces 3.1.4 Communications Interfaces 3.2 Functional 3.2.1 Managing Connections 3.2.2 Managing Credentials 3.2.3 Wallet Backup 3.2.4 Credential Wallet Importing/Exporting 3.2.5 DIDComm Login Support 3.2.6 NFC Scanning (DID Input) 3.2.7 SIOP Login 3.2.8 App Settings Configuration (personalization) 3.2.9 Ledger Selection 3.2.10 Mediator Selection 3.2.11 DID Document Service Endpoint Support 3.2.12 Cloud wallet management 3.3 Other Nonfunctional Requirements 3.3.1 HTTP Requirements 3.3.2 Logging Requirements 3.3.3 Security Requirements 3.3.4 Safety Requirements 3.3.5 Security Requirements 3.3.6 Software Quality Attributes 3.3.7 Business Rules 3.4 Compliance 3.5 Design and Implementation 3.5.1 Installation 3.5.2 Distribution 3.5.3 Usability 3.5.4 Maintainability 3.5.5 Portability 3.5.6 Interoperability 4 System Features 4.1 Managing Connections 4.2 Managing Credentials 4.3 Wallet Backup 4.4 Credential Wallet Importing/Exporting 4.5 DIDComm Login support 4.6 NFC Scanning (DID Input) 4.7 SIOP Login 4.8 App Settings Configuration (personalization) 4.9 Ledger Selection 4.10 Smartphone Application 5 Verification 5.1 Core Verification Requirements 5.2 Functionality Acceptance Criteria 5.2.1 Connections 5.2.2 Managing credentials 5.2.3 Credential Wallet synchronization 5.2.4 NFC 5.2.5 SIOP Login Support 5.2.6 App Settings Configuration (personalization) 5.2.7 Ledger Selection 5.2.8 Mediator Selection 5.2.9 Cloud Wallet Management Appendix A: Glossary Appendix B: Consent Management Appendix C: Personal Credential Manager Layering overview List of Figures Figure 1: Personal Credentials Manager. Layering overview (s. appendix C) Figure 2: Personal Credentials Manager: Component View List of Tables Table 1: References Table 2: User Classes and Characteristics Table 3: Apportioning of Requirements Table 4: Functional Requirements Connection Management Table 5: Functional Requirements Credential Management Table 6: Functional Requirements Wallet Backup Table 7: Functional Requirements Credential Wallet Importing/Exporting Table 8: Functional Requirements DIDComm Login support Table 9: Functional Requirements NFC Scanning (DID Input) Table 10: Functional Requirements SIOP Login Table 11: Functional Requirements App Settings Configuration (personalization) Table 12: Functional Requirements Ledger Selection Introduction To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD]. Document Purpose The purpose of the document is to specify the requirements of the Identity Management and Trust Subcomponent \"Personal Credential Manager\" with the intention of a European wide public tender for implementing this software. Main audience for this document is attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide a credential manager application to be used by natural persons to participate in the Gaia-X trust structure. Product Scope The purpose of this product is to provide all necessary components for the self-sovereign administration of the digital identity of a principal in the Gaia-X context on a mobile device. The Personal Credential Manager enables a natural person to act as a principal of an organization within the SSI-based Gaia-X ecosystem in a privacy-preserving, trustful and secure way. This comprises the following main functionalities: AIP 2.0 Support Reception and management of W3C verifiable credentials Presenting W3C and AIP 2.0 Verifiable Presentations to other parties in a proved manner Secure storage and management of respective secrets Remote Management of the PCM Cloud Solution Support of the Cloud PCM functionality Enhancements in QR Code Support Reading and Presentation Extension of the Personal Credential Manager must be developed as additional features of the existing smartphone-based application for Android and iPhone platforms. Furthermore, the scope includes the provision of the developed software in a usable format for end users including the respective distribution channels (e.g., App Stores). If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams. Definitions, Acronyms and Abbreviations All requirements from other documents are referenced by [IDM.\\<document-id>.XXXXX] as defined in the chapter \"Methodology\" in the document [IDM.AO]. References Concept Source Status Hyperledger Aries Concepts (AIP2.0) GitHub 03-17-2023 Specflow (Getting Started with BDD) Specflow 03-18-2023 Cryptographic Key Length Recommendation (CryptoLen) KeyLength 03-18-2023 DIDComm Messaging (Daniel Hardman) Identity Foundation 03-18-2023 OpenID Self-Issued OpenID Connect Provider DID OpenID - FIPS 140-2 (Federal Information Processing Standard) Wikipedia 03-17-2023 Gaia-X WP1 (Architecture Overview) Refer to \"annex_IDM.AO\" (Base of functional specification) - GXFS Organization Credential Manager W-Stack Refer to \"annex_IDM.OCM.W-STACK\" - Gaia-X Federation Service Non-functional Requirements (NF.SPBD) Refer to annex \"GXFS_Nonfunctional_Requirements_SPBD\" - OpenID for Verifiable Credential Issuance (OID4VC) OpenID 03-17-2023 OpenID for Verifiable Presentations (OID4VP) OpenID 03-17-2023 Gaia-X Policy Rules (PRD) Gaia-X Docs - SOG-IS Crypto Evaluation Scheme (SOG-IS) SOG-IS Document 03-18-2023 Gaia-X Architecture Document (TAD) Gaia-X Docs 03-17-2023 Table 1: References Document Overview The document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the additional system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.EX.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [RFC 2119], are written in capital letters (see also [IDM.AO] - Methodology). Product Overview Product Perspective The personal credential manager is used by a natural person. Within the Gaia-X terminology, such a natural person is named principal . The principal utilizes the PCM in the respective form factor to store VCs issued to her/him as well as to prove the statements necessary to obtain a service. The PCM must extend the support of following overall processes: DIDComm Authentication as the generic way to authenticate a principal Secure backup and restore by file SIOP DID as a method to implement SSI based Login Methods [DID SIOP] Consent Management OIDC4VP for presenting Credentials OIDC4VC to receive Credentials Remote Management and Usage of cPCM DID Document Based Protocol Selection AIP 1.0 Protocol AIP 2.0 Protocol [AIP2.0] Bi-directional synchronization with Cloud Personal Credential Wallet Train Selection > The existing code base MUST be reused and further improved. Other microservices MAY have different languages and architectures. Product Functions Personal Credentials Manager (PCM) enables end-users to interact with the DID-based ecosystem in a privacy-preserving way. PCM acts as a user representative tool which is securely holding the acquired distributed identities and identity attributes and provides the technical means to selectively disclose the aforementioned attributes for authentication and service consumption. The following represents the high-level functional architecture of the PCM. Figure 1: Personal Credentials Manager. Layering overview (s. appendix C) As presented in the PCM big picture layering overview, PCM consists of different components which effectively comprise the following layers: The front-end layer PCM Core (Wallet) layer as well as the Mediator (Relay) layer The front-end layer is comprised of the following features and components: End User Authentication Graphical User Interface (GUI) Local Input Interfaces End User Authentication component provides for the implementation of secure user authentication policies which can include but are not limited to fingerprint authentication in the smart phone case, PIN, password, etc. The GUI component enables end users to interact with the PCM and use the PCM functions. Local Input Interfaces comprise QR-code processing, bootstrapping over Near Field Communication (NFC), etc., and by that provides communication initiation, direct, or peer-to-peer (contact) exchange as well as credentials presentation ensuring the direct proximity requirements. PCM Core (Wallet) layer consists of the following features and components: W3C VC synchronization with cPCM for offline Presentation Consent Management over cPCM Remote Management of cPCM Backup/Restore over cPCM Remote Control of the Cloud PCM by using a didcomm protocol over the websocket connection The Managing Credentials feature provides the functionality for receiving credentials issued by other participants, enabling the user to view and inspect his/her credentials, and the basic functionality for proofing credential attributes to other participants according to the SSI paradigm. The credential manager ensures that the user is always in control, which attributes are provided to which participant. It further enables to create and check proofs according to the SSI paradigm to, for example, achieve DIDComm or SIOP Login, etc. The Wallet Backup feature provides for the secure backup and restore capabilities of the obtained credentials and possibly the app settings. The automatic synchronization feature enables the users to configure a unique channel of communication between PCM and cPCM. Which enables the und users to synchronize W3C VC from PCM to cPCM and via versa. The figure below is the planned component structure which are a matter of this tender (derivations allowed from SW perspective): >Figure 2: Personal Credentials Manager: Component View The existing code base contains partially the components on this picture. In a planned software architecture for this tender all of these components MUST be considered for restructuring the code. Product Constraints [IDM.PCM.E1.00000] OID4VP/VC Compatibility The PCM MUST support exchange over OID4VP protocol [OID4VP] and all other applicable standards needed for communication with the Organization Credential Manager and OCM W- Stack [IDM.OCM.W-STACK]. [IDM.PCM.E1.00001] AIP 2.0 Compatibility The PCM MUST support AIP 2.0 as specified in Aries Interop Profile [AIP2.0]. [IDM.PCM.E1.00002] Offline Presentation All W3C credentials in the wallet (including the synced one) MUST be available for the offline presentation. \"Offline\" is in this case defined as \"No third Party involved\" which is able to track the data. Means the presentation MUST be possible by QR Code, NFC or Bluetooth peer to peer from one Smartphone to the other. This includes a capability to identify trusted verifiers and issuers on the smartphone before presentation e.g., by using Bloom Filters. [IDM.PCM.E1.00003] Cloud PCM The Cloud PCM (also part oft his tender) MUST be used as Integration Layer and as remote backend to store and synchronize W3C credentials including the remote management/control of the cPCM agents and backup storage. The cPCM connection MUST NOT implement Aries Protocols or Aries RFCs, because the PCM and cPCM connection acts as private connection of the PCM Smartphone App with its private backend (cPCM). User Classes and Characteristics User Class Description Expertise Privilege Level Product Usage Personal User The person in possession of the personal credential manager using all functionality of the product Low High Frontend Table 2: User Classes and Characteristics Operating Environment Please refer to [TDR] for further binding requirements regarding the operating environment. [IDM.PCM.E1.00003] Operating Environments The product needs to support different operating environments. Android operating system versions which are still supported by Google (as of now > Android version 9) MUST be supported. iOS operating system versions which are still supported by Apple MUST be supported. User Documentation Please refer to [TDR] for further requirements regarding documentation. [IDM.PCM.E1.00004] Participant Administration Documentation The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the product from source code [IDM.PCM.E1.00005] Participant Documentation The documentation MUST contain: Short Software Description/Usage Usage Guide GDPR Design Decisions Security Concept Operations Concept FAQ Keyword Directory Assumptions and Dependencies An understanding of the overall Gaia-X architecture and philosophy is necessary. Please refer to [TAD] and [PRD]. Apportioning of Requirements Feature Priority OIDV4VP/VC support 1 AIP 2.0 support 1 Cloud wallet synchronization 1 QR generation 1 NFC tag generation 1 NFC Scanning (DID Input) 1 SIOP Login 1 cPCM Remote Control 1 Consent Management 1 Table 3: Apportioning of Requirements Requirements Further binding requirements can be found in [TDR]. External Interfaces User Interfaces [IDM.PCM.E1.00006] Smartphone GUI The PCM MUST provide a GUI for the PCM user to support the enhancements for the Cloud PCM. This requires support for Consent Management, as well for Notifications and the support of W3C credentials provided by the OCM W-Stack [IDM.OCM.W-STACK]. Hardware Interfaces [IDM.PCM.E1.00007] Camera The PCM MUST be able to use the Smartphone's camera to scan QR-Codes for W3C credentials and OpenID4VC issuing Proposals [OID4VC]. [IDM.PCM.E1.00008] NFC The PCM must be able to use the Smartphone's NFC communication to receive DIDComm invitation messages, OpenID4VC Issuing Proposals and W3C Credentials. Software Interfaces [IDM.PCM.E1.00009] Secure Storage The PCM implementation MUST be able to use secure storage (internal storage, encrypted storage, dedicated key storage) by using enclaves provided by the target platform/smartphone operating system for storing PCM data within the smartphone. Especially for key exchange between the Cloud PCM and the PCM App is this required to protect the keys safely. It's highly recommended to use asymmetric encryption protocols by utilizing internal enclaves to exchange the keys (e.g., CMS or other schemes) Communications Interfaces [IDM.PCM.E1.00010] DIDComm v2 Interface The DIDComm interface MUST be provided to send DIDComm messages to be processed by the PCM and the PCM Cloud. [IDM.PCM.E1.00011] NFC The PCM App MUST support the exchange of W3C VCs/VPs and Connection invitations by using NFC (reading and presentation). [IDM.PCM.E1.00011] Local SIOP Endpoint The PCM MUST provide an endpoint for SIOP requests [DID SIOP]. Within the SIOP protocol, the PCM implements the role of the Self-Issued OpenID Provider (SIOP). Applications (PRs (Relying Parties) in SIOP terminology can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response. The SIOP process MUST be triggerable via an URL scheme which is registered during the App Installation (e.g., gxfspcm://siop?...) [IDM.PCM.E1.00012] Personal Wallet and Secrets Synchronization Given that PCM users for security reasons import or export their Personal Wallet and secrets, an interface MUST be provided so that Synchronization between PCM and Cloud Wallet (cPCM) can be established by using web socket protocols. This feature is dedicated to W3Cs and is not relevant for Aries based credentials. All secrets relevant for presentation of W3C credentials MUST be transferred encrypted and in an approach that the private key isn't transmitted at once and just \"activatable\" by user knowledge. For instance, by using key derivation functions. [IDM.PCM.E1.00013] Mediator selection based on DID document PCM needs to be able to find the correct mediator, based on the record in the DID document as well the other endpoints for communication MUST be discovered by the DID document. All endpoint types MUST be configurable with the following format by enhancing the W3C spec [1]: > { > id: {idName} > type: {typeName}, > accept: \\[\"didcomm/v2\",\"didcomm/v1\",{otherProtocols}\\], > serviceEndpoint:\\[\"https://...\"\\] > } [1] [https://www.w3.org/TR/did-core/#example-usage-of-the-service-property] [IDM.PCM.E1.00014] cPCM Connection The mobile application needs a secure communication web socket channel to the PCM Cloud to synchronize Credentials, receiving Consent Notifications, Credential Requests etc. The application MUST implement for this purpose WebSockets and didcomm v2. The message protocol provided by the cPCM MUST be implemented and documented as \"RFC\" similar to Hyperledger Aries RFC documentation format [2]. [2] [https://github.com/hyperledger/aries-rfcs/blob/main/concepts/0074-didcomm-best-practices/README.md#rfc-naming] Functional Managing Connections [IDM.PCM.E1.00015] Connection creation via invitation DIDComm connection requests can be provided to the PCM user via QR-Code, Text input (URL), NFC (Out of band messages according to DIDComm Messaging specification [DIDComm]), and by regular DIDComm messages received. Especially for the device pairing between PCM and Cloud OCM MUST be process described and developed (e.g., by a special invitation protocol) Managing Credentials [IDM.PCM.E1.00016] Receive a Verifiable Credential (VC) The PCM MUST be able to receive VCs according to AIP 2.0 and OpenId4VC Standards for the underlying issuing protocols. The AIP 1.0 functionality MUST remain and still be supported in the App. [IDM.PCM.E1.00017] Answer Request for Verifiable Presentation (VP) The PCM MUST be able to answer presentation requests according to AIP 2.0 and OpenId4VC Standards for the underlying issuing protocols. The AIP 1.0 functionality MUST remain and still be supported in the App. [IDM.PCM.E1.00018] Display history of presenting verifiable Presentations (VPs) to other participants The PCM user can view detailed information about the history of showing/proofing identity information to other participants. For each run of the Proof protocol, the information shown MUST include all information contained in the VP shown to a verifier including the remote one from the cPCM, to which verifier it has been shown, and transaction date/time. Wallet Backup [IDM.PCM.E1.00019] Restore Backup The PCM MUST provide a function to restore a backup containing all information stored in the PCM. The Backup/Restore format MUST be compatible to guarantee PCM App interoperability between form factors and between different providers or Smartphone Applications and Cloud Wallet (cPCM). This MUST be for W3C credentials an encrypted JSON-LD file or for Aries Credentials just a file. Credential Wallet Importing/Exporting [IDM.PCM.E1.00020] Sync Wallets The PCM MUST provide a functionality to synchronize different personal cloud wallet instances (Cloud PCM), e.g., synchronize a cloud wallet (cPCM) with a smartphone wallet. Secure methods for Importing the PCM Secrets MUST be provided. The synchronization MUST consist of W3C Credentials, Aries credentials are out of scope for syncing. DIDComm Login Support [IDM.PCM.E1.00021] DIDComm Login Support The PCM MUST support the Login via DIDComm by using the DIDComm Login protocol of the cPCM (no aries protocol, internal protocol of cPCM). NFC Scanning (DID Input) [IDM.PCM.E1.00024] NFC The PCM MUST support scanning of W3C Credentials and Invitations via NFC. The Presentation of Credentials and Presentations MUST be provided via NFC as well. SIOP Login [IDM.PCM.E1.00022] SIOP Login Support The PCM MUST implement a function to process SIOP requests [DID SIOP] in the role of the Self- Issued OpenID Provider (SIOP). Applications (RPs (Relying Parties) in SIOP terminology) can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response. App Settings Configuration (personalization) [IDM.PCM.E1.00023] Configure Cloud wallet linking The PCM MUST enable the user to configure a secure connection for data synchronization by realizing a prior pairing to the Cloud PCM via DIDComm. Ledger Selection [IDM.PCM.E1.00024] Select Ledger The PCM MUST NOT be enabled to select compatible Ledgers. The selection is pre-configured from a list of supported ledgers and all other Information MUST be extracted from DID Documents. Mediator Selection [IDM.PCM.E1.00025] Select Mediator The mediator MUST be selected by using the DID Document (resolved over DID) to find the right endpoints. DID Document Service Endpoint Support [IDM.PCM.E1.00026] Service Endpoint Usage The DID Document Service Endpoints MUST be used for the PCM functionality, and the formats and accept attributes MUST be considered next to the key material provided by the document. Cloud wallet management [IDM.PCM.E1.00027] Remote controller of the Cloud PCM The PCM user MUST be able to control the basic functions of the Cloud PCM (cPCM) such as Consent management and Credential management. The proofs requested by an external actor, can be consented by the user by using the PCM. A Diagram for the Consent Management is in Appendix B and MUST be realized on SSI based W3C mechanisms. [IDM.PCM.E1.00028] Selective Disclosure JWT The component MUST support Selective Disclosure JWT described in the specification [3]. [3] [https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/] Other Nonfunctional Requirements [IDM.PCM.E1.00029] Architecture Changes All Architecture Changes MUST be aligned with the Principal before implementation. HTTP Requirements [IDM.PCM.E1.00030] HTTPS All HTTP communication MUST be protected by state-of-the-art transport security algorithms such as TLS 1.2 / TLS 1.3 (all protocol version numbers may be superseded by upcoming standards). Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system. [IDM.PCM.E1.00031] HTTP Protocol Definitions All HTTP Endpoints MUST follow RFC 7231 [4] and RFC 5789 [5], but it MAY be chosen what of the protocols is necessary to realize the functionality. For problem reports the RFC7807 [6] MUST be used in combination with Standard HTTP Error Codes. [4] [https://tools.ietf.org/html/rfc7231] [5] [https://tools.ietf.org/html/rfc5789] [6] [https://tools.ietf.org/html/rfc7807] Logging Requirements [IDM.PCM.E1.00032] Data Minimization The data minimization principle is expressed in Article 5(1)(c) of the GDPR and Article 4(1)(c) of Regulation (EU) 2018/1725, which provide that personal data must be \\\"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed\\\". The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of the following elements: (a) node\\'s identification (b) message identification (c) message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review. Security Requirements General Security Requirements Each Gaia-X Federation Service SHALL meet the requirements stated in the document \"Specification of non-functional Requirements Security and Privacy by Design\" [NF.SPBD]. Federation Services specific requirements will be documented in the next chapter. Service Specific Security Requirements This chapter will describe the service specific requirements, which will extend the requirements defined in the chapter above. [IDM.PCM.E1.00033] Secure user authentication To ensure that only allowed entities can access the PCM authentication methods MUST be implemented to grant access to the PCM. The PCM MUST provide a method for securing user login with at least two authentication factors. [IDM.PCM.E1.00034] Multimodal biometric authentication The PCM MAY provide (multimodal) biometric authentication methods to improve the usability of the PCM. [IDM.PCM.E1.00035] Protection of Secrets (Wallet) and Security for the Restore process The PCM secrets MUST be stored and processed securely. There MUST be additional security procedures in place to guarantee that the secret key can be recovered when the holder requires it, even in case the holder himself has lost access to his unlock key. State of the art methods that MAY be applied are for example Shamir's Secret Sharing. [IDM.PCM.E1.00036] Secure communication between frontend and cloud agent/wallet The communication interface in case of the cloud agent/Wallet form factor must be protected according to the latest security standards. [IDM.PCM.E1.00037] Cryptographic Algorithms and Cipher Suites Cryptographic algorithms and TLS cipher suites SHALL be chosen based on the recommendation from the German Federal Office for Information Security (BSI) or SOG-IS. These recommendations and the recommendations of other institutions and standardization organization are quite similar [7] [CryptoLen]. The recommendations can be found in the technical guidelines [8] TR 02102- 1 [TR02102-1] and TR 02102-2 [TR02102-2] or SOG-IS Agreed Cryptographic Mechanisms [9] [SOG- IS]. [7] See [https://www.keylength.com/en] for a comparison [8] See [https://www.bsi.bund.de/EN/Service-Navi/Publications/TechnicalGuidelines/tr02102/tr02102_node.html] for a comparison [9] See [https://www.sogis.eu/documents/cc/crypto/SOGIS-Agreed-Cryptographic-Mechanisms-1.2.pdf] for a comparison [IDM.PCM.E1.00038] Security by Design The software security MUST be from the beginning a design principle. Means separation of concerns, different administrative roles, especially for private key material and separate access to the data MUST be covered from the first second. It MUST be described in the security concept, what are the different security risks of the product and how they are mitigated (e.g., by Threat Modeling Protocols) [IDM.PCM.E1.00039] Installation of Critical Security Updates Node operators SHALL deploy security critical updates without undue delay. [IDM.PCM.E1.00040] Avoid HTTP Request Smuggling To avoid Request Smuggling attacks, the product MUST implement a standard which handles this kind of attack by design, because the attack vector results in an insufficient implementation of the header handling. The chosen way to handle it MUST be shared with the Principal for further alignment with the other implementers of all other subcomponents within the GXFS project and MUST be described in the security concept. [IDM.PCM.E1.00041] Pentesting All parts of the product have to be pentested, at least for the following criteria: Unauthorized Access to the System MUST be tested Unauthorized Actions MUST be triggered without a user action All Interfaces MUST be tested It's RECOMMENDED to test more attack vectors and document it for the purpose to mitigate it in later versions. [IDM.PCM.E1.00042] Storage of Secrets The storage of secret information such as private keys MUST take place in state-of-the-art secure environments to protect secret data confidentiality and integrity. Examples of this are Secure Enclaves, TPMs, HSM or Secure Vaults. In case (Personal) Agents are not equipped with a secure storage it MAY also be possible to store the secrets in a third party (e.g., Cloud) provider (e.g., Secure Wallet) that MUST provide overall the same level of security as the aforementioned methods. [IDM.PCM.E1.00043] Secret Distribution and Usage The product MUST ensure interoperability of cryptographic primitives and components by public standards and MUST use secure state of the art methods to create and import secrets into the secure storage, as well as performing cryptographic operations (e.g., encryption or digital signatures). For Key distribution, state of the art DKMS methods MUST be implemented. [IDM.PCM.E1.00044] Support for Potential Requirements for Secret Storages Devices that hold cryptographic information and perform cryptographic functions MUST be compliant with standard PKCS #11 or other comparable cryptography standards. Moreover, the products MUST be potentially eligible for a FIPS-140-2 or ETSI/Common Criteria certification with the minimum-security level necessary to operate securely in the Gaia-X ecosystem. Security Levels in FIPS-140-2 range from 1 to 4. Current HSM Cloud Service offerings (AWS, Azure, GCP) are Level 3 (Source: [FIPS]). [IDM.PCM.E1.00045] Special Availability and Scalability Requirements for Secret Storage Components Secret Storage components play a central role in storage, encryption and digital signing in the Gaia-X ecosystem, thus they can become a single point of failure for a Gaia-X participant, for example an organization. Therefore, methods and procedures to ensure the availability and scalability of the Secret Storage functionality MUST be implemented. Safety Requirements [IDM.PCM.E1.00046] Major Releases All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening. Security Requirements [IDM.PCM.E1.00047] CVE Patches All software components MUST have applied CVE patches, which are available for major releases. Software Quality Attributes [IDM.PCM.E1.00048] Software Quality Requirements All software components MUST be compliant to the requirements within the quality assurance repository [10]. This includes continuing testing, branch models which verify the code quality at check in time and automated behavior testing of all defined quality attributes. [10] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues] Business Rules [IDM.PCM.E1.00049] Software Consistency The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc. Compliance [IDM.PCM.E1.00050] GDPR Audit Logging All GDPR relevant access to personal relevant data MUST be logged for a later audit. [IDM.PCM.E1.00051] GDPR Data Processing If it is necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant personally identifiable data MUST be deleted after the processing, if applicable. Design and Implementation Please also refer to [TDR] for further requirements. Installation [IDM.PCM.E1.00052] iOS and Android Installation The product must be easily installable and comply with the installation requirements depending on the target platforms. Distribution There are no dedicated distribution requirements for the PCM. Usability [IDM.PCM.E1.00053] GUI usability GUI design MUST comply with common GUI recommendations for the target platforms. [IDM.PCM.E1.00054] PCM accessibility The product MUST comply with the accessibility requirements depending on the target platforms. [IDM.PCM.E1.00055] Internationalization Support The PCM MUST support internationalization. At least the following languages MUST be supported: English. Maintainability [IDM.PCM.E1.00056] Continuous Integration All tests MUST be coded in a continuous tool to ensure the software quality in a further development. All the necessary scripts and setups MUST be provided on the public code repository to make it possible for everyone to compile and execute the product. Portability [IDM.PCM.E1.00057] App Portability The product MUST be portable to different devices, e.g., tablets. This includes as well lower end devices (Moto G3, Pixel 4a etc.) to support non-discriminatory all users without consideration of the purchasing power. Interoperability [IDM.PCM.E1.00058] Interoperability of IT security features and algorithms The following interoperability requirements of the respective IT security features and algorithms MUST be ensured across the system components: Interoperability of crypto algorithms and protocols (including the novel peer-reviewed ones through the established bodies and communities) Interoperability of secure secret transfer protocols (such as the holistic usage of PKCS#11 for HSM communication, etc.) Format interoperability of crypto material (such as the holistic usage of PKCS#12 for relevant cases) System Features Managing Connections - System Features Using this product, the user shall be enabled to manage his Gaia-X connections. Technically, connections are represented by DID-based connections to other Gaia-X participants. Connection data includes the contact DID, DID Document, DIDComm connection status data, and communication history (e.g., VPs exchanged). Via the PCM, the user must be able to establish DIDComm connections based on invitations, which can be input to the PCM by scanning QR-Codes, Text input (URL), NFC, and by regular DIDComm Messages. The following functions are required for connection management: Functional Requirement Functions - Connection creation via invitation Table 4: Functional Requirements Connection Management Managing Credentials - System Features The product shall enable the user to manage his verifiable credentials (VCs). Other Gaia-X participants can issue VCs to the user in possession of the personal credential manager. The user must be enabled to inspect his VCs and to show/proof VC information via verifiable presentations (VPs) to other Gaia-X participants. Within the Gaia-X environment, persons in the role of Gaia-X principals need to be able to receive a VC onboarding them as a principal to an organization. Within the PCM, the function \"receive a VC\" can be used for this purpose. The following functions are required for management of VCs: Functional Requirement Functions - [Receive a Verifiable Credential (VC)] - [Answer Request for Identity Information (VP)] - [Display history of presenting identity information (VPs) to other participants] Table 5: Functional Requirements Credential Management Wallet Backup - System Features The product must provide the functionality to create backups of the information stored within the PCM. Backups must be stored in a secure way, so that only the PCM user, who created the backup, can restore the backup. Backups must contain the full status of the PCM. The following functions are required for backup: Functional Requirement Functions - [Restore Backup] Table 6: Functional Requirements Wallet Backup Credential Wallet Importing/Exporting - System Features To ensure interoperability between providers, applications and form factors, the PCM must implement a procedure to export and import personal wallet data and secret information. The following functions are required for this feature: Functional Requirement Functions - [Sync Wallets] Table 7: Functional Requirements Credential Wallet Importing/Exporting DIDComm Login support - System Features The product must be able to scan DIDComm messages via NFC, to support DIDComm login. Functional Requirement Functions - [DIDComm Login Support] Table 8: Functional Requirements DIDComm Login support NFC Scanning (DID Input) - System Features The product must be able to scan DIDComm messages via NFC, to support DIDComm login. Functional Requirement Functions - [Scan NFC] Table 9: Functional Requirements NFC Scanning (DID Input) SIOP Login - System Features The product must provide support for applications to login into services via the SIOP protocol. The following functions are required for this: Functional Requirement Functions - [SIOP Login Support] Table 10: Functional Requirements SIOP Login App Settings Configuration (personalization) - System Features The product must provide means to the PCM user to configure and save PCM application preferences. The following functions are required for this: Functional Requirement Functions - [Configure Cloud wallet linking] Table 11: Functional Requirements App Settings Configuration (personalization) Ledger Selection - System Features [IDM.PCM.E1.00059] Ledger Support (DID) and Ledger-agnostic behavior The product MUST support multiple Ledgers according to the Architecture Overview [IDM.AO] , e.g., it MUST NOT be bound to a dedicated Ledger by design and the PCM user should not be able to select ledgers - It\\'s pre-configured . | Functional Requirement | | ---------------------- | | Functions | | - [Select Ledger] | Table 12: Functional Requirements Ledger Selection Smartphone Application Smartphone Application The product MUST implement the form factor \"Smartphone Application\", so that the PCM can be used as a full-featured app that implements the GUI functionalities, the connectivity functionalities and credential and personal wallet management locally on the smartphone. The backup/restore mechanisms and the configuration management are handled as well in the mobile Smartphone app. This alternative can benefit from all physical input and output interfaces present in a Smartphone, such as cameras for scanning QR-Codes for connection invitations or the NFC communication. Because Smartphones do not usually have a fixed communication endpoint an SSI-Mediator needs to remain in the Cloud for PCM Notifications. The smartphone application MUST include the following system features: Managing Connections Managing Credentials Wallet Backup End User Authentication QR-Code scanning (DID Input) Notification Support App Settings Configuration Ledger Selection The smartphone application additionally include the following system features: Credential Wallet Importing/Exporting/Syncing NFC tag generation and scanning SIOP Login Verification Core Verification Requirements [IDM.PCM.E1.00060] Behavior Driven Design Verification of fulfillment of the requirements and characteristics MUST be done using automated tests which are part of the deliverables. They SHOULD be done by patterns of the Behavior Driven Development [BDD] using the \"Gherkin Syntax\". Functionality Acceptance Criteria Connections [IDM.PCM.E1.00063] Connection invitation When users are authenticated, then they can receive notification for \"Connection\" via QR-Code, Text input (URL), NFC. The information is shown to the users via the GUI and requests can be validated. The users can accept or to reject the request. When the request is accepted, then the PCM performs the DIDComm protocol required to establish the connection. The connection must be established and stored in the PCM storage, so that it can be used later. Managing credentials - Verification [IDM.PCM.E1.00064] Receive a Verifiable Credential (VC) When a user is authenticated and within an established connection, the user must get notification for VC issuing requests. The user must get the possibility to accept or to reject the request. The request is validated, and the information is shown to the user via the GUI. The issued credential MUST be stored in connected OCM(s) of the cPCM and synced to PCM in the case of a W3C credential. In the case of an Indy credential, the App MUST show the credential by using the remote functionality but MUST NOT sync the indy credential physically. In both cases, two credentials are visible in the PCM App, the indy one is highlighted as \"cloud credential\", the other one as \"Local Credential\". When the PCM App receives a Indy/W3C credential directly from an OCM, the credential MUST be also marked as \"Local Credential\". Is any \"cloud credential\" removed from an connected OCM within the cPCM, the App will sync those changes and push the credential to history overview. [IDM.PCM.E1.00065] Answer Request for Verifiable Presentation (VP) When users are authenticated and Connection established, then: If the user has given his consent, a VP has been proved to the verifier. If the presentation has not been completed successfully, problems have been reported to the users via GUI. The App MUST demonstrate that (synced) W3C or Indy Credentials can be presented offline without any connection to the cPCM. In the online case, the App MUST demonstrate that a credential can be presented via the remote control of the cPCM. [IDM.PCM.E1.00066] Display history of presenting verifiable presentations (VPs) When users are authenticated, then they can view detailed information about the history of showing/proofing identity information to other participants. History information must list information about the transaction date and time, and to whom has been presented. [IDM.PCM.E1.00067] Restore Backup When users are authenticated, they must have a function to restore a backup containing all information stored in the PCM and Cloud wallet (cPCM). When users select the backup file, the restore must be performed only after confirming the security authentication. When successful restoration is completed, users should be informed about the status and they must see all their data(such as VC, Connections, etc.). [IDM.PCM.E1.00068] Card View The PCM MUST present all credentials as cards (like credit cards), with a logo if the credential is in the cloud available or local. The view MUST support easy selection and combination of credentials for the different remote and local use cases. Credential Wallet synchronization [IDM.PCM.E1.00069] Sync Wallets When users are authenticated, then they must be able to configure synchronization with Cloud Wallet(cPCM). After successfully establishing a secure connection, then bi-directional synchronization MUST be triggered by using DIDComm v2 messages. A DIDComm v2 protocol is provided an documented for each use case of the cPCM (e.g., list VCs) NFC [IDM.PCM.E1.00070] Scan NFC A user MUST be able to scan an active NFC tag which can contain W3C VC/VP or Connection Invitations. The App MUST successfully process that. [IDM.PCM.E1.00071] Write NFC A user MUST be able to write an NFC tag which can contain W3C VC/VP or Connection Invitations. Another PCM on a mobile device MUST accept that presentation. SIOP Login Support [IDM.PCM.E1.00072] SIOP Login Support The cPCM MUST implement a function to process SIOP requests [DID SIOP] in the role of the Self- Issued OpenID Provider (SIOP). Applications (RPs (Relying Parties) in SIOP terminology) can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response. App Settings Configuration (personalization) - Verification [IDM.PCM.E1.00073] Configure cloud wallet linking When users are authenticated, the PCM MUST enable the users to configure secure connection(management link) to Cloud wallet. Ledger Selection - Verification [IDM.PCM.E1.00074] Select Ledger The PCM MUST not be enabled to select compatible Ledgers from the PCM GUI. The selection is pre-configured from a list of supported ledgers during the build process. Mediator Selection - Verification [IDM.PCM.E1.00075] Select Mediator The PCM MUST be able to work with different Mediators by using the DID Document, without recompiling the app. Cloud Wallet Management - Verification [IDM.PCM.E1.00076] Remote controller of the Cloud PCM (cPCM) The PCM user MUST be able to control the basic functions of the Cloud PCM(cPCM) such as Consent management, Connection Acceptance, Presentation Allowance, Issuing and Credential management. When users are authenticated and secure management connection is established with cPCM, then the users must be able to consent and access to existing documents. [IDM.PCM.E1.00077] Plugin Management The plugin management of the cPCM MUST be supported in the App. It MUST be possible to use the plugins, configured and enable/disable them remotely. The remote protocol MUST be used to request from plugins a token, present that token to verifiers or holders. All other standard functionality like issuing of credentials, consent etc. which the plugin framework of the cPCM offers, must be supported as well. Appendix A: Glossary For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO] Appendix B: Consent Management The flows are just for example. Flow optimizations can be proposed. Flow 1: External Actor requests Access to Protected API Flow 2: External Actor gives Access to protected Resources Appendix C: Personal Credential Manager Layering overview","title":"Personal Credential Manager Extension 1"},{"location":"pcme1/pcme1/#software-requirements-specification-for-gaia-x-federation-services-personal-credential-manager-extension-1-idmpcme1","text":"Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA","title":"Software Requirements Specification for Gaia-X Federation Services Personal Credential Manager Extension 1 IDM.PCM.E1"},{"location":"pcme1/pcme1/#1-introduction","text":"","title":"1  Introduction"},{"location":"pcme1/pcme1/#11-document-purpose","text":"","title":"1.1  Document Purpose"},{"location":"pcme1/pcme1/#12-product-scope","text":"","title":"1.2  Product Scope"},{"location":"pcme1/pcme1/#13-definitions-acronyms-and-abbreviations","text":"","title":"1.3  Definitions, Acronyms and Abbreviations"},{"location":"pcme1/pcme1/#14-references","text":"","title":"1.4  References"},{"location":"pcme1/pcme1/#15-document-overview","text":"","title":"1.5  Document Overview"},{"location":"pcme1/pcme1/#2-product-overview","text":"","title":"2  Product Overview"},{"location":"pcme1/pcme1/#21-product-perspective","text":"","title":"2.1  Product Perspective"},{"location":"pcme1/pcme1/#22-product-functions","text":"","title":"2.2  Product Functions"},{"location":"pcme1/pcme1/#23-product-constraints","text":"","title":"2.3  Product Constraints"},{"location":"pcme1/pcme1/#24-user-classes-and-characteristics","text":"","title":"2.4  User Classes and Characteristics"},{"location":"pcme1/pcme1/#25-operating-environment","text":"","title":"2.5  Operating Environment"},{"location":"pcme1/pcme1/#26-user-documentation","text":"","title":"2.6  User Documentation"},{"location":"pcme1/pcme1/#27-assumptions-and-dependencies","text":"","title":"2.7  Assumptions and Dependencies"},{"location":"pcme1/pcme1/#28-apportioning-of-requirements","text":"","title":"2.8  Apportioning of Requirements"},{"location":"pcme1/pcme1/#3-requirements","text":"","title":"3  Requirements"},{"location":"pcme1/pcme1/#31-external-interfaces","text":"","title":"3.1  External Interfaces"},{"location":"pcme1/pcme1/#311-user-interfaces","text":"","title":"3.1.1  User Interfaces"},{"location":"pcme1/pcme1/#312-hardware-interfaces","text":"","title":"3.1.2  Hardware Interfaces"},{"location":"pcme1/pcme1/#313-software-interfaces","text":"","title":"3.1.3  Software Interfaces"},{"location":"pcme1/pcme1/#314-communications-interfaces","text":"","title":"3.1.4  Communications Interfaces"},{"location":"pcme1/pcme1/#32-functional","text":"","title":"3.2  Functional"},{"location":"pcme1/pcme1/#321-managing-connections","text":"","title":"3.2.1  Managing Connections"},{"location":"pcme1/pcme1/#322-managing-credentials","text":"","title":"3.2.2  Managing Credentials"},{"location":"pcme1/pcme1/#323-wallet-backup","text":"","title":"3.2.3  Wallet Backup"},{"location":"pcme1/pcme1/#324-credential-wallet-importingexporting","text":"","title":"3.2.4  Credential Wallet Importing/Exporting"},{"location":"pcme1/pcme1/#325-didcomm-login-support","text":"","title":"3.2.5  DIDComm Login Support"},{"location":"pcme1/pcme1/#326-nfc-scanning-did-input","text":"","title":"3.2.6  NFC Scanning (DID Input)"},{"location":"pcme1/pcme1/#327-siop-login","text":"","title":"3.2.7  SIOP Login"},{"location":"pcme1/pcme1/#328-app-settings-configuration-personalization","text":"","title":"3.2.8  App Settings Configuration (personalization)"},{"location":"pcme1/pcme1/#329-ledger-selection","text":"","title":"3.2.9  Ledger Selection"},{"location":"pcme1/pcme1/#3210-mediator-selection","text":"","title":"3.2.10 Mediator Selection"},{"location":"pcme1/pcme1/#3211-did-document-service-endpoint-support","text":"","title":"3.2.11 DID Document Service Endpoint Support"},{"location":"pcme1/pcme1/#3212-cloud-wallet-management","text":"","title":"3.2.12 Cloud wallet management"},{"location":"pcme1/pcme1/#33-other-nonfunctional-requirements","text":"","title":"3.3  Other Nonfunctional Requirements"},{"location":"pcme1/pcme1/#331-http-requirements","text":"","title":"3.3.1  HTTP Requirements"},{"location":"pcme1/pcme1/#332-logging-requirements","text":"","title":"3.3.2  Logging Requirements"},{"location":"pcme1/pcme1/#333-security-requirements","text":"","title":"3.3.3  Security Requirements"},{"location":"pcme1/pcme1/#334-safety-requirements","text":"","title":"3.3.4  Safety Requirements"},{"location":"pcme1/pcme1/#335-security-requirements","text":"","title":"3.3.5  Security Requirements"},{"location":"pcme1/pcme1/#336-software-quality-attributes","text":"","title":"3.3.6  Software Quality Attributes"},{"location":"pcme1/pcme1/#337-business-rules","text":"","title":"3.3.7  Business Rules"},{"location":"pcme1/pcme1/#34-compliance","text":"","title":"3.4  Compliance"},{"location":"pcme1/pcme1/#35-design-and-implementation","text":"","title":"3.5  Design and Implementation"},{"location":"pcme1/pcme1/#351-installation","text":"","title":"3.5.1  Installation"},{"location":"pcme1/pcme1/#352-distribution","text":"","title":"3.5.2  Distribution"},{"location":"pcme1/pcme1/#353-usability","text":"","title":"3.5.3  Usability"},{"location":"pcme1/pcme1/#354-maintainability","text":"","title":"3.5.4  Maintainability"},{"location":"pcme1/pcme1/#355-portability","text":"","title":"3.5.5  Portability"},{"location":"pcme1/pcme1/#356-interoperability","text":"","title":"3.5.6  Interoperability"},{"location":"pcme1/pcme1/#4-system-features","text":"","title":"4  System Features"},{"location":"pcme1/pcme1/#41-managing-connections","text":"","title":"4.1  Managing Connections"},{"location":"pcme1/pcme1/#42-managing-credentials","text":"","title":"4.2  Managing Credentials"},{"location":"pcme1/pcme1/#43-wallet-backup","text":"","title":"4.3  Wallet Backup"},{"location":"pcme1/pcme1/#44-credential-wallet-importingexporting","text":"","title":"4.4  Credential Wallet Importing/Exporting"},{"location":"pcme1/pcme1/#45-didcomm-login-support","text":"","title":"4.5  DIDComm Login support"},{"location":"pcme1/pcme1/#46-nfc-scanning-did-input","text":"","title":"4.6  NFC Scanning (DID Input)"},{"location":"pcme1/pcme1/#47-siop-login","text":"","title":"4.7  SIOP Login"},{"location":"pcme1/pcme1/#48-app-settings-configuration-personalization","text":"","title":"4.8  App Settings Configuration (personalization)"},{"location":"pcme1/pcme1/#49-ledger-selection","text":"","title":"4.9  Ledger Selection"},{"location":"pcme1/pcme1/#410-smartphone-application","text":"","title":"4.10 Smartphone Application"},{"location":"pcme1/pcme1/#5-verification","text":"","title":"5  Verification"},{"location":"pcme1/pcme1/#51-core-verification-requirements","text":"","title":"5.1  Core Verification Requirements"},{"location":"pcme1/pcme1/#52-functionality-acceptance-criteria","text":"","title":"5.2  Functionality Acceptance Criteria"},{"location":"pcme1/pcme1/#521-connections","text":"","title":"5.2.1  Connections"},{"location":"pcme1/pcme1/#522-managing-credentials","text":"","title":"5.2.2  Managing credentials"},{"location":"pcme1/pcme1/#523-credential-wallet-synchronization","text":"","title":"5.2.3  Credential Wallet synchronization"},{"location":"pcme1/pcme1/#524-nfc","text":"","title":"5.2.4  NFC"},{"location":"pcme1/pcme1/#525-siop-login-support","text":"","title":"5.2.5  SIOP Login Support"},{"location":"pcme1/pcme1/#526-app-settings-configuration-personalization","text":"","title":"5.2.6  App Settings Configuration (personalization)"},{"location":"pcme1/pcme1/#527-ledger-selection","text":"","title":"5.2.7  Ledger Selection"},{"location":"pcme1/pcme1/#528-mediator-selection","text":"","title":"5.2.8  Mediator Selection"},{"location":"pcme1/pcme1/#529-cloud-wallet-management","text":"Appendix A: Glossary Appendix B: Consent Management Appendix C: Personal Credential Manager Layering overview","title":"5.2.9  Cloud Wallet Management"},{"location":"pcme1/pcme1/#list-of-figures","text":"Figure 1: Personal Credentials Manager. Layering overview (s. appendix C) Figure 2: Personal Credentials Manager: Component View","title":"List of Figures"},{"location":"pcme1/pcme1/#list-of-tables","text":"Table 1: References Table 2: User Classes and Characteristics Table 3: Apportioning of Requirements Table 4: Functional Requirements Connection Management Table 5: Functional Requirements Credential Management Table 6: Functional Requirements Wallet Backup Table 7: Functional Requirements Credential Wallet Importing/Exporting Table 8: Functional Requirements DIDComm Login support Table 9: Functional Requirements NFC Scanning (DID Input) Table 10: Functional Requirements SIOP Login Table 11: Functional Requirements App Settings Configuration (personalization) Table 12: Functional Requirements Ledger Selection","title":"List of Tables"},{"location":"pcme1/pcme1/#introduction","text":"To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] and [PRD].","title":"Introduction"},{"location":"pcme1/pcme1/#document-purpose","text":"The purpose of the document is to specify the requirements of the Identity Management and Trust Subcomponent \"Personal Credential Manager\" with the intention of a European wide public tender for implementing this software. Main audience for this document is attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide a credential manager application to be used by natural persons to participate in the Gaia-X trust structure.","title":"Document Purpose"},{"location":"pcme1/pcme1/#product-scope","text":"The purpose of this product is to provide all necessary components for the self-sovereign administration of the digital identity of a principal in the Gaia-X context on a mobile device. The Personal Credential Manager enables a natural person to act as a principal of an organization within the SSI-based Gaia-X ecosystem in a privacy-preserving, trustful and secure way. This comprises the following main functionalities: AIP 2.0 Support Reception and management of W3C verifiable credentials Presenting W3C and AIP 2.0 Verifiable Presentations to other parties in a proved manner Secure storage and management of respective secrets Remote Management of the PCM Cloud Solution Support of the Cloud PCM functionality Enhancements in QR Code Support Reading and Presentation Extension of the Personal Credential Manager must be developed as additional features of the existing smartphone-based application for Android and iPhone platforms. Furthermore, the scope includes the provision of the developed software in a usable format for end users including the respective distribution channels (e.g., App Stores). If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams.","title":"Product Scope"},{"location":"pcme1/pcme1/#definitions-acronyms-and-abbreviations","text":"All requirements from other documents are referenced by [IDM.\\<document-id>.XXXXX] as defined in the chapter \"Methodology\" in the document [IDM.AO].","title":"Definitions, Acronyms and Abbreviations"},{"location":"pcme1/pcme1/#references","text":"Concept Source Status Hyperledger Aries Concepts (AIP2.0) GitHub 03-17-2023 Specflow (Getting Started with BDD) Specflow 03-18-2023 Cryptographic Key Length Recommendation (CryptoLen) KeyLength 03-18-2023 DIDComm Messaging (Daniel Hardman) Identity Foundation 03-18-2023 OpenID Self-Issued OpenID Connect Provider DID OpenID - FIPS 140-2 (Federal Information Processing Standard) Wikipedia 03-17-2023 Gaia-X WP1 (Architecture Overview) Refer to \"annex_IDM.AO\" (Base of functional specification) - GXFS Organization Credential Manager W-Stack Refer to \"annex_IDM.OCM.W-STACK\" - Gaia-X Federation Service Non-functional Requirements (NF.SPBD) Refer to annex \"GXFS_Nonfunctional_Requirements_SPBD\" - OpenID for Verifiable Credential Issuance (OID4VC) OpenID 03-17-2023 OpenID for Verifiable Presentations (OID4VP) OpenID 03-17-2023 Gaia-X Policy Rules (PRD) Gaia-X Docs - SOG-IS Crypto Evaluation Scheme (SOG-IS) SOG-IS Document 03-18-2023 Gaia-X Architecture Document (TAD) Gaia-X Docs 03-17-2023 Table 1: References","title":"References"},{"location":"pcme1/pcme1/#document-overview","text":"The document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the additional system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.EX.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [RFC 2119], are written in capital letters (see also [IDM.AO] - Methodology).","title":"Document Overview"},{"location":"pcme1/pcme1/#product-overview","text":"","title":"Product Overview"},{"location":"pcme1/pcme1/#product-perspective","text":"The personal credential manager is used by a natural person. Within the Gaia-X terminology, such a natural person is named principal . The principal utilizes the PCM in the respective form factor to store VCs issued to her/him as well as to prove the statements necessary to obtain a service. The PCM must extend the support of following overall processes: DIDComm Authentication as the generic way to authenticate a principal Secure backup and restore by file SIOP DID as a method to implement SSI based Login Methods [DID SIOP] Consent Management OIDC4VP for presenting Credentials OIDC4VC to receive Credentials Remote Management and Usage of cPCM DID Document Based Protocol Selection AIP 1.0 Protocol AIP 2.0 Protocol [AIP2.0] Bi-directional synchronization with Cloud Personal Credential Wallet Train Selection","title":"Product Perspective"},{"location":"pcme1/pcme1/#the-existing-code-base-must-be-reused-and-further-improved-other-microservices-may-have-different-languages-and-architectures","text":"","title":"&gt; The existing code base MUST be reused and further improved. Other microservices MAY have different languages and architectures."},{"location":"pcme1/pcme1/#product-functions","text":"Personal Credentials Manager (PCM) enables end-users to interact with the DID-based ecosystem in a privacy-preserving way. PCM acts as a user representative tool which is securely holding the acquired distributed identities and identity attributes and provides the technical means to selectively disclose the aforementioned attributes for authentication and service consumption. The following represents the high-level functional architecture of the PCM. Figure 1: Personal Credentials Manager. Layering overview (s. appendix C) As presented in the PCM big picture layering overview, PCM consists of different components which effectively comprise the following layers: The front-end layer PCM Core (Wallet) layer as well as the Mediator (Relay) layer The front-end layer is comprised of the following features and components: End User Authentication Graphical User Interface (GUI) Local Input Interfaces End User Authentication component provides for the implementation of secure user authentication policies which can include but are not limited to fingerprint authentication in the smart phone case, PIN, password, etc. The GUI component enables end users to interact with the PCM and use the PCM functions. Local Input Interfaces comprise QR-code processing, bootstrapping over Near Field Communication (NFC), etc., and by that provides communication initiation, direct, or peer-to-peer (contact) exchange as well as credentials presentation ensuring the direct proximity requirements. PCM Core (Wallet) layer consists of the following features and components: W3C VC synchronization with cPCM for offline Presentation Consent Management over cPCM Remote Management of cPCM Backup/Restore over cPCM Remote Control of the Cloud PCM by using a didcomm protocol over the websocket connection The Managing Credentials feature provides the functionality for receiving credentials issued by other participants, enabling the user to view and inspect his/her credentials, and the basic functionality for proofing credential attributes to other participants according to the SSI paradigm. The credential manager ensures that the user is always in control, which attributes are provided to which participant. It further enables to create and check proofs according to the SSI paradigm to, for example, achieve DIDComm or SIOP Login, etc. The Wallet Backup feature provides for the secure backup and restore capabilities of the obtained credentials and possibly the app settings. The automatic synchronization feature enables the users to configure a unique channel of communication between PCM and cPCM. Which enables the und users to synchronize W3C VC from PCM to cPCM and via versa. The figure below is the planned component structure which are a matter of this tender (derivations allowed from SW perspective):","title":"Product Functions"},{"location":"pcme1/pcme1/#figure-2-personal-credentials-manager-component-view","text":"The existing code base contains partially the components on this picture. In a planned software architecture for this tender all of these components MUST be considered for restructuring the code.","title":"&gt;Figure 2: Personal Credentials Manager: Component View"},{"location":"pcme1/pcme1/#product-constraints","text":"","title":"Product Constraints"},{"location":"pcme1/pcme1/#idmpcme100000-oid4vpvc-compatibility","text":"The PCM MUST support exchange over OID4VP protocol [OID4VP] and all other applicable standards needed for communication with the Organization Credential Manager and OCM W- Stack [IDM.OCM.W-STACK].","title":"[IDM.PCM.E1.00000] OID4VP/VC Compatibility"},{"location":"pcme1/pcme1/#idmpcme100001-aip-20-compatibility","text":"The PCM MUST support AIP 2.0 as specified in Aries Interop Profile [AIP2.0].","title":"[IDM.PCM.E1.00001] AIP 2.0 Compatibility"},{"location":"pcme1/pcme1/#idmpcme100002-offline-presentation","text":"All W3C credentials in the wallet (including the synced one) MUST be available for the offline presentation. \"Offline\" is in this case defined as \"No third Party involved\" which is able to track the data. Means the presentation MUST be possible by QR Code, NFC or Bluetooth peer to peer from one Smartphone to the other. This includes a capability to identify trusted verifiers and issuers on the smartphone before presentation e.g., by using Bloom Filters.","title":"[IDM.PCM.E1.00002] Offline Presentation"},{"location":"pcme1/pcme1/#idmpcme100003-cloud-pcm","text":"The Cloud PCM (also part oft his tender) MUST be used as Integration Layer and as remote backend to store and synchronize W3C credentials including the remote management/control of the cPCM agents and backup storage. The cPCM connection MUST NOT implement Aries Protocols or Aries RFCs, because the PCM and cPCM connection acts as private connection of the PCM Smartphone App with its private backend (cPCM).","title":"[IDM.PCM.E1.00003] Cloud PCM"},{"location":"pcme1/pcme1/#user-classes-and-characteristics","text":"User Class Description Expertise Privilege Level Product Usage Personal User The person in possession of the personal credential manager using all functionality of the product Low High Frontend Table 2: User Classes and Characteristics","title":"User Classes and Characteristics"},{"location":"pcme1/pcme1/#operating-environment","text":"Please refer to [TDR] for further binding requirements regarding the operating environment.","title":"Operating Environment"},{"location":"pcme1/pcme1/#idmpcme100003-operating-environments","text":"The product needs to support different operating environments. Android operating system versions which are still supported by Google (as of now > Android version 9) MUST be supported. iOS operating system versions which are still supported by Apple MUST be supported.","title":"[IDM.PCM.E1.00003] Operating Environments"},{"location":"pcme1/pcme1/#user-documentation","text":"Please refer to [TDR] for further requirements regarding documentation.","title":"User Documentation"},{"location":"pcme1/pcme1/#idmpcme100004-participant-administration-documentation","text":"The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the product from source code","title":"[IDM.PCM.E1.00004] Participant Administration Documentation"},{"location":"pcme1/pcme1/#idmpcme100005-participant-documentation","text":"The documentation MUST contain: Short Software Description/Usage Usage Guide GDPR Design Decisions Security Concept Operations Concept FAQ Keyword Directory","title":"[IDM.PCM.E1.00005] Participant Documentation"},{"location":"pcme1/pcme1/#assumptions-and-dependencies","text":"An understanding of the overall Gaia-X architecture and philosophy is necessary. Please refer to [TAD] and [PRD].","title":"Assumptions and Dependencies"},{"location":"pcme1/pcme1/#apportioning-of-requirements","text":"Feature Priority OIDV4VP/VC support 1 AIP 2.0 support 1 Cloud wallet synchronization 1 QR generation 1 NFC tag generation 1 NFC Scanning (DID Input) 1 SIOP Login 1 cPCM Remote Control 1 Consent Management 1 Table 3: Apportioning of Requirements","title":"Apportioning of Requirements"},{"location":"pcme1/pcme1/#requirements","text":"Further binding requirements can be found in [TDR].","title":"Requirements"},{"location":"pcme1/pcme1/#external-interfaces","text":"","title":"External Interfaces"},{"location":"pcme1/pcme1/#user-interfaces","text":"","title":"User Interfaces"},{"location":"pcme1/pcme1/#idmpcme100006-smartphone-gui","text":"The PCM MUST provide a GUI for the PCM user to support the enhancements for the Cloud PCM. This requires support for Consent Management, as well for Notifications and the support of W3C credentials provided by the OCM W-Stack [IDM.OCM.W-STACK].","title":"[IDM.PCM.E1.00006] Smartphone GUI"},{"location":"pcme1/pcme1/#hardware-interfaces","text":"","title":"Hardware Interfaces"},{"location":"pcme1/pcme1/#idmpcme100007-camera","text":"The PCM MUST be able to use the Smartphone's camera to scan QR-Codes for W3C credentials and OpenID4VC issuing Proposals [OID4VC].","title":"[IDM.PCM.E1.00007] Camera"},{"location":"pcme1/pcme1/#idmpcme100008-nfc","text":"The PCM must be able to use the Smartphone's NFC communication to receive DIDComm invitation messages, OpenID4VC Issuing Proposals and W3C Credentials.","title":"[IDM.PCM.E1.00008] NFC"},{"location":"pcme1/pcme1/#software-interfaces","text":"","title":"Software Interfaces"},{"location":"pcme1/pcme1/#idmpcme100009-secure-storage","text":"The PCM implementation MUST be able to use secure storage (internal storage, encrypted storage, dedicated key storage) by using enclaves provided by the target platform/smartphone operating system for storing PCM data within the smartphone. Especially for key exchange between the Cloud PCM and the PCM App is this required to protect the keys safely. It's highly recommended to use asymmetric encryption protocols by utilizing internal enclaves to exchange the keys (e.g., CMS or other schemes)","title":"[IDM.PCM.E1.00009] Secure Storage"},{"location":"pcme1/pcme1/#communications-interfaces","text":"","title":"Communications Interfaces"},{"location":"pcme1/pcme1/#idmpcme100010-didcomm-v2-interface","text":"The DIDComm interface MUST be provided to send DIDComm messages to be processed by the PCM and the PCM Cloud.","title":"[IDM.PCM.E1.00010] DIDComm v2 Interface"},{"location":"pcme1/pcme1/#idmpcme100011-nfc","text":"The PCM App MUST support the exchange of W3C VCs/VPs and Connection invitations by using NFC (reading and presentation).","title":"[IDM.PCM.E1.00011] NFC"},{"location":"pcme1/pcme1/#idmpcme100011-local-siop-endpoint","text":"The PCM MUST provide an endpoint for SIOP requests [DID SIOP]. Within the SIOP protocol, the PCM implements the role of the Self-Issued OpenID Provider (SIOP). Applications (PRs (Relying Parties) in SIOP terminology can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response. The SIOP process MUST be triggerable via an URL scheme which is registered during the App Installation (e.g., gxfspcm://siop?...)","title":"[IDM.PCM.E1.00011] Local SIOP Endpoint"},{"location":"pcme1/pcme1/#idmpcme100012-personal-wallet-and-secrets-synchronization","text":"Given that PCM users for security reasons import or export their Personal Wallet and secrets, an interface MUST be provided so that Synchronization between PCM and Cloud Wallet (cPCM) can be established by using web socket protocols. This feature is dedicated to W3Cs and is not relevant for Aries based credentials. All secrets relevant for presentation of W3C credentials MUST be transferred encrypted and in an approach that the private key isn't transmitted at once and just \"activatable\" by user knowledge. For instance, by using key derivation functions.","title":"[IDM.PCM.E1.00012] Personal Wallet and Secrets Synchronization"},{"location":"pcme1/pcme1/#idmpcme100013-mediator-selection-based-on-did-document","text":"PCM needs to be able to find the correct mediator, based on the record in the DID document as well the other endpoints for communication MUST be discovered by the DID document. All endpoint types MUST be configurable with the following format by enhancing the W3C spec [1]: > { > id: {idName} > type: {typeName}, > accept: \\[\"didcomm/v2\",\"didcomm/v1\",{otherProtocols}\\], > serviceEndpoint:\\[\"https://...\"\\] > }","title":"[IDM.PCM.E1.00013] Mediator selection based on DID document"},{"location":"pcme1/pcme1/#1-httpswwww3orgtrdid-coreexample-usage-of-the-service-property","text":"","title":"[1] [https://www.w3.org/TR/did-core/#example-usage-of-the-service-property]"},{"location":"pcme1/pcme1/#idmpcme100014-cpcm-connection","text":"The mobile application needs a secure communication web socket channel to the PCM Cloud to synchronize Credentials, receiving Consent Notifications, Credential Requests etc. The application MUST implement for this purpose WebSockets and didcomm v2. The message protocol provided by the cPCM MUST be implemented and documented as \"RFC\" similar to Hyperledger Aries RFC documentation format [2].","title":"[IDM.PCM.E1.00014] cPCM Connection"},{"location":"pcme1/pcme1/#2-httpsgithubcomhyperledgeraries-rfcsblobmainconcepts0074-didcomm-best-practicesreadmemdrfc-naming","text":"","title":"[2] [https://github.com/hyperledger/aries-rfcs/blob/main/concepts/0074-didcomm-best-practices/README.md#rfc-naming]"},{"location":"pcme1/pcme1/#functional","text":"","title":"Functional"},{"location":"pcme1/pcme1/#managing-connections","text":"","title":"Managing Connections"},{"location":"pcme1/pcme1/#idmpcme100015-connection-creation-via-invitation","text":"DIDComm connection requests can be provided to the PCM user via QR-Code, Text input (URL), NFC (Out of band messages according to DIDComm Messaging specification [DIDComm]), and by regular DIDComm messages received. Especially for the device pairing between PCM and Cloud OCM MUST be process described and developed (e.g., by a special invitation protocol)","title":"[IDM.PCM.E1.00015] Connection creation via invitation"},{"location":"pcme1/pcme1/#managing-credentials","text":"","title":"Managing Credentials"},{"location":"pcme1/pcme1/#idmpcme100016-receive-a-verifiable-credential-vc","text":"The PCM MUST be able to receive VCs according to AIP 2.0 and OpenId4VC Standards for the underlying issuing protocols. The AIP 1.0 functionality MUST remain and still be supported in the App.","title":"[IDM.PCM.E1.00016] Receive a Verifiable Credential (VC)"},{"location":"pcme1/pcme1/#idmpcme100017-answer-request-for-verifiable-presentation-vp","text":"The PCM MUST be able to answer presentation requests according to AIP 2.0 and OpenId4VC Standards for the underlying issuing protocols. The AIP 1.0 functionality MUST remain and still be supported in the App.","title":"[IDM.PCM.E1.00017] Answer Request for Verifiable Presentation (VP)"},{"location":"pcme1/pcme1/#idmpcme100018-display-history-of-presenting-verifiable-presentations-vps-to-other-participants","text":"The PCM user can view detailed information about the history of showing/proofing identity information to other participants. For each run of the Proof protocol, the information shown MUST include all information contained in the VP shown to a verifier including the remote one from the cPCM, to which verifier it has been shown, and transaction date/time.","title":"[IDM.PCM.E1.00018] Display history of presenting verifiable Presentations (VPs) to other participants"},{"location":"pcme1/pcme1/#wallet-backup","text":"","title":"Wallet Backup"},{"location":"pcme1/pcme1/#idmpcme100019-restore-backup","text":"The PCM MUST provide a function to restore a backup containing all information stored in the PCM. The Backup/Restore format MUST be compatible to guarantee PCM App interoperability between form factors and between different providers or Smartphone Applications and Cloud Wallet (cPCM). This MUST be for W3C credentials an encrypted JSON-LD file or for Aries Credentials just a file.","title":"[IDM.PCM.E1.00019] Restore Backup"},{"location":"pcme1/pcme1/#credential-wallet-importingexporting","text":"","title":"Credential Wallet Importing/Exporting"},{"location":"pcme1/pcme1/#idmpcme100020-sync-wallets","text":"The PCM MUST provide a functionality to synchronize different personal cloud wallet instances (Cloud PCM), e.g., synchronize a cloud wallet (cPCM) with a smartphone wallet. Secure methods for Importing the PCM Secrets MUST be provided. The synchronization MUST consist of W3C Credentials, Aries credentials are out of scope for syncing.","title":"[IDM.PCM.E1.00020] Sync Wallets"},{"location":"pcme1/pcme1/#didcomm-login-support","text":"","title":"DIDComm Login Support"},{"location":"pcme1/pcme1/#idmpcme100021-didcomm-login-support","text":"The PCM MUST support the Login via DIDComm by using the DIDComm Login protocol of the cPCM (no aries protocol, internal protocol of cPCM).","title":"[IDM.PCM.E1.00021] DIDComm Login Support"},{"location":"pcme1/pcme1/#nfc-scanning-did-input","text":"","title":"NFC Scanning (DID Input)"},{"location":"pcme1/pcme1/#idmpcme100024-nfc","text":"The PCM MUST support scanning of W3C Credentials and Invitations via NFC. The Presentation of Credentials and Presentations MUST be provided via NFC as well.","title":"[IDM.PCM.E1.00024] NFC"},{"location":"pcme1/pcme1/#siop-login","text":"","title":"SIOP Login"},{"location":"pcme1/pcme1/#idmpcme100022-siop-login-support","text":"The PCM MUST implement a function to process SIOP requests [DID SIOP] in the role of the Self- Issued OpenID Provider (SIOP). Applications (RPs (Relying Parties) in SIOP terminology) can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response.","title":"[IDM.PCM.E1.00022] SIOP Login Support"},{"location":"pcme1/pcme1/#app-settings-configuration-personalization","text":"","title":"App Settings Configuration (personalization)"},{"location":"pcme1/pcme1/#idmpcme100023-configure-cloud-wallet-linking","text":"The PCM MUST enable the user to configure a secure connection for data synchronization by realizing a prior pairing to the Cloud PCM via DIDComm.","title":"[IDM.PCM.E1.00023] Configure Cloud wallet linking"},{"location":"pcme1/pcme1/#ledger-selection","text":"","title":"Ledger Selection"},{"location":"pcme1/pcme1/#idmpcme100024-select-ledger","text":"The PCM MUST NOT be enabled to select compatible Ledgers. The selection is pre-configured from a list of supported ledgers and all other Information MUST be extracted from DID Documents.","title":"[IDM.PCM.E1.00024] Select Ledger"},{"location":"pcme1/pcme1/#mediator-selection","text":"","title":"Mediator Selection"},{"location":"pcme1/pcme1/#idmpcme100025-select-mediator","text":"The mediator MUST be selected by using the DID Document (resolved over DID) to find the right endpoints.","title":"[IDM.PCM.E1.00025] Select Mediator"},{"location":"pcme1/pcme1/#did-document-service-endpoint-support","text":"","title":"DID Document Service Endpoint Support"},{"location":"pcme1/pcme1/#idmpcme100026-service-endpoint-usage","text":"The DID Document Service Endpoints MUST be used for the PCM functionality, and the formats and accept attributes MUST be considered next to the key material provided by the document.","title":"[IDM.PCM.E1.00026] Service Endpoint Usage"},{"location":"pcme1/pcme1/#cloud-wallet-management","text":"","title":"Cloud wallet management"},{"location":"pcme1/pcme1/#idmpcme100027-remote-controller-of-the-cloud-pcm","text":"The PCM user MUST be able to control the basic functions of the Cloud PCM (cPCM) such as Consent management and Credential management. The proofs requested by an external actor, can be consented by the user by using the PCM. A Diagram for the Consent Management is in Appendix B and MUST be realized on SSI based W3C mechanisms.","title":"[IDM.PCM.E1.00027] Remote controller of the Cloud PCM"},{"location":"pcme1/pcme1/#idmpcme100028-selective-disclosure-jwt","text":"The component MUST support Selective Disclosure JWT described in the specification [3].","title":"[IDM.PCM.E1.00028] Selective Disclosure JWT"},{"location":"pcme1/pcme1/#3-httpsdatatrackerietforgdocdraft-ietf-oauth-selective-disclosure-jwt","text":"","title":"[3] [https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/]"},{"location":"pcme1/pcme1/#other-nonfunctional-requirements","text":"","title":"Other Nonfunctional Requirements"},{"location":"pcme1/pcme1/#idmpcme100029-architecture-changes","text":"All Architecture Changes MUST be aligned with the Principal before implementation.","title":"[IDM.PCM.E1.00029] Architecture Changes"},{"location":"pcme1/pcme1/#http-requirements","text":"","title":"HTTP Requirements"},{"location":"pcme1/pcme1/#idmpcme100030-https","text":"All HTTP communication MUST be protected by state-of-the-art transport security algorithms such as TLS 1.2 / TLS 1.3 (all protocol version numbers may be superseded by upcoming standards). Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system.","title":"[IDM.PCM.E1.00030] HTTPS"},{"location":"pcme1/pcme1/#idmpcme100031-http-protocol-definitions","text":"All HTTP Endpoints MUST follow RFC 7231 [4] and RFC 5789 [5], but it MAY be chosen what of the protocols is necessary to realize the functionality. For problem reports the RFC7807 [6] MUST be used in combination with Standard HTTP Error Codes.","title":"[IDM.PCM.E1.00031] HTTP Protocol Definitions"},{"location":"pcme1/pcme1/#4-httpstoolsietforghtmlrfc7231","text":"","title":"[4] [https://tools.ietf.org/html/rfc7231]"},{"location":"pcme1/pcme1/#5-httpstoolsietforghtmlrfc5789","text":"","title":"[5] [https://tools.ietf.org/html/rfc5789]"},{"location":"pcme1/pcme1/#6-httpstoolsietforghtmlrfc7807","text":"","title":"[6] [https://tools.ietf.org/html/rfc7807]"},{"location":"pcme1/pcme1/#logging-requirements","text":"","title":"Logging Requirements"},{"location":"pcme1/pcme1/#idmpcme100032-data-minimization","text":"The data minimization principle is expressed in Article 5(1)(c) of the GDPR and Article 4(1)(c) of Regulation (EU) 2018/1725, which provide that personal data must be \\\"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed\\\". The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of the following elements: (a) node\\'s identification (b) message identification (c) message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review.","title":"[IDM.PCM.E1.00032] Data Minimization"},{"location":"pcme1/pcme1/#security-requirements","text":"","title":"Security Requirements"},{"location":"pcme1/pcme1/#general-security-requirements","text":"Each Gaia-X Federation Service SHALL meet the requirements stated in the document \"Specification of non-functional Requirements Security and Privacy by Design\" [NF.SPBD]. Federation Services specific requirements will be documented in the next chapter.","title":"General Security Requirements"},{"location":"pcme1/pcme1/#service-specific-security-requirements","text":"This chapter will describe the service specific requirements, which will extend the requirements defined in the chapter above.","title":"Service Specific Security Requirements"},{"location":"pcme1/pcme1/#idmpcme100033-secure-user-authentication","text":"To ensure that only allowed entities can access the PCM authentication methods MUST be implemented to grant access to the PCM. The PCM MUST provide a method for securing user login with at least two authentication factors.","title":"[IDM.PCM.E1.00033] Secure user authentication"},{"location":"pcme1/pcme1/#idmpcme100034-multimodal-biometric-authentication","text":"The PCM MAY provide (multimodal) biometric authentication methods to improve the usability of the PCM.","title":"[IDM.PCM.E1.00034] Multimodal biometric authentication"},{"location":"pcme1/pcme1/#idmpcme100035-protection-of-secrets-wallet-and-security-for-the-restore-process","text":"The PCM secrets MUST be stored and processed securely. There MUST be additional security procedures in place to guarantee that the secret key can be recovered when the holder requires it, even in case the holder himself has lost access to his unlock key. State of the art methods that MAY be applied are for example Shamir's Secret Sharing.","title":"[IDM.PCM.E1.00035] Protection of Secrets (Wallet) and Security for the Restore process"},{"location":"pcme1/pcme1/#idmpcme100036-secure-communication-between-frontend-and-cloud-agentwallet","text":"The communication interface in case of the cloud agent/Wallet form factor must be protected according to the latest security standards.","title":"[IDM.PCM.E1.00036] Secure communication between frontend and cloud agent/wallet"},{"location":"pcme1/pcme1/#idmpcme100037-cryptographic-algorithms-and-cipher-suites","text":"Cryptographic algorithms and TLS cipher suites SHALL be chosen based on the recommendation from the German Federal Office for Information Security (BSI) or SOG-IS. These recommendations and the recommendations of other institutions and standardization organization are quite similar [7] [CryptoLen]. The recommendations can be found in the technical guidelines [8] TR 02102- 1 [TR02102-1] and TR 02102-2 [TR02102-2] or SOG-IS Agreed Cryptographic Mechanisms [9] [SOG- IS].","title":"[IDM.PCM.E1.00037] Cryptographic Algorithms and Cipher Suites"},{"location":"pcme1/pcme1/#7-see-httpswwwkeylengthcomen-for-a-comparison","text":"","title":"[7] See [https://www.keylength.com/en] for a comparison"},{"location":"pcme1/pcme1/#8-see-httpswwwbsibunddeenservice-navipublicationstechnicalguidelinestr02102tr02102_nodehtml-for-a-comparison","text":"","title":"[8] See [https://www.bsi.bund.de/EN/Service-Navi/Publications/TechnicalGuidelines/tr02102/tr02102_node.html] for a comparison"},{"location":"pcme1/pcme1/#9-see-httpswwwsogiseudocumentscccryptosogis-agreed-cryptographic-mechanisms-12pdf-for-a-comparison","text":"","title":"[9] See [https://www.sogis.eu/documents/cc/crypto/SOGIS-Agreed-Cryptographic-Mechanisms-1.2.pdf] for a comparison"},{"location":"pcme1/pcme1/#idmpcme100038-security-by-design","text":"The software security MUST be from the beginning a design principle. Means separation of concerns, different administrative roles, especially for private key material and separate access to the data MUST be covered from the first second. It MUST be described in the security concept, what are the different security risks of the product and how they are mitigated (e.g., by Threat Modeling Protocols)","title":"[IDM.PCM.E1.00038] Security by Design"},{"location":"pcme1/pcme1/#idmpcme100039-installation-of-critical-security-updates","text":"Node operators SHALL deploy security critical updates without undue delay.","title":"[IDM.PCM.E1.00039] Installation of Critical Security Updates"},{"location":"pcme1/pcme1/#idmpcme100040-avoid-http-request-smuggling","text":"To avoid Request Smuggling attacks, the product MUST implement a standard which handles this kind of attack by design, because the attack vector results in an insufficient implementation of the header handling. The chosen way to handle it MUST be shared with the Principal for further alignment with the other implementers of all other subcomponents within the GXFS project and MUST be described in the security concept.","title":"[IDM.PCM.E1.00040] Avoid HTTP Request Smuggling"},{"location":"pcme1/pcme1/#idmpcme100041-pentesting","text":"All parts of the product have to be pentested, at least for the following criteria: Unauthorized Access to the System MUST be tested Unauthorized Actions MUST be triggered without a user action All Interfaces MUST be tested It's RECOMMENDED to test more attack vectors and document it for the purpose to mitigate it in later versions.","title":"[IDM.PCM.E1.00041] Pentesting"},{"location":"pcme1/pcme1/#idmpcme100042-storage-of-secrets","text":"The storage of secret information such as private keys MUST take place in state-of-the-art secure environments to protect secret data confidentiality and integrity. Examples of this are Secure Enclaves, TPMs, HSM or Secure Vaults. In case (Personal) Agents are not equipped with a secure storage it MAY also be possible to store the secrets in a third party (e.g., Cloud) provider (e.g., Secure Wallet) that MUST provide overall the same level of security as the aforementioned methods.","title":"[IDM.PCM.E1.00042] Storage of Secrets"},{"location":"pcme1/pcme1/#idmpcme100043-secret-distribution-and-usage","text":"The product MUST ensure interoperability of cryptographic primitives and components by public standards and MUST use secure state of the art methods to create and import secrets into the secure storage, as well as performing cryptographic operations (e.g., encryption or digital signatures). For Key distribution, state of the art DKMS methods MUST be implemented.","title":"[IDM.PCM.E1.00043] Secret Distribution and Usage"},{"location":"pcme1/pcme1/#idmpcme100044-support-for-potential-requirements-for-secret-storages","text":"Devices that hold cryptographic information and perform cryptographic functions MUST be compliant with standard PKCS #11 or other comparable cryptography standards. Moreover, the products MUST be potentially eligible for a FIPS-140-2 or ETSI/Common Criteria certification with the minimum-security level necessary to operate securely in the Gaia-X ecosystem. Security Levels in FIPS-140-2 range from 1 to 4. Current HSM Cloud Service offerings (AWS, Azure, GCP) are Level 3 (Source: [FIPS]).","title":"[IDM.PCM.E1.00044] Support for Potential Requirements for Secret Storages"},{"location":"pcme1/pcme1/#idmpcme100045-special-availability-and-scalability-requirements-for-secret-storage-components","text":"Secret Storage components play a central role in storage, encryption and digital signing in the Gaia-X ecosystem, thus they can become a single point of failure for a Gaia-X participant, for example an organization. Therefore, methods and procedures to ensure the availability and scalability of the Secret Storage functionality MUST be implemented.","title":"[IDM.PCM.E1.00045] Special Availability and Scalability Requirements for Secret Storage Components"},{"location":"pcme1/pcme1/#safety-requirements","text":"","title":"Safety Requirements"},{"location":"pcme1/pcme1/#idmpcme100046-major-releases","text":"All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening.","title":"[IDM.PCM.E1.00046] Major Releases"},{"location":"pcme1/pcme1/#security-requirements_1","text":"","title":"Security Requirements"},{"location":"pcme1/pcme1/#idmpcme100047-cve-patches","text":"All software components MUST have applied CVE patches, which are available for major releases.","title":"[IDM.PCM.E1.00047] CVE Patches"},{"location":"pcme1/pcme1/#software-quality-attributes","text":"","title":"Software Quality Attributes"},{"location":"pcme1/pcme1/#idmpcme100048-software-quality-requirements","text":"All software components MUST be compliant to the requirements within the quality assurance repository [10]. This includes continuing testing, branch models which verify the code quality at check in time and automated behavior testing of all defined quality attributes.","title":"[IDM.PCM.E1.00048] Software Quality Requirements"},{"location":"pcme1/pcme1/#10-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesquality-assurance-issues","text":"","title":"[10] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues]"},{"location":"pcme1/pcme1/#business-rules","text":"","title":"Business Rules"},{"location":"pcme1/pcme1/#idmpcme100049-software-consistency","text":"The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc.","title":"[IDM.PCM.E1.00049] Software Consistency"},{"location":"pcme1/pcme1/#compliance","text":"","title":"Compliance"},{"location":"pcme1/pcme1/#idmpcme100050-gdpr-audit-logging","text":"All GDPR relevant access to personal relevant data MUST be logged for a later audit.","title":"[IDM.PCM.E1.00050] GDPR Audit Logging"},{"location":"pcme1/pcme1/#idmpcme100051-gdpr-data-processing","text":"If it is necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant personally identifiable data MUST be deleted after the processing, if applicable.","title":"[IDM.PCM.E1.00051] GDPR Data Processing"},{"location":"pcme1/pcme1/#design-and-implementation","text":"Please also refer to [TDR] for further requirements.","title":"Design and Implementation"},{"location":"pcme1/pcme1/#installation","text":"","title":"Installation"},{"location":"pcme1/pcme1/#idmpcme100052-ios-and-android-installation","text":"The product must be easily installable and comply with the installation requirements depending on the target platforms.","title":"[IDM.PCM.E1.00052] iOS and Android Installation"},{"location":"pcme1/pcme1/#distribution","text":"There are no dedicated distribution requirements for the PCM.","title":"Distribution"},{"location":"pcme1/pcme1/#usability","text":"","title":"Usability"},{"location":"pcme1/pcme1/#idmpcme100053-gui-usability","text":"GUI design MUST comply with common GUI recommendations for the target platforms.","title":"[IDM.PCM.E1.00053] GUI usability"},{"location":"pcme1/pcme1/#idmpcme100054-pcm-accessibility","text":"The product MUST comply with the accessibility requirements depending on the target platforms.","title":"[IDM.PCM.E1.00054] PCM accessibility"},{"location":"pcme1/pcme1/#idmpcme100055-internationalization-support","text":"The PCM MUST support internationalization. At least the following languages MUST be supported: English.","title":"[IDM.PCM.E1.00055] Internationalization Support"},{"location":"pcme1/pcme1/#maintainability","text":"","title":"Maintainability"},{"location":"pcme1/pcme1/#idmpcme100056-continuous-integration","text":"All tests MUST be coded in a continuous tool to ensure the software quality in a further development. All the necessary scripts and setups MUST be provided on the public code repository to make it possible for everyone to compile and execute the product.","title":"[IDM.PCM.E1.00056] Continuous Integration"},{"location":"pcme1/pcme1/#portability","text":"","title":"Portability"},{"location":"pcme1/pcme1/#idmpcme100057-app-portability","text":"The product MUST be portable to different devices, e.g., tablets. This includes as well lower end devices (Moto G3, Pixel 4a etc.) to support non-discriminatory all users without consideration of the purchasing power.","title":"[IDM.PCM.E1.00057] App Portability"},{"location":"pcme1/pcme1/#interoperability","text":"","title":"Interoperability"},{"location":"pcme1/pcme1/#idmpcme100058-interoperability-of-it-security-features-and-algorithms","text":"The following interoperability requirements of the respective IT security features and algorithms MUST be ensured across the system components: Interoperability of crypto algorithms and protocols (including the novel peer-reviewed ones through the established bodies and communities) Interoperability of secure secret transfer protocols (such as the holistic usage of PKCS#11 for HSM communication, etc.) Format interoperability of crypto material (such as the holistic usage of PKCS#12 for relevant cases)","title":"[IDM.PCM.E1.00058] Interoperability of IT security features and algorithms"},{"location":"pcme1/pcme1/#system-features","text":"","title":"System Features"},{"location":"pcme1/pcme1/#managing-connections-system-features","text":"Using this product, the user shall be enabled to manage his Gaia-X connections. Technically, connections are represented by DID-based connections to other Gaia-X participants. Connection data includes the contact DID, DID Document, DIDComm connection status data, and communication history (e.g., VPs exchanged). Via the PCM, the user must be able to establish DIDComm connections based on invitations, which can be input to the PCM by scanning QR-Codes, Text input (URL), NFC, and by regular DIDComm Messages. The following functions are required for connection management: Functional Requirement Functions - Connection creation via invitation Table 4: Functional Requirements Connection Management","title":"Managing Connections - System Features"},{"location":"pcme1/pcme1/#managing-credentials-system-features","text":"The product shall enable the user to manage his verifiable credentials (VCs). Other Gaia-X participants can issue VCs to the user in possession of the personal credential manager. The user must be enabled to inspect his VCs and to show/proof VC information via verifiable presentations (VPs) to other Gaia-X participants. Within the Gaia-X environment, persons in the role of Gaia-X principals need to be able to receive a VC onboarding them as a principal to an organization. Within the PCM, the function \"receive a VC\" can be used for this purpose. The following functions are required for management of VCs: Functional Requirement Functions - [Receive a Verifiable Credential (VC)] - [Answer Request for Identity Information (VP)] - [Display history of presenting identity information (VPs) to other participants] Table 5: Functional Requirements Credential Management","title":"Managing Credentials - System Features"},{"location":"pcme1/pcme1/#wallet-backup-system-features","text":"The product must provide the functionality to create backups of the information stored within the PCM. Backups must be stored in a secure way, so that only the PCM user, who created the backup, can restore the backup. Backups must contain the full status of the PCM. The following functions are required for backup: Functional Requirement Functions - [Restore Backup] Table 6: Functional Requirements Wallet Backup","title":"Wallet Backup - System Features"},{"location":"pcme1/pcme1/#credential-wallet-importingexporting-system-features","text":"To ensure interoperability between providers, applications and form factors, the PCM must implement a procedure to export and import personal wallet data and secret information. The following functions are required for this feature: Functional Requirement Functions - [Sync Wallets] Table 7: Functional Requirements Credential Wallet Importing/Exporting","title":"Credential Wallet Importing/Exporting - System Features"},{"location":"pcme1/pcme1/#didcomm-login-support-system-features","text":"The product must be able to scan DIDComm messages via NFC, to support DIDComm login. Functional Requirement Functions - [DIDComm Login Support] Table 8: Functional Requirements DIDComm Login support","title":"DIDComm Login support - System Features"},{"location":"pcme1/pcme1/#nfc-scanning-did-input-system-features","text":"The product must be able to scan DIDComm messages via NFC, to support DIDComm login. Functional Requirement Functions - [Scan NFC] Table 9: Functional Requirements NFC Scanning (DID Input)","title":"NFC Scanning (DID Input) - System Features"},{"location":"pcme1/pcme1/#siop-login-system-features","text":"The product must provide support for applications to login into services via the SIOP protocol. The following functions are required for this: Functional Requirement Functions - [SIOP Login Support] Table 10: Functional Requirements SIOP Login","title":"SIOP Login - System Features"},{"location":"pcme1/pcme1/#app-settings-configuration-personalization-system-features","text":"The product must provide means to the PCM user to configure and save PCM application preferences. The following functions are required for this: Functional Requirement Functions - [Configure Cloud wallet linking] Table 11: Functional Requirements App Settings Configuration (personalization)","title":"App Settings Configuration (personalization) - System Features"},{"location":"pcme1/pcme1/#ledger-selection-system-features","text":"","title":"Ledger Selection - System Features"},{"location":"pcme1/pcme1/#idmpcme100059-ledger-support-did-and-ledger-agnostic-behavior","text":"The product MUST support multiple Ledgers according to the Architecture Overview [IDM.AO] , e.g., it MUST NOT be bound to a dedicated Ledger by design and the PCM user should not be able to select ledgers - It\\'s pre-configured . | Functional Requirement | | ---------------------- | | Functions | | - [Select Ledger] | Table 12: Functional Requirements Ledger Selection","title":"[IDM.PCM.E1.00059] Ledger Support (DID) and Ledger-agnostic behavior"},{"location":"pcme1/pcme1/#smartphone-application","text":"","title":"Smartphone Application"},{"location":"pcme1/pcme1/#smartphone-application_1","text":"The product MUST implement the form factor \"Smartphone Application\", so that the PCM can be used as a full-featured app that implements the GUI functionalities, the connectivity functionalities and credential and personal wallet management locally on the smartphone. The backup/restore mechanisms and the configuration management are handled as well in the mobile Smartphone app. This alternative can benefit from all physical input and output interfaces present in a Smartphone, such as cameras for scanning QR-Codes for connection invitations or the NFC communication. Because Smartphones do not usually have a fixed communication endpoint an SSI-Mediator needs to remain in the Cloud for PCM Notifications. The smartphone application MUST include the following system features: Managing Connections Managing Credentials Wallet Backup End User Authentication QR-Code scanning (DID Input) Notification Support App Settings Configuration Ledger Selection The smartphone application additionally include the following system features: Credential Wallet Importing/Exporting/Syncing NFC tag generation and scanning SIOP Login","title":"Smartphone Application"},{"location":"pcme1/pcme1/#verification","text":"","title":"Verification"},{"location":"pcme1/pcme1/#core-verification-requirements","text":"","title":"Core Verification Requirements"},{"location":"pcme1/pcme1/#idmpcme100060-behavior-driven-design","text":"Verification of fulfillment of the requirements and characteristics MUST be done using automated tests which are part of the deliverables. They SHOULD be done by patterns of the Behavior Driven Development [BDD] using the \"Gherkin Syntax\".","title":"[IDM.PCM.E1.00060] Behavior Driven Design"},{"location":"pcme1/pcme1/#functionality-acceptance-criteria","text":"","title":"Functionality Acceptance Criteria"},{"location":"pcme1/pcme1/#connections","text":"","title":"Connections"},{"location":"pcme1/pcme1/#idmpcme100063-connection-invitation","text":"When users are authenticated, then they can receive notification for \"Connection\" via QR-Code, Text input (URL), NFC. The information is shown to the users via the GUI and requests can be validated. The users can accept or to reject the request. When the request is accepted, then the PCM performs the DIDComm protocol required to establish the connection. The connection must be established and stored in the PCM storage, so that it can be used later.","title":"[IDM.PCM.E1.00063] Connection invitation"},{"location":"pcme1/pcme1/#managing-credentials-verification","text":"","title":"Managing credentials - Verification"},{"location":"pcme1/pcme1/#idmpcme100064-receive-a-verifiable-credential-vc","text":"When a user is authenticated and within an established connection, the user must get notification for VC issuing requests. The user must get the possibility to accept or to reject the request. The request is validated, and the information is shown to the user via the GUI. The issued credential MUST be stored in connected OCM(s) of the cPCM and synced to PCM in the case of a W3C credential. In the case of an Indy credential, the App MUST show the credential by using the remote functionality but MUST NOT sync the indy credential physically. In both cases, two credentials are visible in the PCM App, the indy one is highlighted as \"cloud credential\", the other one as \"Local Credential\". When the PCM App receives a Indy/W3C credential directly from an OCM, the credential MUST be also marked as \"Local Credential\". Is any \"cloud credential\" removed from an connected OCM within the cPCM, the App will sync those changes and push the credential to history overview.","title":"[IDM.PCM.E1.00064] Receive a Verifiable Credential (VC)"},{"location":"pcme1/pcme1/#idmpcme100065-answer-request-for-verifiable-presentation-vp","text":"When users are authenticated and Connection established, then: If the user has given his consent, a VP has been proved to the verifier. If the presentation has not been completed successfully, problems have been reported to the users via GUI. The App MUST demonstrate that (synced) W3C or Indy Credentials can be presented offline without any connection to the cPCM. In the online case, the App MUST demonstrate that a credential can be presented via the remote control of the cPCM.","title":"[IDM.PCM.E1.00065] Answer Request for Verifiable Presentation (VP)"},{"location":"pcme1/pcme1/#idmpcme100066-display-history-of-presenting-verifiable-presentations-vps","text":"When users are authenticated, then they can view detailed information about the history of showing/proofing identity information to other participants. History information must list information about the transaction date and time, and to whom has been presented.","title":"[IDM.PCM.E1.00066] Display history of presenting verifiable presentations (VPs)"},{"location":"pcme1/pcme1/#idmpcme100067-restore-backup","text":"When users are authenticated, they must have a function to restore a backup containing all information stored in the PCM and Cloud wallet (cPCM). When users select the backup file, the restore must be performed only after confirming the security authentication. When successful restoration is completed, users should be informed about the status and they must see all their data(such as VC, Connections, etc.).","title":"[IDM.PCM.E1.00067] Restore Backup"},{"location":"pcme1/pcme1/#idmpcme100068-card-view","text":"The PCM MUST present all credentials as cards (like credit cards), with a logo if the credential is in the cloud available or local. The view MUST support easy selection and combination of credentials for the different remote and local use cases.","title":"[IDM.PCM.E1.00068] Card View"},{"location":"pcme1/pcme1/#credential-wallet-synchronization","text":"","title":"Credential Wallet synchronization"},{"location":"pcme1/pcme1/#idmpcme100069-sync-wallets","text":"When users are authenticated, then they must be able to configure synchronization with Cloud Wallet(cPCM). After successfully establishing a secure connection, then bi-directional synchronization MUST be triggered by using DIDComm v2 messages. A DIDComm v2 protocol is provided an documented for each use case of the cPCM (e.g., list VCs)","title":"[IDM.PCM.E1.00069] Sync Wallets"},{"location":"pcme1/pcme1/#nfc","text":"","title":"NFC"},{"location":"pcme1/pcme1/#idmpcme100070-scan-nfc","text":"A user MUST be able to scan an active NFC tag which can contain W3C VC/VP or Connection Invitations. The App MUST successfully process that.","title":"[IDM.PCM.E1.00070] Scan NFC"},{"location":"pcme1/pcme1/#idmpcme100071-write-nfc","text":"A user MUST be able to write an NFC tag which can contain W3C VC/VP or Connection Invitations. Another PCM on a mobile device MUST accept that presentation.","title":"[IDM.PCM.E1.00071] Write NFC"},{"location":"pcme1/pcme1/#siop-login-support","text":"","title":"SIOP Login Support"},{"location":"pcme1/pcme1/#idmpcme100072-siop-login-support","text":"The cPCM MUST implement a function to process SIOP requests [DID SIOP] in the role of the Self- Issued OpenID Provider (SIOP). Applications (RPs (Relying Parties) in SIOP terminology) can send SIOP requests to the PCM. The PCM will process such requests and reply with a SIOP response.","title":"[IDM.PCM.E1.00072] SIOP Login Support"},{"location":"pcme1/pcme1/#app-settings-configuration-personalization-verification","text":"","title":"App Settings Configuration (personalization) - Verification"},{"location":"pcme1/pcme1/#idmpcme100073-configure-cloud-wallet-linking","text":"When users are authenticated, the PCM MUST enable the users to configure secure connection(management link) to Cloud wallet.","title":"[IDM.PCM.E1.00073] Configure cloud wallet linking"},{"location":"pcme1/pcme1/#ledger-selection-verification","text":"","title":"Ledger Selection - Verification"},{"location":"pcme1/pcme1/#idmpcme100074-select-ledger","text":"The PCM MUST not be enabled to select compatible Ledgers from the PCM GUI. The selection is pre-configured from a list of supported ledgers during the build process.","title":"[IDM.PCM.E1.00074] Select Ledger"},{"location":"pcme1/pcme1/#mediator-selection-verification","text":"","title":"Mediator Selection - Verification"},{"location":"pcme1/pcme1/#idmpcme100075-select-mediator","text":"The PCM MUST be able to work with different Mediators by using the DID Document, without recompiling the app.","title":"[IDM.PCM.E1.00075] Select Mediator"},{"location":"pcme1/pcme1/#cloud-wallet-management-verification","text":"","title":"Cloud Wallet Management - Verification"},{"location":"pcme1/pcme1/#idmpcme100076-remote-controller-of-the-cloud-pcm-cpcm","text":"The PCM user MUST be able to control the basic functions of the Cloud PCM(cPCM) such as Consent management, Connection Acceptance, Presentation Allowance, Issuing and Credential management. When users are authenticated and secure management connection is established with cPCM, then the users must be able to consent and access to existing documents.","title":"[IDM.PCM.E1.00076] Remote controller of the Cloud PCM (cPCM)"},{"location":"pcme1/pcme1/#idmpcme100077-plugin-management","text":"The plugin management of the cPCM MUST be supported in the App. It MUST be possible to use the plugins, configured and enable/disable them remotely. The remote protocol MUST be used to request from plugins a token, present that token to verifiers or holders. All other standard functionality like issuing of credentials, consent etc. which the plugin framework of the cPCM offers, must be supported as well.","title":"[IDM.PCM.E1.00077] Plugin Management"},{"location":"pcme1/pcme1/#appendix-a-glossary","text":"For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO]","title":"Appendix A: Glossary"},{"location":"pcme1/pcme1/#appendix-b-consent-management","text":"The flows are just for example. Flow optimizations can be proposed. Flow 1: External Actor requests Access to Protected API Flow 2: External Actor gives Access to protected Resources","title":"Appendix B: Consent Management"},{"location":"pcme1/pcme1/#appendix-c-personal-credential-manager-layering-overview","text":"","title":"Appendix C: Personal Credential Manager Layering overview"},{"location":"train/train/","text":"Software Requirements Specification for Gaia-X Federation Services Trust Management Infrastructure IDM.TRAIN Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA 1 Introduction 1.1 Document Purpose 1.2 Product Scope 1.3 Definitions, Acronyms and Abbreviations 1.4 References 1.5 Document Overview 2 Product Overview 2.1 Product Perspective 2.2 Product Functions 2.3 Product Constraints 2.4 User Classes and Characteristics 2.5 Operating Environment 2.6 User Documentation 2.7 Assumptions and Dependencies 3 Requirements 3.1 External Interfaces 3.1.1 User Interfaces 3.1.2 Software Interfaces 3.1.3 Communications Interfaces 3.2 Functional 3.3 Nonfunctional Requirements 3.3.1 HTTP Requirements 3.3.2 Logging Requirements 3.3.3 Performance Requirements 3.3.4 Safety Requirements 3.3.5 Security Requirements 3.3.6 Software Quality Attributes 3.3.7 Business Rules 3.4 Compliance 3.5 Design and Implementation 3.5.1 Installation 3.5.2 Configuration 3.5.3 Distribution 3.5.4 Service Meshing 3.5.5 Standard Technology Stack 3.5.6 Metrics 3.5.7 Configurability 3.5.8 Maintainability 3.5.9 Reusability 3.5.10 Runtime Stability 3.5.11 High Availability Concepts 3.5.12 Proof of Concept 4 System Features 4.1 Trust Framework and Trust List Provision 4.1.1 Description and Priority 4.1.2 Stimulus/Response Sequences 4.1.3 Functional Requirements 4.2 Trusted Content Resolver 4.2.1 Description and Priority 4.2.2 Stimulus/Response Sequences 4.2.3 Functional Requirements 4.3 DNS Zone Management 4.3.1 Description and Priority 4.3.2 Stimulus/Response Sequences 4.3.3 Functional Requirements 5 Verification 5.1 Core Verification Requirements 5.2 Support for Kubernetes 5.3 Functionality Acceptance Criteria Annex A: TRAIN Overview Annex B: Overview GXFS Work Packages List of Figures Figure 1 TRAIN: Overview Figure 2 Trust Framework and Trust List: Stimulus/Response Sequences Figure 3 Trusted Content Resolver: Stimulus/Response Sequences Figure 4 DNS Zone Management: Stimulus/Response Sequences List of Tables Table 1 User Classes and Characteristics Table 2 Standard Technology Stack Introduction To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD], [TF] and [PRD]. Document Purpose The purpose of the document is to specify the requirements of the Identity Management and Trust Subcomponent \"Trust Management Infrastructure for Gaia-X (TRAIN)\" with the intention of a European wide public tender for implementing this software. The main audience for this document is attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide digital support for existing certification bodies within Gaia-X. Product Scope The purpose of this product is to provide components for establishing and verifying the root of trust for participants in the distributed Gaia-X ecosystem and credentials issued by these entities. This is achieved through the introduction of trust lists combined with anchoring of pointers in the DNS. The conceptual framework for this is described in [GX.TRUST]. Gaia-X Federations and other entities are supported in the sovereign publication and administration of trust lists for their specific trust frameworks. Verifying entities are supported in their sovereign trust decisions. To achieve this, the following functionalities MUST be developed: Trust Framework Configuration Trust List Management Zone Manager Handler Trusted Content Resolver (Extended Universal Resolver) + Libraries DNS Zone Manager Please note that the libraries are intentional for different languages such as GO, Java, Python and Javascript. It's also intentional to create the libraries as helpers for using the extended universal resolver, by adding content resolver steps, validation routines for VC and other assistive functionalities. If it's required to do code restructurings, modifying existing solutions by adding new microservices etc. (e.g., the universal resolver) then this is explicitly required. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams. Definitions, Acronyms and Abbreviations The IDM and Trust Architecture Overview Document [[IDM.AO]]{.underline} MUST be considered and applied as the core technical concept that includes also the Terminology and Glossary. References Name Reference Link [IDM.AO] Gaia-X WP1[1] (2021), Architecture Overview - Please refer to annex \"GX_IDM_AO\" [GX.TRUST] Trust Management Infrastructure for Gaia-X, Concept Document - Please refer to annex \"Trust Management Infrastructure for GX\" [LIGHTEST.TSPA] LIGHTest TSPA Source Code - GitHub Link [LIGHTEST.ZM] LIGHTest Zone Manager Source Code - GitHub Link [PRD] Gaia-X Policy Rules and Labelling Document (2022) - Link [RFC2119] Network Working Group (1997) Key words for use in RFCs to Indicate Requirement Levels - RFC Link [TAD] Gaia-X Architecture Document (2022) - Link [TDR] Gaia-X Federation Services Technical Development Requirements - Please refer to annex \"GXFS_Technical_Development_Requirements\" [TF] Gaia-X Trust Framework (2022) - Link [TRAIN] TRAIN (Trust Management Infrastructure) - Website - Link [TRAIN.ESSIF] ESSIF Gitlab for TRAIN with Sourcecode - GitLab Link [VC.DataModel] W3C (2022), Verifiable Credentials Data Model v1.1 - W3C Link [1] Please refer to appendix B for an overview and explanation of the Work Packages (WP). Document Overview The document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.EX.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [ [RFC 2119] ], are written in capital letters (see also [IDM.AO] - Methodology). Product Overview Product Perspective TRAIN provides a trust management infrastructure for Gaia-X Federation Services (GXFS). The TSA can use the Trusted Component Resolver Libraries to verify the institutional trust of verifiable credentials. The Organizational Credential Manager (OCM) can use the Trusted Component Resolver Libraries to validate the trust of the organizational verifiable credentials before storing them in the wallet. The Notary (via the Notarization API) uses the TSPA Connector to enroll trusted entities into the trust framework and add them via the TSPA/Federator to the Trust List. Figure 1 TRAIN: Overview A bigger overview of Figure 1 can be found at the end of this document in annex A. Product Functions The core functions of IDM.TRAIN are: Provision of a Trust Framework and Trust lists (TSPA Manager is responsible for this functionality): Allows for configuration of a Trust Framework Allows for Trust List Management Provides federation/organization/participant specific Trust Lists in different formats Anchoring a Trust Framework and Trust List into the DNS (Zone Manager is responsible for this functionality): Allows for global discovery based on an established and trusted infrastructure Trust Frameworks are anchored in DNS Pointer Resource Record (PTR RR) Trust List URI DID is anchored in DNS URI Resource Record (URI RR) DNSSEC allows for chain of trust Enrollment of trusted entities into the Trust Framework (TSPA connector is responsible for this functionality): Notary (via the Notarization API) uses the TSPA connector to enroll trusted entities to the Trust Lists Verifying the Institutional Trust of Verifiable Credentials: Trusted Content Resolver is responsible for this functionality Allows Global Discovery of Trust Frameworks through DNS Resolver The content from terms of Use of the verifiable credential will be used for trust discovery Verification of issuer details of the credential with the information of the trust list Integrity of VC must also be verified Integrity of the chain of trust of DNSSEC must be validated. Product Constraints [IDM.TRAIN.00000] The document IDM.AO is the common basis for this functional specification The architecture document [IDM.AO] is an essential part of this specification and a prerequisite for understanding the context. The specifications and requirements from the Architecture Document [TAD] MUST be taken into account during implementation. Please note, that part of the functional requirements require Business Analysts to analyze the requirements of Trust Frameworks and different Trust List formats. Inputs from Business Analysts will be required for the development team set up. [IDM.TRAIN.00001] The document GX.TRUST is the basis for the TRAIN Trust concept The Trust Management Infrastructure for Gaia-X document [GX.TRUST] is an essential part of this specification and a prerequisite for understanding the concept for the Gaia-X Trust Infrastructure. It MUST be taken into account during implementation. [IDM.TRAIN.00002] Implementation Requirement for TSPA and Zone Manager The Code Base of TSPA [LIGHTEST.TSPA] and Zone Manager [LIGHTEST.ZM] MUST be taken as reference and MUST be extended based on the functionalities. For example: Trust Framework Initialization and enrollment in DNS follows the format of _scheme._trust.federation.company1.de for both PTR and URI records. User Classes and Characteristics User Class Description Frequency Expertise Privilege Level Product Usage Administrator Sets up Zone Manager, Trust Framework Configuration, Trust List Initialization Low High High Maintenance Notary Uses TSPA Connector to manage the Trust List High High High Administration of enrollment of trusted entities to the Trust List TSA / Developers Uses Trusted Content Resolver to verify the institutional trust of the verifier and verify the trust of the issuer details in the Trust Framework High High Low Verification of inclusion of issuer details in the Trust Framework PCM Uses the trust list to verify the trust of the issuer/verifier High High Low Verification or connection establishment AAS Uses the trust list to decide if a public key must be part of the domain High High Low Cyclic/During Startup OCM(s) Uses the trust lists to decide if a connection is trustworthy High High Low On Connection establishment Table 1 User Classes and Characteristics Operating Environment [IDM.TRAIN.00003] Kubernetes Environment The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on a SCS cluster (Sovereign Cloud Stack) provided by the contractor. In addition, the developed components must also run in a restricted developer local environment. User Documentation [IDM.TRAIN.00004] Administration Documentation The documentation MUST contain: Installation Manuals for Zone Manager, TSPA Manager Trust Framework Configuration and Trust List Management Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the products from source code [IDM.TRAIN.00005] User Documentation The documentation MUST contain: Short Software Description (why and for what, when to use, how use, where to use) Usage guide (Trusted Content Resolver) Usage guide for installation of libraries with GO, Javascript, Java and Python Usage guide to integrate with Notarization Service (NOT) Usage and integration guide for TSA, OCM, PCM GDPR design decisions Security concept Operations concept for all components Blueprint guides how to setup a federation in usage of all components (step by step) FAQ Keyword Directory Assumptions and Dependencies An understanding of the overall Gaia-X architecture and philosophy and the Trust Management Infrastructure Concept is necessary. Please refer to [IDM.AO] and [GX.TRUST]. The control over minimum of 2 fully qualified domains or subdomains is strictly required for the product in combination with an authoritative DNSSec Server. Requirements External Interfaces User Interfaces [IDM.TRAIN.00006] Trust Framework Configuration The product MUST provide a Web UI which allows the administrator to add new trust frameworks and corresponding DIDs. [IDM.TRAIN.00007] Trust Zone Visualization The product MUST provide a Web UI which visualizes the content of a trustzone (e.g., zones, pointers, DIDs etc.) for external/public users. Software Interfaces [IDM.TRAIN.00008] Universal DID Resolver[2] {#idm.train.00008-universal-did-resolver2 .unnumbered} The DIF Universal Resolver is the product basis that is used for resolving trusted content of DIDs. For building the trusted content resolver, this software is the basis that is to be enhanced. [2] [https://github.com/decentralized-identity/universal-resolver] [IDM.TRAIN.00009] DNS Resolver An Open-Source DNS Resolver MUST be used to discover PTR, URI, DNSSEC Resource Records (RR). And this MUST be integrated with Trusted Content Resolver. [IDM.TRAIN.00010] Authoritative DNSSec Name Servers DNS Name Servers such as NSD[3] and KNOT DNS[4] MUST be used and tested for DNS Zone installation and configuration. [3] [https://www.nlnetlabs.nl/projects/nsd/about/] [4] [https://www.knot-dns.cz/] [IDM.TRAIN.00011] Cryptographic Libraries Open-Source Cryptographic libraries compliant with the BSI[5] and EU DSS[6] rules including BSI TR- 02102-1[7] MUST be used for VC/trustlist signing, VC / trustlist proof validation and DNSSEC Trust Chain Validation. [5] [https://www.bsi.bund.de/EN/Themen/Unternehmen-und-Organisationen/Standards-und-Zertifizierung/Kryptografische-Vorgaben/kryptografische-vorgaben_node.html] [6] [https://ec.europa.eu/digital-building-blocks/wikis/display/DIGITAL/Digital+Signature+Service+-++DSS] [7] [https://www.bsi.bund.de/SharedDocs/Downloads/DE/BSI/Publikationen/TechnischeRichtlinien/TR02102/BSI-TR-02102.html] Communications Interfaces [IDM.TRAIN.00012] Eventing {#idm.train.00012-eventing .unnumbered} If the use of events within the software architecture is required, it is mandatory to use software abstraction according to CloudEvents specification[8] for publishing and subscription. The minimal supported protocol binding MUST be HTTP[9] and JSON[10] Protocol Binding. [8] [https://cloudevents.io/] [9] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/bindings/http-protocol-binding.md] [10] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/formats/json-format.md] [IDM.TRAIN.00013] Eventing Infrastructure The event broker for the eventing MUST abstract the storage and delivery infrastructure. In Kubernetes environments, the broker MUST be uniform across all Lots. (e.g., KNative[11]) [11] [https://knative.dev/docs/] Functional [IDM.TRAIN.00014] Trust Framework Configuration Description This functionality MUST allow the creation of trust frameworks, the creation and configuration of DIDs with well-known did configurations[12], instantiation of trust lists, the envelopment of trust lists in Verifiable Credentials with proof and configuring the enveloped VCs in the service end point of DID Documents. The Sequence Diagram (Figure 2, System Features Section) elaborates the process. Each and every process MUST have separate API endpoints to instantiation. [12] [https://identity.foundation/.well-known/resources/did-configuration/] Constraints The following constraints MUST be fulfilled: Allow creation and mapping of multiple trust frameworks (multiple federations/domains) Allow referencing of trust frameworks from other domains Configure DID as URI record with corresponding trust frameworks Verify the DID with well-known DID configuration before enrolling in URI record Creation of digital signed Trust List with different formats - json and xml Allow creation of VC with trust list end point as credential subject Allow signature of VC- and storage of VC Trust Lists Each process MUST have separate API endpoints Interfaces Zone Manager Trust List Storage VC Storage Zone Data Storage Zone Manager Connector Input Trust Framework enrollment DID enrollment Envelope Trust List Endpoint Instantiating Trust List (Storage at Web Server or IPFS) Output Creation of Trust Framework as PTR record in DNS DID enrolled as URI RR mapped with corresponding Trust Framework Verifiable Credential with Trust List endpoint as Credential Subject Trust List published in storage with retrievable API endpoint Acceptance Criteria The following acceptance criteria MUST be met: A request update of trust frameworks and DID configuration is successfully reflected in the DNS Zone File (200) An instantiation of a trust list is reflected in the trust list storage with possibility to retrieve via API endpoints Creation of a VC is allowed with ability to sign the credential A wrong context or missing data leads to an exception (400) An audit entry is created An error is provided if a record is in progress by the operator Should be able to reference Trust Frameworks from other Domains [IDM.TRAIN.00015] Trust List Management Description This functionality MUST allow CRUD (create, read, update, delete) operations on the trust list at the Trusted Data Store. It must also allow for identifying different types of requests based on the enrollment inputs, for example: federation, organization, participant, service provider. If the organization or federation enrolls with its own trust framework, the trust framework name MUST be enrolled in the DNS as PTR record using the Zone Manager Handler. Constraints The following constraints MUST be fulfilled: Support JSON and XML trust-list update Have separate endpoints for create, read, update, delete functionalities Support multiple forms of storage on IPFS and HTTPS WebServer Identify and enroll the trust framework into DNS Zone file as PTR RR Interfaces Database of Trusted Content Storage Zone Manager Handler Zone Manager Notarization API Input A confirmed request record. This MUST include: DID of the organization URI of the trust list URI of the schema Metadata of the entity (to be specified further according to business analyst analysis) Legal Name Certification details Assurance Levels Configure supported DID methods Type of other digital credentials supported (example: x509) Different services offered by the organization Output In create operation: a new trust list entry MUST be created In read operation: the API endpoints MUST have the flexibility to read the whole trust list and also separate entities using UUID In update operation: the change requested by the user MUST be reflected in trust list In delete operation: the trust list entry of the entity MUST be deleted from the list Must contain auditing mechanisms for the trust list. Please refer to the trust concept document [GX.TRUST] for different mechanisms listed there. Must be able to integrate with the Notarization API Acceptance Criteria The following acceptance criteria MUST be met: A request update has been successfully reflected in the trust list (200) A wrong context or missing data leads to an exception (400) Audit entry created Error, if record is in progress by the operator Integrate with the Notarization API [IDM.TRAIN.00016] Trusted Content Resolver (Trust Discovery) Description This functionality MUST allow for the resolution of the trust list to find the issuer details in the trust list. The resolver MUST base of the DIF Universal Resolver[13] and MUST provide additional functionality to iterate recursive over DID Documents by resolving references in service endpoints during the standard resolving. The Resolver MUST integrate with the TSA via libraries. The resolving MUST be controllable by giving a list of endpoint types which are considered during the resolving by a defined range of actions. Responding content references MUST be collected and provided to the user either as list or as Callback during/after the resolving of standard documents. For instance, when a DID is resolved, the extended universal resolver collects additional DIDs from the service endpoint section (selected by types) and searches there again for other content. During this process, the defined content types are collected as reference. E.g., a list of URLs to type \"gx-trusted-issuer\" grouped by DID for a later processing by the libraries. [13] [https://github.com/decentralized-identity/universal-resolver] Constraints The following constraints MUST be fulfilled: Resolve DNS PTR queries Resolve DID URI queries Navigate to corresponding service type on the DID Document to fetch the corresponding trust list based on user inputs Handle multiple Trust Framework Pointer as array Validate DNS Name against DNSSEC Provision MUST be made to allow user to configure their own DNS Resolvers Support different user defined trust list content types for corresponding trust list discovery Interfaces DNS Resolver Universal DID Resolver[14] DNSSEC validator [14] [https://github.com/decentralized-identity/universal-resolver] Input Trust Framework Pointer (e.g., example.federation1.de) + Types to be considered Issuer details from the VC/VP (e.g., DID/URI) ServiceType of the trust list (e.g., issuance service, verifier service) Output Corresponding DID mapped to Trust Framework Pointer DID Document of the DID Trust List VC endpoint Acceptance Criteria The following acceptance criteria MUST be met: Use standardized DNS resolvers Use standardized DID resolver Navigate multiple trust framework pointers Discover different trust list formats Support different service types Optimized search mechanisms (e.g., Merkle Tree) MUST Allow configuration of different DNS Name Servers MUST allow configuration of user defined service content type (e.g., gxfs-trusted-issuer) The complete discovery process MUST be able to integrate with the TSA via libraries in GO, JAVA, Javascript, Python [IDM.TRAIN.00017] Validation Description This functionality MUST validate the output of the trust discovery functionality of the Trusted Content Resolver. The validation functionality MUST validate the association of DID with a well- known DID configuration. And MUST also be able to validate the integrity of the VC. Then it MUST also be able to validate the issuer details from the trust lists extracted from service endpoints. The validation functionality MUST integrate with the TSA via libraries. Constraints The following constraints MUST be fulfilled: Validate the association of a DID with a well-known DID Configuration Verify the proof of a VC with a public key from a DID Document Display the metadata information, public keys, schema from the trust list Support multiple signature proofs Interfaces Trust Discovery Input The inputs for validation are based on the output of the trust discovery functionality Corresponding DID mapped to Trust Framework Pointer DID Document of the DID Trust List VC endpoint Output Validation result of VC Validation result of Issuer details (present/not present) If Issuer details are found, display meta data information, public keys, schema from the trust list Acceptance Criteria The following acceptance criteria MUST be met: VC validation mechanism supports multiple signature proofs Standardized open-source libraries for validation in GO, JAVA, Javascript, Python OCI compliant containerization (Dockerized) Resolve different trust strategies Resolve multiple lists Implement the resolving strategies The complete validation process of the Trusted Content Resolver MUST be able to integrate with the TSA via libraries in GO, JAVA, Javascript, Python [IDM.TRAIN.00018] Translate xml This functionality of the Trusted Content Resolver is responsible for detecting and translating the format of the trust list. If the format of the trust list is XML, this functionality is responsible for finding the right attributes and passing the information to the validation functionality. [IDM.TRAIN.00019] Translate JSON This functionality at Trusted Content Resolver is responsible for detecting and translating the format of the trust list. If the format of the trust list is JSON, this functionality is responsible for finding the right attributes and pass the information to the validation functionality. [IDM.TRAIN.00020] Zone Manager Handler Description This functionality part of TSPA is responsible for configuring the TSPA with Zone Manger. It MUST allow publishing the Trust Framework and the DID in the DNS Zone file via the Zone Manager. Constraints The config file MUST be configured with the Domain Name of the Zone Manager and the password in order for the Zone Manager Handler to be able to communicate with the zone manager. Interfaces Zone Manager Trust Framework and Trust List Pointer Storage Trust Framework Configuration Acceptance Criteria The following acceptance criteria MUST be met: The TSPA MUST be able to configure the Zone Manager using the Zone Manager Handler. [IDM.TRAIN.00021] Federation specific Framework and Trust Lists Description This functionality is responsible for providing the trust list data model for federation specific use cases. Interfaces Trust Framework Configuration Trust List Management Input No input Output The Trust List Data model MUST cover the following aspects in detail: Business rules Federation meta data (e.g., legal name, etc.) Accommodate different identifiers (e.g., LEI - Legal Entity Identifier) Accommodate assurance levels Accommodate different digital identities (e.g., DID, PKI) Different services offered by the federation Accommodate auditable history information URI in trust list Acceptance Criteria The following acceptance criteria MUST be met: Analysis with existing standards (e.g., ETSI, NIST, etc.) Trust list data model in JSON and XML format with proper semantics Address three use cases (i.e., Automotive, IIOT, Dataspaces ) [IDM.TRAIN.00022] Participant specific Frameworks and Trust Lists Description This functionality is responsible for providing the trust list data model for participant specific use cases. Interfaces Trust Framework Configuration Trust List Management Input No input Output The Trust List Data model MUST cover the following aspects in detail: Business rules Participant meta data (e.g., legal name, etc.) Accommodate different identifiers (e.g.: LEI) Accommodate assurance levels Accommodate different digital identities (e.g., DID, PKI) Different services trusted by the participant Accommodate auditable history information URI in trust list Acceptance Criteria The following acceptance criteria MUST be met: Analysis with existing standards (e.g., ETSI, NIST, etc.) Trust list data model in json and xml format with proper semantics Address three use cases for different participants [IDM.TRAIN.00023] Organization specific Frameworks and Trust Lists Description This functionality is responsible for providing the trust list data models for organization specific use cases. Interfaces Trust Framework Configuration Trust List Management Input No input Output The Trust List Data model MUST cover the following aspects in detail. Business rules Organization meta data (e.g., legal name, etc.) Accommodate different identifiers (e.g., LEI) Accommodate assurance levels Accommodate different digital identities (e.g., DID, PKI) Different services offered by the organization Accommodate auditable history information URI in trust list Acceptance Criteria The following acceptance criteria MUST be met: Analysis with existing standards (e.g.., ETSI, NIST) Trust list data model in json and xml format with proper semantics Address three use cases for different organizations [IDM.TRAIN.00024] Zone Manager Description This functionality MUST allow publishing the Trust Framework and the DID in the DNS Zone file. It integrates with the TSPA Manager using the Zone Manager Handler. Constraints Zone Manager MUST be extended on the code base [LIGHTEST.ZM] Trust Frameworks MUST be published as PTR records DIDs corresponding to Trust Frameworks MUST be published as URI records Zone Manager MUST provide DNSSEC configurations Zone File MUST be re-signed on every new update MUST allow trust framework to point to multiple other trust frameworks Interfaces Zone Manager Handler Trust Framework and Trust List Pointers Storage (sqlite) TSPA Manager DNS Servers (NSD & KNOT) Input Trust Framework DID Enrollment corresponding to Trust Framework Output Update of Trust Framework and DID in the DNS Zone file Acceptance Criteria The following acceptance criteria MUST be met: A request update has been successfully reflected in the sqlite storage and Zone file (200) A wrong context or missing data leads to an exception (400) An audit entry is created An error, if record is in progress by the operator MUST integrate with the TSPA Manager using the Zone Manager Handler MUST be tested with NSD & KNOT DNS Servers Nonfunctional Requirements HTTP Requirements [IDM.TRAIN.00025] HTTPS All HTTP Endpoints MUST be protected by TLS 1.2 (all protocol version numbers SHOULD be superseded by upcoming standards). Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system. [IDM.TRAIN.00026] HTTP Protocol Definitions {#idm.train.00026-http-protocol-definitions .unnumbered} All HTTP Endpoints MUST follow RFC7231 and RFC5789 but it MAY be chosen which of the protocols are necessary to realize the functionality. For problem reports the RFC7807 MUST be used in combination with Standard HTTP Error Codes. Logging Requirements [IDM.TRAIN.00027] Data Minimization The data minimization principle is expressed in Article 5(1)(c) of the GDPR and Article 4(1)(c) of Regulation (EU) 2018/1725, which provide that personal data must be \\\"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed\\\". The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of the following elements: a. node\\'s identification b. message identification c. message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review. [IDM.TRAIN.00028] Logging Frameworks The product MUST support logging frameworks e.g., graylog, fluentD or logstash to support logging and analysis by enterprise infrastructures. The supported framework MAY be chosen for the first version, but it MUST support the common open-source logging solutions with OpenTelemetry[15] support. The final solution MUST be aligned with the other subcomponents. It MUST be sketched in the operations concept how the support of multiple solutions is given in the future. [15] [https://opentelemetry.io/] Performance Requirements [IDM.TRAIN.00029] Up/Down Scale All components MUST be able to scale out/down their functionality for an undefined amount of instances. This requires a parallel execution possibility which will be tested later on by performance tests. [IDM.TRAIN.00030] Docker and Kubernetes Deployment Trust Framework and Trust List Provision service MUST provide a OCI containerized (dockerized) version for example DID with a DID Document that can be published locally and also a sample trust list enveloped in a VC that can be run on a local server for testing purposes. A OCI containerized version of the Trust Framework and Trust List Provision service MUST be able to be integrated with DNS Zone Manager. An implementation of the DNS Zone Manager MUST be tested with core DNS Kubernetes and also the service MUST be OCI containerized and able to resolve queries from the Trusted Content Resolver. [IDM.TRAIN.00031] Integration Functionality The DNS Zone Manager MUST be able to integrate Trust Framework and Trust List Provision Services. [IDM.TRAIN.00032] Resolving Functionality The Trusted Content Resolver MUST be able to resolve DNS Queries and MUST be able to fetch and verify trust framework and trust list provision services. Safety Requirements [IDM.TRAIN.00033] Major Releases All used software components MUST use the major releases with Long Term Support (LTS). If no LTS is available, all components MUST use the latest major releases with security hardening. Security Requirements [IDM.TRAIN.00034] CVE Patches All software components MUST have applied CVE patches, which are available for major releases. [IDM.TRAIN.00035] Risk-Management and Pentesting Requirements An adequate security risk management process is applied compliant to EU ENISA Risk Management in usage of a Tread Modelling Process like PASTA[16] or OWSAP[17] All software components MUST be compliant to the requirements of the Pentesting like BSI IS- Penetrationstest[18] [16] [https://threat-modeling.com/pasta-threat-modeling/] [17] [https://owasp.org/www-community/Threat_Modeling_Process] [18] [https://www.bsi.bund.de/SharedDocs/Downloads/DE/BSI/Sicherheitsberatung/Pentest_Webcheck/Leitfaden_Penetrationstest.pdf?blob=publicationFile&v=10] Software Quality Attributes [IDM.TRAIN.00036] Software Quality Requirements All software components MUST be compliant to the requirements within the quality assurance repository[19]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing (BDD) methodology. [19] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues] Business Rules [IDM.TRAIN.00037] Software Consistency The used technologies MUST have consistency. Standard technologies e.g., databases MUST be abstracted over JDBC, authentication over OIDC etc. [IDM.TRAIN.00038] Cherry Picking All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow enterprise deployment customization. Compliance [IDM.TRAIN.00039] GDPR Audit Logging The seven EU GDPR principles MUST be considered: Data handling and logging MUST fulfill lawfulness, fairness and transparency; purpose limitation; data minimization; accuracy; storage limitation; integrity and confidentiality (security); and accountability. [IDM.TRAIN.00040] GDPR Data Processing Is it necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable. Design and Implementation Installation [IDM.TRAIN.00041] Helm/Argo CD Deployment All installations MUST be scripted/templated to ensure automated deployment into an enterprise Kubernetes cluster (K8S), SCS K8S demonstration cluster and local K8S development instance. This MUST be ensured uniform over HELM templates which MUST follow uniform across all lots (orientation on existing deployment pipelines from phase I and with alignment with the contractor). The charts MUST be integrable in a ARGO CD Pipeline defined in the gxfs-integration repository[20]. [20] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration] Configuration [IDM.TRAIN.00042] Configuration All components MUST support one of the major configuration formats (yaml, json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged. Distribution [IDM.TRAIN.00043] Helm Repositories All component helm charts MUST be available under a helm repository hosted in the gitlab, with different channels for distribution[21]. [21] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml] [IDM.TRAIN.00044] Istio Resources Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc.) following the integration pattern specified in the gxfs-integration repo[22]. [22] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration] Service Meshing [IDM.TRAIN.00045] Istio Support All HELM charts MUST be provided with Istio support aligned together with the contractor. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment. Standard Technology Stack [IDM.TRAIN.00046] Default Toolstack Each development MUST consider the following standard technologies if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React[23] Ingress Controller Nginx API Testing Postman (manual) API Design OpenAPI > Table 2 Standard Technology Stack [23] [https://react-bootstrap.github.io/] The technology stack is mandatory to avoid integration impact. Metrics [IDM.TRAIN.00047] Opentelemetry Support All helm charts/services MUST provide metrics endpoints in opentelemetry[24] format. [24] [https://opentelemetry.io/docs/] Configurability [IDM.TRAIN.00048] Configuration Profiles Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening [IDM.TRAIN.00049] Secret References in Helm Charts The configuration secrets within Helm Charts MUST use secretRefs to support external Secret Management. Clear text secrets within the Helm Charts are not allowed. Maintainability [IDM.TRAIN.00050] Microservice Architecture For a better scale out, maintainability and decentralization, the product architecture MUST have a microservice architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment). [IDM.TRAIN.00051] Domain Driven Design To support the microservice architecture within the maintainability, a domain model MUST be declared before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers. Reusability [IDM.TRAIN.00052] Enterprise Environments All components MUST be reusable in different enterprise environments by customization and whitelabeling. This means that all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.) Runtime Stability [IDM.TRAIN.00053] Readiness Checkups All components MUST reflect - after bootstrap and during runtime - the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during runtime: An unreachable configured Services results in failed state Configured Service Endpoints need to be checked for readiness during runtime, if not reachable, it results in failure state Check dependent components (Database, Microservice etc.) behind it, if not reachable, it results in failed state High Availability Concepts [IDM.TRAIN.00054] Redundant Deployment Each deployment MUST be configured for a minimum fault tolerance of 2 instances. Proof of Concept [IDM.TRAIN.00055] Architecture Changes All Architecture Changes MUST be aligned with the contractor before implementation. System Features Trust Framework and Trust List Provision Description and Priority - Trust Framework and Trust List Provision The feature Trust Framework and Trust List Provision is responsible for configuring and managing trust frameworks with its corresponding trust lists for hosting the trust list VC for anchoring the service end points to the DID Document transferring the data to be anchored in the DNS using the Zone Manager Handler. Please refer to the source code on [LIGHTEST.TSPA] for integrating the Trust Framework and Trust List Provision with the Zone Manager. Stimulus/Response Sequences - Trust Framework and Trust List Provision Figure 2Trust Framework and Trust List: Stimulus/Response Sequences Functional Requirements - Trust Framework and Trust List Provision Functional Requirements Trust Framework Configuration Trust List Management Federation specific Framework and Trustlists Participant specific Frameworks and Trustlists Organization specific Frameworks and Trustlists Zone Manager Handler Trusted Content Resolver Description and Priority - Trusted Content Resolver The Trusted Content Resolver feature is responsible for the Trust Discovery and Trust Validation functionalities based on the input from the Verifiable Credential / Verifiable Presentation. The trust discovery process is realized through the DNS Resolver and the Universal DID Resolver. This feature MUST also be able to validate the cryptographic signatures of the VC and the trust list. It MUST also be able to differentiate different trust lists based on the data anchored in the VC. It MUST be able to validate the institutional trust of credentials by using issuer details on the trust list. The discovery traverse mechanism MUST be mathematically improved using efficient search algorithms (e.g., Merkle Trees). The service MUST be available as connection libraries in GO, JAVA, Javascript, python languages. The libraries SHOULD be user configurable for different input (e.g., service endpoint type: gxfs-issuer-list, gxfs-self- description) and output formats (e.g., json with defined parameters (service name, digital id, etc.). The Trusted Content Resolver MUST be able to integrate with TSA to validate the trust via libraries mentioned in the above programming languages.The service should also be dockerized and easily integrable with existing systems to validate the trust. Stimulus/Response Sequences - Trusted Content Resolver Figure 3 Trusted Content Resolver: Stimulus/Response Sequences Functional Requirements - Trusted Content Resolver Functional Requirements Trust Discovery Validation Translate XML Translate JSON DNS Zone Management Description and Priority - DNS Zone Management The DNS Zone Management feature is responsible for managing the DNS zone file and used for anchoring the trust framework DID information into the zone file. This feature is also responsible for resigning the zone file based on DNSSEC for every new update in the zone file. The implementation approach MUST be based on https://github.com/H2020LIGHTest/ZoneManager with the latest python version. The DNS server used for the backend MUST be NSD and KnotDNS. The service MUST be dockerized. Stimulus/Response Sequences - DNS Zone Management Figure 4 DNS Zone Management: Stimulus/Response Sequences* Functional Requirements - DNS Zone Management Functional Requirement Zone Manager Verification Core Verification Requirements All listed verification items/criterias MUST be fulfilled by a demonstration of the implementation within the provided Kubernetes environment. [IDM.TRAIN.00056] Kubernetes Deployment If the verification is related to software components, it MUST be deployed in a k8s test cluster and the components must be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration. Support for Kubernetes [IDM.TRAIN.00057] Eventing All eventings MUST be demonstrated based on cloud events specifications together with the kNative[25] broker in a Kubernetes environment. [25] [https://knative.dev/docs/eventing/] [IDM.TRAIN.00058] Config Map Support Each service MUST be demonstrated up and running in Kubernetes, configured by config maps. [IDM.TRAIN.00059] Helm Installation The service installation MUST be demonstrated during HELM install. [IDM.TRAIN.00060] ArgoCD Integration The helm chart MUST be able to install inside of argoCD. This includes the usage of the postgres hooks[26] and the provisioning of usable values.yaml(s) for all developed services. [26] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration/-/tree/main/helm/charts/postgresql-hook] [IDM.TRAIN.00061] SCS Environment All HELM installations MUST run on SCS (Sovereign Cloud Stack). The [final acceptance] demonstration cannot be realized on azure, google cloud etc. Functionality Acceptance Criteria [IDM.TRAIN.00062] Zone Manager/TSPA Configuration A domain was registered, and a DNSSec Server is linked to it. The product Zone Manager was installed on a machine, and it MUST be possible to link the Zone Manager with the DNSSec Server. The Zone Manager Handler MUST be configured to allow access to the zone manager (internal API). After this, using TSPA Trust Frameworks and DIDs can be published over the Zone Manager Handler into the zone file. After the rollout, using the endpoints of the TSPA with Dig commands and queries, the Trust Framework and DID (PTR and URI RR) of the Zone File are resolvable. [IDM.TRAIN.00063] Trust Zone Demonstration Trusted Content publishing and resolution MUST be demonstrated over a public domain with DNSsec functionality. Various entries MUST be added to the zone and be resolved by the Trusted Content Resolver. [IDM.TRAIN.00064] Trust Framework cross-linking Demonstration Cross-linking of Trust Frameworks MUST be demonstrated over two public domains with DNSsec functionality. A cross-link from one trust framework on domain 1 (using the PTR Record) MUST reference another Trust Framework on domain 2. Various entries MUST be added to the Trust Frameworks on domain 1 and domain 2 and be correctly resolved by the Trusted Content Resolver. [IDM.TRAIN.00065] Trust Framework and DID Enrollment Trust Frameworks and their corresponding DIDs MUST be enrolled using API endpoints offered by the TSPA. The enrolled details MUST be reflected in the database and the DNS Zone file of the Name server. [IDM.TRAIN.00066] Trusted List Management using API endpoints The Trust List content MUST be managed using API endpoints. Separate API endpoints MUST be available for performing CRUD Operations. [IDM.TRAIN.00067] Trusted Content Resolver resolves Trust Zone Pointers The trusted content resolver is called by a Trust Framework Pointer (URL/DNS Name). The resolver recognizes that a DNS query must be made and it's starting to resolve the records about other Trust Framework Pointers (if applicable). After resolving the entire Zone, the DIDs of the RR/URI Records can be resolved as usual. Output is a List of Pointers which the resolver returns. [IDM.TRAIN.00068] Trusted Content Resolver resolves Trusted Content The trusted content resolver is called by a DID, and a list of requested content types. The resolver resolves the DID, iterates through the service endpoint references, and returns a list of trust lists (no DID documents), regarding the given DID. The DID documents for the resolved references can be found in a second list. [IDM.TRAIN.00069] Trusted Content Resolver validates institutional trust of a Verifiable Credential The issuer details of a credential MUST be validated with the resources found from the Trust List. This MUST be demonstrated with Trust Frameworks that are cross-linked to other Trust Frameworks (hosted on different domains) as well as Trust Frameworks that do not include a cross-linking. This MUST be available as integratable libraries for programming languages GO, Javascript, python and Java. Software Requirements Specification for IDM.TRAIN 30 Annex A: TRAIN Overview Software Requirements Specification for IDM.TRAIN 31 Annex B: Overview GXFS Work Packages The project \"Gaia-X Federation Services\" (GXFS) is an initiative funded by the German Federal Ministry of Economic Affairs and Energy (BMWi) to develop the first set of Gaia-X Federation Services, which form the technical basis for the operational implementation of Gaia-X. The project is structured in five Working Groups, focusing on different functional areas as follows: Work Package 1 (WP1): Identity & Trust Identity &Trust covers authentication and authorization, credential management, decentral Identity management as well as the verification of analogue credentials. Work Package 2 (WP2): Federated Catalogue The Federated Catalogue constitutes the central repository for Gaia-X Self-Descriptions to enable the discovery and selection of Providers and their Service Offerings. The Self-Description as expression of properties and Claims of Participants and Assets represents a key element for transparency and trust in Gaia-X. Work Package 3 (WP3): Sovereign Data Exchange Data Sovereignty Services enable the sovereign data exchange of Participants by providing a Data Agreement Service and a Data Logging Service to enable the enforcement of Policies. Further, usage constraints for data exchange can be expressed by Provider Policies as part of the Self-Description Work Package 4 (WP4): Compliance Compliance includes mechanisms to ensure a Participant's adherence to the Policy Rules in areas such as security, privacy transparency and interoperability during onboarding and service delivery. Work Package 5 (WP5): Portal & Integration Gaia-X Portals and API will support onboarding and Accreditation of Participants, demonstrate service discovery, orchestration, and provisioning of sample services. Further general information on the Federation Services can be found in [TAD].","title":"Trust Management Infrastructure"},{"location":"train/train/#software-requirements-specification-for-gaia-x-federation-services-trust-management-infrastructure-idmtrain","text":"Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA","title":"Software Requirements Specification  for  Gaia-X Federation Services Trust Management Infrastructure IDM.TRAIN"},{"location":"train/train/#1-introduction","text":"","title":"1  Introduction"},{"location":"train/train/#11-document-purpose","text":"","title":"1.1 Document Purpose"},{"location":"train/train/#12-product-scope","text":"","title":"1.2 Product Scope"},{"location":"train/train/#13-definitions-acronyms-and-abbreviations","text":"","title":"1.3  Definitions, Acronyms and Abbreviations"},{"location":"train/train/#14-references","text":"","title":"1.4 References"},{"location":"train/train/#15-document-overview","text":"","title":"1.5 Document Overview"},{"location":"train/train/#2-product-overview","text":"","title":"2 Product Overview"},{"location":"train/train/#21-product-perspective","text":"","title":"2.1 Product Perspective"},{"location":"train/train/#22-product-functions","text":"","title":"2.2 Product Functions"},{"location":"train/train/#23-product-constraints","text":"","title":"2.3 Product Constraints"},{"location":"train/train/#24-user-classes-and-characteristics","text":"","title":"2.4 User Classes and Characteristics"},{"location":"train/train/#25-operating-environment","text":"","title":"2.5 Operating Environment"},{"location":"train/train/#26-user-documentation","text":"","title":"2.6 User Documentation"},{"location":"train/train/#27-assumptions-and-dependencies","text":"","title":"2.7 Assumptions and Dependencies"},{"location":"train/train/#3-requirements","text":"","title":"3 Requirements"},{"location":"train/train/#31-external-interfaces","text":"","title":"3.1 External Interfaces"},{"location":"train/train/#311-user-interfaces","text":"","title":"3.1.1 User Interfaces"},{"location":"train/train/#312-software-interfaces","text":"","title":"3.1.2 Software Interfaces"},{"location":"train/train/#313-communications-interfaces","text":"","title":"3.1.3 Communications Interfaces"},{"location":"train/train/#32-functional","text":"","title":"3.2 Functional"},{"location":"train/train/#33-nonfunctional-requirements","text":"","title":"3.3 Nonfunctional Requirements"},{"location":"train/train/#331-http-requirements","text":"","title":"3.3.1 HTTP Requirements"},{"location":"train/train/#332-logging-requirements","text":"","title":"3.3.2 Logging Requirements"},{"location":"train/train/#333-performance-requirements","text":"","title":"3.3.3 Performance Requirements"},{"location":"train/train/#334-safety-requirements","text":"","title":"3.3.4 Safety Requirements"},{"location":"train/train/#335-security-requirements","text":"","title":"3.3.5 Security Requirements"},{"location":"train/train/#336-software-quality-attributes","text":"","title":"3.3.6 Software Quality Attributes"},{"location":"train/train/#337-business-rules","text":"","title":"3.3.7 Business Rules"},{"location":"train/train/#34-compliance","text":"","title":"3.4 Compliance"},{"location":"train/train/#35-design-and-implementation","text":"","title":"3.5 Design and Implementation"},{"location":"train/train/#351-installation","text":"","title":"3.5.1 Installation"},{"location":"train/train/#352-configuration","text":"","title":"3.5.2 Configuration"},{"location":"train/train/#353-distribution","text":"","title":"3.5.3 Distribution"},{"location":"train/train/#354-service-meshing","text":"","title":"3.5.4 Service Meshing"},{"location":"train/train/#355-standard-technology-stack","text":"","title":"3.5.5 Standard Technology Stack"},{"location":"train/train/#356-metrics","text":"","title":"3.5.6 Metrics"},{"location":"train/train/#357-configurability","text":"","title":"3.5.7 Configurability"},{"location":"train/train/#358-maintainability","text":"","title":"3.5.8 Maintainability"},{"location":"train/train/#359-reusability","text":"","title":"3.5.9 Reusability"},{"location":"train/train/#3510-runtime-stability","text":"","title":"3.5.10 Runtime Stability"},{"location":"train/train/#3511-high-availability-concepts","text":"","title":"3.5.11 High Availability Concepts"},{"location":"train/train/#3512-proof-of-concept","text":"","title":"3.5.12 Proof of Concept"},{"location":"train/train/#4-system-features","text":"","title":"4 System Features"},{"location":"train/train/#41-trust-framework-and-trust-list-provision","text":"","title":"4.1 Trust Framework and Trust List Provision"},{"location":"train/train/#411-description-and-priority","text":"","title":"4.1.1 Description and Priority"},{"location":"train/train/#412-stimulusresponse-sequences","text":"","title":"4.1.2 Stimulus/Response Sequences"},{"location":"train/train/#413-functional-requirements","text":"","title":"4.1.3 Functional Requirements"},{"location":"train/train/#42-trusted-content-resolver","text":"","title":"4.2 Trusted Content Resolver"},{"location":"train/train/#421-description-and-priority","text":"","title":"4.2.1 Description and Priority"},{"location":"train/train/#422-stimulusresponse-sequences","text":"","title":"4.2.2 Stimulus/Response Sequences"},{"location":"train/train/#423-functional-requirements","text":"","title":"4.2.3 Functional Requirements"},{"location":"train/train/#43-dns-zone-management","text":"","title":"4.3 DNS Zone Management"},{"location":"train/train/#431-description-and-priority","text":"","title":"4.3.1 Description and Priority"},{"location":"train/train/#432-stimulusresponse-sequences","text":"","title":"4.3.2 Stimulus/Response Sequences"},{"location":"train/train/#433-functional-requirements","text":"","title":"4.3.3 Functional Requirements"},{"location":"train/train/#5-verification","text":"","title":"5 Verification"},{"location":"train/train/#51-core-verification-requirements","text":"","title":"5.1 Core Verification Requirements"},{"location":"train/train/#52-support-for-kubernetes","text":"","title":"5.2 Support for Kubernetes"},{"location":"train/train/#53-functionality-acceptance-criteria","text":"Annex A: TRAIN Overview Annex B: Overview GXFS Work Packages List of Figures Figure 1 TRAIN: Overview Figure 2 Trust Framework and Trust List: Stimulus/Response Sequences Figure 3 Trusted Content Resolver: Stimulus/Response Sequences Figure 4 DNS Zone Management: Stimulus/Response Sequences List of Tables Table 1 User Classes and Characteristics Table 2 Standard Technology Stack","title":"5.3 Functionality Acceptance Criteria"},{"location":"train/train/#introduction","text":"To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD], [TF] and [PRD].","title":"Introduction"},{"location":"train/train/#document-purpose","text":"The purpose of the document is to specify the requirements of the Identity Management and Trust Subcomponent \"Trust Management Infrastructure for Gaia-X (TRAIN)\" with the intention of a European wide public tender for implementing this software. The main audience for this document is attendees of the public tender, which are able to supply an open-source software solution for the area of identity and document verification with the purpose to provide digital support for existing certification bodies within Gaia-X.","title":"Document Purpose"},{"location":"train/train/#product-scope","text":"The purpose of this product is to provide components for establishing and verifying the root of trust for participants in the distributed Gaia-X ecosystem and credentials issued by these entities. This is achieved through the introduction of trust lists combined with anchoring of pointers in the DNS. The conceptual framework for this is described in [GX.TRUST]. Gaia-X Federations and other entities are supported in the sovereign publication and administration of trust lists for their specific trust frameworks. Verifying entities are supported in their sovereign trust decisions. To achieve this, the following functionalities MUST be developed: Trust Framework Configuration Trust List Management Zone Manager Handler Trusted Content Resolver (Extended Universal Resolver) + Libraries DNS Zone Manager Please note that the libraries are intentional for different languages such as GO, Java, Python and Javascript. It's also intentional to create the libraries as helpers for using the extended universal resolver, by adding content resolver steps, validation routines for VC and other assistive functionalities. If it's required to do code restructurings, modifying existing solutions by adding new microservices etc. (e.g., the universal resolver) then this is explicitly required. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams.","title":"Product Scope"},{"location":"train/train/#definitions-acronyms-and-abbreviations","text":"The IDM and Trust Architecture Overview Document [[IDM.AO]]{.underline} MUST be considered and applied as the core technical concept that includes also the Terminology and Glossary.","title":"Definitions, Acronyms and Abbreviations"},{"location":"train/train/#references","text":"Name Reference Link [IDM.AO] Gaia-X WP1[1] (2021), Architecture Overview - Please refer to annex \"GX_IDM_AO\" [GX.TRUST] Trust Management Infrastructure for Gaia-X, Concept Document - Please refer to annex \"Trust Management Infrastructure for GX\" [LIGHTEST.TSPA] LIGHTest TSPA Source Code - GitHub Link [LIGHTEST.ZM] LIGHTest Zone Manager Source Code - GitHub Link [PRD] Gaia-X Policy Rules and Labelling Document (2022) - Link [RFC2119] Network Working Group (1997) Key words for use in RFCs to Indicate Requirement Levels - RFC Link [TAD] Gaia-X Architecture Document (2022) - Link [TDR] Gaia-X Federation Services Technical Development Requirements - Please refer to annex \"GXFS_Technical_Development_Requirements\" [TF] Gaia-X Trust Framework (2022) - Link [TRAIN] TRAIN (Trust Management Infrastructure) - Website - Link [TRAIN.ESSIF] ESSIF Gitlab for TRAIN with Sourcecode - GitLab Link [VC.DataModel] W3C (2022), Verifiable Credentials Data Model v1.1 - W3C Link [1] Please refer to appendix B for an overview and explanation of the Work Packages (WP).","title":"References"},{"location":"train/train/#document-overview","text":"The document describes the product perspective, functions, and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.EX.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [ [RFC 2119] ], are written in capital letters (see also [IDM.AO] - Methodology).","title":"Document Overview"},{"location":"train/train/#product-overview","text":"","title":"Product Overview"},{"location":"train/train/#product-perspective","text":"TRAIN provides a trust management infrastructure for Gaia-X Federation Services (GXFS). The TSA can use the Trusted Component Resolver Libraries to verify the institutional trust of verifiable credentials. The Organizational Credential Manager (OCM) can use the Trusted Component Resolver Libraries to validate the trust of the organizational verifiable credentials before storing them in the wallet. The Notary (via the Notarization API) uses the TSPA Connector to enroll trusted entities into the trust framework and add them via the TSPA/Federator to the Trust List. Figure 1 TRAIN: Overview A bigger overview of Figure 1 can be found at the end of this document in annex A.","title":"Product Perspective"},{"location":"train/train/#product-functions","text":"The core functions of IDM.TRAIN are: Provision of a Trust Framework and Trust lists (TSPA Manager is responsible for this functionality): Allows for configuration of a Trust Framework Allows for Trust List Management Provides federation/organization/participant specific Trust Lists in different formats Anchoring a Trust Framework and Trust List into the DNS (Zone Manager is responsible for this functionality): Allows for global discovery based on an established and trusted infrastructure Trust Frameworks are anchored in DNS Pointer Resource Record (PTR RR) Trust List URI DID is anchored in DNS URI Resource Record (URI RR) DNSSEC allows for chain of trust Enrollment of trusted entities into the Trust Framework (TSPA connector is responsible for this functionality): Notary (via the Notarization API) uses the TSPA connector to enroll trusted entities to the Trust Lists Verifying the Institutional Trust of Verifiable Credentials: Trusted Content Resolver is responsible for this functionality Allows Global Discovery of Trust Frameworks through DNS Resolver The content from terms of Use of the verifiable credential will be used for trust discovery Verification of issuer details of the credential with the information of the trust list Integrity of VC must also be verified Integrity of the chain of trust of DNSSEC must be validated.","title":"Product Functions"},{"location":"train/train/#product-constraints","text":"","title":"Product Constraints"},{"location":"train/train/#idmtrain00000-the-document-idmao-is-the-common-basis-for-this-functional-specification","text":"The architecture document [IDM.AO] is an essential part of this specification and a prerequisite for understanding the context. The specifications and requirements from the Architecture Document [TAD] MUST be taken into account during implementation. Please note, that part of the functional requirements require Business Analysts to analyze the requirements of Trust Frameworks and different Trust List formats. Inputs from Business Analysts will be required for the development team set up.","title":"[IDM.TRAIN.00000] The document IDM.AO is the common basis for this functional specification"},{"location":"train/train/#idmtrain00001-the-document-gxtrust-is-the-basis-for-the-train-trust-concept","text":"The Trust Management Infrastructure for Gaia-X document [GX.TRUST] is an essential part of this specification and a prerequisite for understanding the concept for the Gaia-X Trust Infrastructure. It MUST be taken into account during implementation.","title":"[IDM.TRAIN.00001] The document GX.TRUST is the basis for the TRAIN Trust concept"},{"location":"train/train/#idmtrain00002-implementation-requirement-for-tspa-and-zone-manager","text":"The Code Base of TSPA [LIGHTEST.TSPA] and Zone Manager [LIGHTEST.ZM] MUST be taken as reference and MUST be extended based on the functionalities. For example: Trust Framework Initialization and enrollment in DNS follows the format of _scheme._trust.federation.company1.de for both PTR and URI records.","title":"[IDM.TRAIN.00002] Implementation Requirement for TSPA and Zone Manager"},{"location":"train/train/#user-classes-and-characteristics","text":"User Class Description Frequency Expertise Privilege Level Product Usage Administrator Sets up Zone Manager, Trust Framework Configuration, Trust List Initialization Low High High Maintenance Notary Uses TSPA Connector to manage the Trust List High High High Administration of enrollment of trusted entities to the Trust List TSA / Developers Uses Trusted Content Resolver to verify the institutional trust of the verifier and verify the trust of the issuer details in the Trust Framework High High Low Verification of inclusion of issuer details in the Trust Framework PCM Uses the trust list to verify the trust of the issuer/verifier High High Low Verification or connection establishment AAS Uses the trust list to decide if a public key must be part of the domain High High Low Cyclic/During Startup OCM(s) Uses the trust lists to decide if a connection is trustworthy High High Low On Connection establishment Table 1 User Classes and Characteristics","title":"User Classes and Characteristics"},{"location":"train/train/#operating-environment","text":"","title":"Operating Environment"},{"location":"train/train/#idmtrain00003-kubernetes-environment","text":"The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on a SCS cluster (Sovereign Cloud Stack) provided by the contractor. In addition, the developed components must also run in a restricted developer local environment.","title":"[IDM.TRAIN.00003] Kubernetes Environment"},{"location":"train/train/#user-documentation","text":"","title":"User Documentation"},{"location":"train/train/#idmtrain00004-administration-documentation","text":"The documentation MUST contain: Installation Manuals for Zone Manager, TSPA Manager Trust Framework Configuration and Trust List Management Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the products from source code","title":"[IDM.TRAIN.00004] Administration Documentation"},{"location":"train/train/#idmtrain00005-user-documentation","text":"The documentation MUST contain: Short Software Description (why and for what, when to use, how use, where to use) Usage guide (Trusted Content Resolver) Usage guide for installation of libraries with GO, Javascript, Java and Python Usage guide to integrate with Notarization Service (NOT) Usage and integration guide for TSA, OCM, PCM GDPR design decisions Security concept Operations concept for all components Blueprint guides how to setup a federation in usage of all components (step by step) FAQ Keyword Directory","title":"[IDM.TRAIN.00005] User Documentation"},{"location":"train/train/#assumptions-and-dependencies","text":"An understanding of the overall Gaia-X architecture and philosophy and the Trust Management Infrastructure Concept is necessary. Please refer to [IDM.AO] and [GX.TRUST]. The control over minimum of 2 fully qualified domains or subdomains is strictly required for the product in combination with an authoritative DNSSec Server.","title":"Assumptions and Dependencies"},{"location":"train/train/#requirements","text":"","title":"Requirements"},{"location":"train/train/#external-interfaces","text":"","title":"External Interfaces"},{"location":"train/train/#user-interfaces","text":"","title":"User Interfaces"},{"location":"train/train/#idmtrain00006-trust-framework-configuration","text":"The product MUST provide a Web UI which allows the administrator to add new trust frameworks and corresponding DIDs.","title":"[IDM.TRAIN.00006] Trust Framework Configuration"},{"location":"train/train/#idmtrain00007-trust-zone-visualization","text":"The product MUST provide a Web UI which visualizes the content of a trustzone (e.g., zones, pointers, DIDs etc.) for external/public users.","title":"[IDM.TRAIN.00007] Trust Zone Visualization"},{"location":"train/train/#software-interfaces","text":"","title":"Software Interfaces"},{"location":"train/train/#idmtrain00008-universal-did-resolver2-idmtrain00008-universal-did-resolver2-unnumbered","text":"The DIF Universal Resolver is the product basis that is used for resolving trusted content of DIDs. For building the trusted content resolver, this software is the basis that is to be enhanced.","title":"[IDM.TRAIN.00008] Universal DID Resolver[2] {#idm.train.00008-universal-did-resolver2 .unnumbered}"},{"location":"train/train/#2-httpsgithubcomdecentralized-identityuniversal-resolver","text":"","title":"[2] [https://github.com/decentralized-identity/universal-resolver]"},{"location":"train/train/#idmtrain00009-dns-resolver","text":"An Open-Source DNS Resolver MUST be used to discover PTR, URI, DNSSEC Resource Records (RR). And this MUST be integrated with Trusted Content Resolver.","title":"[IDM.TRAIN.00009] DNS Resolver"},{"location":"train/train/#idmtrain00010-authoritative-dnssec-name-servers","text":"DNS Name Servers such as NSD[3] and KNOT DNS[4] MUST be used and tested for DNS Zone installation and configuration.","title":"[IDM.TRAIN.00010] Authoritative DNSSec Name Servers"},{"location":"train/train/#3-httpswwwnlnetlabsnlprojectsnsdabout","text":"","title":"[3] [https://www.nlnetlabs.nl/projects/nsd/about/]"},{"location":"train/train/#4-httpswwwknot-dnscz","text":"","title":"[4] [https://www.knot-dns.cz/]"},{"location":"train/train/#idmtrain00011-cryptographic-libraries","text":"Open-Source Cryptographic libraries compliant with the BSI[5] and EU DSS[6] rules including BSI TR- 02102-1[7] MUST be used for VC/trustlist signing, VC / trustlist proof validation and DNSSEC Trust Chain Validation.","title":"[IDM.TRAIN.00011] Cryptographic Libraries"},{"location":"train/train/#5-httpswwwbsibunddeenthemenunternehmen-und-organisationenstandards-und-zertifizierungkryptografische-vorgabenkryptografische-vorgaben_nodehtml","text":"","title":"[5] [https://www.bsi.bund.de/EN/Themen/Unternehmen-und-Organisationen/Standards-und-Zertifizierung/Kryptografische-Vorgaben/kryptografische-vorgaben_node.html]"},{"location":"train/train/#6-httpseceuropaeudigital-building-blockswikisdisplaydigitaldigitalsignatureservice-dss","text":"","title":"[6] [https://ec.europa.eu/digital-building-blocks/wikis/display/DIGITAL/Digital+Signature+Service+-++DSS]"},{"location":"train/train/#7-httpswwwbsibunddeshareddocsdownloadsdebsipublikationentechnischerichtlinientr02102bsi-tr-02102html","text":"","title":"[7] [https://www.bsi.bund.de/SharedDocs/Downloads/DE/BSI/Publikationen/TechnischeRichtlinien/TR02102/BSI-TR-02102.html]"},{"location":"train/train/#communications-interfaces","text":"","title":"Communications Interfaces"},{"location":"train/train/#idmtrain00012-eventing-idmtrain00012-eventing-unnumbered","text":"If the use of events within the software architecture is required, it is mandatory to use software abstraction according to CloudEvents specification[8] for publishing and subscription. The minimal supported protocol binding MUST be HTTP[9] and JSON[10] Protocol Binding.","title":"[IDM.TRAIN.00012] Eventing {#idm.train.00012-eventing .unnumbered}"},{"location":"train/train/#8-httpscloudeventsio","text":"","title":"[8] [https://cloudevents.io/]"},{"location":"train/train/#9-httpsgithubcomcloudeventsspecblobv102cloudeventsbindingshttp-protocol-bindingmd","text":"","title":"[9] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/bindings/http-protocol-binding.md]"},{"location":"train/train/#10-httpsgithubcomcloudeventsspecblobv102cloudeventsformatsjson-formatmd","text":"","title":"[10] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/formats/json-format.md]"},{"location":"train/train/#idmtrain00013-eventing-infrastructure","text":"The event broker for the eventing MUST abstract the storage and delivery infrastructure. In Kubernetes environments, the broker MUST be uniform across all Lots. (e.g., KNative[11])","title":"[IDM.TRAIN.00013] Eventing Infrastructure"},{"location":"train/train/#11-httpsknativedevdocs","text":"","title":"[11] [https://knative.dev/docs/]"},{"location":"train/train/#functional","text":"","title":"Functional"},{"location":"train/train/#idmtrain00014-trust-framework-configuration","text":"Description This functionality MUST allow the creation of trust frameworks, the creation and configuration of DIDs with well-known did configurations[12], instantiation of trust lists, the envelopment of trust lists in Verifiable Credentials with proof and configuring the enveloped VCs in the service end point of DID Documents. The Sequence Diagram (Figure 2, System Features Section) elaborates the process. Each and every process MUST have separate API endpoints to instantiation.","title":"[IDM.TRAIN.00014] Trust Framework Configuration"},{"location":"train/train/#12-httpsidentityfoundationwell-knownresourcesdid-configuration","text":"Constraints The following constraints MUST be fulfilled: Allow creation and mapping of multiple trust frameworks (multiple federations/domains) Allow referencing of trust frameworks from other domains Configure DID as URI record with corresponding trust frameworks Verify the DID with well-known DID configuration before enrolling in URI record Creation of digital signed Trust List with different formats - json and xml Allow creation of VC with trust list end point as credential subject Allow signature of VC- and storage of VC Trust Lists Each process MUST have separate API endpoints Interfaces Zone Manager Trust List Storage VC Storage Zone Data Storage Zone Manager Connector Input Trust Framework enrollment DID enrollment Envelope Trust List Endpoint Instantiating Trust List (Storage at Web Server or IPFS) Output Creation of Trust Framework as PTR record in DNS DID enrolled as URI RR mapped with corresponding Trust Framework Verifiable Credential with Trust List endpoint as Credential Subject Trust List published in storage with retrievable API endpoint Acceptance Criteria The following acceptance criteria MUST be met: A request update of trust frameworks and DID configuration is successfully reflected in the DNS Zone File (200) An instantiation of a trust list is reflected in the trust list storage with possibility to retrieve via API endpoints Creation of a VC is allowed with ability to sign the credential A wrong context or missing data leads to an exception (400) An audit entry is created An error is provided if a record is in progress by the operator Should be able to reference Trust Frameworks from other Domains","title":"[12] [https://identity.foundation/.well-known/resources/did-configuration/]"},{"location":"train/train/#idmtrain00015-trust-list-management","text":"Description This functionality MUST allow CRUD (create, read, update, delete) operations on the trust list at the Trusted Data Store. It must also allow for identifying different types of requests based on the enrollment inputs, for example: federation, organization, participant, service provider. If the organization or federation enrolls with its own trust framework, the trust framework name MUST be enrolled in the DNS as PTR record using the Zone Manager Handler. Constraints The following constraints MUST be fulfilled: Support JSON and XML trust-list update Have separate endpoints for create, read, update, delete functionalities Support multiple forms of storage on IPFS and HTTPS WebServer Identify and enroll the trust framework into DNS Zone file as PTR RR Interfaces Database of Trusted Content Storage Zone Manager Handler Zone Manager Notarization API Input A confirmed request record. This MUST include: DID of the organization URI of the trust list URI of the schema Metadata of the entity (to be specified further according to business analyst analysis) Legal Name Certification details Assurance Levels Configure supported DID methods Type of other digital credentials supported (example: x509) Different services offered by the organization Output In create operation: a new trust list entry MUST be created In read operation: the API endpoints MUST have the flexibility to read the whole trust list and also separate entities using UUID In update operation: the change requested by the user MUST be reflected in trust list In delete operation: the trust list entry of the entity MUST be deleted from the list Must contain auditing mechanisms for the trust list. Please refer to the trust concept document [GX.TRUST] for different mechanisms listed there. Must be able to integrate with the Notarization API Acceptance Criteria The following acceptance criteria MUST be met: A request update has been successfully reflected in the trust list (200) A wrong context or missing data leads to an exception (400) Audit entry created Error, if record is in progress by the operator Integrate with the Notarization API","title":"[IDM.TRAIN.00015] Trust List Management"},{"location":"train/train/#idmtrain00016-trusted-content-resolver-trust-discovery","text":"Description This functionality MUST allow for the resolution of the trust list to find the issuer details in the trust list. The resolver MUST base of the DIF Universal Resolver[13] and MUST provide additional functionality to iterate recursive over DID Documents by resolving references in service endpoints during the standard resolving. The Resolver MUST integrate with the TSA via libraries. The resolving MUST be controllable by giving a list of endpoint types which are considered during the resolving by a defined range of actions. Responding content references MUST be collected and provided to the user either as list or as Callback during/after the resolving of standard documents. For instance, when a DID is resolved, the extended universal resolver collects additional DIDs from the service endpoint section (selected by types) and searches there again for other content. During this process, the defined content types are collected as reference. E.g., a list of URLs to type \"gx-trusted-issuer\" grouped by DID for a later processing by the libraries.","title":"[IDM.TRAIN.00016] Trusted Content Resolver (Trust Discovery)"},{"location":"train/train/#13-httpsgithubcomdecentralized-identityuniversal-resolver","text":"Constraints The following constraints MUST be fulfilled: Resolve DNS PTR queries Resolve DID URI queries Navigate to corresponding service type on the DID Document to fetch the corresponding trust list based on user inputs Handle multiple Trust Framework Pointer as array Validate DNS Name against DNSSEC Provision MUST be made to allow user to configure their own DNS Resolvers Support different user defined trust list content types for corresponding trust list discovery Interfaces DNS Resolver Universal DID Resolver[14] DNSSEC validator","title":"[13] [https://github.com/decentralized-identity/universal-resolver]"},{"location":"train/train/#14-httpsgithubcomdecentralized-identityuniversal-resolver","text":"Input Trust Framework Pointer (e.g., example.federation1.de) + Types to be considered Issuer details from the VC/VP (e.g., DID/URI) ServiceType of the trust list (e.g., issuance service, verifier service) Output Corresponding DID mapped to Trust Framework Pointer DID Document of the DID Trust List VC endpoint Acceptance Criteria The following acceptance criteria MUST be met: Use standardized DNS resolvers Use standardized DID resolver Navigate multiple trust framework pointers Discover different trust list formats Support different service types Optimized search mechanisms (e.g., Merkle Tree) MUST Allow configuration of different DNS Name Servers MUST allow configuration of user defined service content type (e.g., gxfs-trusted-issuer) The complete discovery process MUST be able to integrate with the TSA via libraries in GO, JAVA, Javascript, Python","title":"[14] [https://github.com/decentralized-identity/universal-resolver]"},{"location":"train/train/#idmtrain00017-validation","text":"Description This functionality MUST validate the output of the trust discovery functionality of the Trusted Content Resolver. The validation functionality MUST validate the association of DID with a well- known DID configuration. And MUST also be able to validate the integrity of the VC. Then it MUST also be able to validate the issuer details from the trust lists extracted from service endpoints. The validation functionality MUST integrate with the TSA via libraries. Constraints The following constraints MUST be fulfilled: Validate the association of a DID with a well-known DID Configuration Verify the proof of a VC with a public key from a DID Document Display the metadata information, public keys, schema from the trust list Support multiple signature proofs Interfaces Trust Discovery Input The inputs for validation are based on the output of the trust discovery functionality Corresponding DID mapped to Trust Framework Pointer DID Document of the DID Trust List VC endpoint Output Validation result of VC Validation result of Issuer details (present/not present) If Issuer details are found, display meta data information, public keys, schema from the trust list Acceptance Criteria The following acceptance criteria MUST be met: VC validation mechanism supports multiple signature proofs Standardized open-source libraries for validation in GO, JAVA, Javascript, Python OCI compliant containerization (Dockerized) Resolve different trust strategies Resolve multiple lists Implement the resolving strategies The complete validation process of the Trusted Content Resolver MUST be able to integrate with the TSA via libraries in GO, JAVA, Javascript, Python","title":"[IDM.TRAIN.00017] Validation"},{"location":"train/train/#idmtrain00018-translate-xml","text":"This functionality of the Trusted Content Resolver is responsible for detecting and translating the format of the trust list. If the format of the trust list is XML, this functionality is responsible for finding the right attributes and passing the information to the validation functionality.","title":"[IDM.TRAIN.00018] Translate xml"},{"location":"train/train/#idmtrain00019-translate-json","text":"This functionality at Trusted Content Resolver is responsible for detecting and translating the format of the trust list. If the format of the trust list is JSON, this functionality is responsible for finding the right attributes and pass the information to the validation functionality.","title":"[IDM.TRAIN.00019] Translate JSON"},{"location":"train/train/#idmtrain00020-zone-manager-handler","text":"Description This functionality part of TSPA is responsible for configuring the TSPA with Zone Manger. It MUST allow publishing the Trust Framework and the DID in the DNS Zone file via the Zone Manager. Constraints The config file MUST be configured with the Domain Name of the Zone Manager and the password in order for the Zone Manager Handler to be able to communicate with the zone manager. Interfaces Zone Manager Trust Framework and Trust List Pointer Storage Trust Framework Configuration Acceptance Criteria The following acceptance criteria MUST be met: The TSPA MUST be able to configure the Zone Manager using the Zone Manager Handler.","title":"[IDM.TRAIN.00020] Zone Manager Handler"},{"location":"train/train/#idmtrain00021-federation-specific-framework-and-trust-lists","text":"Description This functionality is responsible for providing the trust list data model for federation specific use cases. Interfaces Trust Framework Configuration Trust List Management Input No input Output The Trust List Data model MUST cover the following aspects in detail: Business rules Federation meta data (e.g., legal name, etc.) Accommodate different identifiers (e.g., LEI - Legal Entity Identifier) Accommodate assurance levels Accommodate different digital identities (e.g., DID, PKI) Different services offered by the federation Accommodate auditable history information URI in trust list Acceptance Criteria The following acceptance criteria MUST be met: Analysis with existing standards (e.g., ETSI, NIST, etc.) Trust list data model in JSON and XML format with proper semantics Address three use cases (i.e., Automotive, IIOT, Dataspaces )","title":"[IDM.TRAIN.00021] Federation specific Framework and Trust Lists"},{"location":"train/train/#idmtrain00022-participant-specific-frameworks-and-trust-lists","text":"Description This functionality is responsible for providing the trust list data model for participant specific use cases. Interfaces Trust Framework Configuration Trust List Management Input No input Output The Trust List Data model MUST cover the following aspects in detail: Business rules Participant meta data (e.g., legal name, etc.) Accommodate different identifiers (e.g.: LEI) Accommodate assurance levels Accommodate different digital identities (e.g., DID, PKI) Different services trusted by the participant Accommodate auditable history information URI in trust list Acceptance Criteria The following acceptance criteria MUST be met: Analysis with existing standards (e.g., ETSI, NIST, etc.) Trust list data model in json and xml format with proper semantics Address three use cases for different participants","title":"[IDM.TRAIN.00022] Participant specific Frameworks and Trust Lists"},{"location":"train/train/#idmtrain00023-organization-specific-frameworks-and-trust-lists","text":"Description This functionality is responsible for providing the trust list data models for organization specific use cases. Interfaces Trust Framework Configuration Trust List Management Input No input Output The Trust List Data model MUST cover the following aspects in detail. Business rules Organization meta data (e.g., legal name, etc.) Accommodate different identifiers (e.g., LEI) Accommodate assurance levels Accommodate different digital identities (e.g., DID, PKI) Different services offered by the organization Accommodate auditable history information URI in trust list Acceptance Criteria The following acceptance criteria MUST be met: Analysis with existing standards (e.g.., ETSI, NIST) Trust list data model in json and xml format with proper semantics Address three use cases for different organizations","title":"[IDM.TRAIN.00023] Organization specific Frameworks and Trust Lists"},{"location":"train/train/#idmtrain00024-zone-manager","text":"Description This functionality MUST allow publishing the Trust Framework and the DID in the DNS Zone file. It integrates with the TSPA Manager using the Zone Manager Handler. Constraints Zone Manager MUST be extended on the code base [LIGHTEST.ZM] Trust Frameworks MUST be published as PTR records DIDs corresponding to Trust Frameworks MUST be published as URI records Zone Manager MUST provide DNSSEC configurations Zone File MUST be re-signed on every new update MUST allow trust framework to point to multiple other trust frameworks Interfaces Zone Manager Handler Trust Framework and Trust List Pointers Storage (sqlite) TSPA Manager DNS Servers (NSD & KNOT) Input Trust Framework DID Enrollment corresponding to Trust Framework Output Update of Trust Framework and DID in the DNS Zone file Acceptance Criteria The following acceptance criteria MUST be met: A request update has been successfully reflected in the sqlite storage and Zone file (200) A wrong context or missing data leads to an exception (400) An audit entry is created An error, if record is in progress by the operator MUST integrate with the TSPA Manager using the Zone Manager Handler MUST be tested with NSD & KNOT DNS Servers","title":"[IDM.TRAIN.00024] Zone Manager"},{"location":"train/train/#nonfunctional-requirements","text":"","title":"Nonfunctional Requirements"},{"location":"train/train/#http-requirements","text":"","title":"HTTP Requirements"},{"location":"train/train/#idmtrain00025-https","text":"All HTTP Endpoints MUST be protected by TLS 1.2 (all protocol version numbers SHOULD be superseded by upcoming standards). Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system.","title":"[IDM.TRAIN.00025] HTTPS"},{"location":"train/train/#idmtrain00026-http-protocol-definitions-idmtrain00026-http-protocol-definitions-unnumbered","text":"All HTTP Endpoints MUST follow RFC7231 and RFC5789 but it MAY be chosen which of the protocols are necessary to realize the functionality. For problem reports the RFC7807 MUST be used in combination with Standard HTTP Error Codes.","title":"[IDM.TRAIN.00026] HTTP Protocol Definitions {#idm.train.00026-http-protocol-definitions .unnumbered}"},{"location":"train/train/#logging-requirements","text":"","title":"Logging Requirements"},{"location":"train/train/#idmtrain00027-data-minimization","text":"The data minimization principle is expressed in Article 5(1)(c) of the GDPR and Article 4(1)(c) of Regulation (EU) 2018/1725, which provide that personal data must be \\\"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed\\\". The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of the following elements: a. node\\'s identification b. message identification c. message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review.","title":"[IDM.TRAIN.00027] Data Minimization"},{"location":"train/train/#idmtrain00028-logging-frameworks","text":"The product MUST support logging frameworks e.g., graylog, fluentD or logstash to support logging and analysis by enterprise infrastructures. The supported framework MAY be chosen for the first version, but it MUST support the common open-source logging solutions with OpenTelemetry[15] support. The final solution MUST be aligned with the other subcomponents. It MUST be sketched in the operations concept how the support of multiple solutions is given in the future.","title":"[IDM.TRAIN.00028] Logging Frameworks"},{"location":"train/train/#15-httpsopentelemetryio","text":"","title":"[15] [https://opentelemetry.io/]"},{"location":"train/train/#performance-requirements","text":"","title":"Performance Requirements"},{"location":"train/train/#idmtrain00029-updown-scale","text":"All components MUST be able to scale out/down their functionality for an undefined amount of instances. This requires a parallel execution possibility which will be tested later on by performance tests.","title":"[IDM.TRAIN.00029] Up/Down Scale"},{"location":"train/train/#idmtrain00030-docker-and-kubernetes-deployment","text":"Trust Framework and Trust List Provision service MUST provide a OCI containerized (dockerized) version for example DID with a DID Document that can be published locally and also a sample trust list enveloped in a VC that can be run on a local server for testing purposes. A OCI containerized version of the Trust Framework and Trust List Provision service MUST be able to be integrated with DNS Zone Manager. An implementation of the DNS Zone Manager MUST be tested with core DNS Kubernetes and also the service MUST be OCI containerized and able to resolve queries from the Trusted Content Resolver.","title":"[IDM.TRAIN.00030] Docker and Kubernetes Deployment"},{"location":"train/train/#idmtrain00031-integration-functionality","text":"The DNS Zone Manager MUST be able to integrate Trust Framework and Trust List Provision Services.","title":"[IDM.TRAIN.00031] Integration Functionality"},{"location":"train/train/#idmtrain00032-resolving-functionality","text":"The Trusted Content Resolver MUST be able to resolve DNS Queries and MUST be able to fetch and verify trust framework and trust list provision services.","title":"[IDM.TRAIN.00032] Resolving Functionality"},{"location":"train/train/#safety-requirements","text":"","title":"Safety Requirements"},{"location":"train/train/#idmtrain00033-major-releases","text":"All used software components MUST use the major releases with Long Term Support (LTS). If no LTS is available, all components MUST use the latest major releases with security hardening.","title":"[IDM.TRAIN.00033] Major Releases"},{"location":"train/train/#security-requirements","text":"","title":"Security Requirements"},{"location":"train/train/#idmtrain00034-cve-patches","text":"All software components MUST have applied CVE patches, which are available for major releases.","title":"[IDM.TRAIN.00034] CVE Patches"},{"location":"train/train/#idmtrain00035-risk-management-and-pentesting-requirements","text":"An adequate security risk management process is applied compliant to EU ENISA Risk Management in usage of a Tread Modelling Process like PASTA[16] or OWSAP[17] All software components MUST be compliant to the requirements of the Pentesting like BSI IS- Penetrationstest[18]","title":"[IDM.TRAIN.00035] Risk-Management and Pentesting Requirements"},{"location":"train/train/#16-httpsthreat-modelingcompasta-threat-modeling","text":"","title":"[16] [https://threat-modeling.com/pasta-threat-modeling/]"},{"location":"train/train/#17-httpsowasporgwww-communitythreat_modeling_process","text":"","title":"[17] [https://owasp.org/www-community/Threat_Modeling_Process]"},{"location":"train/train/#18-httpswwwbsibunddeshareddocsdownloadsdebsisicherheitsberatungpentest_webcheckleitfaden_penetrationstestpdfblobpublicationfilev10","text":"","title":"[18] [https://www.bsi.bund.de/SharedDocs/Downloads/DE/BSI/Sicherheitsberatung/Pentest_Webcheck/Leitfaden_Penetrationstest.pdf?blob=publicationFile&amp;v=10]"},{"location":"train/train/#software-quality-attributes","text":"","title":"Software Quality Attributes"},{"location":"train/train/#idmtrain00036-software-quality-requirements","text":"All software components MUST be compliant to the requirements within the quality assurance repository[19]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing (BDD) methodology.","title":"[IDM.TRAIN.00036] Software Quality Requirements"},{"location":"train/train/#19-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesquality-assurance-issues","text":"","title":"[19] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues]"},{"location":"train/train/#business-rules","text":"","title":"Business Rules"},{"location":"train/train/#idmtrain00037-software-consistency","text":"The used technologies MUST have consistency. Standard technologies e.g., databases MUST be abstracted over JDBC, authentication over OIDC etc.","title":"[IDM.TRAIN.00037] Software Consistency"},{"location":"train/train/#idmtrain00038-cherry-picking","text":"All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow enterprise deployment customization.","title":"[IDM.TRAIN.00038] Cherry Picking"},{"location":"train/train/#compliance","text":"","title":"Compliance"},{"location":"train/train/#idmtrain00039-gdpr-audit-logging","text":"The seven EU GDPR principles MUST be considered: Data handling and logging MUST fulfill lawfulness, fairness and transparency; purpose limitation; data minimization; accuracy; storage limitation; integrity and confidentiality (security); and accountability.","title":"[IDM.TRAIN.00039] GDPR Audit Logging"},{"location":"train/train/#idmtrain00040-gdpr-data-processing","text":"Is it necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable.","title":"[IDM.TRAIN.00040] GDPR Data Processing"},{"location":"train/train/#design-and-implementation","text":"","title":"Design and Implementation"},{"location":"train/train/#installation","text":"","title":"Installation"},{"location":"train/train/#idmtrain00041-helmargo-cd-deployment","text":"All installations MUST be scripted/templated to ensure automated deployment into an enterprise Kubernetes cluster (K8S), SCS K8S demonstration cluster and local K8S development instance. This MUST be ensured uniform over HELM templates which MUST follow uniform across all lots (orientation on existing deployment pipelines from phase I and with alignment with the contractor). The charts MUST be integrable in a ARGO CD Pipeline defined in the gxfs-integration repository[20].","title":"[IDM.TRAIN.00041] Helm/Argo CD Deployment"},{"location":"train/train/#20-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesgxfs-integration","text":"","title":"[20] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration]"},{"location":"train/train/#configuration","text":"","title":"Configuration"},{"location":"train/train/#idmtrain00042-configuration","text":"All components MUST support one of the major configuration formats (yaml, json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged.","title":"[IDM.TRAIN.00042] Configuration"},{"location":"train/train/#distribution","text":"","title":"Distribution"},{"location":"train/train/#idmtrain00043-helm-repositories","text":"All component helm charts MUST be available under a helm repository hosted in the gitlab, with different channels for distribution[21].","title":"[IDM.TRAIN.00043] Helm Repositories"},{"location":"train/train/#21-httpsgitlabcomapiv4projects41175300packageshelmintegrationindexyaml","text":"","title":"[21] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml]"},{"location":"train/train/#idmtrain00044-istio-resources","text":"Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc.) following the integration pattern specified in the gxfs-integration repo[22].","title":"[IDM.TRAIN.00044] Istio Resources"},{"location":"train/train/#22-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesgxfs-integration","text":"","title":"[22] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration]"},{"location":"train/train/#service-meshing","text":"","title":"Service Meshing"},{"location":"train/train/#idmtrain00045-istio-support","text":"All HELM charts MUST be provided with Istio support aligned together with the contractor. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment.","title":"[IDM.TRAIN.00045] Istio Support"},{"location":"train/train/#standard-technology-stack","text":"","title":"Standard Technology Stack"},{"location":"train/train/#idmtrain00046-default-toolstack","text":"Each development MUST consider the following standard technologies if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React[23] Ingress Controller Nginx API Testing Postman (manual) API Design OpenAPI > Table 2 Standard Technology Stack","title":"[IDM.TRAIN.00046] Default Toolstack"},{"location":"train/train/#23-httpsreact-bootstrapgithubio","text":"The technology stack is mandatory to avoid integration impact.","title":"[23] [https://react-bootstrap.github.io/]"},{"location":"train/train/#metrics","text":"","title":"Metrics"},{"location":"train/train/#idmtrain00047-opentelemetry-support","text":"All helm charts/services MUST provide metrics endpoints in opentelemetry[24] format.","title":"[IDM.TRAIN.00047] Opentelemetry Support"},{"location":"train/train/#24-httpsopentelemetryiodocs","text":"","title":"[24] [https://opentelemetry.io/docs/]"},{"location":"train/train/#configurability","text":"","title":"Configurability"},{"location":"train/train/#idmtrain00048-configuration-profiles","text":"Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening","title":"[IDM.TRAIN.00048] Configuration Profiles"},{"location":"train/train/#idmtrain00049-secret-references-in-helm-charts","text":"The configuration secrets within Helm Charts MUST use secretRefs to support external Secret Management. Clear text secrets within the Helm Charts are not allowed.","title":"[IDM.TRAIN.00049] Secret References in Helm Charts"},{"location":"train/train/#maintainability","text":"","title":"Maintainability"},{"location":"train/train/#idmtrain00050-microservice-architecture","text":"For a better scale out, maintainability and decentralization, the product architecture MUST have a microservice architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment).","title":"[IDM.TRAIN.00050] Microservice Architecture"},{"location":"train/train/#idmtrain00051-domain-driven-design","text":"To support the microservice architecture within the maintainability, a domain model MUST be declared before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers.","title":"[IDM.TRAIN.00051] Domain Driven Design"},{"location":"train/train/#reusability","text":"","title":"Reusability"},{"location":"train/train/#idmtrain00052-enterprise-environments","text":"All components MUST be reusable in different enterprise environments by customization and whitelabeling. This means that all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.)","title":"[IDM.TRAIN.00052] Enterprise Environments"},{"location":"train/train/#runtime-stability","text":"","title":"Runtime Stability"},{"location":"train/train/#idmtrain00053-readiness-checkups","text":"All components MUST reflect - after bootstrap and during runtime - the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during runtime: An unreachable configured Services results in failed state Configured Service Endpoints need to be checked for readiness during runtime, if not reachable, it results in failure state Check dependent components (Database, Microservice etc.) behind it, if not reachable, it results in failed state","title":"[IDM.TRAIN.00053] Readiness Checkups"},{"location":"train/train/#high-availability-concepts","text":"","title":"High Availability Concepts"},{"location":"train/train/#idmtrain00054-redundant-deployment","text":"Each deployment MUST be configured for a minimum fault tolerance of 2 instances.","title":"[IDM.TRAIN.00054] Redundant Deployment"},{"location":"train/train/#proof-of-concept","text":"","title":"Proof of Concept"},{"location":"train/train/#idmtrain00055-architecture-changes","text":"All Architecture Changes MUST be aligned with the contractor before implementation.","title":"[IDM.TRAIN.00055] Architecture Changes"},{"location":"train/train/#system-features","text":"","title":"System Features"},{"location":"train/train/#trust-framework-and-trust-list-provision","text":"","title":"Trust Framework and Trust List Provision"},{"location":"train/train/#description-and-priority-trust-framework-and-trust-list-provision","text":"The feature Trust Framework and Trust List Provision is responsible for configuring and managing trust frameworks with its corresponding trust lists for hosting the trust list VC for anchoring the service end points to the DID Document transferring the data to be anchored in the DNS using the Zone Manager Handler. Please refer to the source code on [LIGHTEST.TSPA] for integrating the Trust Framework and Trust List Provision with the Zone Manager.","title":"Description and Priority - Trust Framework and Trust List Provision"},{"location":"train/train/#stimulusresponse-sequences-trust-framework-and-trust-list-provision","text":"Figure 2Trust Framework and Trust List: Stimulus/Response Sequences","title":"Stimulus/Response Sequences - Trust Framework and Trust List Provision"},{"location":"train/train/#functional-requirements-trust-framework-and-trust-list-provision","text":"Functional Requirements Trust Framework Configuration Trust List Management Federation specific Framework and Trustlists Participant specific Frameworks and Trustlists Organization specific Frameworks and Trustlists Zone Manager Handler","title":"Functional Requirements - Trust Framework and Trust List Provision"},{"location":"train/train/#trusted-content-resolver","text":"","title":"Trusted Content Resolver"},{"location":"train/train/#description-and-priority-trusted-content-resolver","text":"The Trusted Content Resolver feature is responsible for the Trust Discovery and Trust Validation functionalities based on the input from the Verifiable Credential / Verifiable Presentation. The trust discovery process is realized through the DNS Resolver and the Universal DID Resolver. This feature MUST also be able to validate the cryptographic signatures of the VC and the trust list. It MUST also be able to differentiate different trust lists based on the data anchored in the VC. It MUST be able to validate the institutional trust of credentials by using issuer details on the trust list. The discovery traverse mechanism MUST be mathematically improved using efficient search algorithms (e.g., Merkle Trees). The service MUST be available as connection libraries in GO, JAVA, Javascript, python languages. The libraries SHOULD be user configurable for different input (e.g., service endpoint type: gxfs-issuer-list, gxfs-self- description) and output formats (e.g., json with defined parameters (service name, digital id, etc.). The Trusted Content Resolver MUST be able to integrate with TSA to validate the trust via libraries mentioned in the above programming languages.The service should also be dockerized and easily integrable with existing systems to validate the trust.","title":"Description and Priority - Trusted Content Resolver"},{"location":"train/train/#stimulusresponse-sequences-trusted-content-resolver","text":"Figure 3 Trusted Content Resolver: Stimulus/Response Sequences","title":"Stimulus/Response Sequences - Trusted Content Resolver"},{"location":"train/train/#functional-requirements-trusted-content-resolver","text":"Functional Requirements Trust Discovery Validation Translate XML Translate JSON","title":"Functional Requirements - Trusted Content Resolver"},{"location":"train/train/#dns-zone-management","text":"","title":"DNS Zone Management"},{"location":"train/train/#description-and-priority-dns-zone-management","text":"The DNS Zone Management feature is responsible for managing the DNS zone file and used for anchoring the trust framework DID information into the zone file. This feature is also responsible for resigning the zone file based on DNSSEC for every new update in the zone file. The implementation approach MUST be based on https://github.com/H2020LIGHTest/ZoneManager with the latest python version. The DNS server used for the backend MUST be NSD and KnotDNS. The service MUST be dockerized.","title":"Description and Priority - DNS Zone Management"},{"location":"train/train/#stimulusresponse-sequences-dns-zone-management","text":"Figure 4 DNS Zone Management: Stimulus/Response Sequences*","title":"Stimulus/Response Sequences - DNS Zone Management"},{"location":"train/train/#functional-requirements-dns-zone-management","text":"Functional Requirement Zone Manager","title":"Functional Requirements - DNS Zone Management"},{"location":"train/train/#verification","text":"","title":"Verification"},{"location":"train/train/#core-verification-requirements","text":"All listed verification items/criterias MUST be fulfilled by a demonstration of the implementation within the provided Kubernetes environment.","title":"Core Verification Requirements"},{"location":"train/train/#idmtrain00056-kubernetes-deployment","text":"If the verification is related to software components, it MUST be deployed in a k8s test cluster and the components must be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration.","title":"[IDM.TRAIN.00056] Kubernetes Deployment"},{"location":"train/train/#support-for-kubernetes","text":"","title":"Support for Kubernetes"},{"location":"train/train/#idmtrain00057-eventing","text":"All eventings MUST be demonstrated based on cloud events specifications together with the kNative[25] broker in a Kubernetes environment.","title":"[IDM.TRAIN.00057] Eventing"},{"location":"train/train/#25-httpsknativedevdocseventing","text":"","title":"[25] [https://knative.dev/docs/eventing/]"},{"location":"train/train/#idmtrain00058-config-map-support","text":"Each service MUST be demonstrated up and running in Kubernetes, configured by config maps.","title":"[IDM.TRAIN.00058] Config Map Support"},{"location":"train/train/#idmtrain00059-helm-installation","text":"The service installation MUST be demonstrated during HELM install.","title":"[IDM.TRAIN.00059] Helm Installation"},{"location":"train/train/#idmtrain00060-argocd-integration","text":"The helm chart MUST be able to install inside of argoCD. This includes the usage of the postgres hooks[26] and the provisioning of usable values.yaml(s) for all developed services.","title":"[IDM.TRAIN.00060] ArgoCD Integration"},{"location":"train/train/#26-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesgxfs-integration-treemainhelmchartspostgresql-hook","text":"","title":"[26] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration/-/tree/main/helm/charts/postgresql-hook]"},{"location":"train/train/#idmtrain00061-scs-environment","text":"All HELM installations MUST run on SCS (Sovereign Cloud Stack). The [final acceptance] demonstration cannot be realized on azure, google cloud etc.","title":"[IDM.TRAIN.00061] SCS Environment"},{"location":"train/train/#functionality-acceptance-criteria","text":"","title":"Functionality Acceptance Criteria"},{"location":"train/train/#idmtrain00062-zone-managertspa-configuration","text":"A domain was registered, and a DNSSec Server is linked to it. The product Zone Manager was installed on a machine, and it MUST be possible to link the Zone Manager with the DNSSec Server. The Zone Manager Handler MUST be configured to allow access to the zone manager (internal API). After this, using TSPA Trust Frameworks and DIDs can be published over the Zone Manager Handler into the zone file. After the rollout, using the endpoints of the TSPA with Dig commands and queries, the Trust Framework and DID (PTR and URI RR) of the Zone File are resolvable.","title":"[IDM.TRAIN.00062] Zone Manager/TSPA Configuration"},{"location":"train/train/#idmtrain00063-trust-zone-demonstration","text":"Trusted Content publishing and resolution MUST be demonstrated over a public domain with DNSsec functionality. Various entries MUST be added to the zone and be resolved by the Trusted Content Resolver.","title":"[IDM.TRAIN.00063] Trust Zone Demonstration"},{"location":"train/train/#idmtrain00064-trust-framework-cross-linking-demonstration","text":"Cross-linking of Trust Frameworks MUST be demonstrated over two public domains with DNSsec functionality. A cross-link from one trust framework on domain 1 (using the PTR Record) MUST reference another Trust Framework on domain 2. Various entries MUST be added to the Trust Frameworks on domain 1 and domain 2 and be correctly resolved by the Trusted Content Resolver.","title":"[IDM.TRAIN.00064] Trust Framework cross-linking Demonstration"},{"location":"train/train/#idmtrain00065-trust-framework-and-did-enrollment","text":"Trust Frameworks and their corresponding DIDs MUST be enrolled using API endpoints offered by the TSPA. The enrolled details MUST be reflected in the database and the DNS Zone file of the Name server.","title":"[IDM.TRAIN.00065] Trust Framework and DID Enrollment"},{"location":"train/train/#idmtrain00066-trusted-list-management-using-api-endpoints","text":"The Trust List content MUST be managed using API endpoints. Separate API endpoints MUST be available for performing CRUD Operations.","title":"[IDM.TRAIN.00066] Trusted List Management using API endpoints"},{"location":"train/train/#idmtrain00067-trusted-content-resolver-resolves-trust-zone-pointers","text":"The trusted content resolver is called by a Trust Framework Pointer (URL/DNS Name). The resolver recognizes that a DNS query must be made and it's starting to resolve the records about other Trust Framework Pointers (if applicable). After resolving the entire Zone, the DIDs of the RR/URI Records can be resolved as usual. Output is a List of Pointers which the resolver returns.","title":"[IDM.TRAIN.00067] Trusted Content Resolver resolves Trust Zone Pointers"},{"location":"train/train/#idmtrain00068-trusted-content-resolver-resolves-trusted-content","text":"The trusted content resolver is called by a DID, and a list of requested content types. The resolver resolves the DID, iterates through the service endpoint references, and returns a list of trust lists (no DID documents), regarding the given DID. The DID documents for the resolved references can be found in a second list.","title":"[IDM.TRAIN.00068] Trusted Content Resolver resolves Trusted Content"},{"location":"train/train/#idmtrain00069-trusted-content-resolver-validates-institutional-trust-of-a-verifiable-credential","text":"The issuer details of a credential MUST be validated with the resources found from the Trust List. This MUST be demonstrated with Trust Frameworks that are cross-linked to other Trust Frameworks (hosted on different domains) as well as Trust Frameworks that do not include a cross-linking. This MUST be available as integratable libraries for programming languages GO, Javascript, python and Java. Software Requirements Specification for IDM.TRAIN 30","title":"[IDM.TRAIN.00069] Trusted Content Resolver validates institutional trust of a Verifiable Credential"},{"location":"train/train/#annex-a-train-overview","text":"Software Requirements Specification for IDM.TRAIN 31","title":"Annex A: TRAIN Overview"},{"location":"train/train/#annex-b-overview-gxfs-work-packages","text":"The project \"Gaia-X Federation Services\" (GXFS) is an initiative funded by the German Federal Ministry of Economic Affairs and Energy (BMWi) to develop the first set of Gaia-X Federation Services, which form the technical basis for the operational implementation of Gaia-X. The project is structured in five Working Groups, focusing on different functional areas as follows: Work Package 1 (WP1): Identity & Trust Identity &Trust covers authentication and authorization, credential management, decentral Identity management as well as the verification of analogue credentials. Work Package 2 (WP2): Federated Catalogue The Federated Catalogue constitutes the central repository for Gaia-X Self-Descriptions to enable the discovery and selection of Providers and their Service Offerings. The Self-Description as expression of properties and Claims of Participants and Assets represents a key element for transparency and trust in Gaia-X. Work Package 3 (WP3): Sovereign Data Exchange Data Sovereignty Services enable the sovereign data exchange of Participants by providing a Data Agreement Service and a Data Logging Service to enable the enforcement of Policies. Further, usage constraints for data exchange can be expressed by Provider Policies as part of the Self-Description Work Package 4 (WP4): Compliance Compliance includes mechanisms to ensure a Participant's adherence to the Policy Rules in areas such as security, privacy transparency and interoperability during onboarding and service delivery. Work Package 5 (WP5): Portal & Integration Gaia-X Portals and API will support onboarding and Accreditation of Participants, demonstrate service discovery, orchestration, and provisioning of sample services. Further general information on the Federation Services can be found in [TAD].","title":"Annex B: Overview GXFS Work Packages"},{"location":"traincd/traincd/","text":"Gaia-X Federation Services for Identity & Trust Trust Management Infrastructure for Gaia-X Concept Document 1 Motivation 2 Introduction 3 Vision 4 Assumptions & Side Conditions 5 Concept 5.1 Role of the DNS/DNSSEC 5.2 Functional Roles and Components in TRAIN 5.3 Integration with Verifiable Credentials 5.4 Unified Signature & Verification Model for Trust Lists via DID and VC 5.5 Trust Verification 5.6 Sequence Diagram: Trust List Initialization, Trust List Enrolment and Update, Trust Discovery and Validation 5.7 Initial Integration into Trust Framework Memberships 5.8 Cross-Referencing of Trust Framework Memberships 5.9 Integration into a New Trust Framework with existing Credentials 5.10 Integration with TSA 5.11 Integration with OCM 5.12 Integration with Notary 5.13 Required Trust Lists for Gaia-X 5.14 Trust List Formats 6 Trusted Content Handling 6.1 Trusted Content Locations 6.2 Enrolment Process of Entities in Trust Lists 6.3 Trusted Content Resolving 6.4 Trusted Content Auditing 6.5 Setup Process for Trust Verification 6.6 Packages for Programming Languages 7 Conclusion and Consequences 7.1 Security consolidations and implications 7.2 Advanced Concepts 7.2.1 Integration with the Ethereum Name Service (ENS) 7.2.2 Establishment of Trust against Man-in-the-Middle Attacks: PCM and OCM 7.2.3 Verification of the Verifier from the Holder 7.2.4 Support of Federation Membership Verification in the OIDC4VP Standard List of Figures Figure 1 TRAIN in the \"Triangle of Trust\" Figure 2 TRAIN in the \"Triangle of Trust\" -- Trusted Issuers Figure 3 Overall Vision for TRAIN Figure 4 Overview TRAIN Concept Figure 5 TRAIN Archimate Diagra Figure 6 Cross-Referencing of Trust Framework Memberships Figure 7 TRAIN integration with the Notary Figure 8 Trusted Content Resolver Figure 9 TRAIN in the \"Triangle of Trust\": Trusted Verifiers List of Tables Table 1 DNS & Resource Records Table 2 Comparison: Roles and Components in TRAIN with other trust concepts Table 3 Cross-Referencing of Trust Framework Memberships: DNS and Resource Records Table 4 Procedures for auditability requirements Motivation The Gaia-X Trust Framework requires a decentralized, flexible, scalable, and interoperable Trust Model to manage information on trusted entities, federations or participants in the ecosystem. Individual federations have to be able to define and manage their trust anchors in a sovereign way, while at the same time these trust domains have to be interoperable across federations. Decentralized identity management technology is currently developing fast. At the same time, multiple trust domains exist. It might be overly optimistic to settle on one specific decentralized identity technology and trust domain. Hence, the trust management infrastructure, as defined in this document, aims to be agnostic towards the specific decentralized identity technology, ledger and framework (e.g., EBSI, Indy). Its goal is to bridge different trust domains and to allow individual entities and frameworks to make sovereign trust decisions. Parts of this document are based on the work of the ICAM Gaia-X Community. Introduction The trust management infrastructure enables the establishment of a root of trust for entities acting in the Gaia-X ecosystem and credentials issued by these entities. This is achieved through the introduction of trust lists combined with anchoring of pointers in the DNS following the TRAIN (Trust Management Infrastructure) concept. These lists, published by Governance Authorities, include entities that are certified according to a certain Trust Framework that is maintained by the respective governance authority. This, for example, supports verifying entities in examining the trustworthiness of Issuers through inclusion in trust lists under a specific trust framework that is administered by a specific governance authority. Gaia-X Federations and other entities are supported in the sovereign publication and administration of trust lists for specific trust frameworks. This approach addresses the main trust challenges in the standard SSI triangle as sketched in figure 1: Figure 1: TRAIN in the \"Triangle of Trust\" A flexible trust management infrastructure can address the trust challenges as mentioned above. An example for Challenge C1: Trusted issuers is given in figure 2. This approach leverages the well-established global Domain Name Service (DNS and DNSSEC) and combines it with the decentralized Gaia-X SSI approach. To publish and identify the correct trust lists as well as establish a chain of trust, the widely accepted DNS is leveraged. Figure 2: TRAIN in the \"Triangle of Trust\" -- Trusted Issuers This Trust Management Infrastructure concept is based on the use of Trust Lists for trusted entities. Trust Lists might not be optimal for all use cases and at all levels to ensure trust. This is why the Chained Credentials Concept[1] is regarded as complementary to the Trust List approach, that is in the focus of this document. Vision The TRAIN (Trust Management Infrastructure) for Gaia-X will be used to publish lists of trusted entities that are enrolled by a trustable authority. An example could be a specific Gaia-X Federation enrolling its member companies in a member trust list. In the following TRAIN will be abbreviated if this Infrastructure is used. TRAIN will allow individual entities (e.g., individual companies, federations that are Gaia-X accredited, federations without Gaia-X accreditation) to make trust statements to support individual trust decisions by sovereign entities. At the same time, depending on individual preference, trust decisions can also be delegated between entities. As an example, companies can decide to trust all enrolled members of a certain (parallel acting) federation. Federations can also link their trust framework to the trust framework of a different federation. To enable this, authorities like the Gaia-X AISBL and individual Gaia-X Federation operators will act as governance authorities that operate trust frameworks and enroll trustable entities in their trust lists. TRAIN makes use of the DNS(DNSSEC) as a fundamental and well-established anchor to discover and validate trust. In order for an entity to be able to set up a trust list, it has to control a DNS domain to create a Trust Framework (Trust Scheme) in its DNS record and to set pointers to the Trusted Content, specifically the Trust List, in its DNS record. The DNS hostname is then embedded into the meta section (TermsOfUse) of verifiable credentials by entities claiming enrollment in the Trust Framework of a specific Trust Framework operator. Verifying entities use the DNS hostname to resolve trusted content and validate the inclusion of entities in Trust Frameworks - according to their trust requirements, as they can define which Trust Frameworks (via their DNS hostnames) to trust. For setting up a trust list and enrolling members, the respective Gaia-X Federation performs the following steps[2]: The federation requires a fully qualified domain name (FQDN). This domain name has to be configured using the \"Well Known DID\" configuration[3] which gives the [ability for a DID controller to prove they are the same entity that controls an origin.] The DID used for the Well Known DID configuration is published in the DNS URI Resource Record of the domain - it serves as a pointer to resolve the location and key material for the trust list. [1] [https://wiki.trustoverip.org/display/HOME/ToIP+Trust+Registry+Protocol+Specification#ToIPTrustRegistryProtocolSpecification-CredentialChaining ] [2] [ [For the sake of clarity, some, mainly technical steps have been abbreviated here. They are included in the sequence diagram below.] ] [3] [https://identity.foundation/.well-known/resources/did-configuration/] A trust list in JSON format[4] is created. The trust list is published on a Trust List Data store (a web server or the IPFS - depending on the specific requirements). The DIDs of specific member organizations that comply with the requirements of the Trust Framework of this Gaia-X Federation to the federation member are added to that trust list. A Verifiable Credential (VC) with the Location of the Trust List in the credential subject is created. The location of this VC is included as a Service Endpoint in the DID Document for the DID that was associated with the DNS domain. DID document is published (on a web server or ledger - depending on the specific requirements). The organizational, regulatory/legal, and technical measures to assert trust-relevant aspects for enrollment of companies are defined in the Trust Framework for this Gaia-X federation. Publishing trust lists, setting pointers to trust lists, enrollment, discovery as well as querying of trust lists will be supported by respective components as described in this concept. Although the TRAIN infrastructure uses the DNS for lookups, the trust frameworks, (optional JSON schemas) and trust lists are distributed on the web (or in the IPFS) and are not stored in the DNS. There can be different instances of trust lists and trust frameworks hosted by different trust framework operators (institutions providing trust frameworks, for example: a Gaia-X Federation operating a Trust Framework for its members. The verifying entity alone can decide which existing trust frameworks and trust lists (for example: the trust framework of Catena-X) to trust. The overall Vision for TRAIN, over different layers, is described in figure 3. [4] TRAIN also supports Trust Lists in the Format XML, ETSI TS 119 612 that is used for eIDAS (1.0) Trust Schemes, i.e. https://tl.bundesnetzagentur.de/TL-DE.xml . However, for this document we will focus on trust lists in JSON format resolved via DID / VC Figure 3: Overall Vision for TRAIN Any Gaia-X self-sovereign federation controlling a DNS can create their own trust framework and become a trust framework operator e.g., federation1.com . Every entity that has to perform trust decisions decides which trust framework operators to trust for which context. Trust framework operators (or delegated Gaia-X Notaries) perform the onboarding/ offboarding of members in the trust framework. An example could be that these companies are members of Federation1 and therefore are trusted to issue VCs of a certain type (e.g., membership credentials) with a certain schema. The entity operating the trust framework enrolls the members of its trust framework in a trust list. But it can also cross-reference to other trust frameworks. An example could be that a particular trust framework, e.g., federation1.com , with trust framework \" example \" may also trust a second trust framework e.g., \"partners \", of another trust framework operator, e.g., federation2.de . It may wish to include the members of this other trust framework as being equivalent to its own members, but avoid having to enroll each of these members to its own trust list. The trust framework operator would therefore add pointer resource records (PTR RRs) to its DNS trust framework entry (as described in detail below) to point to these other equivalent trust frameworks. The use of PTR RRs forms mappings between trust frameworks and trust lists and enables cross-referencing of trust frameworks without individually enrolling entities into trust lists. Assumptions & Side Conditions The trust management infrastructure makes use of the existing global Domain Name Service (DNS) for discovering information relevant for the validation of trust as described in the concept below. As a distributed database both in terms of organization of data as well as responsibility for operation and management, the DNS is very suitable for an infrastructure that aims to support integration and interoperation of various trust domains of different Gaia-X Federations that are operationalized through Trust Frameworks and Trust Lists. The original design of the DNS did not consider a number of attacks allowing miscreants to alter information retrieved via the DNS. It is susceptible to cache poisoning and MITM attacks, which can lead to false results being returned. The Domain Name Service Security Extensions (DNSSEC) have been developed to mitigate this problem. They allow users of the DNS to verify that the data they received is indeed the data intended. This ability for verification is vital for the use of DNS in the context of a trust infrastructure. Hence, the trust management infrastructure requires acceptance and availability of DNS/DNSSEC as fundamental infrastructure. To ensure an adequate level of security, the use of DNSSEC is required. Concept For a first overview of the TRAIN concept and its relationships, please refer to the following Archimate diagram. The subsequent sections will cover the main aspects of the concept. [ Figure 4: Overview TRAIN Concept Role of the DNS/DNSSEC A Gaia-X Federation controlling a DNS record can set up one or multiple Trust Frameworks with one or multiple trust lists, for example for creating a member trust list. To do this, it performs the following steps: The DNS controller creates a DNS entry with the name of its trust framework e.g., example.federation1.com ., or partners.federation2.de. . Then below this, two further DNS entries named _trust and _scheme respectively are created. The names of these two entries were specified by the EU Lightest project[5], and TRAIN is following those guidelines. Here, example is the name of the Framework, federation1.com is the authority responsible for the Trust Framework, and _scheme._trust are standardized constant terms used across the TRAIN trust infrastructure. The bottom entry, e.g., _scheme._example.federation1.com , contains one or more PTR RRs. Each PTR RR points to a DNS entry where the location of a trust list can be found, in a URI RR[6]. This use of PTR RRs allows one Trust Framework to point to several trust lists, for example, one Gaia-X Federation could point to the equivalent trust frameworks of different Gaia-X Federations. It also allows one trust list to be incorporated into multiple trust frameworks. DNS Resource Records PTR _scheme._example.federation1.com. PTR _scheme._partners.federation2.de. URI [https://some.org/trust_list] / did:web:xyz... Table 1: DNS & Resource Records Functional Roles and Components in TRAIN The table below compares roles and components in TRAIN with other trust concepts currently being developed. Description Term in Gaia-X Term in EBSI Terms in other Concepts Organizational authority certifying trustworthiness of entities and enrolling them into the list of trusted entities, maintaining the list(s)/registrie(s) and organizational framework Trust Framework (AISBL, Federator of a specific Gaia-X Federation) Trusted Accreditation (TAO, Organisation) Governance Authority, Trust Scheme Provider Defined organizational, regulatory/legal, and technical measures to assert trust-relevant attributes for enrolled entities (in a certain domain) Gaia-X Trust Framework, Frameworks of specific Federations Use-case Policies Trust Framework, Trust Scheme, Governance Framework List of trusted entities in specific data file/format certified by a maintaining authority Trust List (JSON or XML following ETSI TS 119 612) Registry of Issuers (on EBSI Ledger) as Smart Contract Trust Registry, List of Trusted Entities (Issuers etc.) Formalized set of rules to automate trust decisions for individual transactions (Trust) Policy (REGO) Not defined or unknown n/a Table 2: Comparison: Roles and Components in TRAIN with other trust concepts [5] Wagner, S.; Kurowski, S.; Laufs, U.; Ro\u00dfnagel, H.: A mechanism for discovery and verification of trust scheme memberships: the LIGHTest Reference Architecture, in Open Identity Summit 2017 - Proceedings, Lecture Notes in Informatics (LNI), Bonn: K\u00f6llen Druck + Verlag GmbH, pp. 81\u201392, 2017. [6] This step is abbreviated here. Both, a URL or a DID can be used as URI to point to the trust list. In case of the DID the trust list will be resolved via a verifiable credential that is located over the DID. Integration with Verifiable Credentials Every VC that is issued by an entity that claims to be in a certain Trust Framework must contain a standard Terms of Use property (according to W3C Verifiable Credentials Data Model 1.0). The Terms of Use contains the DNS names of the trust framework(s) that the issuer claims to be a member of. For this, there must at least be one \"trustScheme\" defined, as in the following example: [\\\"trustScheme\\\" : [ \"example . federation1.com\" , \"partners . federation2.de\" ]. ] If schemas are also to be included in the trust framework, the credential must also contain a standard credentialSchema property listing the URL where the schema can be found, along with the syntax of the schema. As with claimed trust framework memberships, these could be true or false statements. In any case, the Verifier will check the claims using TRAIN. What counts in the end is the actual inclusion of the details into the trust list of the Trust Framework Operator as defined in the enrollment process. An example for the format of the TRAIN Terms of Use property is given below: \"termsOfUse\":[{ \"type\": \"train\", \"id\": \"https://train.trust-scheme.de/info\", \"trustScheme\": \"example.federation1.com\", \"partners.federation2.de\" }] Optional reference to a credential schema: \"credentialSchema\": { \"id\": \"[https://train.trust-scheme.de/schema/membershipCredential-schema.json]\", \"type\": \"JsonSchemaValidator2018\" } Unified Signature & Verification Model for Trust Lists via DID and VC The Unified Signature & Verification model for Trust List via DID and VC allows trust lists across trust domains to be signed and verified uniformly using Verifiable Credentials (VC). This is achieved by enveloping the storage location of the Trust List (Trusted Data Store, e.g., https url or IPFS) in the credential subject of a Verifiable Credential. The entity operating the trust framework (the Federator) is responsible for signing the VC with its proof. The signature approach is as follows: A DID is created and associated with the DNS domain under the control of the trust framework operator (the Federator) following the Well Known DID configuration approach[7]. [7] [https://identity.foundation/.well-known/resources/did-configuration/] The DID is stored in the DNS PTR record URI A DID Document is created for the DID and stored on a ledger/IPFS/https URL resource. The DID document defines a Service End Point with the URI to a Verifiable Credential / Presentation The Verifiable Credential / Presentation is created so that it can be resolved via the URI in the DID Document. The Credential Subject of the VC/VP contains the URI to resolve the Trust List. The VC/VP is signed so that it can be validated with the public key from the DID Document. The Trust List is stored at the Trusted Data Store at the location (IPFS/https web resource) defined in the Credential Subject of the VC The verification process is described in the next section. Trust Verification To verify the inclusion of an entity in a specific trust framework, minimum two specific inputs are required: The trust framework reference (Trust Framework Pointer), that is embedded as a DNS name in the termsofUse object of the VC (see section \"Trusted Content Resolving\" below). The URI of the VC issuer, obtained from the VC. The URI of the issuer is flexible and may depend on the backend technology being used by the VC ecosystem. For example: the URI can be a DID that could be anchored in a blockchain/distributed ledger, but it could also be a https URL from a PKI or it could also be a UUID. The TRAIN trust verification is not restricted by the backend technology behind the VC in the respective SSI ecosystem used in Gaia-X. If a user needs a certain service-specific information they can restrict it by adding additional parameters to the inputs. For example: If a Trust Verifier needs to process only DID requests, the user can include an input called ServiceDigitalIdentity: \"DID\". Thereby the verifier after verification process will return only those identities specific to the DID as output. The trust verification is performed by a trust verification component denoted \"Trusted Content Resolver\" (see also the Sequence Diagram below, in TRAIN also called ATV: Automatic Trust Verifier). The registration/enrolment process is also elaborated in the respective section further below. The \"TSPA/Federator\" is located at the authority operating the trust framework, e.g., a specific Gaia-X Federation. The trust list is detailed further below in the respective section. Based on the Trust Framework Pointer as DNS name in the termsOfUse, the Trusted Content Resolver will first attempt to connect to the DNS name server that holds the entries of the trust framework operator using DNSSEC. This provides an unbroken chain of trust from the root DNSKEY RR set to the Trust Framework's DNS entries. However, if DNSSEC is not available, it will use standard DNS. The use of DNS without DNSSEC is not recommended as described in the Security Considerations below. The reason for this is that support for DNSSEC might not be within the control of the Trust Framework Operator. If participants still prefer to use TRAIN and are willing to accept the risks, they can use TRAIN with only DNS and are not forced to wait until DNSSEC is available to them. We recognize that this leaves the trust framework open to certain attacks, such as DNS MITM and cache poisoning, but Trust Framework Operators and verifiers can perform this risk assessment before deciding to use TRAIN without DNSSEC. The verification process is as follows: The Trusted Content Resolver will read the PTR RRs of the DNS domain resolved from the trust framework reference (Trust Framework Pointer). There the Trusted Content Resolver dereferences the URI RRs , and expects to find a DID . The Well Known DID configuration verification is performed.[8] [8] [https://identity.foundation/.well-known/resources/did-configuration/] From the DID the Trusted Content Resolver resolves a DID Document which via its Service Endpoint leads to a Verifiable Credential/Verifiable Presentation . The proof of the VC/VP is validated against the public keys of the DID Document. The Credential Subject of the VC/VP is ready to obtain the URI of the Trust List (at a https URL or IPFS resource). The trust list is resolved and the Trusted Content Resolver checks if the specific entity is listed in the trust list. If this is the case, the Trusted Content Resolver will return that the claimed entity is a member of the trust framework operated by this \\\"DNS name\\\". Likewise, the VC schema can be checked. Hence, it does not matter whether the entity was telling the truth when it claimed membership of a certain trust framework. The Trusted Content Resolver and the DNS controller/trust framework operator establish the root of trust. The source code for a sample implementation of the Trusted Content Resolver component is available under Apache 2.0 (developed in the ESSIF-TRAIN Project and called ATV: Automatic Trust Verifier). The Trusted Content Resolver can be automated through policy languages (the ATV implementation supports TPL - Trust Policy Language) or other languages like REGO as foreseen for GXFS. Trusted Content Resolvers can be run by any entity, so that there can be multiple distributed copies of this service running in clouds as backup services or completely locally under sovereign control. The existing Trusted Content Resolver (ATV) implementation also offers a \"TRAIN API\" allowing to initiate the trust verification process using the POST API Service and to return the result to the verifier.[9] [9] [https://essif.trust-scheme.de/swagger_train/ ] An overview of TRAIN and the integration with GXFS is given in the Archimate Diagram in figure 5. Integration with other GXFS components is described in further details in the sections below. Sequence Diagram: Trust List Initialization, Trust List Enrolment and Update, Trust Discovery and Validation The sequence diagram in figure 5 summarizes what was described above and gives an overview of the central steps to: initially set up of a Trust List (Trust List Initialization) update the Trust List, e.g., to add new entities (Trust List Enrolment and Update) discover the correct Trust List and validate the trust (Trust Discovery and Validation) Figure: TRAIN Archimate Diagra Initial Integration into Trust Framework Memberships For an entity to be enrolled into a specific trust framework, the DID and potentially additional relevant information for the entity (see exemplary trust lists below) must be added to the Trust List of this trust framework. For this, the TSPA/Federator performs CRUD operations on the Trust List located on the Trust List Data Store. The initial integration into Trust Framework Memberships is being triggered via the Notary. Please refer to the Section \"Integration with Notary\" for details. Cross-Referencing of Trust Framework Memberships The entities operating a Trust Framework are able to cross reference other Trust Framework Memberships using the PTR record. Hence, the DNS record of Trust Framework 1 will hold the DNS hostname pointer for Trust Framework 2 that is being trusted by Trust Framework 1. This would then imply that a verifier trusting Trust Framework 1 will automatically also trust the entities that are enrolled in Trust Framework 2. This way, Trust Framework 1 will not have to individually enroll all entities enrolled in Trust Framework 2 but can simply cross-reference to the other framework. An example is given by the figure 6 and table 3. Moreover, during Verifiable Credential issuance, entities can include multiple Trust Framework membership pointers in the termsOfUse (e.g., \"trustScheme\":\"example.federation1.com\", \"partners.federation2.de\" to claim memberships in multiple trust frameworks. Figure 6: Cross-Referencing of Trust Framework Memberships DNS Resource Records PTR _scheme._example.federation1.com. PTR _scheme._partners.federation2.de. URI [https://some.org/trust_list] did:web:xyz... Table 3: Cross-Referencing of Trust Framework Memberships: DNS and Resource Records Integration into a New Trust Framework with existing Credentials Using TRAIN, the enrollment of an entity into a new Trust Framework is immediately reflected and does not require an update of already issued credentials. This can be achieved by leveraging the PTR record cross-referencing of Trust Frameworks as explained above to enroll into a new Trust Framework. This could be illustrated as follows: An exemplary \"Federation X\" maintains a trust list of members for the Trust Framework \"Members Federation X\" and gives out VCs. In their terms of use, these VCs include the DNS hostname pointer \"trustScheme\": \"members.federationX.com\" to claim membership in the Trust Framework \"Members Federation X\". Federation X is not a member of the Trust Framework of the \"Example-Dataspace\" (with the Trust Framework identified by the DNS hostname accredited.exampleDatataspace.com as it has not been accredited.) A validating entity that has configured their Trusted Content Resolver to trust VCs issued under the Trust Framework members.federationX.com will be able to validate these credentials as trustworthy. However, if a validating entity has configured their Trusted Content Resolver to only trust VCs issued under the Trust Framework accredited.exampleDatataspace.com, it will not be able to validate these credentials as trustworthy. Now, Federation X gets accredited according to the Trust Framework of Example-Dataspace. Example-Dataspace will therefore add a PTR record pointer to members.federationX.com right into their DNS under accredited.exampleDatataspace.com to reference the Trust Framework of Federation X as trustworthy. A validating entity that receives the DNS hostname pointer \"trustScheme\":\"members . federationX.com\" that has configured their Trusted Content Resolver to trust VCs issued under the Trust Framework accredited.exampleDatataspace.com will now be able to follow the PTR record pointer to members.federationX.com under the PTR record of accredited.exampleDatataspace.com and validate these credentials as trustworthy - without any changes in the initially issued credentials. Integration with TSA The Trust Services API (TSA) can integrate the Trusted Component Resolver Libraries to verify the institutional trust of the verifiable credentials. Integration with OCM The Organization Credential Manager (OCM) can use the TSA to validate the trust of the organizational verifiable credentials (via the Trusted Component Resolver Libraries) before storing them in the wallet. Integration with Notary The Notary uses the TSPA Connector to enroll trusted entities into the trust framework and add them via the TSPA/Federator to the Trust List. The integration with the Notary is illustrated in figure 7: Figure 7: TRAIN integration with the Notary Required Trust Lists for Gaia-X Certain trust aspects will be covered through the use of chained credentials. For others, trust lists are more efficient. Hence, the following trust lists are foreseen: One Gaia-X Federations Trust List (one single Trust List operated by Gaia-X AISBL for the Gaia-X Federations that are conformant to the general Gaia-X Trust Framework) Trust List of Notaries operated by Gaia-X AISBL (one single Trust List operated by Gaia-X AISBL for the Notaries that are conformant to the general Gaia-X Trust Framework) Multiple Federation Participants Trust Lists (one Trust List operated by each Federation , listing the participants of this Federation that are conformant to its Trust Framework) Multiple Trust Lists of Notaries operated by Federations (one Trust List operated by each Federation , listing the Notaries that are trusted by each Federation and their services offered and credentials issued) Multiple Participant Trust Lists (one Trust List operated by each Participant , listing the services offered and credentials issued by each participant) Multiple Participant Notaries Trust Lists (one Trust List operated by each Participant , listing the Notaries that are trusted by each Participant and their services offered and credentials issued) Further Trust Lists for additional entities or application scenarios are possible. Trust List Formats Trust Lists used by TRAIN contain all the enrolled entities (e.g., Members of a Gaia-X Federation) in a specific data file/format certified by the Trust Framework authority (e.g., the respective Gaia-X Federation operating the Trust Framework). Trust lists for Gaia-X are referenced from a VC (the location is embedded into the credential subject) and the content can be in JSON-LD or in XML-Format. An exemplary trust list in XML Format (following the ETSI TS 119 612 standard, a JSON example is shown after this) is given in the following: [\\<TrustServiceStatusList xmlns=\\\"http://uri.etsi.org/02231/v2#\\\" xmlns:ns2=\\\"http://www.w3.org/2000/09/xmldsig#\\\" xmlns:ns3=\\\"http://uri.etsi.org/01903/v1.3.2#\\\" xmlns:ns4=\\\"http://uri.etsi.org/02231/v2/additionaltypes#\\\" xmlns:ns5=\\\"http://uri.etsi.org/TrstSvc/SvcInfoExt/eSigDir-1999-93-EC-TrustedList/#\\\" xmlns:ns6=\\\"http://uri.etsi.org/01903/v1.4.1#\\\" TSLTag=\\\"http://uri.etsi.org/19612/TSLTag\\\">] [\\<SchemeInformation>] [ \\<TSLVersionIdentifier>5\\</TSLVersionIdentifier>] [ \\<TSLSequenceNumber>1\\</TSLSequenceNumber>] [ \\<TSLType>http://uri.etsi.org/TrstSvc/TrustedList/TSLType/EUgeneric\\</TSLType>] [ \\<SchemeOperatorName>] [ \\<Name xml:lang=\\\"en\\\">Federation 1 Notary\\</Name>] [ \\</SchemeOperatorName>] [ \\<SchemeOperatorAddress>] [ \\<PostalAddresses>] [ \\<PostalAddress xml:lang=\\\"en\\\">] [ \\<StreetAddress>Lichtstra\u00dfe 43h\\</StreetAddress>] [ \\<Locality>K\u00f6ln\\</Locality>] [ \\<PostalCode>50825\\</PostalCode>] [ \\<CountryName>DE\\</CountryName>] [ \\</PostalAddress>] [ \\</PostalAddresses>] [ \\<ElectronicAddress>] [ \\<URI xml:lang=\\\"en\\\">mailto:mail@federation1.com\\</URI>] [ \\<URI xml:lang=\\\"en\\\">https://www.federation1.com\\</URI>] [ \\</ElectronicAddress>] [ \\</SchemeOperatorAddress>] [ \\<SchemeName>] [ \\<Name xml:lang=\\\"en\\\">DE:TRAIN\\</Name>] [ \\</SchemeName>] [ \\<SchemeInformationURI>] [ \\<URI xml:lang=\\\"en\\\">https://dl.gi.de/handle/20.500.12116/38702\\</URI>] [ \\</SchemeInformationURI>] [ \\<StatusDeterminationApproach>http://uri.etsi.org/TrstSvc/TrustedList/StatusDetn/EUappropriate \\</StatusDeterminationApproach>] [ \\<SchemeTypeCommunityRules>] [ \\<URI xml:lang=\\\"en\\\">https://train.trustscheme.de /schemerules/ngi.train.trustscheme.de \\</URI>] [ \\</SchemeTypeCommunityRules>] [ \\<SchemeTerritory>GLOBAL\\</SchemeTerritory>] [ \\<PolicyOrLegalNotice>] [ \\<TSLLegalNotice xml:lang=\\\"en\\\">This is an experimental list for the GXFS Federation Notary.\\</TSLLegalNotice>] [ \\</PolicyOrLegalNotice>] [ \\<HistoricalInformationPeriod>65535\\</HistoricalInformationPeriod>] [ \\<ListIssueDateTime>2022-09-27T00:00:00Z\\</ListIssueDateTime>] [ \\<NextUpdate>2022-12-27T00:00:00Z\\</NextUpdate>] [\\</SchemeInformation>] [\\<TrustServiceProviderList>] [ \\<TrustServiceProvider>] [ \\<UID>] [ \\<Name xml:lang=\\\"en\\\">2325\\</Name>] [ \\</UID>] [ \\<TSPCurrentStatus>] [ \\<Name xml:lang=\\\"en\\\">Active\\</Name>] [ \\</TSPCurrentStatus>] [ \\<StatusStartingTime>] [ \\<dateTime>2022-11-22T00:00:00Z\\</dateTime>] [ \\</StatusStartingTime>] [ \\<TSPInformation>] [ \\<TSPName>] [ \\<Name xml:lang=\\\"en\\\">Notary 1\\</Name>] [ \\</TSPName>] [ \\<TSPTradeName>] [ \\<Name xml:lang=\\\"en\\\">NTRUK-SC090312\\</Name>] [ \\<Name xml:lang=\\\"en\\\">Notary Federation 1 \\</Name>] [ \\</TSPTradeName>] [ \\<TSPAddress>] [ \\<PostalAddresses>] [ \\<PostalAddress xml:lang=\\\"en\\\">] [ \\<StreetAddress>Lichtstra\u00dfe 43h\\</StreetAddress>] [ \\<Locality>K\u00f6ln\\</Locality>] [ \\<PostalCode>50825\\</PostalCode>] [ \\<CountryName>DE\\</CountryName>] [ \\</PostalAddress>] [ \\</PostalAddresses>] [ \\<ElectronicAddress>] [ \\<URI xml:lang=\\\"en\\\">mailto:mail.notary1@federation.com\\</URI>] [ \\</ElectronicAddress>] [ \\</TSPAddress>] [ \\<TSPInformationURI>] [ \\<URI xml:lang=\\\"en\\\">https://notary1.info/TRAIN/info\\</URI>] [ \\</TSPInformationURI>] [ \\<TSPCertificationList>] [ \\<TSPCertification xml:lang=\\\"en\\\">] [ \\<Type>LEI\\</Type>] [ \\<Value>1234567\\</Value>] [ \\<Scope>\\</Scope>] [ \\</TSPCertification>] [ \\<TSPCertification xml:lang=\\\"en\\\">] [ \\<Type>Gaia-X Compliance\\</Type>] [ \\<Value>1234567\\</Value>] [ \\<Scope>\\</Scope>] [ \\</TSPCertification>] [ \\<TSPCertification xml:lang=\\\"en\\\">] [ \\<Type>eidas\\</Type>] [ \\<Value>1234567\\</Value>] [ \\<Scope>\\</Scope>] [ \\</TSPCertification>] [ \\</TSPCertificationList>] [ \\</TSPInformation>] [ \\<TSPServices>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://participant.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Participant Membership Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://participant.membership.notary1.federation.com\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://principal.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Principal Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://verifier.research.identiproof.io/\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://consumer.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Consumer Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://verifier.research.identiproof.io/\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://resource.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Resource Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://resource.membership.notary1.federation.com\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://onboarding.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Onboarding Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://onboarding.membership.notary1.federation.com\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\</TSPServices>] [ \\</TrustServiceProvider>] [\\</TrustServiceProviderList>] [\\</TrustServiceStatusList>] The details of every entity enrolled in the trust list are described under the attribute \\<TrustServiceProvider>. The ID of the entity is under the attribute \\<IssuerName>. Each entity in the trust list can have a Service Type Identifier under the attribute \\<ServiceTypeIdentifier>. This is a URL, and the web page that it points to should contain the JSON schema (including the \\@context property) for the VCs that are issued for this Service Type. In this way the verifier can find out which attributes the entity is trusted to issue. This trust list also offers the flexibility to the service provider to add different services with different schemas. An example for a trust list in JSON format would look as follows: { \\\"TrustServiceStatusList\\\": { \\\"SchemeInformation\\\": { \\\"HistoricalInformationPeriod\\\": \\\"65535\\\", \\\"ListIssueDateTime\\\": \\\"2022-09-27T00:00:00Z\\\", \\\"NextUpdate\\\": \\\"2022-12-27T00:00:00Z\\\", \\\"PolicyOrLegalNotice\\\": { \\\"TSLLegalNotice\\\": { \\\"#text\\\": \\\"This is an experimental list for the GXFS Federation Notary.\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"SchemeInformationURI\\\": { \\\"URI\\\": { \\\"#text\\\": \\\"https://dl.gi.de/handle/20.500.12116/38702\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"SchemeName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"DE:TRAIN\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"SchemeOperatorAddress\\\": { \\\"ElectronicAddress\\\": { \\\"URI\\\": [ { \\\"#text\\\": \\\"mailto:mail@federation1.com\\\", \\\"@xml:lang\\\": \\\"en\\\" }, { \\\"#text\\\": \\\"https://www.federation1.com\\\", \\\"@xml:lang\\\": \\\"en\\\" } ] }, \\\"PostalAddresses\\\": { \\\"PostalAddress\\\": { \\\"@xml:lang\\\": \\\"en\\\", \\\"CountryName\\\": \\\"DE\\\", \\\"Locality\\\": \\\"K\\u00f6ln\\\", \\\"PostalCode\\\": \\\"50825\\\", \\\"StreetAddress\\\": \\\"Lichtstra\\u00dfe 43h\\\" } } }, \\\"SchemeOperatorName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation 1 Notary\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"SchemeTerritory\\\": \\\"GLOBAL\\\", \\\"SchemeTypeCommunityRules\\\": { \\\"URI\\\": { \\\"#text\\\": \\\"https://train.trustscheme.de /schemerules/ngi.train.trustscheme.de\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"StatusDeterminationApproach\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/StatusDetn/EUappropriate\\\", \\\"TSLSequenceNumber\\\": \\\"1\\\", \\\"TSLType\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/TSLType/EUgeneric\\\", \\\"TSLVersionIdentifier\\\": \\\"5\\\" }, \\\"TrustServiceProviderList\\\": { \\\"TrustServiceProvider\\\": { \\\"StatusStartingTime\\\": { \\\"dateTime\\\": \\\"2022-11-22T00:00:00Z\\\" }, \\\"TSPCurrentStatus\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Active\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"TSPInformation\\\": { \\\"TSPAddress\\\": { \\\"ElectronicAddress\\\": { \\\"URI\\\": { \\\"#text\\\": \\\"mailto:mail.notary1@federation.com\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"PostalAddresses\\\": { \\\"PostalAddress\\\": { \\\"@xml:lang\\\": \\\"en\\\", \\\"CountryName\\\": \\\"DE\\\", \\\"Locality\\\": \\\"K\\u00f6ln\\\", \\\"PostalCode\\\": \\\"50825\\\", \\\"StreetAddress\\\": \\\"Lichtstra\\u00dfe 43h\\\" } } }, \\\"TSPCertificationList\\\": { \\\"TSPCertification\\\": [ { \\\"@xml:lang\\\": \\\"en\\\", \\\"Scope\\\": null, \\\"Type\\\": \\\"LEI\\\", \\\"Value\\\": \\\"1234567\\\" }, { \\\"@xml:lang\\\": \\\"en\\\", \\\"Scope\\\": null, \\\"Type\\\": \\\"Gaia-X Compliance\\\", \\\"Value\\\": \\\"1234567\\\" }, { \\\"@xml:lang\\\": \\\"en\\\", \\\"Scope\\\": null, \\\"Type\\\": \\\"eidas\\\", \\\"Value\\\": \\\"1234567\\\" } ] }, \\\"TSPInformationURI\\\": { \\\"URI\\\": { \\\"#text\\\": \\\"https://notary1.info/TRAIN/info\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"TSPName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Notary 1\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"TSPTradeName\\\": { \\\"Name\\\": [ { \\\"#text\\\": \\\"NTRUK-SC090312\\\", \\\"@xml:lang\\\": \\\"en\\\" }, { \\\"#text\\\": \\\"Notary Federation 1\\\", \\\"@xml:lang\\\": \\\"en\\\" } ] } }, \\\"TSPServices\\\": { \\\"TSPService\\\": [ { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Participant Membership Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://participant.membership.notary1.federation.com\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://participant.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } }, { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Principal Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://verifier.research.identiproof.io/\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://principal.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } }, { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Consumer Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://verifier.research.identiproof.io/\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://consumer.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } }, { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Resource Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://resource.membership.notary1.federation.com\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://resource.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } }, { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Onboarding Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://onboarding.membership.notary1.federation.com\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://onboarding.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } } ] }, \\\"UID\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"2325\\\", \\\"@xml:lang\\\": \\\"en\\\" } } } } } } Trusted Content Handling Trust lists and pointers to the trust lists will be summarized under the term \"Trusted Content\" in the following. Trusted Content Locations Pointers to trust frameworks will be placed as in the DNS of the Trust Framework Operators. Depending on requirements of the specific use case, trust lists can be placed on https web servers or in the IPFS. To maintain auditability and security against manipulation, it is recommended that the Trust List is published in the IPFS. DID Documents can be placed on Ledgers, the IPFS or https web servers. The Verifiable Credential with the Trust List URI can also be published on the different locations as mentioned. Enrolment Process of Entities in Trust Lists The Notarization API will cover the enrolment of entities in trust lists. The requirements that have to be fulfilled for enrolment are dependent on the Trust Framework of the respective context, i.e., the Gaia-X Trust Framework, the Trust Framework of a certain Federation, etc. The technical process is triggered by the notary and executed by the TSPA/Federator performing CRUD operations on the trust list that is located on the Trusted Data Store. Trusted Content Resolving Resolving trusted content via trust list involves trust discovery and trust validation processes. In order to resolve the trusted content, the following data model is to be followed: { \"IssuerDetails\": \"did:web:company.de\" \"Trust Framework Pointer\": [\"federation1.com\", \"gaia-x.eu\"], \"ServiceContentType\": \"gx-trust-list-issuer\" } The term: \"IssuerDetails\\'\\' describes the DID or URI of the issuer credential \"Trust Framework Pointer\\'\\' describes the trust frameworks mentioned in the termsofUse of the verifiable credential \"ServiceContentType\" is set by the Resolver to resolve the corresponding trust list. For example: gx-type-list-issuer contains the information of a trusted issuer trust list but if the resolver needs information regarding schema then it can point to \"gx-trust-list-schemas\". The following are minimum set of trusted content service types for TRAIN in Gaia-X: <!-- --> gx-trust-list-issuer (format: Verifiable credentials, JSON) gx-trust-list-schemas gx-trust-list-policies gx-trust-list-apps gx-trust-list-verifier gx-trust-list-authorities It is foreseen that a further analysis of the specific requirements of the concrete use cases is performed. This analysis will define if a specific type is needed and/or if further types will have to be added, as well as the specific format and content of the types. Please refer to the sections \"Trust Verification\" and \"Unified Signature & Verification Model for Trust Lists via DID and VC\" which describe in detail the discovery process of the trust list and the step-by-step validation. Trusted Content Auditing Depending on the requirements for auditability, different procedures are recommended for the anchoring of trusted content: Requirement Procedure Trusted Content must be Anchor all items into an audible, tamper-proof auditible up to system (e.g., IPFS, Ledgers) Enrollment Trusted Content Creator Anchor the DID in the DNS Zones (default) must be audible Trusted Content Location Anchor the URL in the DNS Zones must be anchored Table 4: Procedures for auditability requirements Other options remain possible. Setup Process for Trust Verification An entity performing trust verification, i.e., to check whether a certain company is indeed a member of the specific Gaia-X Trust Framework that it claims to be, the entity has to configure the DNS names of the trust frameworks that it trusts in the Trusted Content Resolver [10]. So, if it would choose to trust the Trust Framework \"Example\" of the Gaia-X Federation \"Federation1\" it would configure the Trusted Content Resolver for \" example.federation1.com .\" And if it also trusts the Trust Framework \"Partners\" of \"Federation2\" it would also add \" partners.federation2.de.\" [10] If an API is used, the URL(s) of the TRAIN API(s) to call to verify the membership lists have to be set up as well. Additionally, the Trusted Content resolver can also configure what type of trust lists needs to be resolved, as different types of trust lists can be configured in the DID Document using service type. Examples are: gx-trust-list-issuer , gx-trust-list-verifier , gx-trust-list-schemas , gx-trust-list-apps , gx-trust-list-authorities . When the verifying entity receives a VC, it extracts the asserted trust framework claims made by the issuer in the Terms of Use property. If it trusts any of the claimed trust frameworks, it calls the Trusted Content Resolver, passing it the URI of the issuer (taken from the VC, e.g., \\\" did:example:123456789abcdefghi \\\") and the DNS name of the trusted trust framework that the VC Issuer purports to be a member of (e.g., \\\"Trust_Scheme_Pointer\\\": \\\" example.federation1.com \\\"). The Trusted Content Resolver will then check if the VC issuer is a member of any of the trust lists pointed to by this trust framework, and if so, return the Service Type URL to the Verifier. The verifier can check that this URL is identical to the one in the credentialSchema property, and if it is, use the schema contained at this URL to validate that the attributes in the received VC match the schema for this Service Type. Packages for Programming Languages The Trusted Content Resolver will be developed for the following programming languages: Java Javascript Go Figure: Trusted Content Resolver Conclusion and Consequences Security consolidations and implications As a distributed database both in terms of organization of data as well as responsibility for operation and management, the DNS is very suitable for an infrastructure that aims to support integration and interoperation of various trust frameworks across federations. The original design of the DNS did not consider a number of attacks allowing miscreants to alter information retrieved via the DNS. The Domain Name Service Security Extensions (DNSSEC) have been developed to mitigate this problem. They allow users of the DNS to verify that the data they received is indeed the data intended. This ability for verification is vital for use of DNS in the context of a trust infrastructure. However, this also means that the secure control of the DNS is essential for a trust framework provider in TRAIN. Hence, TRAIN requires secure organizational governance of the DNS processes at the DNS controller responsible for creating the Trust Schemes/Trust Frameworks and setting the pointers to locations of the Trust Lists. Advanced Concepts Integration with the Ethereum Name Service (ENS) A potential for further development would be to evaluate further the use of Ethereum ledger based DIDs as pointers to the Trust Lists. This could leverage the trust of Smart Contracts and a decentralized consensus mechanism. The Ethereum Name Service (ENS) is a distributed, open, and extensible naming system based on the Ethereum blockchain.[11] ENS supports text records as well as reverse resolution. Hence, there is a potential for TRAIN to use ENS complementary to DNS/DNSSEC. However, the ENS is not as mature and established as DNS/DNSSEC and this approach would need further research. [11] [https://docs.ens.domains/] Establishment of Trust against Man-in-the-Middle Attacks: PCM and OCM Further investigation would be required in order to evaluate how Trust Lists can be leveraged to protect against Man-in-the-Middle Attacks between different components. This would be particularly important for interactions between Personal Credential Manager (PCM) and Organizational Credential Manager (OCM). Verification of the Verifier from the Holder The following figure shows how TRAIN can be used to establish trust into the verifier. To enable this, a certain authority, such as a specific Gaia-X Federation, has to develop a Trust Framework that specifies how a verifier can be trustworthy (and potentially which verifiers can be trusted to receive which information). Verifiers complying with these requirements will be enrolled via their DID to the trusted verifiers trust list of this Gaia-X Federation. Now, before a VC is exchanged, the verifier passes the Trust_Scheme_Pointer in the presentation request to the holder. With this, the verifier claims membership in a certain verifier trust framework/scheme. It follows a validation process as described above - only that it is initiated from the holder. After this validation is successful, the requested data can be passed to the verifier. Figure 9: TRAIN in the \"Triangle of Trust\": Trusted Verifiers Support of Federation Membership Verification in the OIDC4VP Standard The following section is for information purposes. The use of TRAIN is explicitly referenced in the implementation considerations of the OIDC4VP at: [https://openid.net/specs/openid-connect-4-verifiable-presentations-1_0.html#name-implementation-consideratio] It is written there: \"Trust schemes that conform to the TRAIN trust scheme are identified by the type https://train.trust-scheme.de/info. Individual federations are identified by their DNS names.An example claims parameter containing a presentation_definition that filters VCs based on their federation memberships is given below.\" { \\\"vp_token\\\": { \\\"presentation_definition\\\": { \\\"id\\\": \\\"32f54163-7166-48f1\\\", \\\"input_descriptors\\\": [ { \\\"id\\\": \\\"federationExample\\\", \\\"purpose\\\": \\\"To pick a UK university that is a member of the UK academic federation\\\", \\\"constraints\\\": { \\\"fields\\\": [ { \\\"path\\\": [ \\\"\\$.termsOfUse.type\\\" ], \\\"filter\\\": { \\\"type\\\": \\\"string\\\", \\\"const\\\": \\\"https://train.trust-scheme.de/info\\\" } }, { \\\"path\\\": [ \\\"\\$.termsOfUse.federations\\\" ], \\\"filter\\\": { \\\"type\\\": \\\"string\\\", \\\"const\\\": \\\"ukuniversities.ac.uk\\\" } } ] } } ] } } } This example will choose a VC that has been issued by a university that is a member of the ukuniversities.ac.uk federation and that uses the TRAIN terms of use specification for asserting federation memberships.","title":"Trust Management Infrastructure - Concept Document"},{"location":"traincd/traincd/#gaia-x-federation-services-for-identity-trust","text":"Trust Management Infrastructure for Gaia-X Concept Document","title":"Gaia-X Federation Services for Identity &amp; Trust"},{"location":"traincd/traincd/#1-motivation","text":"","title":"1 Motivation"},{"location":"traincd/traincd/#2-introduction","text":"","title":"2 Introduction"},{"location":"traincd/traincd/#3-vision","text":"","title":"3 Vision"},{"location":"traincd/traincd/#4-assumptions-side-conditions","text":"","title":"4 Assumptions &amp; Side Conditions"},{"location":"traincd/traincd/#5-concept","text":"","title":"5 Concept"},{"location":"traincd/traincd/#51-role-of-the-dnsdnssec","text":"","title":"5.1 Role of the DNS/DNSSEC"},{"location":"traincd/traincd/#52-functional-roles-and-components-in-train","text":"","title":"5.2 Functional Roles and Components in TRAIN"},{"location":"traincd/traincd/#53-integration-with-verifiable-credentials","text":"","title":"5.3 Integration with Verifiable Credentials"},{"location":"traincd/traincd/#54-unified-signature-verification-model-for-trust-lists-via-did-and-vc","text":"","title":"5.4 Unified Signature &amp; Verification Model for Trust Lists via DID and VC"},{"location":"traincd/traincd/#55-trust-verification","text":"","title":"5.5 Trust Verification"},{"location":"traincd/traincd/#56-sequence-diagram-trust-list-initialization-trust-list-enrolment-and-update-trust-discovery-and-validation","text":"","title":"5.6 Sequence Diagram: Trust List Initialization, Trust List Enrolment and Update, Trust Discovery and Validation"},{"location":"traincd/traincd/#57-initial-integration-into-trust-framework-memberships","text":"","title":"5.7 Initial Integration into Trust Framework Memberships"},{"location":"traincd/traincd/#58-cross-referencing-of-trust-framework-memberships","text":"","title":"5.8 Cross-Referencing of Trust Framework Memberships"},{"location":"traincd/traincd/#59-integration-into-a-new-trust-framework-with-existing-credentials","text":"","title":"5.9 Integration into a New Trust Framework with existing Credentials"},{"location":"traincd/traincd/#510-integration-with-tsa","text":"","title":"5.10 Integration with TSA"},{"location":"traincd/traincd/#511-integration-with-ocm","text":"","title":"5.11 Integration with OCM"},{"location":"traincd/traincd/#512-integration-with-notary","text":"","title":"5.12 Integration with Notary"},{"location":"traincd/traincd/#513-required-trust-lists-for-gaia-x","text":"","title":"5.13 Required Trust Lists for Gaia-X"},{"location":"traincd/traincd/#514-trust-list-formats","text":"","title":"5.14 Trust List Formats"},{"location":"traincd/traincd/#6-trusted-content-handling","text":"","title":"6 Trusted Content Handling"},{"location":"traincd/traincd/#61-trusted-content-locations","text":"","title":"6.1 Trusted Content Locations"},{"location":"traincd/traincd/#62-enrolment-process-of-entities-in-trust-lists","text":"","title":"6.2 Enrolment Process of Entities in Trust Lists"},{"location":"traincd/traincd/#63-trusted-content-resolving","text":"","title":"6.3 Trusted Content Resolving"},{"location":"traincd/traincd/#64-trusted-content-auditing","text":"","title":"6.4 Trusted Content Auditing"},{"location":"traincd/traincd/#65-setup-process-for-trust-verification","text":"","title":"6.5 Setup Process for Trust Verification"},{"location":"traincd/traincd/#66-packages-for-programming-languages","text":"","title":"6.6 Packages for Programming Languages"},{"location":"traincd/traincd/#7-conclusion-and-consequences","text":"","title":"7 Conclusion and Consequences"},{"location":"traincd/traincd/#71-security-consolidations-and-implications","text":"","title":"7.1 Security consolidations and implications"},{"location":"traincd/traincd/#72-advanced-concepts","text":"","title":"7.2 Advanced Concepts"},{"location":"traincd/traincd/#721-integration-with-the-ethereum-name-service-ens","text":"","title":"7.2.1 Integration with the Ethereum Name Service (ENS)"},{"location":"traincd/traincd/#722-establishment-of-trust-against-man-in-the-middle-attacks-pcm-and-ocm","text":"","title":"7.2.2 Establishment of Trust against Man-in-the-Middle Attacks: PCM and OCM"},{"location":"traincd/traincd/#723-verification-of-the-verifier-from-the-holder","text":"","title":"7.2.3 Verification of the Verifier from the Holder"},{"location":"traincd/traincd/#724-support-of-federation-membership-verification-in-the-oidc4vp-standard","text":"List of Figures Figure 1 TRAIN in the \"Triangle of Trust\" Figure 2 TRAIN in the \"Triangle of Trust\" -- Trusted Issuers Figure 3 Overall Vision for TRAIN Figure 4 Overview TRAIN Concept Figure 5 TRAIN Archimate Diagra Figure 6 Cross-Referencing of Trust Framework Memberships Figure 7 TRAIN integration with the Notary Figure 8 Trusted Content Resolver Figure 9 TRAIN in the \"Triangle of Trust\": Trusted Verifiers List of Tables Table 1 DNS & Resource Records Table 2 Comparison: Roles and Components in TRAIN with other trust concepts Table 3 Cross-Referencing of Trust Framework Memberships: DNS and Resource Records Table 4 Procedures for auditability requirements","title":"7.2.4 Support of Federation Membership Verification in the OIDC4VP Standard"},{"location":"traincd/traincd/#motivation","text":"The Gaia-X Trust Framework requires a decentralized, flexible, scalable, and interoperable Trust Model to manage information on trusted entities, federations or participants in the ecosystem. Individual federations have to be able to define and manage their trust anchors in a sovereign way, while at the same time these trust domains have to be interoperable across federations. Decentralized identity management technology is currently developing fast. At the same time, multiple trust domains exist. It might be overly optimistic to settle on one specific decentralized identity technology and trust domain. Hence, the trust management infrastructure, as defined in this document, aims to be agnostic towards the specific decentralized identity technology, ledger and framework (e.g., EBSI, Indy). Its goal is to bridge different trust domains and to allow individual entities and frameworks to make sovereign trust decisions. Parts of this document are based on the work of the ICAM Gaia-X Community.","title":"Motivation"},{"location":"traincd/traincd/#introduction","text":"The trust management infrastructure enables the establishment of a root of trust for entities acting in the Gaia-X ecosystem and credentials issued by these entities. This is achieved through the introduction of trust lists combined with anchoring of pointers in the DNS following the TRAIN (Trust Management Infrastructure) concept. These lists, published by Governance Authorities, include entities that are certified according to a certain Trust Framework that is maintained by the respective governance authority. This, for example, supports verifying entities in examining the trustworthiness of Issuers through inclusion in trust lists under a specific trust framework that is administered by a specific governance authority. Gaia-X Federations and other entities are supported in the sovereign publication and administration of trust lists for specific trust frameworks. This approach addresses the main trust challenges in the standard SSI triangle as sketched in figure 1: Figure 1: TRAIN in the \"Triangle of Trust\" A flexible trust management infrastructure can address the trust challenges as mentioned above. An example for Challenge C1: Trusted issuers is given in figure 2. This approach leverages the well-established global Domain Name Service (DNS and DNSSEC) and combines it with the decentralized Gaia-X SSI approach. To publish and identify the correct trust lists as well as establish a chain of trust, the widely accepted DNS is leveraged. Figure 2: TRAIN in the \"Triangle of Trust\" -- Trusted Issuers This Trust Management Infrastructure concept is based on the use of Trust Lists for trusted entities. Trust Lists might not be optimal for all use cases and at all levels to ensure trust. This is why the Chained Credentials Concept[1] is regarded as complementary to the Trust List approach, that is in the focus of this document.","title":"Introduction"},{"location":"traincd/traincd/#vision","text":"The TRAIN (Trust Management Infrastructure) for Gaia-X will be used to publish lists of trusted entities that are enrolled by a trustable authority. An example could be a specific Gaia-X Federation enrolling its member companies in a member trust list. In the following TRAIN will be abbreviated if this Infrastructure is used. TRAIN will allow individual entities (e.g., individual companies, federations that are Gaia-X accredited, federations without Gaia-X accreditation) to make trust statements to support individual trust decisions by sovereign entities. At the same time, depending on individual preference, trust decisions can also be delegated between entities. As an example, companies can decide to trust all enrolled members of a certain (parallel acting) federation. Federations can also link their trust framework to the trust framework of a different federation. To enable this, authorities like the Gaia-X AISBL and individual Gaia-X Federation operators will act as governance authorities that operate trust frameworks and enroll trustable entities in their trust lists. TRAIN makes use of the DNS(DNSSEC) as a fundamental and well-established anchor to discover and validate trust. In order for an entity to be able to set up a trust list, it has to control a DNS domain to create a Trust Framework (Trust Scheme) in its DNS record and to set pointers to the Trusted Content, specifically the Trust List, in its DNS record. The DNS hostname is then embedded into the meta section (TermsOfUse) of verifiable credentials by entities claiming enrollment in the Trust Framework of a specific Trust Framework operator. Verifying entities use the DNS hostname to resolve trusted content and validate the inclusion of entities in Trust Frameworks - according to their trust requirements, as they can define which Trust Frameworks (via their DNS hostnames) to trust. For setting up a trust list and enrolling members, the respective Gaia-X Federation performs the following steps[2]: The federation requires a fully qualified domain name (FQDN). This domain name has to be configured using the \"Well Known DID\" configuration[3] which gives the [ability for a DID controller to prove they are the same entity that controls an origin.] The DID used for the Well Known DID configuration is published in the DNS URI Resource Record of the domain - it serves as a pointer to resolve the location and key material for the trust list.","title":"Vision"},{"location":"traincd/traincd/#1-httpswikitrustoveriporgdisplayhometoiptrustregistryprotocolspecificationtoiptrustregistryprotocolspecification-credentialchaining","text":"","title":"[1] [https://wiki.trustoverip.org/display/HOME/ToIP+Trust+Registry+Protocol+Specification#ToIPTrustRegistryProtocolSpecification-CredentialChaining ]"},{"location":"traincd/traincd/#2-for-the-sake-of-clarity-some-mainly-technical-steps-have-been-abbreviated-here-they-are-included-in-the-sequence-diagram-below","text":"","title":"[2] [[For the sake of clarity, some, mainly technical steps have been abbreviated here. They are included in the sequence diagram below.]]"},{"location":"traincd/traincd/#3-httpsidentityfoundationwell-knownresourcesdid-configuration","text":"A trust list in JSON format[4] is created. The trust list is published on a Trust List Data store (a web server or the IPFS - depending on the specific requirements). The DIDs of specific member organizations that comply with the requirements of the Trust Framework of this Gaia-X Federation to the federation member are added to that trust list. A Verifiable Credential (VC) with the Location of the Trust List in the credential subject is created. The location of this VC is included as a Service Endpoint in the DID Document for the DID that was associated with the DNS domain. DID document is published (on a web server or ledger - depending on the specific requirements). The organizational, regulatory/legal, and technical measures to assert trust-relevant aspects for enrollment of companies are defined in the Trust Framework for this Gaia-X federation. Publishing trust lists, setting pointers to trust lists, enrollment, discovery as well as querying of trust lists will be supported by respective components as described in this concept. Although the TRAIN infrastructure uses the DNS for lookups, the trust frameworks, (optional JSON schemas) and trust lists are distributed on the web (or in the IPFS) and are not stored in the DNS. There can be different instances of trust lists and trust frameworks hosted by different trust framework operators (institutions providing trust frameworks, for example: a Gaia-X Federation operating a Trust Framework for its members. The verifying entity alone can decide which existing trust frameworks and trust lists (for example: the trust framework of Catena-X) to trust. The overall Vision for TRAIN, over different layers, is described in figure 3.","title":"[3] [https://identity.foundation/.well-known/resources/did-configuration/]"},{"location":"traincd/traincd/#4-train-also-supports-trust-lists-in-the-format-xml-etsi-ts-119-612-that-is-used-for-eidas-10-trust-schemes-ie-httpstlbundesnetzagenturdetl-dexml-however-for-this-document-we-will-focus-on-trust-lists-in-json-format-resolved-via-did-vc","text":"Figure 3: Overall Vision for TRAIN Any Gaia-X self-sovereign federation controlling a DNS can create their own trust framework and become a trust framework operator e.g., federation1.com . Every entity that has to perform trust decisions decides which trust framework operators to trust for which context. Trust framework operators (or delegated Gaia-X Notaries) perform the onboarding/ offboarding of members in the trust framework. An example could be that these companies are members of Federation1 and therefore are trusted to issue VCs of a certain type (e.g., membership credentials) with a certain schema. The entity operating the trust framework enrolls the members of its trust framework in a trust list. But it can also cross-reference to other trust frameworks. An example could be that a particular trust framework, e.g., federation1.com , with trust framework \" example \" may also trust a second trust framework e.g., \"partners \", of another trust framework operator, e.g., federation2.de . It may wish to include the members of this other trust framework as being equivalent to its own members, but avoid having to enroll each of these members to its own trust list. The trust framework operator would therefore add pointer resource records (PTR RRs) to its DNS trust framework entry (as described in detail below) to point to these other equivalent trust frameworks. The use of PTR RRs forms mappings between trust frameworks and trust lists and enables cross-referencing of trust frameworks without individually enrolling entities into trust lists.","title":"[4] TRAIN also supports Trust Lists in the Format XML, ETSI TS 119 612 that is used for eIDAS (1.0) Trust Schemes, i.e. https://tl.bundesnetzagentur.de/TL-DE.xml. However, for this document we will focus on trust lists in JSON format resolved via DID / VC"},{"location":"traincd/traincd/#assumptions-side-conditions","text":"The trust management infrastructure makes use of the existing global Domain Name Service (DNS) for discovering information relevant for the validation of trust as described in the concept below. As a distributed database both in terms of organization of data as well as responsibility for operation and management, the DNS is very suitable for an infrastructure that aims to support integration and interoperation of various trust domains of different Gaia-X Federations that are operationalized through Trust Frameworks and Trust Lists. The original design of the DNS did not consider a number of attacks allowing miscreants to alter information retrieved via the DNS. It is susceptible to cache poisoning and MITM attacks, which can lead to false results being returned. The Domain Name Service Security Extensions (DNSSEC) have been developed to mitigate this problem. They allow users of the DNS to verify that the data they received is indeed the data intended. This ability for verification is vital for the use of DNS in the context of a trust infrastructure. Hence, the trust management infrastructure requires acceptance and availability of DNS/DNSSEC as fundamental infrastructure. To ensure an adequate level of security, the use of DNSSEC is required.","title":"Assumptions &amp; Side Conditions"},{"location":"traincd/traincd/#concept","text":"For a first overview of the TRAIN concept and its relationships, please refer to the following Archimate diagram. The subsequent sections will cover the main aspects of the concept. [ Figure 4: Overview TRAIN Concept","title":"Concept"},{"location":"traincd/traincd/#role-of-the-dnsdnssec","text":"A Gaia-X Federation controlling a DNS record can set up one or multiple Trust Frameworks with one or multiple trust lists, for example for creating a member trust list. To do this, it performs the following steps: The DNS controller creates a DNS entry with the name of its trust framework e.g., example.federation1.com ., or partners.federation2.de. . Then below this, two further DNS entries named _trust and _scheme respectively are created. The names of these two entries were specified by the EU Lightest project[5], and TRAIN is following those guidelines. Here, example is the name of the Framework, federation1.com is the authority responsible for the Trust Framework, and _scheme._trust are standardized constant terms used across the TRAIN trust infrastructure. The bottom entry, e.g., _scheme._example.federation1.com , contains one or more PTR RRs. Each PTR RR points to a DNS entry where the location of a trust list can be found, in a URI RR[6]. This use of PTR RRs allows one Trust Framework to point to several trust lists, for example, one Gaia-X Federation could point to the equivalent trust frameworks of different Gaia-X Federations. It also allows one trust list to be incorporated into multiple trust frameworks. DNS Resource Records PTR _scheme._example.federation1.com. PTR _scheme._partners.federation2.de. URI [https://some.org/trust_list] / did:web:xyz... Table 1: DNS & Resource Records","title":"Role of the DNS/DNSSEC"},{"location":"traincd/traincd/#functional-roles-and-components-in-train","text":"The table below compares roles and components in TRAIN with other trust concepts currently being developed. Description Term in Gaia-X Term in EBSI Terms in other Concepts Organizational authority certifying trustworthiness of entities and enrolling them into the list of trusted entities, maintaining the list(s)/registrie(s) and organizational framework Trust Framework (AISBL, Federator of a specific Gaia-X Federation) Trusted Accreditation (TAO, Organisation) Governance Authority, Trust Scheme Provider Defined organizational, regulatory/legal, and technical measures to assert trust-relevant attributes for enrolled entities (in a certain domain) Gaia-X Trust Framework, Frameworks of specific Federations Use-case Policies Trust Framework, Trust Scheme, Governance Framework List of trusted entities in specific data file/format certified by a maintaining authority Trust List (JSON or XML following ETSI TS 119 612) Registry of Issuers (on EBSI Ledger) as Smart Contract Trust Registry, List of Trusted Entities (Issuers etc.) Formalized set of rules to automate trust decisions for individual transactions (Trust) Policy (REGO) Not defined or unknown n/a Table 2: Comparison: Roles and Components in TRAIN with other trust concepts","title":"Functional Roles and Components in TRAIN"},{"location":"traincd/traincd/#5-wagner-s-kurowski-s-laufs-u-ronagel-h-a-mechanism-for-discovery-and-verification-of-trust-scheme-memberships-the-lightest-reference-architecture-in-open-identity-summit-2017-proceedings-lecture-notes-in-informatics-lni-bonn-kollen-druck-verlag-gmbh-pp-8192-2017","text":"","title":"[5] Wagner, S.; Kurowski, S.; Laufs, U.; Ro\u00dfnagel, H.: A mechanism for discovery and verification of trust scheme memberships: the LIGHTest Reference Architecture, in Open Identity Summit 2017 - Proceedings, Lecture Notes in Informatics (LNI), Bonn: K\u00f6llen Druck + Verlag GmbH, pp. 81\u201392, 2017."},{"location":"traincd/traincd/#6-this-step-is-abbreviated-here-both-a-url-or-a-did-can-be-used-as-uri-to-point-to-the-trust-list-in-case-of-the-did-the-trust-list-will-be-resolved-via-a-verifiable-credential-that-is-located-over-the-did","text":"","title":"[6] This step is abbreviated here. Both, a URL or a DID can be used as URI to point to the trust list. In case of the DID the trust list will be resolved via a verifiable credential that is located over the DID."},{"location":"traincd/traincd/#integration-with-verifiable-credentials","text":"Every VC that is issued by an entity that claims to be in a certain Trust Framework must contain a standard Terms of Use property (according to W3C Verifiable Credentials Data Model 1.0). The Terms of Use contains the DNS names of the trust framework(s) that the issuer claims to be a member of. For this, there must at least be one \"trustScheme\" defined, as in the following example: [\\\"trustScheme\\\" : [ \"example . federation1.com\" , \"partners . federation2.de\" ]. ] If schemas are also to be included in the trust framework, the credential must also contain a standard credentialSchema property listing the URL where the schema can be found, along with the syntax of the schema. As with claimed trust framework memberships, these could be true or false statements. In any case, the Verifier will check the claims using TRAIN. What counts in the end is the actual inclusion of the details into the trust list of the Trust Framework Operator as defined in the enrollment process. An example for the format of the TRAIN Terms of Use property is given below: \"termsOfUse\":[{ \"type\": \"train\", \"id\": \"https://train.trust-scheme.de/info\", \"trustScheme\": \"example.federation1.com\", \"partners.federation2.de\" }] Optional reference to a credential schema: \"credentialSchema\": { \"id\": \"[https://train.trust-scheme.de/schema/membershipCredential-schema.json]\", \"type\": \"JsonSchemaValidator2018\" }","title":"Integration with Verifiable Credentials"},{"location":"traincd/traincd/#unified-signature-verification-model-for-trust-lists-via-did-and-vc","text":"The Unified Signature & Verification model for Trust List via DID and VC allows trust lists across trust domains to be signed and verified uniformly using Verifiable Credentials (VC). This is achieved by enveloping the storage location of the Trust List (Trusted Data Store, e.g., https url or IPFS) in the credential subject of a Verifiable Credential. The entity operating the trust framework (the Federator) is responsible for signing the VC with its proof. The signature approach is as follows: A DID is created and associated with the DNS domain under the control of the trust framework operator (the Federator) following the Well Known DID configuration approach[7].","title":"Unified Signature &amp; Verification Model for Trust Lists via DID and VC"},{"location":"traincd/traincd/#7-httpsidentityfoundationwell-knownresourcesdid-configuration","text":"The DID is stored in the DNS PTR record URI A DID Document is created for the DID and stored on a ledger/IPFS/https URL resource. The DID document defines a Service End Point with the URI to a Verifiable Credential / Presentation The Verifiable Credential / Presentation is created so that it can be resolved via the URI in the DID Document. The Credential Subject of the VC/VP contains the URI to resolve the Trust List. The VC/VP is signed so that it can be validated with the public key from the DID Document. The Trust List is stored at the Trusted Data Store at the location (IPFS/https web resource) defined in the Credential Subject of the VC The verification process is described in the next section.","title":"[7] [https://identity.foundation/.well-known/resources/did-configuration/]"},{"location":"traincd/traincd/#trust-verification","text":"To verify the inclusion of an entity in a specific trust framework, minimum two specific inputs are required: The trust framework reference (Trust Framework Pointer), that is embedded as a DNS name in the termsofUse object of the VC (see section \"Trusted Content Resolving\" below). The URI of the VC issuer, obtained from the VC. The URI of the issuer is flexible and may depend on the backend technology being used by the VC ecosystem. For example: the URI can be a DID that could be anchored in a blockchain/distributed ledger, but it could also be a https URL from a PKI or it could also be a UUID. The TRAIN trust verification is not restricted by the backend technology behind the VC in the respective SSI ecosystem used in Gaia-X. If a user needs a certain service-specific information they can restrict it by adding additional parameters to the inputs. For example: If a Trust Verifier needs to process only DID requests, the user can include an input called ServiceDigitalIdentity: \"DID\". Thereby the verifier after verification process will return only those identities specific to the DID as output. The trust verification is performed by a trust verification component denoted \"Trusted Content Resolver\" (see also the Sequence Diagram below, in TRAIN also called ATV: Automatic Trust Verifier). The registration/enrolment process is also elaborated in the respective section further below. The \"TSPA/Federator\" is located at the authority operating the trust framework, e.g., a specific Gaia-X Federation. The trust list is detailed further below in the respective section. Based on the Trust Framework Pointer as DNS name in the termsOfUse, the Trusted Content Resolver will first attempt to connect to the DNS name server that holds the entries of the trust framework operator using DNSSEC. This provides an unbroken chain of trust from the root DNSKEY RR set to the Trust Framework's DNS entries. However, if DNSSEC is not available, it will use standard DNS. The use of DNS without DNSSEC is not recommended as described in the Security Considerations below. The reason for this is that support for DNSSEC might not be within the control of the Trust Framework Operator. If participants still prefer to use TRAIN and are willing to accept the risks, they can use TRAIN with only DNS and are not forced to wait until DNSSEC is available to them. We recognize that this leaves the trust framework open to certain attacks, such as DNS MITM and cache poisoning, but Trust Framework Operators and verifiers can perform this risk assessment before deciding to use TRAIN without DNSSEC. The verification process is as follows: The Trusted Content Resolver will read the PTR RRs of the DNS domain resolved from the trust framework reference (Trust Framework Pointer). There the Trusted Content Resolver dereferences the URI RRs , and expects to find a DID . The Well Known DID configuration verification is performed.[8]","title":"Trust Verification"},{"location":"traincd/traincd/#8-httpsidentityfoundationwell-knownresourcesdid-configuration","text":"From the DID the Trusted Content Resolver resolves a DID Document which via its Service Endpoint leads to a Verifiable Credential/Verifiable Presentation . The proof of the VC/VP is validated against the public keys of the DID Document. The Credential Subject of the VC/VP is ready to obtain the URI of the Trust List (at a https URL or IPFS resource). The trust list is resolved and the Trusted Content Resolver checks if the specific entity is listed in the trust list. If this is the case, the Trusted Content Resolver will return that the claimed entity is a member of the trust framework operated by this \\\"DNS name\\\". Likewise, the VC schema can be checked. Hence, it does not matter whether the entity was telling the truth when it claimed membership of a certain trust framework. The Trusted Content Resolver and the DNS controller/trust framework operator establish the root of trust. The source code for a sample implementation of the Trusted Content Resolver component is available under Apache 2.0 (developed in the ESSIF-TRAIN Project and called ATV: Automatic Trust Verifier). The Trusted Content Resolver can be automated through policy languages (the ATV implementation supports TPL - Trust Policy Language) or other languages like REGO as foreseen for GXFS. Trusted Content Resolvers can be run by any entity, so that there can be multiple distributed copies of this service running in clouds as backup services or completely locally under sovereign control. The existing Trusted Content Resolver (ATV) implementation also offers a \"TRAIN API\" allowing to initiate the trust verification process using the POST API Service and to return the result to the verifier.[9]","title":"[8] [https://identity.foundation/.well-known/resources/did-configuration/]"},{"location":"traincd/traincd/#9-httpsessiftrust-schemedeswagger_train","text":"An overview of TRAIN and the integration with GXFS is given in the Archimate Diagram in figure 5. Integration with other GXFS components is described in further details in the sections below.","title":"[9] [https://essif.trust-scheme.de/swagger_train/ ]"},{"location":"traincd/traincd/#sequence-diagram-trust-list-initialization-trust-list-enrolment-and-update-trust-discovery-and-validation","text":"The sequence diagram in figure 5 summarizes what was described above and gives an overview of the central steps to: initially set up of a Trust List (Trust List Initialization) update the Trust List, e.g., to add new entities (Trust List Enrolment and Update) discover the correct Trust List and validate the trust (Trust Discovery and Validation) Figure: TRAIN Archimate Diagra","title":"Sequence Diagram: Trust List Initialization, Trust List Enrolment and Update, Trust Discovery and Validation"},{"location":"traincd/traincd/#initial-integration-into-trust-framework-memberships","text":"For an entity to be enrolled into a specific trust framework, the DID and potentially additional relevant information for the entity (see exemplary trust lists below) must be added to the Trust List of this trust framework. For this, the TSPA/Federator performs CRUD operations on the Trust List located on the Trust List Data Store. The initial integration into Trust Framework Memberships is being triggered via the Notary. Please refer to the Section \"Integration with Notary\" for details.","title":"Initial Integration into Trust Framework Memberships"},{"location":"traincd/traincd/#cross-referencing-of-trust-framework-memberships","text":"The entities operating a Trust Framework are able to cross reference other Trust Framework Memberships using the PTR record. Hence, the DNS record of Trust Framework 1 will hold the DNS hostname pointer for Trust Framework 2 that is being trusted by Trust Framework 1. This would then imply that a verifier trusting Trust Framework 1 will automatically also trust the entities that are enrolled in Trust Framework 2. This way, Trust Framework 1 will not have to individually enroll all entities enrolled in Trust Framework 2 but can simply cross-reference to the other framework. An example is given by the figure 6 and table 3. Moreover, during Verifiable Credential issuance, entities can include multiple Trust Framework membership pointers in the termsOfUse (e.g., \"trustScheme\":\"example.federation1.com\", \"partners.federation2.de\" to claim memberships in multiple trust frameworks. Figure 6: Cross-Referencing of Trust Framework Memberships DNS Resource Records PTR _scheme._example.federation1.com. PTR _scheme._partners.federation2.de. URI [https://some.org/trust_list] did:web:xyz... Table 3: Cross-Referencing of Trust Framework Memberships: DNS and Resource Records","title":"Cross-Referencing of Trust Framework Memberships"},{"location":"traincd/traincd/#integration-into-a-new-trust-framework-with-existing-credentials","text":"Using TRAIN, the enrollment of an entity into a new Trust Framework is immediately reflected and does not require an update of already issued credentials. This can be achieved by leveraging the PTR record cross-referencing of Trust Frameworks as explained above to enroll into a new Trust Framework. This could be illustrated as follows: An exemplary \"Federation X\" maintains a trust list of members for the Trust Framework \"Members Federation X\" and gives out VCs. In their terms of use, these VCs include the DNS hostname pointer \"trustScheme\": \"members.federationX.com\" to claim membership in the Trust Framework \"Members Federation X\". Federation X is not a member of the Trust Framework of the \"Example-Dataspace\" (with the Trust Framework identified by the DNS hostname accredited.exampleDatataspace.com as it has not been accredited.) A validating entity that has configured their Trusted Content Resolver to trust VCs issued under the Trust Framework members.federationX.com will be able to validate these credentials as trustworthy. However, if a validating entity has configured their Trusted Content Resolver to only trust VCs issued under the Trust Framework accredited.exampleDatataspace.com, it will not be able to validate these credentials as trustworthy. Now, Federation X gets accredited according to the Trust Framework of Example-Dataspace. Example-Dataspace will therefore add a PTR record pointer to members.federationX.com right into their DNS under accredited.exampleDatataspace.com to reference the Trust Framework of Federation X as trustworthy. A validating entity that receives the DNS hostname pointer \"trustScheme\":\"members . federationX.com\" that has configured their Trusted Content Resolver to trust VCs issued under the Trust Framework accredited.exampleDatataspace.com will now be able to follow the PTR record pointer to members.federationX.com under the PTR record of accredited.exampleDatataspace.com and validate these credentials as trustworthy - without any changes in the initially issued credentials.","title":"Integration into a New Trust Framework with existing Credentials"},{"location":"traincd/traincd/#integration-with-tsa","text":"The Trust Services API (TSA) can integrate the Trusted Component Resolver Libraries to verify the institutional trust of the verifiable credentials.","title":"Integration with TSA"},{"location":"traincd/traincd/#integration-with-ocm","text":"The Organization Credential Manager (OCM) can use the TSA to validate the trust of the organizational verifiable credentials (via the Trusted Component Resolver Libraries) before storing them in the wallet.","title":"Integration with OCM"},{"location":"traincd/traincd/#integration-with-notary","text":"The Notary uses the TSPA Connector to enroll trusted entities into the trust framework and add them via the TSPA/Federator to the Trust List. The integration with the Notary is illustrated in figure 7: Figure 7: TRAIN integration with the Notary","title":"Integration with Notary"},{"location":"traincd/traincd/#required-trust-lists-for-gaia-x","text":"Certain trust aspects will be covered through the use of chained credentials. For others, trust lists are more efficient. Hence, the following trust lists are foreseen: One Gaia-X Federations Trust List (one single Trust List operated by Gaia-X AISBL for the Gaia-X Federations that are conformant to the general Gaia-X Trust Framework) Trust List of Notaries operated by Gaia-X AISBL (one single Trust List operated by Gaia-X AISBL for the Notaries that are conformant to the general Gaia-X Trust Framework) Multiple Federation Participants Trust Lists (one Trust List operated by each Federation , listing the participants of this Federation that are conformant to its Trust Framework) Multiple Trust Lists of Notaries operated by Federations (one Trust List operated by each Federation , listing the Notaries that are trusted by each Federation and their services offered and credentials issued) Multiple Participant Trust Lists (one Trust List operated by each Participant , listing the services offered and credentials issued by each participant) Multiple Participant Notaries Trust Lists (one Trust List operated by each Participant , listing the Notaries that are trusted by each Participant and their services offered and credentials issued) Further Trust Lists for additional entities or application scenarios are possible.","title":"Required Trust Lists for Gaia-X"},{"location":"traincd/traincd/#trust-list-formats","text":"Trust Lists used by TRAIN contain all the enrolled entities (e.g., Members of a Gaia-X Federation) in a specific data file/format certified by the Trust Framework authority (e.g., the respective Gaia-X Federation operating the Trust Framework). Trust lists for Gaia-X are referenced from a VC (the location is embedded into the credential subject) and the content can be in JSON-LD or in XML-Format. An exemplary trust list in XML Format (following the ETSI TS 119 612 standard, a JSON example is shown after this) is given in the following: [\\<TrustServiceStatusList xmlns=\\\"http://uri.etsi.org/02231/v2#\\\" xmlns:ns2=\\\"http://www.w3.org/2000/09/xmldsig#\\\" xmlns:ns3=\\\"http://uri.etsi.org/01903/v1.3.2#\\\" xmlns:ns4=\\\"http://uri.etsi.org/02231/v2/additionaltypes#\\\" xmlns:ns5=\\\"http://uri.etsi.org/TrstSvc/SvcInfoExt/eSigDir-1999-93-EC-TrustedList/#\\\" xmlns:ns6=\\\"http://uri.etsi.org/01903/v1.4.1#\\\" TSLTag=\\\"http://uri.etsi.org/19612/TSLTag\\\">] [\\<SchemeInformation>] [ \\<TSLVersionIdentifier>5\\</TSLVersionIdentifier>] [ \\<TSLSequenceNumber>1\\</TSLSequenceNumber>] [ \\<TSLType>http://uri.etsi.org/TrstSvc/TrustedList/TSLType/EUgeneric\\</TSLType>] [ \\<SchemeOperatorName>] [ \\<Name xml:lang=\\\"en\\\">Federation 1 Notary\\</Name>] [ \\</SchemeOperatorName>] [ \\<SchemeOperatorAddress>] [ \\<PostalAddresses>] [ \\<PostalAddress xml:lang=\\\"en\\\">] [ \\<StreetAddress>Lichtstra\u00dfe 43h\\</StreetAddress>] [ \\<Locality>K\u00f6ln\\</Locality>] [ \\<PostalCode>50825\\</PostalCode>] [ \\<CountryName>DE\\</CountryName>] [ \\</PostalAddress>] [ \\</PostalAddresses>] [ \\<ElectronicAddress>] [ \\<URI xml:lang=\\\"en\\\">mailto:mail@federation1.com\\</URI>] [ \\<URI xml:lang=\\\"en\\\">https://www.federation1.com\\</URI>] [ \\</ElectronicAddress>] [ \\</SchemeOperatorAddress>] [ \\<SchemeName>] [ \\<Name xml:lang=\\\"en\\\">DE:TRAIN\\</Name>] [ \\</SchemeName>] [ \\<SchemeInformationURI>] [ \\<URI xml:lang=\\\"en\\\">https://dl.gi.de/handle/20.500.12116/38702\\</URI>] [ \\</SchemeInformationURI>] [ \\<StatusDeterminationApproach>http://uri.etsi.org/TrstSvc/TrustedList/StatusDetn/EUappropriate \\</StatusDeterminationApproach>] [ \\<SchemeTypeCommunityRules>] [ \\<URI xml:lang=\\\"en\\\">https://train.trustscheme.de /schemerules/ngi.train.trustscheme.de \\</URI>] [ \\</SchemeTypeCommunityRules>] [ \\<SchemeTerritory>GLOBAL\\</SchemeTerritory>] [ \\<PolicyOrLegalNotice>] [ \\<TSLLegalNotice xml:lang=\\\"en\\\">This is an experimental list for the GXFS Federation Notary.\\</TSLLegalNotice>] [ \\</PolicyOrLegalNotice>] [ \\<HistoricalInformationPeriod>65535\\</HistoricalInformationPeriod>] [ \\<ListIssueDateTime>2022-09-27T00:00:00Z\\</ListIssueDateTime>] [ \\<NextUpdate>2022-12-27T00:00:00Z\\</NextUpdate>] [\\</SchemeInformation>] [\\<TrustServiceProviderList>] [ \\<TrustServiceProvider>] [ \\<UID>] [ \\<Name xml:lang=\\\"en\\\">2325\\</Name>] [ \\</UID>] [ \\<TSPCurrentStatus>] [ \\<Name xml:lang=\\\"en\\\">Active\\</Name>] [ \\</TSPCurrentStatus>] [ \\<StatusStartingTime>] [ \\<dateTime>2022-11-22T00:00:00Z\\</dateTime>] [ \\</StatusStartingTime>] [ \\<TSPInformation>] [ \\<TSPName>] [ \\<Name xml:lang=\\\"en\\\">Notary 1\\</Name>] [ \\</TSPName>] [ \\<TSPTradeName>] [ \\<Name xml:lang=\\\"en\\\">NTRUK-SC090312\\</Name>] [ \\<Name xml:lang=\\\"en\\\">Notary Federation 1 \\</Name>] [ \\</TSPTradeName>] [ \\<TSPAddress>] [ \\<PostalAddresses>] [ \\<PostalAddress xml:lang=\\\"en\\\">] [ \\<StreetAddress>Lichtstra\u00dfe 43h\\</StreetAddress>] [ \\<Locality>K\u00f6ln\\</Locality>] [ \\<PostalCode>50825\\</PostalCode>] [ \\<CountryName>DE\\</CountryName>] [ \\</PostalAddress>] [ \\</PostalAddresses>] [ \\<ElectronicAddress>] [ \\<URI xml:lang=\\\"en\\\">mailto:mail.notary1@federation.com\\</URI>] [ \\</ElectronicAddress>] [ \\</TSPAddress>] [ \\<TSPInformationURI>] [ \\<URI xml:lang=\\\"en\\\">https://notary1.info/TRAIN/info\\</URI>] [ \\</TSPInformationURI>] [ \\<TSPCertificationList>] [ \\<TSPCertification xml:lang=\\\"en\\\">] [ \\<Type>LEI\\</Type>] [ \\<Value>1234567\\</Value>] [ \\<Scope>\\</Scope>] [ \\</TSPCertification>] [ \\<TSPCertification xml:lang=\\\"en\\\">] [ \\<Type>Gaia-X Compliance\\</Type>] [ \\<Value>1234567\\</Value>] [ \\<Scope>\\</Scope>] [ \\</TSPCertification>] [ \\<TSPCertification xml:lang=\\\"en\\\">] [ \\<Type>eidas\\</Type>] [ \\<Value>1234567\\</Value>] [ \\<Scope>\\</Scope>] [ \\</TSPCertification>] [ \\</TSPCertificationList>] [ \\</TSPInformation>] [ \\<TSPServices>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://participant.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Participant Membership Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://participant.membership.notary1.federation.com\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://principal.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Principal Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://verifier.research.identiproof.io/\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://consumer.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Consumer Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://verifier.research.identiproof.io/\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://resource.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Resource Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://resource.membership.notary1.federation.com\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\<TSPService>] [ \\<ServiceInformation>] [ \\<ServiceTypeIdentifier>https://onboarding.membership.notary1.federation.com\\</ServiceTypeIdentifier>] [ \\<ServiceName>] [ \\<Name xml:lang=\\\"en\\\">Federation Onboarding Credential\\</Name>] [ \\</ServiceName>] [ \\<ServiceDigitalIdentity>] [ \\<x509>242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\</x509>] [ \\<did>did:web:notary.federation1.com\\</did>] [ \\</ServiceDigitalIdentity>] [ \\<ServiceStatus>http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\</ServiceStatus>] [ \\<StatusStartingTime>2022-09-29T22:00:00Z\\</StatusStartingTime>] [ \\<ServiceSupplyPoints>] [ \\<ServiceSupplyPoint>https://onboarding.membership.notary1.federation.com\\</ServiceSupplyPoint>] [ \\</ServiceSupplyPoints>] [ \\<TSPServiceDefinitionURI>] [ \\<URI>https://notary1.info/schema/V-2022-1/participant_membership.json\\</URI>] [ \\</TSPServiceDefinitionURI>] [ \\<AdditionalServiceInformation>] [ \\<ServiceCredentialTypes>] [ \\<CredentialType>X.509\\</CredentialType>] [ \\<CredentialType>did:web\\</CredentialType>] [ \\</ServiceCredentialTypes>] [ \\<ServiceGovernanceURI>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceGovernanceURI>] [ \\<ServiceBusinessRules>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\</ServiceBusinessRules>] [ \\</AdditionalServiceInformation>] [ \\</ServiceInformation>] [ \\</TSPService>] [ \\</TSPServices>] [ \\</TrustServiceProvider>] [\\</TrustServiceProviderList>] [\\</TrustServiceStatusList>] The details of every entity enrolled in the trust list are described under the attribute \\<TrustServiceProvider>. The ID of the entity is under the attribute \\<IssuerName>. Each entity in the trust list can have a Service Type Identifier under the attribute \\<ServiceTypeIdentifier>. This is a URL, and the web page that it points to should contain the JSON schema (including the \\@context property) for the VCs that are issued for this Service Type. In this way the verifier can find out which attributes the entity is trusted to issue. This trust list also offers the flexibility to the service provider to add different services with different schemas. An example for a trust list in JSON format would look as follows: { \\\"TrustServiceStatusList\\\": { \\\"SchemeInformation\\\": { \\\"HistoricalInformationPeriod\\\": \\\"65535\\\", \\\"ListIssueDateTime\\\": \\\"2022-09-27T00:00:00Z\\\", \\\"NextUpdate\\\": \\\"2022-12-27T00:00:00Z\\\", \\\"PolicyOrLegalNotice\\\": { \\\"TSLLegalNotice\\\": { \\\"#text\\\": \\\"This is an experimental list for the GXFS Federation Notary.\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"SchemeInformationURI\\\": { \\\"URI\\\": { \\\"#text\\\": \\\"https://dl.gi.de/handle/20.500.12116/38702\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"SchemeName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"DE:TRAIN\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"SchemeOperatorAddress\\\": { \\\"ElectronicAddress\\\": { \\\"URI\\\": [ { \\\"#text\\\": \\\"mailto:mail@federation1.com\\\", \\\"@xml:lang\\\": \\\"en\\\" }, { \\\"#text\\\": \\\"https://www.federation1.com\\\", \\\"@xml:lang\\\": \\\"en\\\" } ] }, \\\"PostalAddresses\\\": { \\\"PostalAddress\\\": { \\\"@xml:lang\\\": \\\"en\\\", \\\"CountryName\\\": \\\"DE\\\", \\\"Locality\\\": \\\"K\\u00f6ln\\\", \\\"PostalCode\\\": \\\"50825\\\", \\\"StreetAddress\\\": \\\"Lichtstra\\u00dfe 43h\\\" } } }, \\\"SchemeOperatorName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation 1 Notary\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"SchemeTerritory\\\": \\\"GLOBAL\\\", \\\"SchemeTypeCommunityRules\\\": { \\\"URI\\\": { \\\"#text\\\": \\\"https://train.trustscheme.de /schemerules/ngi.train.trustscheme.de\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"StatusDeterminationApproach\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/StatusDetn/EUappropriate\\\", \\\"TSLSequenceNumber\\\": \\\"1\\\", \\\"TSLType\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/TSLType/EUgeneric\\\", \\\"TSLVersionIdentifier\\\": \\\"5\\\" }, \\\"TrustServiceProviderList\\\": { \\\"TrustServiceProvider\\\": { \\\"StatusStartingTime\\\": { \\\"dateTime\\\": \\\"2022-11-22T00:00:00Z\\\" }, \\\"TSPCurrentStatus\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Active\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"TSPInformation\\\": { \\\"TSPAddress\\\": { \\\"ElectronicAddress\\\": { \\\"URI\\\": { \\\"#text\\\": \\\"mailto:mail.notary1@federation.com\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"PostalAddresses\\\": { \\\"PostalAddress\\\": { \\\"@xml:lang\\\": \\\"en\\\", \\\"CountryName\\\": \\\"DE\\\", \\\"Locality\\\": \\\"K\\u00f6ln\\\", \\\"PostalCode\\\": \\\"50825\\\", \\\"StreetAddress\\\": \\\"Lichtstra\\u00dfe 43h\\\" } } }, \\\"TSPCertificationList\\\": { \\\"TSPCertification\\\": [ { \\\"@xml:lang\\\": \\\"en\\\", \\\"Scope\\\": null, \\\"Type\\\": \\\"LEI\\\", \\\"Value\\\": \\\"1234567\\\" }, { \\\"@xml:lang\\\": \\\"en\\\", \\\"Scope\\\": null, \\\"Type\\\": \\\"Gaia-X Compliance\\\", \\\"Value\\\": \\\"1234567\\\" }, { \\\"@xml:lang\\\": \\\"en\\\", \\\"Scope\\\": null, \\\"Type\\\": \\\"eidas\\\", \\\"Value\\\": \\\"1234567\\\" } ] }, \\\"TSPInformationURI\\\": { \\\"URI\\\": { \\\"#text\\\": \\\"https://notary1.info/TRAIN/info\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"TSPName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Notary 1\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"TSPTradeName\\\": { \\\"Name\\\": [ { \\\"#text\\\": \\\"NTRUK-SC090312\\\", \\\"@xml:lang\\\": \\\"en\\\" }, { \\\"#text\\\": \\\"Notary Federation 1\\\", \\\"@xml:lang\\\": \\\"en\\\" } ] } }, \\\"TSPServices\\\": { \\\"TSPService\\\": [ { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Participant Membership Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://participant.membership.notary1.federation.com\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://participant.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } }, { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Principal Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://verifier.research.identiproof.io/\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://principal.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } }, { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Consumer Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://verifier.research.identiproof.io/\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://consumer.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } }, { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Resource Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://resource.membership.notary1.federation.com\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://resource.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } }, { \\\"ServiceInformation\\\": { \\\"AdditionalServiceInformation\\\": { \\\"ServiceBusinessRules\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\", \\\"ServiceCredentialTypes\\\": { \\\"CredentialType\\\": [ \\\"X.509\\\", \\\"did:web\\\" ] }, \\\"ServiceGovernanceURI\\\": \\\"https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021R0953\\\" }, \\\"ServiceDigitalIdentity\\\": { \\\"did\\\": \\\"did:web:notary.federation1.com\\\", \\\"x509\\\": \\\"242364735r634785634857348957349587395473957395739573932458743rz3ufgf3hrfv3hfv3hfv3hfv3hf\\\" }, \\\"ServiceName\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"Federation Onboarding Credential\\\", \\\"@xml:lang\\\": \\\"en\\\" } }, \\\"ServiceStatus\\\": \\\"http://uri.etsi.org/TrstSvc/TrustedList/Svcstatus/granted\\\", \\\"ServiceSupplyPoints\\\": { \\\"ServiceSupplyPoint\\\": \\\"https://onboarding.membership.notary1.federation.com\\\" }, \\\"ServiceTypeIdentifier\\\": \\\"https://onboarding.membership.notary1.federation.com\\\", \\\"StatusStartingTime\\\": \\\"2022-09-29T22:00:00Z\\\", \\\"TSPServiceDefinitionURI\\\": { \\\"URI\\\": \\\"https://notary1.info/schema/V-2022-1/participant_membership.json\\\" } } } ] }, \\\"UID\\\": { \\\"Name\\\": { \\\"#text\\\": \\\"2325\\\", \\\"@xml:lang\\\": \\\"en\\\" } } } } } }","title":"Trust List Formats"},{"location":"traincd/traincd/#trusted-content-handling","text":"Trust lists and pointers to the trust lists will be summarized under the term \"Trusted Content\" in the following.","title":"Trusted Content Handling"},{"location":"traincd/traincd/#trusted-content-locations","text":"Pointers to trust frameworks will be placed as in the DNS of the Trust Framework Operators. Depending on requirements of the specific use case, trust lists can be placed on https web servers or in the IPFS. To maintain auditability and security against manipulation, it is recommended that the Trust List is published in the IPFS. DID Documents can be placed on Ledgers, the IPFS or https web servers. The Verifiable Credential with the Trust List URI can also be published on the different locations as mentioned.","title":"Trusted Content Locations"},{"location":"traincd/traincd/#enrolment-process-of-entities-in-trust-lists","text":"The Notarization API will cover the enrolment of entities in trust lists. The requirements that have to be fulfilled for enrolment are dependent on the Trust Framework of the respective context, i.e., the Gaia-X Trust Framework, the Trust Framework of a certain Federation, etc. The technical process is triggered by the notary and executed by the TSPA/Federator performing CRUD operations on the trust list that is located on the Trusted Data Store.","title":"Enrolment Process of Entities in Trust Lists"},{"location":"traincd/traincd/#trusted-content-resolving","text":"Resolving trusted content via trust list involves trust discovery and trust validation processes. In order to resolve the trusted content, the following data model is to be followed: { \"IssuerDetails\": \"did:web:company.de\" \"Trust Framework Pointer\": [\"federation1.com\", \"gaia-x.eu\"], \"ServiceContentType\": \"gx-trust-list-issuer\" } The term: \"IssuerDetails\\'\\' describes the DID or URI of the issuer credential \"Trust Framework Pointer\\'\\' describes the trust frameworks mentioned in the termsofUse of the verifiable credential \"ServiceContentType\" is set by the Resolver to resolve the corresponding trust list. For example: gx-type-list-issuer contains the information of a trusted issuer trust list but if the resolver needs information regarding schema then it can point to \"gx-trust-list-schemas\". The following are minimum set of trusted content service types for TRAIN in Gaia-X: <!-- --> gx-trust-list-issuer (format: Verifiable credentials, JSON) gx-trust-list-schemas gx-trust-list-policies gx-trust-list-apps gx-trust-list-verifier gx-trust-list-authorities It is foreseen that a further analysis of the specific requirements of the concrete use cases is performed. This analysis will define if a specific type is needed and/or if further types will have to be added, as well as the specific format and content of the types. Please refer to the sections \"Trust Verification\" and \"Unified Signature & Verification Model for Trust Lists via DID and VC\" which describe in detail the discovery process of the trust list and the step-by-step validation.","title":"Trusted Content Resolving"},{"location":"traincd/traincd/#trusted-content-auditing","text":"Depending on the requirements for auditability, different procedures are recommended for the anchoring of trusted content: Requirement Procedure Trusted Content must be Anchor all items into an audible, tamper-proof auditible up to system (e.g., IPFS, Ledgers) Enrollment Trusted Content Creator Anchor the DID in the DNS Zones (default) must be audible Trusted Content Location Anchor the URL in the DNS Zones must be anchored Table 4: Procedures for auditability requirements Other options remain possible.","title":"Trusted Content Auditing"},{"location":"traincd/traincd/#setup-process-for-trust-verification","text":"An entity performing trust verification, i.e., to check whether a certain company is indeed a member of the specific Gaia-X Trust Framework that it claims to be, the entity has to configure the DNS names of the trust frameworks that it trusts in the Trusted Content Resolver [10]. So, if it would choose to trust the Trust Framework \"Example\" of the Gaia-X Federation \"Federation1\" it would configure the Trusted Content Resolver for \" example.federation1.com .\" And if it also trusts the Trust Framework \"Partners\" of \"Federation2\" it would also add \" partners.federation2.de.\"","title":"Setup Process for Trust Verification"},{"location":"traincd/traincd/#10-if-an-api-is-used-the-urls-of-the-train-apis-to-call-to-verify-the-membership-lists-have-to-be-set-up-as-well","text":"Additionally, the Trusted Content resolver can also configure what type of trust lists needs to be resolved, as different types of trust lists can be configured in the DID Document using service type. Examples are: gx-trust-list-issuer , gx-trust-list-verifier , gx-trust-list-schemas , gx-trust-list-apps , gx-trust-list-authorities . When the verifying entity receives a VC, it extracts the asserted trust framework claims made by the issuer in the Terms of Use property. If it trusts any of the claimed trust frameworks, it calls the Trusted Content Resolver, passing it the URI of the issuer (taken from the VC, e.g., \\\" did:example:123456789abcdefghi \\\") and the DNS name of the trusted trust framework that the VC Issuer purports to be a member of (e.g., \\\"Trust_Scheme_Pointer\\\": \\\" example.federation1.com \\\"). The Trusted Content Resolver will then check if the VC issuer is a member of any of the trust lists pointed to by this trust framework, and if so, return the Service Type URL to the Verifier. The verifier can check that this URL is identical to the one in the credentialSchema property, and if it is, use the schema contained at this URL to validate that the attributes in the received VC match the schema for this Service Type.","title":"[10]  If an API is used, the URL(s) of the TRAIN API(s) to call to verify the membership lists have to be set up as well."},{"location":"traincd/traincd/#packages-for-programming-languages","text":"The Trusted Content Resolver will be developed for the following programming languages: Java Javascript Go Figure: Trusted Content Resolver","title":"Packages for Programming Languages"},{"location":"traincd/traincd/#conclusion-and-consequences","text":"","title":"Conclusion and Consequences"},{"location":"traincd/traincd/#security-consolidations-and-implications","text":"As a distributed database both in terms of organization of data as well as responsibility for operation and management, the DNS is very suitable for an infrastructure that aims to support integration and interoperation of various trust frameworks across federations. The original design of the DNS did not consider a number of attacks allowing miscreants to alter information retrieved via the DNS. The Domain Name Service Security Extensions (DNSSEC) have been developed to mitigate this problem. They allow users of the DNS to verify that the data they received is indeed the data intended. This ability for verification is vital for use of DNS in the context of a trust infrastructure. However, this also means that the secure control of the DNS is essential for a trust framework provider in TRAIN. Hence, TRAIN requires secure organizational governance of the DNS processes at the DNS controller responsible for creating the Trust Schemes/Trust Frameworks and setting the pointers to locations of the Trust Lists.","title":"Security consolidations and implications"},{"location":"traincd/traincd/#advanced-concepts","text":"","title":"Advanced Concepts"},{"location":"traincd/traincd/#integration-with-the-ethereum-name-service-ens","text":"A potential for further development would be to evaluate further the use of Ethereum ledger based DIDs as pointers to the Trust Lists. This could leverage the trust of Smart Contracts and a decentralized consensus mechanism. The Ethereum Name Service (ENS) is a distributed, open, and extensible naming system based on the Ethereum blockchain.[11] ENS supports text records as well as reverse resolution. Hence, there is a potential for TRAIN to use ENS complementary to DNS/DNSSEC. However, the ENS is not as mature and established as DNS/DNSSEC and this approach would need further research.","title":"Integration with the Ethereum Name Service (ENS)"},{"location":"traincd/traincd/#11-httpsdocsensdomains","text":"","title":"[11] [https://docs.ens.domains/]"},{"location":"traincd/traincd/#establishment-of-trust-against-man-in-the-middle-attacks-pcm-and-ocm","text":"Further investigation would be required in order to evaluate how Trust Lists can be leveraged to protect against Man-in-the-Middle Attacks between different components. This would be particularly important for interactions between Personal Credential Manager (PCM) and Organizational Credential Manager (OCM).","title":"Establishment of Trust against Man-in-the-Middle Attacks: PCM and OCM"},{"location":"traincd/traincd/#verification-of-the-verifier-from-the-holder","text":"The following figure shows how TRAIN can be used to establish trust into the verifier. To enable this, a certain authority, such as a specific Gaia-X Federation, has to develop a Trust Framework that specifies how a verifier can be trustworthy (and potentially which verifiers can be trusted to receive which information). Verifiers complying with these requirements will be enrolled via their DID to the trusted verifiers trust list of this Gaia-X Federation. Now, before a VC is exchanged, the verifier passes the Trust_Scheme_Pointer in the presentation request to the holder. With this, the verifier claims membership in a certain verifier trust framework/scheme. It follows a validation process as described above - only that it is initiated from the holder. After this validation is successful, the requested data can be passed to the verifier. Figure 9: TRAIN in the \"Triangle of Trust\": Trusted Verifiers","title":"Verification of the Verifier from the Holder"},{"location":"traincd/traincd/#support-of-federation-membership-verification-in-the-oidc4vp-standard","text":"The following section is for information purposes. The use of TRAIN is explicitly referenced in the implementation considerations of the OIDC4VP at: [https://openid.net/specs/openid-connect-4-verifiable-presentations-1_0.html#name-implementation-consideratio] It is written there: \"Trust schemes that conform to the TRAIN trust scheme are identified by the type https://train.trust-scheme.de/info. Individual federations are identified by their DNS names.An example claims parameter containing a presentation_definition that filters VCs based on their federation memberships is given below.\" { \\\"vp_token\\\": { \\\"presentation_definition\\\": { \\\"id\\\": \\\"32f54163-7166-48f1\\\", \\\"input_descriptors\\\": [ { \\\"id\\\": \\\"federationExample\\\", \\\"purpose\\\": \\\"To pick a UK university that is a member of the UK academic federation\\\", \\\"constraints\\\": { \\\"fields\\\": [ { \\\"path\\\": [ \\\"\\$.termsOfUse.type\\\" ], \\\"filter\\\": { \\\"type\\\": \\\"string\\\", \\\"const\\\": \\\"https://train.trust-scheme.de/info\\\" } }, { \\\"path\\\": [ \\\"\\$.termsOfUse.federations\\\" ], \\\"filter\\\": { \\\"type\\\": \\\"string\\\", \\\"const\\\": \\\"ukuniversities.ac.uk\\\" } } ] } } ] } } } This example will choose a VC that has been issued by a university that is a member of the ukuniversities.ac.uk federation and that uses the TRAIN terms of use specification for asserting federation memberships.","title":"Support of Federation Membership Verification in the OIDC4VP Standard"},{"location":"tsae1/tsae1/","text":"Software Requirements Specification for Gaia-X Federation Services Trust Services API Extension 1 IDM.TSA.E1 Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA 1 Introduction 1.1 Document Purpose 1.2 Product Scope 1.3 Definitions, Acronyms and Abbreviations 1.4 References 1.5 Document Overview 2 Product Overview 2.1 Product Perspective 2.2 Product Functions 2.3 Product Constraints 2.4 User Classes and Characteristics 2.5 Operating Environment 2.6 User Documentation 2.7 Assumptions and Dependencies 2.8 Apportioning of Requirements 3 Requirements 3.1 External Interfaces 3.1.1 User Interfaces 3.1.2 Hardware Interfaces 3.1.3 Software Interfaces 3.1.4 Communications Interfaces 3.2 Functional 3.2.1 Policy Management Module 3.2.2 Policy Decision Engine 3.2.3 Task Controller 3.2.4 JSON-LD signatures and validations 3.2.5 Distributable Cache 3.2.6 eIDAS 3.2.7 General 3.3 Other Nonfunctional Requirements 3.3.1 HTTP Requirements 3.3.2 Logging Requirements 3.3.3 Performance Requirements 3.3.4 Safety Requirements 3.3.5 Security Requirements 3.3.6 Software Quality Attributes 3.3.7 Business Rules 3.4 Compliance 3.5 Design and Implementation 3.5.1 Installation 3.5.2 Distribution 3.5.3 Service Meshing 3.5.4 Standard Technology 3.5.5 Metrics 3.5.6 Configurability 3.5.7 Maintainability 3.5.8 Reusability 3.5.9 Runtime Stability 3.5.10 High Availability Concepts 4 System Features 4.1 Policy Management 4.1.1 Description 4.1.2 Functional Requirements 4.2 Policy Evaluation 4.2.1 Description 4.2.2 Functional Requirements 4.3 Task Controller 4.3.1 Description 4.3.2 Functional Requirements 4.4 JSON-LD Signing and verification 4.4.1 Description 4.4.2 Functional Requirements 4.5 Trusted Caching 4.5.1 Description 4.5.2 Functional Requirements 4.6 eIDAS Compliant Signatures 4.6.1 Description 4.6.2 Functional Requirements 5 Verification 5.1 Core Verification Requirements 5.2 Acceptance Criteria 5.2.1 Policy Management Module 5.2.2 Policy Decision Engine 5.2.3 Task Controller 5.2.4 JSON-LD signatures and validations 5.2.5 Distributable Cache 5.2.6 eIDAS 5.3 Support for Kubernetes Appendix A: Glossary Appendix B: Architecture List of Figures Figure 1: Architecture (semi-transparent boxes are out of scope) List of Tables Table 1: References Table 2: Apportioning of Requirements Table 3: Technology Stack Table 4: Functional Requirements Policy Management Table 5: Functional Requirements Policy Evaluation Table 6: Functional Requirements Task Controller Table 7: Functional Requirements JSON-LD Signing and Verification Table 8: Functional Requirements Trusted Caching Table 9: Functional Requirements eIDAS Compliant Signatures Introduction To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] []{#1.1_Document_Purpose .anchor}and [PRD]. Document Purpose The purpose of the document is to specify the requirements of the Identity Management and Trust Subcomponent \"Trust Services API Extension 1\" with the intention of a European wide public tender for implementing this software. Main audience for this document is attendees of the public tender, which are able to supply an open-source software solution for the area of Signing/Validation, Secure Policy Management and Policy Execution with the purpose to provide trusted services around Decision Evaluations and Verifications. Product Scope The product scope covers the functionalities of the Trust Services API. The aim of the Trust Services API Extension 1 is to ensure a consistent level of trust between Gaia-X participants and components. The Trust Services API can be used by all components. The creation and validation of digital signatures plays a particularly important role here. The product scope includes signing and verifying of necessary data, enabling policy driven trust, ensuring trust-chains between participants and validating eIDAS compliant signatures. The scope also includes necessary tools (e.g., Command Line Scripts) to operate and maintain the created software components in an enterprise environment with focus on high-availability, security and monitoring and logging based on common standards. Documentation for developer, operator and user MUST be written in markdown format which is publicly consumable over a publicly accessible source repository without access limitations. If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams. Definitions, Acronyms and Abbreviations The Trust Architecture Overview Document [IDM.AO] MUST be considered and applied as the core technical concept that includes also the Terminology and Glossary. All requirements from other documents are referenced by [IDM.\\<document-id>.XXXXX] as defined in chapter 1 \"Methodology\" in the document [IDM.AO]. References Description Status Specflow (n.D.), BDD Specflow BDD 07-04-2023 Cloud Events CloudEvents 07-04-2023 D:EBSI EBSI DID Method 07-04-2023 IDM.AO Gaia-X WP1 (2021), Architecture Overview IDM.TRAIN Gaia-X Federation Services - Trust Management Infrastructure JSON-LD JSON-LD 1.1 07-04-2023 LD Proofs Linked Data Proofs 1.0 07-04-2023 PRD Gaia-X Policy Rules Document 08-14-2023 Rego Rego Policy Language 07-04-2023 RFC 2119 RFC 2119 07-04-2023 RFC 5789 PATCH Method for HTTP 07-04-2023 RFC 7231 HTTP/1.1: Semantics and Content 07-04-2023 RFC 7807 Problem Details for HTTP APIs 07-04-2023 TAD Gaia-X Architecture Document 08-14-2023 TDR Gaia-X Federation Services Technical Development Requirements TSA Gaia-X, European Association for Data and Cloud, AISBL (2021): Gaia-X Trusted Services API Document TSA.GITLAB Gitlab tickets for the GAIA-X Trust Services API Table 1: References Document Overview The document describes the product perspective, functions and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [RFC 2119], are written in capital letters (see also [IDM.AO] - Methodology). Product Overview Product Perspective Please refer to [TDR] and [TSA] . The existing code base [1] MUST be reused and further improved. Other microservices MAY have different languages and architectures. [1] [https://gitlab.eclipse.org/eclipse/xfsc/tsa] Product Functions The functions of the Trust Services component are provided case-dependent either as runtime or library components. Runtime components MUST expose endpoints as REST services. In addition, policy configuration with GitOps should be used to enable the provisioning and sharing of policies. The component is part of the Gaia-X Trust and identity management toolstack and not centrally hosted. To properly maintain and update, appropriate security measures MUST be in place. This includes role concepts, data storage protection and access control. The overall functionality of the product MUST be auditable (GDPR compliant). Figure 1: Architecture (semi-transparent boxes are out of scope) Product Constraints Please refer to [TSA] Section 2.3 and [TDR] . User Classes and Characteristics Please refer to [TSA] 2.4 and [TDR] . Operating Environment Please refer to [TSA] 2.5 and [TDR] for further binding requirements regarding the operating environment. [IDM.TSA.E1.00000] Kubernetes Environment The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on the provided SCS cluster (Sovereign Cloud Stack), which will be provided by the Client. User Documentation Please refer to [TDR] for further requirements regarding documentation. [IDM.TSA.E1.00001] Participant Administration Documentation The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the products from source code [IDM.TSA.E1.00002] Participant Documentation The documentation MUST contain: Short Software Description (why and for what, when to use, how use, where to use) Usage guide GDPR design decisions Security concept Operations concept FAQ Keyword Directory Assumptions and Dependencies An understanding of the overall Gaia-X architecture and philosophy is necessary. Please refer to [TAD] und [PDR]. Attendees of the public tender MUST assume responsibility of: All tickets in GitLab ( [TSA.GITLAB] ) with label \"Specification\" The existing code and improvements upon the existing code Extending or contributing to the used frameworks in order to provision a way in which realization of the requirements can be achieved Updating dependencies to the latest stable version Apportioning of Requirements Feature Priority Policy Management 1 Policy Evaluation 1 Task Coordination 1 Feature Priority JSON-LD Verification 1 JSON-LD Signing 1 Trusted Caching 1 eIDAS compliant Signatures 2 Table 2: Apportioning of Requirements Requirements Further binding requirements can be found in [TDR]. External Interfaces User Interfaces Please refer to [TSA] 3.1.1. Hardware Interfaces Please refer to [TSA] 3.1.2. Software Interfaces Please refer to [TSA] 3.1.3. Communications Interfaces Please refer to [TSA] 3.1.4. [IDM.TSA.E1.00003] Eventing If it is required to use events within the software architecture, it is mandatory to use software abstraction according to cloud event specification [CloudEvents] for publishing and subscription. The minimal supported protocol binding MUST be HTTP Protocol Binding [2]. [2] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/bindings/http-protocol-binding.md] [IDM.TSA.E1.00004] Eventing Infrastructure The event broker for the eventing MUST abstract the storage and delivery infrastructure. In Kubernetes environments, the broker MUST be uniform across all Lots. (e.g., kNative) Functional Policy Management Module [IDM.TSA.E1.00005] Policy Bundles Policy bundles MUST contain further information, e.g., data input JSON files. They MUST contain meta-data and references like resolvable DIDs to be verifiable and trustworthy. The bundle MUST be signed in a productive state or before the export. It MAY be chosen, how the signing and verification is standardized. For instance, the metadata can be signed for the included files of the bundle, or the bundle itself can be signed as a compressed package e.g., Zip packed in a CMS to exchange later on policy bundles. [IDM.TSA.E1.00006] Policy Import and Export The policy administrator MUST be able to configure policy import endpoints where the system automatically downloads new policy bundles. The policy export endpoint itself MUST be configurable in that way, so that the policy administrator can decide which bundles from the productive repository can be exported. Each import and export MUST be signed with a key registered in the DID document and verifiable against the public keys from the DID document defined in the bundle. For this purpose, the DID resolver MUST be used. Import and export MUST be observable for the configured repositories. [IDM.TSA.E1.00007] Policy Changes Notification The system MUST be able to notify other components when policy source code or data has changed. Notifications may be passed to message queue, smart contract or use other notification mechanisms which are suitable in the context of the technology stack. Notifications might be granular and explicitly contain information about what has changed. [IDM.TSA.E1.00008] Webhooks for policy changes The product MUST allow other components to subscribe for policy changes via webhooks. Clients MUST be able to give a URL and the product MUST send the relevant payload once there are policy changes. [IDM.TSA.E1.00009] JSON Schema Validation for Policy Output Optional policy configuration files may specify mandatory JSON schemas which must be part of the JSON output from a policy evaluation. The validation must check whether the schemas are present and must validate the JSON document with Strict validation. To execute the validation procedure, a new HTTP URL can be automatically generated. Example: Evaluation URL pattern: /{repo}/policies/{group}/{policyname}/{version}/evaluation Validation URL pattern: /{repo}/policies/{group}/{policyname}/{version}/validation If the validation fails, the policy service might LOCK the policy for execution and log an error/warning in the logs. [IDM.TSA.E1.00010] Fine granular policy management The system SHOULD allow managing policies in separate GIT repositories. This will allow separate GIT Workflows for different system contexts. Synchronization mechanisms SHOULD be separate for different GIT repositories. A new URL path parameter SHOULD be introduced in order to achieve context separation upon policy evaluation. Example: Current evaluation URL: ../policy/ {group} / {name} / {version} /evaluation Evaluation URL with GIT Repository separation: ../policy/ {repository} / {group} / {name} / {version} /evaluation [IDM.TSA.E1.00011] Interface for Export Configuration The policy administration module MUST be able to define new export configurations for each policy. The system MUST have an automated export configuration update flow, that will always take the main branch of the configurations and publish them, making them available for execution. Interface GitOps Input Export configurations Output Updated Export Configurations are available for execution [IDM.TSA.E1.00012] Policy Admin API The policy service may provide an HTTP API to inspect the current policy service state. For example, get a list of all unlocked/locked policies, return a specific policy source code or some policy meta information like last update timestamp. This could be useful while debugging the service or for building a UI dashboard for administrators. For example, the sync from Git to Policy Database could fail unexpectedly or even complete without errors, but there could be a bug where policy source code in the database is different from policy source code in the Gilt repo. Debugging such issues would be extremely difficult without having the ability to look at the current Policy service state/data, because just looking at the external Git policy repo will not be helpful to discover some discrepancies. The API could start with the following functionalities but could be further expanded as necessary. Retrieve all/some policies from the Policy DB. Optionally specify which fields should be returned - e.g., source code, static data, meta fields, etc. Retrieve policy lock/unlock state Retrieve static data/configurations for a given policy Policy Decision Engine [IDM.TSA.E1.00013] Call of external URLs The decision engine MUST have the capability to call HTTP URLs with free chosen query parameters, headers, and request bodies for any HTTP verb within the policy execution. This MUST be possible out of the defined policy to load external data dynamically into the execution context. It MAY be created also helper components e.g., built in functions, to support this feature outside of the policy policy execution context. Constraints Policy Language Policy Execution Input HTTP URL with Parameters, Header and Request Body. Output JSON HTTP Response. [IDM.TSA.E1.00014] Storage Extension Functions The decision engine MUST have the capability to work with database storage, that a policy can persist and pick up data during execution. This MUST be achieved with REGO extension functions. The functions MUST have the ability to create, update and delete data from a predefined database table/collection during policy evaluations. Constraints Rego Policy Language [Rego] [IDM.TSA.E1.00015] Storage Implementation The storage layer for policy storage MUST be implemented in a way that no specific database technology is strictly required for the purpose of policy execution. The implementation MUST support the following levels: Policy Service uses internal storage for cloning the policy repositories. This level supports not just in time sync, but a very quick usage of simple, not often changed policies. Policy change requires container restart. This can be realized by a script during container startup (if configured) The policy service uses an external storage to pick up the policies. E.g., from a postgres db, a mongodb or similar. The external storage provides events when a policy has changed, or a sync happens Both levels MUST be configurable and adaptable by an internal interface e.g., IPolicyStorage to allow additional implementations in the future for internal and external storage implementations. [IDM.TSA.E1.00016] TRAIN validation & verification The TRAIN validation service ([IDM.TRAIN.00017], [IDM.TRAIN] p. 12) needs to be included in the process of verifying a verifiable presentation. If a requestor is showing a verifiable presentation during a task which needs to be fulfilled the notarization service needs to validate the terms Of Use by calling the TRAIN validation module. This will verify if the shown verifiable presentation and its respective owner is on a trustlist. Constraints DID of the organization. Database system. Interfaces TRAIN validation module Input A verification with an incoming verifiable presentation Output Verification output of the TRAIN validation module Task Controller [IDM.TSA.E1.00017] Cache Event Subscription If a data update event occurs from the distributable cache, the task controller MUST execute a policy which evaluates whether any further tasks must be created. If any task is configured, the tasks MUST be created for execution. The task has the same metadata as the event (key, namespace and scope) For instance: A proof data object is inserted from the OCM into the cache. This object contains a DID from the issuer. The policy evaluates the schema of the data object and returns Task \"IssuerProof\". The task controller inserts this task to the tasklist by adding the http URL of the OCM proof manager with the DID of the issuer as parameter. Some seconds later, the proof from the issuer arrives and the policy returns null (nothing to do). Constraints Distributable Cache Event Policy Evaluation Input An Insert/Update Event Output A task result or null. [IDM.TSA.E1.00018] Task Queue and Storage Abstraction Layer An abstraction layer MUST be implemented for the Queue and the Storage interfaces in the task controller. The Abstraction layer MUST be agnostic of the underlying implementation. JSON-LD signatures and validations [IDM.TSA.E1.00019] Proof Chains in JSON-LD JSON-LD proof chains [LD.Proofs] SHOULD be supported to link multiple entities to the same data, when proof sequences are required. This can be useful for notary counter-signing a proof that had been created on a document. It MUST support signing and verifying the VCs. Example: { > \\\"@context\\\": \\[ > \\\"https://[www.w3.org/2018/credentials/v1\\\"](http://www.w3.org/2018/credentials/v1), > \\\"https://[www.w3.org/2018/credentials/examples/v1\\\"](http://www.w3.org/2018/credentials/examples/v1) > > \\], > > \\\"title\\\": \\\"Hello World!\\\", > > \\\"proofChain\\\": \\[{ > > \\\"type\\\": \\\"Ed25519Signature2018\\\", \\\"proofPurpose\\\": > \\\"assertionMethod\\\", \\\"created\\\": \\\"2019-08-23T20:21:34Z\\\", > > \\\"verificationMethod\\\": \\\"did:example:123456#key1\\\", \\\"domain\\\": > \\\"example.org\\\", > > \\\"jws\\\": \\\"eyJ0eXAiOiJK\\...gFWFOEjXk\\\" > > }, > > { > > \\\"type\\\": \\\"RsaSignature2018\\\", \\\"proofPurpose\\\": \\\"assertionMethod\\\", > \\\"created\\\": \\\"2017-09-23T20:21:34Z\\\", > > \\\"verificationMethod\\\": \\\"https://example.com/i/pat/keys/5\\\", > \\\"domain\\\": \\\"example.org\\\", > > \\\"jws\\\": \\\"eyJ0eXAiOiJK\\...gFWFOEjXk\\\" > > }\\] > > } Distributable Cache [IDM.TSA.E1.00020] Content Access The cached content MUST be accessible over a key (e.g., a DID), a namespace and an array of scopes, which results in an array of JSON documents. For instance, the access to the cache can be the following: Key: DID:sov:2358585 Namespace: Login Scopes: administration, read, visitor Result: {\"name\":\"userX\",\"iss\":did:sov:33333}, {\"membership\":\"company\",\"iss\":did:sov:1111} To optimize the access, it MAY be optimized by flatten the access pattern like: Key: DID:sov:2358585 Namespace: Login:administration Independent from the format, the result for the accessor MUST be a flatten JSON structure. In the flattening step, it SHOULD namespace duplicated claims if they are semantically different (e.g., using JSON-LD context [JSON.LD]). If two JSON structures bring a duplicated claim which is semantically the same claim (say two JSON structures bring Name and Surname, but the values are different) then a policy shall decide whether to: take one of them or discard all of them. Constraints Supported data format of the cache technology Policy Decision Engine eIDAS [IDM.TSA.E1.00021] eIDAS compliant Signature Creation / Validation Signatures must be generated/verified in compliance with eIDAS so that legally secure trust can be achieved. This should include the eIDAS signature types basic, advanced, and qualified. The implementation variant must be selected individually in coordination with the used technology. [IDM.TSA.E1.00022] Support for DID:EBSI encoding for Natural Persons Support public key encoding in DID document for Natural Persons according to the EBSI DID Method specification [DID:EBSI]. Constraints EBSI DID Method [DID:EBSI]. General [IDM.TSA.E1.00023] Architecture Restructuring The architecture of the existing TSA MUST be changed in this way, so that the software can be deployed feature by feature without the need to deploy for each feature every subcomponent like databases etc. In summary, all dependencies MUST be organized like this, that the deployment is more independent and operational cost friendly. The following changes MUST be provided: The plain policy execution MUST be able to work without the mongoDB (e.g., by using git clone on container startup) Usage of MongoDB MUST be just optional by configuration If the user wants to dynamically configure the policies, the policy execution MUST require mongoDB The task controller feature MUST be shipped with a generic message queue interface to support usage of different queues (currently mongodb is the queue, other queues must not be provided) The signing service MUST be more generic to support different signing engines The policy execution MUST be aware of existing features and MUST reply during the policy execution the non-existence of the feature e.g., \"Signing Service not available or this function requires the usage of MongoDB\" There may be other required changes during the architecture change, which MUST be highlighted to the technical lead and planned in the cost calculation during the analysis. Overall goal of this requirement is to allow the users to reduce the costs of their operational environment. Means if a user decides to use just the policy execution, an operational setup for instance of mongoDB and redis MUST be not required to operate it 24/7. Other Nonfunctional Requirements [IDM.TSA.E1.00024] Architecture Changes All Architecture Changes MUST be aligned with the Principal before implementation. HTTP Requirements [IDM.TSA.E1.00025] HTTPS All HTTP Endpoints MUST be protected by TLS 1.2 (all protocol version numbers SHOULD be superseded by upcoming standards) Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system. [IDM.TSA.E1.00026] HTTP Protocol Definitions All HTTP Endpoints MUST follow [RFC7231] and [RFC5789], but it MAY be chosen what of the protocols is necessary to realize the functionality. For problem reports the [RFC7807] MUST be used in combination with Standard HTTP Error Codes. Logging Requirements [IDM.TSA.E1.00027] Data Minimization The data minimization principle is expressed in Article 5(1)(c) of the GDPR and Article 4(1)(c) of Regulation (EU) 2018/1725, which provide that personal data must be \\\"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed\\\". The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of the following elements: (a) node\\'s identification (b) message identification (c) message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review. [IDM.TSA.E1.00028] Logging Frameworks The product MUST support logging frameworks e.g., graylog, fluentD or logstash to support logging and analysis by enterprise infrastructures. The supported framework MAY be chosen for the first version, but it MUST support potentially the most common open-source logging solutions. The final solution MUST be aligned with the other subcomponents. It MUST be sketched in the operations concept how the support of multiple solutions is given in the future. Performance Requirements [IDM.TSA.E1.00029] Up/Down Scale All components MUST be able to scale up/down their functionality for undefined amount instances. This requires a parallel execution possibility which will be tested later on by performance tests which are defined by the test team. Safety Requirements [IDM.TSA.E1.00030] Major Releases All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening. Security Requirements [IDM.TSA.E1.00031] CVE Patches All software components MUST have applied CVE patches, which are available for major releases. Software Quality Attributes [IDM.TSA.E1.00032] Software Quality Requirements All software components MUST be compliant to the requirements within the quality assurance repository [3]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology. [3] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues] Business Rules [IDM.TSA.E1.00033] Software Consistency The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc. [IDM.TSA.E1.00034] Cherry Picking All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow an enterprise deployment customization. Compliance [IDM.TSA.E1.00035] GDPR Audit Logging All GDPR relevant access to personal relevant data MUST be logged for a later audit. [IDM.TSA.E1.00036] GDPR Data Processing Is it necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable. Design and Implementation Installation [IDM.TSA.E1.00037] Helm/Argo CD Deployment All installations MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a ARGO CD Pipeline defined in the gxfs-integration repository [4]. [4] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Distribution [IDM.TSA.E1.00038] Helm Repositories All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [5]. [5] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml] [IDM.TSA.E1.00039] Istio Resources Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc. ) following the integration pattern specified in the gxfs-integration repo[6]. [6] [https://gitlab.eclipse.org/eclipse/xfsc/integration] Service Meshing [IDM.TSA.E1.00040] Istio Support All HELM charts MUST be provided with Istio support aligned together with the project team. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment. Standard Technology [IDM.TSA.E1.00041] Default Toolstack Each development MUST consider the following standard technologies, if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React [7] Ingress Controller Nginx/Istio API Testing Postman (manual) API Design OpenAPI Kubernetes v1.26+ > Table 3: Technology Stack [7] [https://react-bootstrap.github.io/] The technology stack is mandatory to avoid integration impact. Metrics [IDM.TSA.E1.00042] Opentelemtry Support All helm charts/services MUST provide metrics endpoints in opentelemetry [8]format. [8] [https://opentelemetry.io/docs/] Configurability [IDM.TSA.E1.00043] Configuration All components MUST support one of the major configuration formats (yaml, json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged. [IDM.TSA.E1.00044] Configuration Profiles Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening. [IDM.TSA.E1.00045] Secret References in Helm Charts The configuration secrets within Helm Charts MUST use secretRefs to support external Secretmanagement. Clear text secrets within the Helm Charts are not allowed. Maintainability [IDM.TSA.E1.00046] Micro Service Architecture For a better scale out, maintainability and decentralization, the product architecture MUST have a micro service architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement it. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment). [IDM.TSA.E1.00047] Domain Driven Design To support the micro service architecture within the maintainability, it MUST be declared a domain model before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers. Reusability [IDM.TSA.E1.00048] Enterprise Environments All components MUST be reusable in different enterprise environments by customization and whitelabeling. Means all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.) Runtime Stability [IDM.TSA.E1.00049] Readiness Check Ups All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: A unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state High Availability Concepts [IDM.TSA.E1.00050] Redundant Deployment Each deployment MUST be configured for a minimum fault tolerance of 2 instances. System Features Policy Management Description - Policy Management The policy management provides functionalities around the signing, validation, import, export, and merge of policies from internal and external policy repos. This is necessary to ensure that only trusted policies are imported from trusted resources. The feature must help and support the policy administrator in decisions to trust a policy repository from outside, trust imported policies, sign policies for export, export specific policies and merge changes into the productive repository. This feature can be automated by a continuous integration system (e.g., Jenkins), but it SHOULD include configurable manual reviewing steps to ensure that the signing of policies MUST be done by an authorized person. Functional Requirements - Policy Management Endpoints Webhooks for policy changes JSON Schema Validation for Policy Output Fine granular policy management Policy Admin API Functions Policy Bundles Policy Import and Export Policy Changes Notification Interface for Export Configuration Table 4: Functional Requirements Policy Management Policy Evaluation Description - Policy Evaluation The policy evaluation provides functionality around the execution of policies. This includes the provisioning of versioned HTTP routes to execute the policy, synchronous and asynchronous policy evaluation, usage of external HTTP resources within the execution and a policy decision engine to create JSON response for a given JSON request and helper functionality around it. For instance, the caching of results or the inclusion of static JSON documents into the policy decisions, to evaluate more complex policies. All policies and static documents for the execution must be loaded from the encrypted hard disk into memory to guarantee the maximum execution speed. Temporary JSON documents can be stored into an open-source database for caching and SHOULD be deleted when no longer required. Any process or user behaves as an actor if the policy route was called. Functional Requirements - Policy Evaluation Functions Call of external URLs Storage Extension Functions Storage Implementation TRAIN validation & verification CLI tools (command-line) for common operations Table 5: Functional Requirements Policy Evaluation Task Controller - System Features Description - Task Controller The task controller feature provides an API which is able to handle asynchronous task lists. Each task represents one single action which executes an HTTP URL. Each task has a unique id and stores its result in the distributable cache for a later processing. Task lists can be preconfigured in the repository by a name, to create a new task subset more easily from a policy or any other component (e.g., a 1 to many task mapping). The task execution is asynchronous, and the result can be queried over the task(list) id, to query the state of the processing. Functional Requirements - Task Controller Functions Cache Event Subscription Task Queue and Storage Abstraction Layer Table 6: Functional Requirements Task Controller JSON-LD Signing and verification Description - JSON-LD Signing and verification The feature provides verification and signature functionality of LD-Proofs embedded in JSON-LD files. The functionality is an internal HTTP API, but the core crypto functionality has to be provided as a separate library and SHOULD run within a secure environment. Functional Requirements - JSON-LD Signing and verification Functions Proof Chains in JSON-LD Table 7: Functional Requirements JSON-LD Signing and Verification Trusted Caching Description - Trusted Caching The trusted caching provides the functionality to store securely in memory data for identities and related information for trust evaluation. Functional Requirements - Trusted Caching Functions Content Access Table 8: Functional Requirements Trusted Caching eIDAS Compliant Signatures Description - eIDAS Compliant Signatures To provide eIDAS compliant signatures the feature should be able to generate and validate eIDAS compliant signatures. In consideration of the different eIDAS types, legal signatures should be considered and a bridge functionality to sign the data should be implemented. A secure environment MUST be provided to store and execute the necessary functions (signature, validation) and SHOULD require at least two factor authentication. Functional Requirements - eIDAS Compliant Signatures Functions eIDAS compliant Signature Creation / Validation Support for DID:EBSI encoding for Natural Persons Table 9: Functional Requirements eIDAS Compliant Signatures Verification Core Verification Requirements All listed verification items/criterias, must be fulfilled by a demonstration of the implementation within the provided Kubernetes environment. [IDM.TSA.E1.00051] Kubernetes Deployment If the verification is related to software components, it must be deployed in a Kubernetes test cluster and the components must be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration. [IDM.TSA.E1.00052] Behavior Driven Design Verification of fulfillment of the requirements and characteristics MUST be done using automated tests which are part of the deliverables. They SHOULD be done by patterns of the Behavior Driven Development [BDD] using the \"Gherkin Syntax\". [IDM.TSA.E1.00053] Test Environment All functionalities MUST be demonstrated in a test environment within a sandbox, with the following infrastructure components: Load Balancer, e.g., HAProxy API Gateway, e.g., Kong Service Mesh, e.g., Linkerd/Istio DNS Multiple Servers Firewalls All tests MUST be passed in this test environment. [IDM.TSA.E1.00054] Load Tests Scalability and Performance around the high workload scenarios MUST be demonstrated, by using any kind of Load Test Framework for HTTP APIs. [IDM.TSA.E1.00055] Automated Integration Tests Automation Integration tests must be created, and they must be runnable by a CI job. Acceptance Criteria Policy Management Module - Verification [IDM.TSA.E1.00056] Policy Bundles Policy Bundles are signed when they become in a productive state or before export. The metadata can be signed for the included files of the bundle, or the bundle itself can be signed as a compressed package. [IDM.TSA.E1.00057] Policy Import and Export The export of a policy bundle MUST be signed with a keypair which is evaluable against the public keys registered in the DID document. Import and Exports are observable. [IDM.TSA.E1.00058] Policy Changes Notification A notification is triggered upon every change in a policy source code or static data file. [IDM.TSA.E1.00059] Webhooks for policy changes There is an available endpoint for client webhook subscription which takes a URL. Data payload is sent to all subscribers with relevant policy changes using the webhook URLs. [IDM.TSA.E1.00060] JSON Schema Validation for Policy Output A simple JSON schema is validated on the validation endpoint. An appropriate HTTP status code is returned. [IDM.TSA.E1.00061] Fine granular policy management The system allows policy management through separate GIT repositories. Separate synchronization mechanisms are in place for each GIT repository. [IDM.TSA.E1.00062] Interface for Export Configuration Export configurations are able to be defined in the policy management module. There is a synchronization flow in place for export configurations to make them available for execution. [IDM.TSA.E1.00063] Policy Admin API An administration API for policies is available. Policy Decision Engine - Verification [IDM.TSA.E1.00064] Call of external URLs The decision engine is capable of making HTTP requests with query parameters, headers and request body for any HTTP method within the policy execution runtime. [IDM.TSA.E1.00065] Storage Extension Functions REGO extension functions are available for creating, updating and deleting data from a predefined database table/collection during policy evaluation. [IDM.TSA.E1.00066] Storage Implementation A storage layer can be replaced during the configuration in the deployment without any need to do code modifications. If internal storage is configured, the policy must be executable without any database deployment. [IDM.TSA.E1.00067] TRAIN validation & verification The service is able to use the components provided by the TRAIN lot to cross check the DID trust during the verification of credentials. [IDM.TSA.E1.00068] CLI tools (command-line) for common operations CLI tools for the common operations, performed by the TSA HTTP API are created. Task Controller - Verification [IDM.TSA.E1.00069] Cache Event Subscription After an update event in the distributable cache, a task must be created as pre-configured (or dynamically by policy). [IDM.TSA.E1.00070] Task Queue and Storage Abstraction Layer An abstraction layer is implemented for the Queue and Storage interfaces in the Task Controller. JSON-LD signatures and validations - Verification [IDM.TSA.E1.00071] Proof Chains in JSON-LD JSON-LD proof chains are supported to link multiple entities to the same data, when proof sequences are required. Distributable Cache - Verification [IDM.TSA.E1.00072] Content Access When accessing a content with given DID, namespace and scope, the result is a flat JSON file. Duplicate entries are handled during the flattening of multiple documents. eIDAS - Verification [IDM.TSA.E1.00073] eIDAS compliant Signature Creation / Validation Signatures are generated/verified in compliance with eIDAS. Basic, advanced and qualified signature types are supported. [IDM.TSA.E1.00074] Support for DID:EBSI encoding for Natural Persons Public key encoding in DID document for Natural Persons according to the EBSI DID Method is supported. Support for Kubernetes [IDM.TSA.E1.00075] Eventing All eventings must be demonstrated on basis of cloud events specifications together with the kNative [9] broker in a Kubernetes environment. [9] [https://knative.dev/docs/eventing/] [IDM.TSA.E1.00076] Config Map Support Each service must be demonstrated up and running in Kubernetes, configured by config maps. [IDM.TSA.E1.00077] Helm Installation The service installation MUST be demonstrated during HELM install. [IDM.TSA.E1.00078] ArgoCD Integration The helm chart MUST be able to install inside of ArgoCD. This includes the usage of the postgres hooks [10] and the providing of usable values.yaml(s) for all developed services. [10] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration/-/tree/main/helm/charts/postgresql-hook] [IDM.TSA.E1.00079] SCS Environment All HELM installations MUST run on SCS (Sovereign Cloud Stack). The final acceptance demonstration cannot be realized on azure, google cloud etc. Appendix A: Glossary For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO] Appendix B: Architecture","title":"Trust Services API Extension"},{"location":"tsae1/tsae1/#software-requirements-specification-for-gaia-x-federation-services-trust-services-api-extension-1-idmtsae1","text":"Published by eco -- Association of the Internet Industry (eco -- Verband der Internetwirtschaft e.V.) Lichtstrasse 43h 50825 Cologne, Germany Copyright \u00a9 2023 eco -- Association of the Internet Industry This work is licensed under the Creative Commons attribution 4.0nInternational License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA","title":"Software Requirements Specification for Gaia-X Federation Services Trust Services API Extension 1 IDM.TSA.E1"},{"location":"tsae1/tsae1/#1-introduction","text":"","title":"1  Introduction"},{"location":"tsae1/tsae1/#11-document-purpose","text":"","title":"1.1  Document Purpose"},{"location":"tsae1/tsae1/#12-product-scope","text":"","title":"1.2  Product Scope"},{"location":"tsae1/tsae1/#13-definitions-acronyms-and-abbreviations","text":"","title":"1.3  Definitions, Acronyms and Abbreviations"},{"location":"tsae1/tsae1/#14-references","text":"","title":"1.4  References"},{"location":"tsae1/tsae1/#15-document-overview","text":"","title":"1.5  Document Overview"},{"location":"tsae1/tsae1/#2-product-overview","text":"","title":"2  Product Overview"},{"location":"tsae1/tsae1/#21-product-perspective","text":"","title":"2.1  Product Perspective"},{"location":"tsae1/tsae1/#22-product-functions","text":"","title":"2.2  Product Functions"},{"location":"tsae1/tsae1/#23-product-constraints","text":"","title":"2.3  Product Constraints"},{"location":"tsae1/tsae1/#24-user-classes-and-characteristics","text":"","title":"2.4  User Classes and Characteristics"},{"location":"tsae1/tsae1/#25-operating-environment","text":"","title":"2.5  Operating Environment"},{"location":"tsae1/tsae1/#26-user-documentation","text":"","title":"2.6  User Documentation"},{"location":"tsae1/tsae1/#27-assumptions-and-dependencies","text":"","title":"2.7  Assumptions and Dependencies"},{"location":"tsae1/tsae1/#28-apportioning-of-requirements","text":"","title":"2.8  Apportioning of Requirements"},{"location":"tsae1/tsae1/#3-requirements","text":"","title":"3  Requirements"},{"location":"tsae1/tsae1/#31-external-interfaces","text":"","title":"3.1  External Interfaces"},{"location":"tsae1/tsae1/#311-user-interfaces","text":"","title":"3.1.1  User Interfaces"},{"location":"tsae1/tsae1/#312-hardware-interfaces","text":"","title":"3.1.2  Hardware Interfaces"},{"location":"tsae1/tsae1/#313-software-interfaces","text":"","title":"3.1.3  Software Interfaces"},{"location":"tsae1/tsae1/#314-communications-interfaces","text":"","title":"3.1.4  Communications Interfaces"},{"location":"tsae1/tsae1/#32-functional","text":"","title":"3.2  Functional"},{"location":"tsae1/tsae1/#321-policy-management-module","text":"","title":"3.2.1  Policy Management Module"},{"location":"tsae1/tsae1/#322-policy-decision-engine","text":"","title":"3.2.2  Policy Decision Engine"},{"location":"tsae1/tsae1/#323-task-controller","text":"","title":"3.2.3  Task Controller"},{"location":"tsae1/tsae1/#324-json-ld-signatures-and-validations","text":"","title":"3.2.4  JSON-LD signatures and validations"},{"location":"tsae1/tsae1/#325-distributable-cache","text":"","title":"3.2.5  Distributable Cache"},{"location":"tsae1/tsae1/#326-eidas","text":"","title":"3.2.6  eIDAS"},{"location":"tsae1/tsae1/#327-general","text":"","title":"3.2.7  General"},{"location":"tsae1/tsae1/#33-other-nonfunctional-requirements","text":"","title":"3.3  Other Nonfunctional Requirements"},{"location":"tsae1/tsae1/#331-http-requirements","text":"","title":"3.3.1  HTTP Requirements"},{"location":"tsae1/tsae1/#332-logging-requirements","text":"","title":"3.3.2  Logging Requirements"},{"location":"tsae1/tsae1/#333-performance-requirements","text":"","title":"3.3.3  Performance Requirements"},{"location":"tsae1/tsae1/#334-safety-requirements","text":"","title":"3.3.4  Safety Requirements"},{"location":"tsae1/tsae1/#335-security-requirements","text":"","title":"3.3.5  Security Requirements"},{"location":"tsae1/tsae1/#336-software-quality-attributes","text":"","title":"3.3.6  Software Quality Attributes"},{"location":"tsae1/tsae1/#337-business-rules","text":"","title":"3.3.7  Business Rules"},{"location":"tsae1/tsae1/#34-compliance","text":"","title":"3.4  Compliance"},{"location":"tsae1/tsae1/#35-design-and-implementation","text":"","title":"3.5  Design and Implementation"},{"location":"tsae1/tsae1/#351-installation","text":"","title":"3.5.1  Installation"},{"location":"tsae1/tsae1/#352-distribution","text":"","title":"3.5.2  Distribution"},{"location":"tsae1/tsae1/#353-service-meshing","text":"","title":"3.5.3  Service Meshing"},{"location":"tsae1/tsae1/#354-standard-technology","text":"","title":"3.5.4  Standard Technology"},{"location":"tsae1/tsae1/#355-metrics","text":"","title":"3.5.5  Metrics"},{"location":"tsae1/tsae1/#356-configurability","text":"","title":"3.5.6  Configurability"},{"location":"tsae1/tsae1/#357-maintainability","text":"","title":"3.5.7  Maintainability"},{"location":"tsae1/tsae1/#358-reusability","text":"","title":"3.5.8  Reusability"},{"location":"tsae1/tsae1/#359-runtime-stability","text":"","title":"3.5.9  Runtime Stability"},{"location":"tsae1/tsae1/#3510-high-availability-concepts","text":"","title":"3.5.10 High Availability Concepts"},{"location":"tsae1/tsae1/#4-system-features","text":"","title":"4  System Features"},{"location":"tsae1/tsae1/#41-policy-management","text":"","title":"4.1  Policy Management"},{"location":"tsae1/tsae1/#411-description","text":"","title":"4.1.1  Description"},{"location":"tsae1/tsae1/#412-functional-requirements","text":"","title":"4.1.2  Functional Requirements"},{"location":"tsae1/tsae1/#42-policy-evaluation","text":"","title":"4.2  Policy Evaluation"},{"location":"tsae1/tsae1/#421-description","text":"","title":"4.2.1  Description"},{"location":"tsae1/tsae1/#422-functional-requirements","text":"","title":"4.2.2  Functional Requirements"},{"location":"tsae1/tsae1/#43-task-controller","text":"","title":"4.3  Task Controller"},{"location":"tsae1/tsae1/#431-description","text":"","title":"4.3.1  Description"},{"location":"tsae1/tsae1/#432-functional-requirements","text":"","title":"4.3.2  Functional Requirements"},{"location":"tsae1/tsae1/#44-json-ld-signing-and-verification","text":"","title":"4.4  JSON-LD Signing and verification"},{"location":"tsae1/tsae1/#441-description","text":"","title":"4.4.1  Description"},{"location":"tsae1/tsae1/#442-functional-requirements","text":"","title":"4.4.2  Functional Requirements"},{"location":"tsae1/tsae1/#45-trusted-caching","text":"","title":"4.5  Trusted Caching"},{"location":"tsae1/tsae1/#451-description","text":"","title":"4.5.1  Description"},{"location":"tsae1/tsae1/#452-functional-requirements","text":"","title":"4.5.2  Functional Requirements"},{"location":"tsae1/tsae1/#46-eidas-compliant-signatures","text":"","title":"4.6  eIDAS Compliant Signatures"},{"location":"tsae1/tsae1/#461-description","text":"","title":"4.6.1  Description"},{"location":"tsae1/tsae1/#462-functional-requirements","text":"","title":"4.6.2  Functional Requirements"},{"location":"tsae1/tsae1/#5-verification","text":"","title":"5  Verification"},{"location":"tsae1/tsae1/#51-core-verification-requirements","text":"","title":"5.1  Core Verification Requirements"},{"location":"tsae1/tsae1/#52-acceptance-criteria","text":"","title":"5.2  Acceptance Criteria"},{"location":"tsae1/tsae1/#521-policy-management-module","text":"","title":"5.2.1  Policy Management Module"},{"location":"tsae1/tsae1/#522-policy-decision-engine","text":"","title":"5.2.2  Policy Decision Engine"},{"location":"tsae1/tsae1/#523-task-controller","text":"","title":"5.2.3  Task Controller"},{"location":"tsae1/tsae1/#524-json-ld-signatures-and-validations","text":"","title":"5.2.4  JSON-LD signatures and validations"},{"location":"tsae1/tsae1/#525-distributable-cache","text":"","title":"5.2.5  Distributable Cache"},{"location":"tsae1/tsae1/#526-eidas","text":"","title":"5.2.6  eIDAS"},{"location":"tsae1/tsae1/#53-support-for-kubernetes","text":"Appendix A: Glossary Appendix B: Architecture","title":"5.3  Support for Kubernetes"},{"location":"tsae1/tsae1/#list-of-figures","text":"Figure 1: Architecture (semi-transparent boxes are out of scope)","title":"List of Figures"},{"location":"tsae1/tsae1/#list-of-tables","text":"Table 1: References Table 2: Apportioning of Requirements Table 3: Technology Stack Table 4: Functional Requirements Policy Management Table 5: Functional Requirements Policy Evaluation Table 6: Functional Requirements Task Controller Table 7: Functional Requirements JSON-LD Signing and Verification Table 8: Functional Requirements Trusted Caching Table 9: Functional Requirements eIDAS Compliant Signatures","title":"List of Tables"},{"location":"tsae1/tsae1/#introduction","text":"To get general information regarding Gaia-X and the Gaia-X Federation Services please refer to [TAD] []{#1.1_Document_Purpose .anchor}and [PRD].","title":"Introduction"},{"location":"tsae1/tsae1/#document-purpose","text":"The purpose of the document is to specify the requirements of the Identity Management and Trust Subcomponent \"Trust Services API Extension 1\" with the intention of a European wide public tender for implementing this software. Main audience for this document is attendees of the public tender, which are able to supply an open-source software solution for the area of Signing/Validation, Secure Policy Management and Policy Execution with the purpose to provide trusted services around Decision Evaluations and Verifications.","title":"Document Purpose"},{"location":"tsae1/tsae1/#product-scope","text":"The product scope covers the functionalities of the Trust Services API. The aim of the Trust Services API Extension 1 is to ensure a consistent level of trust between Gaia-X participants and components. The Trust Services API can be used by all components. The creation and validation of digital signatures plays a particularly important role here. The product scope includes signing and verifying of necessary data, enabling policy driven trust, ensuring trust-chains between participants and validating eIDAS compliant signatures. The scope also includes necessary tools (e.g., Command Line Scripts) to operate and maintain the created software components in an enterprise environment with focus on high-availability, security and monitoring and logging based on common standards. Documentation for developer, operator and user MUST be written in markdown format which is publicly consumable over a publicly accessible source repository without access limitations. If it's required to do code restructurings, modifying the current solution by adding new microservices etc. then this is explicitly allowed. Please note, that it is explicitly required to deliver the software up and running. Responsibility for existing code cannot be shifted to previous development teams.","title":"Product Scope"},{"location":"tsae1/tsae1/#definitions-acronyms-and-abbreviations","text":"The Trust Architecture Overview Document [IDM.AO] MUST be considered and applied as the core technical concept that includes also the Terminology and Glossary. All requirements from other documents are referenced by [IDM.\\<document-id>.XXXXX] as defined in chapter 1 \"Methodology\" in the document [IDM.AO].","title":"Definitions, Acronyms and Abbreviations"},{"location":"tsae1/tsae1/#references","text":"Description Status Specflow (n.D.), BDD Specflow BDD 07-04-2023 Cloud Events CloudEvents 07-04-2023 D:EBSI EBSI DID Method 07-04-2023 IDM.AO Gaia-X WP1 (2021), Architecture Overview IDM.TRAIN Gaia-X Federation Services - Trust Management Infrastructure JSON-LD JSON-LD 1.1 07-04-2023 LD Proofs Linked Data Proofs 1.0 07-04-2023 PRD Gaia-X Policy Rules Document 08-14-2023 Rego Rego Policy Language 07-04-2023 RFC 2119 RFC 2119 07-04-2023 RFC 5789 PATCH Method for HTTP 07-04-2023 RFC 7231 HTTP/1.1: Semantics and Content 07-04-2023 RFC 7807 Problem Details for HTTP APIs 07-04-2023 TAD Gaia-X Architecture Document 08-14-2023 TDR Gaia-X Federation Services Technical Development Requirements TSA Gaia-X, European Association for Data and Cloud, AISBL (2021): Gaia-X Trusted Services API Document TSA.GITLAB Gitlab tickets for the GAIA-X Trust Services API Table 1: References","title":"References"},{"location":"tsae1/tsae1/#document-overview","text":"The document describes the product perspective, functions and constraints. It furthermore lists the functional and non-functional requirements and defines the system features in detail. The listed requirements are binding. Requirements as an expression of normative specifications are identified by a unique ID in square brackets (e.g. [IDM.ID.Number] ) and the keywords MUST, MUST NOT, SHOULD, SHOULD NOT, MAY, corresponding to RFC 2119 [RFC 2119], are written in capital letters (see also [IDM.AO] - Methodology).","title":"Document Overview"},{"location":"tsae1/tsae1/#product-overview","text":"","title":"Product Overview"},{"location":"tsae1/tsae1/#product-perspective","text":"Please refer to [TDR] and [TSA] . The existing code base [1] MUST be reused and further improved. Other microservices MAY have different languages and architectures.","title":"Product Perspective"},{"location":"tsae1/tsae1/#1-httpsgitlabeclipseorgeclipsexfsctsa","text":"","title":"[1] [https://gitlab.eclipse.org/eclipse/xfsc/tsa]"},{"location":"tsae1/tsae1/#product-functions","text":"The functions of the Trust Services component are provided case-dependent either as runtime or library components. Runtime components MUST expose endpoints as REST services. In addition, policy configuration with GitOps should be used to enable the provisioning and sharing of policies. The component is part of the Gaia-X Trust and identity management toolstack and not centrally hosted. To properly maintain and update, appropriate security measures MUST be in place. This includes role concepts, data storage protection and access control. The overall functionality of the product MUST be auditable (GDPR compliant). Figure 1: Architecture (semi-transparent boxes are out of scope)","title":"Product Functions"},{"location":"tsae1/tsae1/#product-constraints","text":"Please refer to [TSA] Section 2.3 and [TDR] .","title":"Product Constraints"},{"location":"tsae1/tsae1/#user-classes-and-characteristics","text":"Please refer to [TSA] 2.4 and [TDR] .","title":"User Classes and Characteristics"},{"location":"tsae1/tsae1/#operating-environment","text":"Please refer to [TSA] 2.5 and [TDR] for further binding requirements regarding the operating environment.","title":"Operating Environment"},{"location":"tsae1/tsae1/#idmtsae100000-kubernetes-environment","text":"The product MUST be operable on standard Kubernetes based environments without any hardware restrictions. The reference environment for demonstration and development purposes MUST be on the provided SCS cluster (Sovereign Cloud Stack), which will be provided by the Client.","title":"[IDM.TSA.E1.00000] Kubernetes Environment"},{"location":"tsae1/tsae1/#user-documentation","text":"Please refer to [TDR] for further requirements regarding documentation.","title":"User Documentation"},{"location":"tsae1/tsae1/#idmtsae100001-participant-administration-documentation","text":"The documentation MUST contain: Installation Manuals Cryptographic Initialization (if applicable) Description of Deployment/Compile Process Description of the Automatic Tests / Verification How to build the products from source code","title":"[IDM.TSA.E1.00001] Participant Administration Documentation"},{"location":"tsae1/tsae1/#idmtsae100002-participant-documentation","text":"The documentation MUST contain: Short Software Description (why and for what, when to use, how use, where to use) Usage guide GDPR design decisions Security concept Operations concept FAQ Keyword Directory","title":"[IDM.TSA.E1.00002] Participant Documentation"},{"location":"tsae1/tsae1/#assumptions-and-dependencies","text":"An understanding of the overall Gaia-X architecture and philosophy is necessary. Please refer to [TAD] und [PDR]. Attendees of the public tender MUST assume responsibility of: All tickets in GitLab ( [TSA.GITLAB] ) with label \"Specification\" The existing code and improvements upon the existing code Extending or contributing to the used frameworks in order to provision a way in which realization of the requirements can be achieved Updating dependencies to the latest stable version","title":"Assumptions and Dependencies"},{"location":"tsae1/tsae1/#apportioning-of-requirements","text":"Feature Priority Policy Management 1 Policy Evaluation 1 Task Coordination 1 Feature Priority JSON-LD Verification 1 JSON-LD Signing 1 Trusted Caching 1 eIDAS compliant Signatures 2 Table 2: Apportioning of Requirements","title":"Apportioning of Requirements"},{"location":"tsae1/tsae1/#requirements","text":"Further binding requirements can be found in [TDR].","title":"Requirements"},{"location":"tsae1/tsae1/#external-interfaces","text":"","title":"External Interfaces"},{"location":"tsae1/tsae1/#user-interfaces","text":"Please refer to [TSA] 3.1.1.","title":"User Interfaces"},{"location":"tsae1/tsae1/#hardware-interfaces","text":"Please refer to [TSA] 3.1.2.","title":"Hardware Interfaces"},{"location":"tsae1/tsae1/#software-interfaces","text":"Please refer to [TSA] 3.1.3.","title":"Software Interfaces"},{"location":"tsae1/tsae1/#communications-interfaces","text":"Please refer to [TSA] 3.1.4.","title":"Communications Interfaces"},{"location":"tsae1/tsae1/#idmtsae100003-eventing","text":"If it is required to use events within the software architecture, it is mandatory to use software abstraction according to cloud event specification [CloudEvents] for publishing and subscription. The minimal supported protocol binding MUST be HTTP Protocol Binding [2].","title":"[IDM.TSA.E1.00003] Eventing"},{"location":"tsae1/tsae1/#2-httpsgithubcomcloudeventsspecblobv102cloudeventsbindingshttp-protocol-bindingmd","text":"","title":"[2] [https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/bindings/http-protocol-binding.md]"},{"location":"tsae1/tsae1/#idmtsae100004-eventing-infrastructure","text":"The event broker for the eventing MUST abstract the storage and delivery infrastructure. In Kubernetes environments, the broker MUST be uniform across all Lots. (e.g., kNative)","title":"[IDM.TSA.E1.00004] Eventing Infrastructure"},{"location":"tsae1/tsae1/#functional","text":"","title":"Functional"},{"location":"tsae1/tsae1/#policy-management-module","text":"","title":"Policy Management Module"},{"location":"tsae1/tsae1/#idmtsae100005-policy-bundles","text":"Policy bundles MUST contain further information, e.g., data input JSON files. They MUST contain meta-data and references like resolvable DIDs to be verifiable and trustworthy. The bundle MUST be signed in a productive state or before the export. It MAY be chosen, how the signing and verification is standardized. For instance, the metadata can be signed for the included files of the bundle, or the bundle itself can be signed as a compressed package e.g., Zip packed in a CMS to exchange later on policy bundles.","title":"[IDM.TSA.E1.00005] Policy Bundles"},{"location":"tsae1/tsae1/#idmtsae100006-policy-import-and-export","text":"The policy administrator MUST be able to configure policy import endpoints where the system automatically downloads new policy bundles. The policy export endpoint itself MUST be configurable in that way, so that the policy administrator can decide which bundles from the productive repository can be exported. Each import and export MUST be signed with a key registered in the DID document and verifiable against the public keys from the DID document defined in the bundle. For this purpose, the DID resolver MUST be used. Import and export MUST be observable for the configured repositories.","title":"[IDM.TSA.E1.00006] Policy Import and Export"},{"location":"tsae1/tsae1/#idmtsae100007-policy-changes-notification","text":"The system MUST be able to notify other components when policy source code or data has changed. Notifications may be passed to message queue, smart contract or use other notification mechanisms which are suitable in the context of the technology stack. Notifications might be granular and explicitly contain information about what has changed.","title":"[IDM.TSA.E1.00007] Policy Changes Notification"},{"location":"tsae1/tsae1/#idmtsae100008-webhooks-for-policy-changes","text":"The product MUST allow other components to subscribe for policy changes via webhooks. Clients MUST be able to give a URL and the product MUST send the relevant payload once there are policy changes.","title":"[IDM.TSA.E1.00008] Webhooks for policy changes"},{"location":"tsae1/tsae1/#idmtsae100009-json-schema-validation-for-policy-output","text":"Optional policy configuration files may specify mandatory JSON schemas which must be part of the JSON output from a policy evaluation. The validation must check whether the schemas are present and must validate the JSON document with Strict validation. To execute the validation procedure, a new HTTP URL can be automatically generated. Example: Evaluation URL pattern: /{repo}/policies/{group}/{policyname}/{version}/evaluation Validation URL pattern: /{repo}/policies/{group}/{policyname}/{version}/validation If the validation fails, the policy service might LOCK the policy for execution and log an error/warning in the logs.","title":"[IDM.TSA.E1.00009] JSON Schema Validation for Policy Output"},{"location":"tsae1/tsae1/#idmtsae100010-fine-granular-policy-management","text":"The system SHOULD allow managing policies in separate GIT repositories. This will allow separate GIT Workflows for different system contexts. Synchronization mechanisms SHOULD be separate for different GIT repositories. A new URL path parameter SHOULD be introduced in order to achieve context separation upon policy evaluation. Example: Current evaluation URL: ../policy/ {group} / {name} / {version} /evaluation Evaluation URL with GIT Repository separation: ../policy/ {repository} / {group} / {name} / {version} /evaluation","title":"[IDM.TSA.E1.00010] Fine granular policy management"},{"location":"tsae1/tsae1/#idmtsae100011-interface-for-export-configuration","text":"The policy administration module MUST be able to define new export configurations for each policy. The system MUST have an automated export configuration update flow, that will always take the main branch of the configurations and publish them, making them available for execution. Interface GitOps Input Export configurations Output Updated Export Configurations are available for execution","title":"[IDM.TSA.E1.00011] Interface for Export Configuration"},{"location":"tsae1/tsae1/#idmtsae100012-policy-admin-api","text":"The policy service may provide an HTTP API to inspect the current policy service state. For example, get a list of all unlocked/locked policies, return a specific policy source code or some policy meta information like last update timestamp. This could be useful while debugging the service or for building a UI dashboard for administrators. For example, the sync from Git to Policy Database could fail unexpectedly or even complete without errors, but there could be a bug where policy source code in the database is different from policy source code in the Gilt repo. Debugging such issues would be extremely difficult without having the ability to look at the current Policy service state/data, because just looking at the external Git policy repo will not be helpful to discover some discrepancies. The API could start with the following functionalities but could be further expanded as necessary. Retrieve all/some policies from the Policy DB. Optionally specify which fields should be returned - e.g., source code, static data, meta fields, etc. Retrieve policy lock/unlock state Retrieve static data/configurations for a given policy","title":"[IDM.TSA.E1.00012] Policy Admin API"},{"location":"tsae1/tsae1/#policy-decision-engine","text":"","title":"Policy Decision Engine"},{"location":"tsae1/tsae1/#idmtsae100013-call-of-external-urls","text":"The decision engine MUST have the capability to call HTTP URLs with free chosen query parameters, headers, and request bodies for any HTTP verb within the policy execution. This MUST be possible out of the defined policy to load external data dynamically into the execution context. It MAY be created also helper components e.g., built in functions, to support this feature outside of the policy policy execution context. Constraints Policy Language Policy Execution Input HTTP URL with Parameters, Header and Request Body. Output JSON HTTP Response.","title":"[IDM.TSA.E1.00013] Call of external URLs"},{"location":"tsae1/tsae1/#idmtsae100014-storage-extension-functions","text":"The decision engine MUST have the capability to work with database storage, that a policy can persist and pick up data during execution. This MUST be achieved with REGO extension functions. The functions MUST have the ability to create, update and delete data from a predefined database table/collection during policy evaluations. Constraints Rego Policy Language [Rego]","title":"[IDM.TSA.E1.00014] Storage Extension Functions"},{"location":"tsae1/tsae1/#idmtsae100015-storage-implementation","text":"The storage layer for policy storage MUST be implemented in a way that no specific database technology is strictly required for the purpose of policy execution. The implementation MUST support the following levels: Policy Service uses internal storage for cloning the policy repositories. This level supports not just in time sync, but a very quick usage of simple, not often changed policies. Policy change requires container restart. This can be realized by a script during container startup (if configured) The policy service uses an external storage to pick up the policies. E.g., from a postgres db, a mongodb or similar. The external storage provides events when a policy has changed, or a sync happens Both levels MUST be configurable and adaptable by an internal interface e.g., IPolicyStorage to allow additional implementations in the future for internal and external storage implementations.","title":"[IDM.TSA.E1.00015] Storage Implementation"},{"location":"tsae1/tsae1/#idmtsae100016-train-validation-verification","text":"The TRAIN validation service ([IDM.TRAIN.00017], [IDM.TRAIN] p. 12) needs to be included in the process of verifying a verifiable presentation. If a requestor is showing a verifiable presentation during a task which needs to be fulfilled the notarization service needs to validate the terms Of Use by calling the TRAIN validation module. This will verify if the shown verifiable presentation and its respective owner is on a trustlist. Constraints DID of the organization. Database system. Interfaces TRAIN validation module Input A verification with an incoming verifiable presentation Output Verification output of the TRAIN validation module","title":"[IDM.TSA.E1.00016] TRAIN validation &amp; verification"},{"location":"tsae1/tsae1/#task-controller","text":"","title":"Task Controller"},{"location":"tsae1/tsae1/#idmtsae100017-cache-event-subscription","text":"If a data update event occurs from the distributable cache, the task controller MUST execute a policy which evaluates whether any further tasks must be created. If any task is configured, the tasks MUST be created for execution. The task has the same metadata as the event (key, namespace and scope) For instance: A proof data object is inserted from the OCM into the cache. This object contains a DID from the issuer. The policy evaluates the schema of the data object and returns Task \"IssuerProof\". The task controller inserts this task to the tasklist by adding the http URL of the OCM proof manager with the DID of the issuer as parameter. Some seconds later, the proof from the issuer arrives and the policy returns null (nothing to do). Constraints Distributable Cache Event Policy Evaluation Input An Insert/Update Event Output A task result or null.","title":"[IDM.TSA.E1.00017] Cache Event Subscription"},{"location":"tsae1/tsae1/#idmtsae100018-task-queue-and-storage-abstraction-layer","text":"An abstraction layer MUST be implemented for the Queue and the Storage interfaces in the task controller. The Abstraction layer MUST be agnostic of the underlying implementation.","title":"[IDM.TSA.E1.00018] Task Queue and Storage Abstraction Layer"},{"location":"tsae1/tsae1/#json-ld-signatures-and-validations","text":"","title":"JSON-LD signatures and validations"},{"location":"tsae1/tsae1/#idmtsae100019-proof-chains-in-json-ld","text":"JSON-LD proof chains [LD.Proofs] SHOULD be supported to link multiple entities to the same data, when proof sequences are required. This can be useful for notary counter-signing a proof that had been created on a document. It MUST support signing and verifying the VCs. Example: { > \\\"@context\\\": \\[ > \\\"https://[www.w3.org/2018/credentials/v1\\\"](http://www.w3.org/2018/credentials/v1), > \\\"https://[www.w3.org/2018/credentials/examples/v1\\\"](http://www.w3.org/2018/credentials/examples/v1) > > \\], > > \\\"title\\\": \\\"Hello World!\\\", > > \\\"proofChain\\\": \\[{ > > \\\"type\\\": \\\"Ed25519Signature2018\\\", \\\"proofPurpose\\\": > \\\"assertionMethod\\\", \\\"created\\\": \\\"2019-08-23T20:21:34Z\\\", > > \\\"verificationMethod\\\": \\\"did:example:123456#key1\\\", \\\"domain\\\": > \\\"example.org\\\", > > \\\"jws\\\": \\\"eyJ0eXAiOiJK\\...gFWFOEjXk\\\" > > }, > > { > > \\\"type\\\": \\\"RsaSignature2018\\\", \\\"proofPurpose\\\": \\\"assertionMethod\\\", > \\\"created\\\": \\\"2017-09-23T20:21:34Z\\\", > > \\\"verificationMethod\\\": \\\"https://example.com/i/pat/keys/5\\\", > \\\"domain\\\": \\\"example.org\\\", > > \\\"jws\\\": \\\"eyJ0eXAiOiJK\\...gFWFOEjXk\\\" > > }\\] > > }","title":"[IDM.TSA.E1.00019] Proof Chains in JSON-LD"},{"location":"tsae1/tsae1/#distributable-cache","text":"","title":"Distributable Cache"},{"location":"tsae1/tsae1/#idmtsae100020-content-access","text":"The cached content MUST be accessible over a key (e.g., a DID), a namespace and an array of scopes, which results in an array of JSON documents. For instance, the access to the cache can be the following: Key: DID:sov:2358585 Namespace: Login Scopes: administration, read, visitor Result: {\"name\":\"userX\",\"iss\":did:sov:33333}, {\"membership\":\"company\",\"iss\":did:sov:1111} To optimize the access, it MAY be optimized by flatten the access pattern like: Key: DID:sov:2358585 Namespace: Login:administration Independent from the format, the result for the accessor MUST be a flatten JSON structure. In the flattening step, it SHOULD namespace duplicated claims if they are semantically different (e.g., using JSON-LD context [JSON.LD]). If two JSON structures bring a duplicated claim which is semantically the same claim (say two JSON structures bring Name and Surname, but the values are different) then a policy shall decide whether to: take one of them or discard all of them. Constraints Supported data format of the cache technology Policy Decision Engine","title":"[IDM.TSA.E1.00020] Content Access"},{"location":"tsae1/tsae1/#eidas","text":"","title":"eIDAS"},{"location":"tsae1/tsae1/#idmtsae100021-eidas-compliant-signature-creation-validation","text":"Signatures must be generated/verified in compliance with eIDAS so that legally secure trust can be achieved. This should include the eIDAS signature types basic, advanced, and qualified. The implementation variant must be selected individually in coordination with the used technology.","title":"[IDM.TSA.E1.00021] eIDAS compliant Signature Creation / Validation"},{"location":"tsae1/tsae1/#idmtsae100022-support-for-didebsi-encoding-for-natural-persons","text":"Support public key encoding in DID document for Natural Persons according to the EBSI DID Method specification [DID:EBSI]. Constraints EBSI DID Method [DID:EBSI].","title":"[IDM.TSA.E1.00022] Support for DID:EBSI encoding for Natural Persons"},{"location":"tsae1/tsae1/#general","text":"","title":"General"},{"location":"tsae1/tsae1/#idmtsae100023-architecture-restructuring","text":"The architecture of the existing TSA MUST be changed in this way, so that the software can be deployed feature by feature without the need to deploy for each feature every subcomponent like databases etc. In summary, all dependencies MUST be organized like this, that the deployment is more independent and operational cost friendly. The following changes MUST be provided: The plain policy execution MUST be able to work without the mongoDB (e.g., by using git clone on container startup) Usage of MongoDB MUST be just optional by configuration If the user wants to dynamically configure the policies, the policy execution MUST require mongoDB The task controller feature MUST be shipped with a generic message queue interface to support usage of different queues (currently mongodb is the queue, other queues must not be provided) The signing service MUST be more generic to support different signing engines The policy execution MUST be aware of existing features and MUST reply during the policy execution the non-existence of the feature e.g., \"Signing Service not available or this function requires the usage of MongoDB\" There may be other required changes during the architecture change, which MUST be highlighted to the technical lead and planned in the cost calculation during the analysis. Overall goal of this requirement is to allow the users to reduce the costs of their operational environment. Means if a user decides to use just the policy execution, an operational setup for instance of mongoDB and redis MUST be not required to operate it 24/7.","title":"[IDM.TSA.E1.00023] Architecture Restructuring"},{"location":"tsae1/tsae1/#other-nonfunctional-requirements","text":"","title":"Other Nonfunctional Requirements"},{"location":"tsae1/tsae1/#idmtsae100024-architecture-changes","text":"All Architecture Changes MUST be aligned with the Principal before implementation.","title":"[IDM.TSA.E1.00024] Architecture Changes"},{"location":"tsae1/tsae1/#http-requirements","text":"","title":"HTTP Requirements"},{"location":"tsae1/tsae1/#idmtsae100025-https","text":"All HTTP Endpoints MUST be protected by TLS 1.2 (all protocol version numbers SHOULD be superseded by upcoming standards) Each endpoint of the product MUST support TLS certificates which are configurable by the administrator of the system.","title":"[IDM.TSA.E1.00025] HTTPS"},{"location":"tsae1/tsae1/#idmtsae100026-http-protocol-definitions","text":"All HTTP Endpoints MUST follow [RFC7231] and [RFC5789], but it MAY be chosen what of the protocols is necessary to realize the functionality. For problem reports the [RFC7807] MUST be used in combination with Standard HTTP Error Codes.","title":"[IDM.TSA.E1.00026] HTTP Protocol Definitions"},{"location":"tsae1/tsae1/#logging-requirements","text":"","title":"Logging Requirements"},{"location":"tsae1/tsae1/#idmtsae100027-data-minimization","text":"The data minimization principle is expressed in Article 5(1)(c) of the GDPR and Article 4(1)(c) of Regulation (EU) 2018/1725, which provide that personal data must be \\\"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed\\\". The data shall be stored for a period of time in accordance with national requirements and, as a minimum, shall consist of the following elements: (a) node\\'s identification (b) message identification (c) message data and time All logged data/information MUST be documented in the GDPR design decisions for a GDPR review.","title":"[IDM.TSA.E1.00027] Data Minimization"},{"location":"tsae1/tsae1/#idmtsae100028-logging-frameworks","text":"The product MUST support logging frameworks e.g., graylog, fluentD or logstash to support logging and analysis by enterprise infrastructures. The supported framework MAY be chosen for the first version, but it MUST support potentially the most common open-source logging solutions. The final solution MUST be aligned with the other subcomponents. It MUST be sketched in the operations concept how the support of multiple solutions is given in the future.","title":"[IDM.TSA.E1.00028] Logging Frameworks"},{"location":"tsae1/tsae1/#performance-requirements","text":"","title":"Performance Requirements"},{"location":"tsae1/tsae1/#idmtsae100029-updown-scale","text":"All components MUST be able to scale up/down their functionality for undefined amount instances. This requires a parallel execution possibility which will be tested later on by performance tests which are defined by the test team.","title":"[IDM.TSA.E1.00029] Up/Down Scale"},{"location":"tsae1/tsae1/#safety-requirements","text":"","title":"Safety Requirements"},{"location":"tsae1/tsae1/#idmtsae100030-major-releases","text":"All used software components MUST use the major releases with Long Term Support. If no LTS is available, all components MUST use the latest major releases with security hardening.","title":"[IDM.TSA.E1.00030] Major Releases"},{"location":"tsae1/tsae1/#security-requirements","text":"","title":"Security Requirements"},{"location":"tsae1/tsae1/#idmtsae100031-cve-patches","text":"All software components MUST have applied CVE patches, which are available for major releases.","title":"[IDM.TSA.E1.00031] CVE Patches"},{"location":"tsae1/tsae1/#software-quality-attributes","text":"","title":"Software Quality Attributes"},{"location":"tsae1/tsae1/#idmtsae100032-software-quality-requirements","text":"All software components MUST be compliant to the requirements within the quality assurance repository [3]. This includes testing on different layers (unit, component, integration), branch model that support stages, patch management, and code quality verification with adequate reporting. In addition, all requirements and quality attributes MUST demonstrated by automated behavior driven testing [BDD] methodology.","title":"[IDM.TSA.E1.00032] Software Quality Requirements"},{"location":"tsae1/tsae1/#3-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesquality-assurance-issues","text":"","title":"[3] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/quality-assurance/-/issues]"},{"location":"tsae1/tsae1/#business-rules","text":"","title":"Business Rules"},{"location":"tsae1/tsae1/#idmtsae100033-software-consistency","text":"The used technologies MUST have consistency. Standard technologies e.g., Databases MUST be abstracted over JDBC, authentication over OIDC etc.","title":"[IDM.TSA.E1.00033] Software Consistency"},{"location":"tsae1/tsae1/#idmtsae100034-cherry-picking","text":"All components and the entire software architecture MUST be checked for the necessity for deployment of each single feature, to allow an enterprise deployment customization.","title":"[IDM.TSA.E1.00034] Cherry Picking"},{"location":"tsae1/tsae1/#compliance","text":"","title":"Compliance"},{"location":"tsae1/tsae1/#idmtsae100035-gdpr-audit-logging","text":"All GDPR relevant access to personal relevant data MUST be logged for a later audit.","title":"[IDM.TSA.E1.00035] GDPR Audit Logging"},{"location":"tsae1/tsae1/#idmtsae100036-gdpr-data-processing","text":"Is it necessary to process person-relevant data, it MUST be earmarked to a clearly defined business process, which has to be described in the GDPR design decisions. All relevant data MUST be deleted after the processing, if applicable.","title":"[IDM.TSA.E1.00036] GDPR Data Processing"},{"location":"tsae1/tsae1/#design-and-implementation","text":"","title":"Design and Implementation"},{"location":"tsae1/tsae1/#installation","text":"","title":"Installation"},{"location":"tsae1/tsae1/#idmtsae100037-helmargo-cd-deployment","text":"All installations MUST be scripted/templated to ensure automated deployment. This MUST be ensured over HELM templates which MUST follow uniform rules across all lots. The charts MUST be integrable in a ARGO CD Pipeline defined in the gxfs-integration repository [4].","title":"[IDM.TSA.E1.00037] Helm/Argo CD Deployment"},{"location":"tsae1/tsae1/#4-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[4] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"tsae1/tsae1/#distribution","text":"","title":"Distribution"},{"location":"tsae1/tsae1/#idmtsae100038-helm-repositories","text":"All component helm charts MUST be available under a helm repository hosted in the GitLab, with different channels for distribution [5].","title":"[IDM.TSA.E1.00038] Helm Repositories"},{"location":"tsae1/tsae1/#5-httpsgitlabcomapiv4projects41175300packageshelmintegrationindexyaml","text":"","title":"[5] [https://gitlab.com/api/v4/projects/41175300/packages/helm/Integration/index.yaml]"},{"location":"tsae1/tsae1/#idmtsae100039-istio-resources","text":"Additionally, the Charts MUST provide Istio Resource (e.g., Authorization Rules, Virtual Services etc. ) following the integration pattern specified in the gxfs-integration repo[6].","title":"[IDM.TSA.E1.00039] Istio Resources"},{"location":"tsae1/tsae1/#6-httpsgitlabeclipseorgeclipsexfscintegration","text":"","title":"[6] [https://gitlab.eclipse.org/eclipse/xfsc/integration]"},{"location":"tsae1/tsae1/#service-meshing","text":"","title":"Service Meshing"},{"location":"tsae1/tsae1/#idmtsae100040-istio-support","text":"All HELM charts MUST be provided with Istio support aligned together with the project team. This consists of Authorization Rules, Virtual Service Definitions and other relevant Istio Definitions which are required for integration in a Istio Environment.","title":"[IDM.TSA.E1.00040] Istio Support"},{"location":"tsae1/tsae1/#standard-technology","text":"","title":"Standard Technology"},{"location":"tsae1/tsae1/#idmtsae100041-default-toolstack","text":"Each development MUST consider the following standard technologies, if nothing else is explicitly requested: Area Technology Service Meshing Istio Databases Redis, Mongo, Postgres Messaging CloudEvents Continuous Integration Argo CD, Gitlab Installation Templates HELM Container Docker Images (ARM64/AMD64) Secret Storage Hashicorp Vault, k8s Secret UI Technology React [7] Ingress Controller Nginx/Istio API Testing Postman (manual) API Design OpenAPI Kubernetes v1.26+ > Table 3: Technology Stack","title":"[IDM.TSA.E1.00041] Default Toolstack"},{"location":"tsae1/tsae1/#7-httpsreact-bootstrapgithubio","text":"The technology stack is mandatory to avoid integration impact.","title":"[7] [https://react-bootstrap.github.io/]"},{"location":"tsae1/tsae1/#metrics","text":"","title":"Metrics"},{"location":"tsae1/tsae1/#idmtsae100042-opentelemtry-support","text":"All helm charts/services MUST provide metrics endpoints in opentelemetry [8]format.","title":"[IDM.TSA.E1.00042] Opentelemtry Support"},{"location":"tsae1/tsae1/#8-httpsopentelemetryiodocs","text":"","title":"[8] [https://opentelemetry.io/docs/]"},{"location":"tsae1/tsae1/#configurability","text":"","title":"Configurability"},{"location":"tsae1/tsae1/#idmtsae100043-configuration","text":"All components MUST support one of the major configuration formats (yaml, json, ini, environment variables) wherever configuration is required. If environment variables are overwriting an actively set configuration, a warning SHOULD be logged.","title":"[IDM.TSA.E1.00043] Configuration"},{"location":"tsae1/tsae1/#idmtsae100044-configuration-profiles","text":"Environment specific parameters MUST be configurable over the helm templates by using profiles. Each component MUST be delivered minimum for profile: DEV, a local environment for round trip development and testing Acceptance, a restricted resource environment (with minimal system requirements) which can be deployed in cluster (remote or locally) Prod, a scalable environment with fault tolerance, HA settings and security hardening.","title":"[IDM.TSA.E1.00044] Configuration Profiles"},{"location":"tsae1/tsae1/#idmtsae100045-secret-references-in-helm-charts","text":"The configuration secrets within Helm Charts MUST use secretRefs to support external Secretmanagement. Clear text secrets within the Helm Charts are not allowed.","title":"[IDM.TSA.E1.00045] Secret References in Helm Charts"},{"location":"tsae1/tsae1/#maintainability","text":"","title":"Maintainability"},{"location":"tsae1/tsae1/#idmtsae100046-micro-service-architecture","text":"For a better scale out, maintainability and decentralization, the product architecture MUST have a micro service architecture. Each microservice MUST NOT be limited on the lines of code or number of days to implement it. The service \"size\" SHOULD be oriented on the fine granular business capabilities. (e.g., Order, ListMenu, Payment).","title":"[IDM.TSA.E1.00046] Micro Service Architecture"},{"location":"tsae1/tsae1/#idmtsae100047-domain-driven-design","text":"To support the micro service architecture within the maintainability, it MUST be declared a domain model before realization. The software description MUST explain which domain model was chosen, which services contain it and how it scales. This MUST be documented in the public code repository to support future enhancements for new developers.","title":"[IDM.TSA.E1.00047] Domain Driven Design"},{"location":"tsae1/tsae1/#reusability","text":"","title":"Reusability"},{"location":"tsae1/tsae1/#idmtsae100048-enterprise-environments","text":"All components MUST be reusable in different enterprise environments by customization and whitelabeling. Means all components MUST be able to customize and white label the components by configuration settings (e.g., UIs, text labels, endpoints etc.)","title":"[IDM.TSA.E1.00048] Enterprise Environments"},{"location":"tsae1/tsae1/#runtime-stability","text":"","title":"Runtime Stability"},{"location":"tsae1/tsae1/#idmtsae100049-readiness-check-ups","text":"All components MUST reflect after bootstrap and during runtime the correctness of the service functionality by reflecting it over health endpoints. The health endpoint MUST return failure (red), if any internal behavior failure or misconfiguration occurs (not just the software running state). This means for instance to check continuously during the runtime: A unreachable configured Services results in failed state Configured Service Endpoints needs to be checked for readiness during runtime, if not reachable, it results in failure state Check depending components (Database, Microservice etc.) behind it, if not reachable, it results in failed state","title":"[IDM.TSA.E1.00049] Readiness Check Ups"},{"location":"tsae1/tsae1/#high-availability-concepts","text":"","title":"High Availability Concepts"},{"location":"tsae1/tsae1/#idmtsae100050-redundant-deployment","text":"Each deployment MUST be configured for a minimum fault tolerance of 2 instances.","title":"[IDM.TSA.E1.00050] Redundant Deployment"},{"location":"tsae1/tsae1/#system-features","text":"","title":"System Features"},{"location":"tsae1/tsae1/#policy-management","text":"","title":"Policy Management"},{"location":"tsae1/tsae1/#description-policy-management","text":"The policy management provides functionalities around the signing, validation, import, export, and merge of policies from internal and external policy repos. This is necessary to ensure that only trusted policies are imported from trusted resources. The feature must help and support the policy administrator in decisions to trust a policy repository from outside, trust imported policies, sign policies for export, export specific policies and merge changes into the productive repository. This feature can be automated by a continuous integration system (e.g., Jenkins), but it SHOULD include configurable manual reviewing steps to ensure that the signing of policies MUST be done by an authorized person.","title":"Description - Policy Management"},{"location":"tsae1/tsae1/#functional-requirements-policy-management","text":"Endpoints Webhooks for policy changes JSON Schema Validation for Policy Output Fine granular policy management Policy Admin API Functions Policy Bundles Policy Import and Export Policy Changes Notification Interface for Export Configuration Table 4: Functional Requirements Policy Management","title":"Functional Requirements - Policy Management"},{"location":"tsae1/tsae1/#policy-evaluation","text":"","title":"Policy Evaluation"},{"location":"tsae1/tsae1/#description-policy-evaluation","text":"The policy evaluation provides functionality around the execution of policies. This includes the provisioning of versioned HTTP routes to execute the policy, synchronous and asynchronous policy evaluation, usage of external HTTP resources within the execution and a policy decision engine to create JSON response for a given JSON request and helper functionality around it. For instance, the caching of results or the inclusion of static JSON documents into the policy decisions, to evaluate more complex policies. All policies and static documents for the execution must be loaded from the encrypted hard disk into memory to guarantee the maximum execution speed. Temporary JSON documents can be stored into an open-source database for caching and SHOULD be deleted when no longer required. Any process or user behaves as an actor if the policy route was called.","title":"Description - Policy Evaluation"},{"location":"tsae1/tsae1/#functional-requirements-policy-evaluation","text":"Functions Call of external URLs Storage Extension Functions Storage Implementation TRAIN validation & verification CLI tools (command-line) for common operations Table 5: Functional Requirements Policy Evaluation","title":"Functional Requirements - Policy Evaluation"},{"location":"tsae1/tsae1/#task-controller-system-features","text":"","title":"Task Controller - System Features"},{"location":"tsae1/tsae1/#description-task-controller","text":"The task controller feature provides an API which is able to handle asynchronous task lists. Each task represents one single action which executes an HTTP URL. Each task has a unique id and stores its result in the distributable cache for a later processing. Task lists can be preconfigured in the repository by a name, to create a new task subset more easily from a policy or any other component (e.g., a 1 to many task mapping). The task execution is asynchronous, and the result can be queried over the task(list) id, to query the state of the processing.","title":"Description - Task Controller"},{"location":"tsae1/tsae1/#functional-requirements-task-controller","text":"Functions Cache Event Subscription Task Queue and Storage Abstraction Layer Table 6: Functional Requirements Task Controller","title":"Functional Requirements - Task Controller"},{"location":"tsae1/tsae1/#json-ld-signing-and-verification","text":"","title":"JSON-LD Signing and verification"},{"location":"tsae1/tsae1/#description-json-ld-signing-and-verification","text":"The feature provides verification and signature functionality of LD-Proofs embedded in JSON-LD files. The functionality is an internal HTTP API, but the core crypto functionality has to be provided as a separate library and SHOULD run within a secure environment.","title":"Description - JSON-LD Signing and verification"},{"location":"tsae1/tsae1/#functional-requirements-json-ld-signing-and-verification","text":"Functions Proof Chains in JSON-LD Table 7: Functional Requirements JSON-LD Signing and Verification","title":"Functional Requirements - JSON-LD Signing and verification"},{"location":"tsae1/tsae1/#trusted-caching","text":"","title":"Trusted Caching"},{"location":"tsae1/tsae1/#description-trusted-caching","text":"The trusted caching provides the functionality to store securely in memory data for identities and related information for trust evaluation.","title":"Description - Trusted Caching"},{"location":"tsae1/tsae1/#functional-requirements-trusted-caching","text":"Functions Content Access Table 8: Functional Requirements Trusted Caching","title":"Functional Requirements - Trusted Caching"},{"location":"tsae1/tsae1/#eidas-compliant-signatures","text":"","title":"eIDAS Compliant Signatures"},{"location":"tsae1/tsae1/#description-eidas-compliant-signatures","text":"To provide eIDAS compliant signatures the feature should be able to generate and validate eIDAS compliant signatures. In consideration of the different eIDAS types, legal signatures should be considered and a bridge functionality to sign the data should be implemented. A secure environment MUST be provided to store and execute the necessary functions (signature, validation) and SHOULD require at least two factor authentication.","title":"Description - eIDAS Compliant Signatures"},{"location":"tsae1/tsae1/#functional-requirements-eidas-compliant-signatures","text":"Functions eIDAS compliant Signature Creation / Validation Support for DID:EBSI encoding for Natural Persons Table 9: Functional Requirements eIDAS Compliant Signatures","title":"Functional Requirements - eIDAS Compliant Signatures"},{"location":"tsae1/tsae1/#verification","text":"","title":"Verification"},{"location":"tsae1/tsae1/#core-verification-requirements","text":"All listed verification items/criterias, must be fulfilled by a demonstration of the implementation within the provided Kubernetes environment.","title":"Core Verification Requirements"},{"location":"tsae1/tsae1/#idmtsae100051-kubernetes-deployment","text":"If the verification is related to software components, it must be deployed in a Kubernetes test cluster and the components must be deployable in a Kubernetes cluster with automated package manager deployment (e.g., Helm). Docker Compose and other local systems can be used for local development and testing, but it's NOT allowed for a final acceptance demonstration.","title":"[IDM.TSA.E1.00051] Kubernetes Deployment"},{"location":"tsae1/tsae1/#idmtsae100052-behavior-driven-design","text":"Verification of fulfillment of the requirements and characteristics MUST be done using automated tests which are part of the deliverables. They SHOULD be done by patterns of the Behavior Driven Development [BDD] using the \"Gherkin Syntax\".","title":"[IDM.TSA.E1.00052] Behavior Driven Design"},{"location":"tsae1/tsae1/#idmtsae100053-test-environment","text":"All functionalities MUST be demonstrated in a test environment within a sandbox, with the following infrastructure components: Load Balancer, e.g., HAProxy API Gateway, e.g., Kong Service Mesh, e.g., Linkerd/Istio DNS Multiple Servers Firewalls All tests MUST be passed in this test environment.","title":"[IDM.TSA.E1.00053] Test Environment"},{"location":"tsae1/tsae1/#idmtsae100054-load-tests","text":"Scalability and Performance around the high workload scenarios MUST be demonstrated, by using any kind of Load Test Framework for HTTP APIs.","title":"[IDM.TSA.E1.00054] Load Tests"},{"location":"tsae1/tsae1/#idmtsae100055-automated-integration-tests","text":"Automation Integration tests must be created, and they must be runnable by a CI job.","title":"[IDM.TSA.E1.00055] Automated Integration Tests"},{"location":"tsae1/tsae1/#acceptance-criteria","text":"","title":"Acceptance Criteria"},{"location":"tsae1/tsae1/#policy-management-module-verification","text":"","title":"Policy Management Module - Verification"},{"location":"tsae1/tsae1/#idmtsae100056-policy-bundles","text":"Policy Bundles are signed when they become in a productive state or before export. The metadata can be signed for the included files of the bundle, or the bundle itself can be signed as a compressed package.","title":"[IDM.TSA.E1.00056] Policy Bundles"},{"location":"tsae1/tsae1/#idmtsae100057-policy-import-and-export","text":"The export of a policy bundle MUST be signed with a keypair which is evaluable against the public keys registered in the DID document. Import and Exports are observable.","title":"[IDM.TSA.E1.00057] Policy Import and Export"},{"location":"tsae1/tsae1/#idmtsae100058-policy-changes-notification","text":"A notification is triggered upon every change in a policy source code or static data file.","title":"[IDM.TSA.E1.00058] Policy Changes Notification"},{"location":"tsae1/tsae1/#idmtsae100059-webhooks-for-policy-changes","text":"There is an available endpoint for client webhook subscription which takes a URL. Data payload is sent to all subscribers with relevant policy changes using the webhook URLs.","title":"[IDM.TSA.E1.00059] Webhooks for policy changes"},{"location":"tsae1/tsae1/#idmtsae100060-json-schema-validation-for-policy-output","text":"A simple JSON schema is validated on the validation endpoint. An appropriate HTTP status code is returned.","title":"[IDM.TSA.E1.00060] JSON Schema Validation for Policy Output"},{"location":"tsae1/tsae1/#idmtsae100061-fine-granular-policy-management","text":"The system allows policy management through separate GIT repositories. Separate synchronization mechanisms are in place for each GIT repository.","title":"[IDM.TSA.E1.00061] Fine granular policy management"},{"location":"tsae1/tsae1/#idmtsae100062-interface-for-export-configuration","text":"Export configurations are able to be defined in the policy management module. There is a synchronization flow in place for export configurations to make them available for execution.","title":"[IDM.TSA.E1.00062] Interface for Export Configuration"},{"location":"tsae1/tsae1/#idmtsae100063-policy-admin-api","text":"An administration API for policies is available.","title":"[IDM.TSA.E1.00063] Policy Admin API"},{"location":"tsae1/tsae1/#policy-decision-engine-verification","text":"","title":"Policy Decision Engine - Verification"},{"location":"tsae1/tsae1/#idmtsae100064-call-of-external-urls","text":"The decision engine is capable of making HTTP requests with query parameters, headers and request body for any HTTP method within the policy execution runtime.","title":"[IDM.TSA.E1.00064] Call of external URLs"},{"location":"tsae1/tsae1/#idmtsae100065-storage-extension-functions","text":"REGO extension functions are available for creating, updating and deleting data from a predefined database table/collection during policy evaluation.","title":"[IDM.TSA.E1.00065] Storage Extension Functions"},{"location":"tsae1/tsae1/#idmtsae100066-storage-implementation","text":"A storage layer can be replaced during the configuration in the deployment without any need to do code modifications. If internal storage is configured, the policy must be executable without any database deployment.","title":"[IDM.TSA.E1.00066] Storage Implementation"},{"location":"tsae1/tsae1/#idmtsae100067-train-validation-verification","text":"The service is able to use the components provided by the TRAIN lot to cross check the DID trust during the verification of credentials.","title":"[IDM.TSA.E1.00067] TRAIN validation &amp; verification"},{"location":"tsae1/tsae1/#idmtsae100068-cli-tools-command-line-for-common-operations","text":"CLI tools for the common operations, performed by the TSA HTTP API are created.","title":"[IDM.TSA.E1.00068] CLI tools (command-line) for common operations"},{"location":"tsae1/tsae1/#task-controller-verification","text":"","title":"Task Controller - Verification"},{"location":"tsae1/tsae1/#idmtsae100069-cache-event-subscription","text":"After an update event in the distributable cache, a task must be created as pre-configured (or dynamically by policy).","title":"[IDM.TSA.E1.00069] Cache Event Subscription"},{"location":"tsae1/tsae1/#idmtsae100070-task-queue-and-storage-abstraction-layer","text":"An abstraction layer is implemented for the Queue and Storage interfaces in the Task Controller.","title":"[IDM.TSA.E1.00070] Task Queue and Storage Abstraction Layer"},{"location":"tsae1/tsae1/#json-ld-signatures-and-validations-verification","text":"","title":"JSON-LD signatures and validations - Verification"},{"location":"tsae1/tsae1/#idmtsae100071-proof-chains-in-json-ld","text":"JSON-LD proof chains are supported to link multiple entities to the same data, when proof sequences are required.","title":"[IDM.TSA.E1.00071] Proof Chains in JSON-LD"},{"location":"tsae1/tsae1/#distributable-cache-verification","text":"","title":"Distributable Cache - Verification"},{"location":"tsae1/tsae1/#idmtsae100072-content-access","text":"When accessing a content with given DID, namespace and scope, the result is a flat JSON file. Duplicate entries are handled during the flattening of multiple documents.","title":"[IDM.TSA.E1.00072] Content Access"},{"location":"tsae1/tsae1/#eidas-verification","text":"","title":"eIDAS - Verification"},{"location":"tsae1/tsae1/#idmtsae100073-eidas-compliant-signature-creation-validation","text":"Signatures are generated/verified in compliance with eIDAS. Basic, advanced and qualified signature types are supported.","title":"[IDM.TSA.E1.00073] eIDAS compliant Signature Creation / Validation"},{"location":"tsae1/tsae1/#idmtsae100074-support-for-didebsi-encoding-for-natural-persons","text":"Public key encoding in DID document for Natural Persons according to the EBSI DID Method is supported.","title":"[IDM.TSA.E1.00074] Support for DID:EBSI encoding for Natural Persons"},{"location":"tsae1/tsae1/#support-for-kubernetes","text":"","title":"Support for Kubernetes"},{"location":"tsae1/tsae1/#idmtsae100075-eventing","text":"All eventings must be demonstrated on basis of cloud events specifications together with the kNative [9] broker in a Kubernetes environment.","title":"[IDM.TSA.E1.00075] Eventing"},{"location":"tsae1/tsae1/#9-httpsknativedevdocseventing","text":"","title":"[9] [https://knative.dev/docs/eventing/]"},{"location":"tsae1/tsae1/#idmtsae100076-config-map-support","text":"Each service must be demonstrated up and running in Kubernetes, configured by config maps.","title":"[IDM.TSA.E1.00076] Config Map Support"},{"location":"tsae1/tsae1/#idmtsae100077-helm-installation","text":"The service installation MUST be demonstrated during HELM install.","title":"[IDM.TSA.E1.00077] Helm Installation"},{"location":"tsae1/tsae1/#idmtsae100078-argocd-integration","text":"The helm chart MUST be able to install inside of ArgoCD. This includes the usage of the postgres hooks [10] and the providing of usable values.yaml(s) for all developed services.","title":"[IDM.TSA.E1.00078] ArgoCD Integration"},{"location":"tsae1/tsae1/#10-httpsgitlabcomgaia-xdata-infrastructure-federation-servicesgxfs-integration-treemainhelmchartspostgresql-hook","text":"","title":"[10] [https://gitlab.com/gaia-x/data-infrastructure-federation-services/gxfs-integration/-/tree/main/helm/charts/postgresql-hook]"},{"location":"tsae1/tsae1/#idmtsae100079-scs-environment","text":"All HELM installations MUST run on SCS (Sovereign Cloud Stack). The final acceptance demonstration cannot be realized on azure, google cloud etc.","title":"[IDM.TSA.E1.00079] SCS Environment"},{"location":"tsae1/tsae1/#appendix-a-glossary","text":"For the glossary refer to IDM.AO Glossary/Terminology [IDM.AO]","title":"Appendix A: Glossary"},{"location":"tsae1/tsae1/#appendix-b-architecture","text":"","title":"Appendix B: Architecture"}]}